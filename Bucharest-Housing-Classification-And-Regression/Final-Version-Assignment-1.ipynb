{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X_train, X_test, preprocessing_type = \"normalization\"):\n",
    "    \n",
    "    if preprocessing_type == \"normalization\":\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "    scaler.fit(X_train) \n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_test = scaler.transform(X_test)  \n",
    "    \n",
    "    return X_train, X_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_correlation_matrix(data):\n",
    "    \n",
    "    corr_matrix = data.corr()\n",
    "    \n",
    "    display(corr_matrix)\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=np.bool))\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=1, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_correlated_features(data, threshold = 0.99):\n",
    "\n",
    "    corr_matrix = data.corr().abs()\n",
    "\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    print(\"Features to drop for Threshold \" + str(threshold), to_drop)\n",
    "    \n",
    "    data.drop(data[to_drop], axis = 1, inplace = True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_importance(model, features, labels):\n",
    "    print(\"Features: \", features.columns.values)\n",
    "    importance = PermutationImportance(model).fit(features, y_test)\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__ (self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, m_hidden_layers, n_input, n_hidden, n_output, network_type = \"classification\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.m_hidden_layers = m_hidden_layers\n",
    "        \n",
    "        self.input_layer = nn.Linear(n_input, n_hidden)\n",
    "    \n",
    "        self.hidden_layer = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.output_layer = nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.bn  = nn.BatchNorm1d(n_hidden)\n",
    "        \n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "        assert network_type in [\"classification\", \"regression\"]\n",
    "        \n",
    "        self.network_type = network_type\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Use dropout only for regression\n",
    "        \n",
    "        if self.network_type == \"regression\":\n",
    "            \n",
    "            x = self.dropout(self.activation(self.input_layer(x)))\n",
    "\n",
    "            for step in range(self.m_hidden_layers):\n",
    "                x = self.dropout(self.activation(self.bn(self.hidden_layer(x))))\n",
    "\n",
    "            x = self.output_layer(x)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            x = self.activation(self.input_layer(x))\n",
    "\n",
    "            for step in range(self.m_hidden_layers):\n",
    "                x = self.activation(self.bn(self.hidden_layer(x)))\n",
    "\n",
    "            x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    def __init__(self):\n",
    "        self.coef = 0\n",
    "\n",
    "    def loss(self, coef, samples, labels):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        limit = [-np.inf] + list(np.sort(coef)) + [np.inf]\n",
    "\n",
    "        opt_labels = pd.cut(samples, limit, labels = [0, 1, 2, 3, 4])\n",
    "\n",
    "        return -accuracy_score(opt_labels, labels) \n",
    "\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self.loss, samples = X, labels=y)\n",
    "        \n",
    "        initial_coef = [1, 2, 3, 4]\n",
    "\n",
    "        self.coef = minimize(loss_partial, initial_coef, method='Nelder-Mead')\n",
    "        \n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        \n",
    "        limit = [-np.inf] + list(np.sort(self.coef['x'])) + [np.inf]\n",
    "\n",
    "        return pd.cut(X, limit, labels = [0, 1, 2, 3, 4])\n",
    "    \n",
    "    def coefficients(self):\n",
    "        return self.coef['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLELoss(y_true, y_hat):\n",
    "    return torch.abs(torch.sqrt(torch.mean((torch.log(y_true + 1) - torch.log(y_hat.float() + 1)) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLELoss_for_numpy(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "    \n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset\n",
    "- Will separate the labels from features\n",
    "- And will map the labels from (1 - 5) to (0 - 4) for convenience in the softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr Camere</th>\n",
       "      <th>Suprafata</th>\n",
       "      <th>Etaj</th>\n",
       "      <th>Total Etaje</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scor</th>\n",
       "      <th>Pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>108.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63.52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>84900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>62.00</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>132.00</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>349990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>49.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>36500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>92.00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>68.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>110.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nr Camere  Suprafata  Etaj  Total Etaje  Sector  Scor    Pret\n",
       "0          4     108.00     2            3       4     5   83000\n",
       "1          1      41.00     1            8       1     1   39900\n",
       "2          3      63.52     1            3       2     3   84900\n",
       "3          1      33.00     3           10       5     1   45500\n",
       "4          2      62.00     5            9       5     5   54900\n",
       "5          3     132.00     2            6       1     2  349990\n",
       "6          2      49.00     6            6       6     4   36500\n",
       "7          3      92.00     4            8       2     2  119000\n",
       "8          3      68.00     3            5       4     5   67500\n",
       "9          3     110.00     1            2       1     1  133000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Bucharest_HousePriceDataset.csv\")\n",
    "\n",
    "display(data.head(n = 10))\n",
    "\n",
    "features = data.drop(['Scor'], axis = 1, inplace = False)\n",
    "\n",
    "labels   = data[\"Scor\"].apply(lambda x : x - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the correlation matrix \n",
    "- Drop higgly correlated features (if necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr Camere</th>\n",
       "      <th>Suprafata</th>\n",
       "      <th>Etaj</th>\n",
       "      <th>Total Etaje</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scor</th>\n",
       "      <th>Pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nr Camere</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807278</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>-0.012815</td>\n",
       "      <td>-0.183737</td>\n",
       "      <td>-0.215591</td>\n",
       "      <td>0.635789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suprafata</th>\n",
       "      <td>0.807278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060527</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>-0.240274</td>\n",
       "      <td>-0.299838</td>\n",
       "      <td>0.807414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etaj</th>\n",
       "      <td>0.066427</td>\n",
       "      <td>0.060527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.559217</td>\n",
       "      <td>0.061581</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.038719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Etaje</th>\n",
       "      <td>-0.012815</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>0.559217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103467</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.006063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sector</th>\n",
       "      <td>-0.183737</td>\n",
       "      <td>-0.240274</td>\n",
       "      <td>0.061581</td>\n",
       "      <td>0.103467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577602</td>\n",
       "      <td>-0.409052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scor</th>\n",
       "      <td>-0.215591</td>\n",
       "      <td>-0.299838</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.577602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.531826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pret</th>\n",
       "      <td>0.635789</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.038719</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>-0.409052</td>\n",
       "      <td>-0.531826</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Nr Camere  Suprafata      Etaj  Total Etaje    Sector      Scor  \\\n",
       "Nr Camere     1.000000   0.807278  0.066427    -0.012815 -0.183737 -0.215591   \n",
       "Suprafata     0.807278   1.000000  0.060527    -0.041367 -0.240274 -0.299838   \n",
       "Etaj          0.066427   0.060527  1.000000     0.559217  0.061581  0.027381   \n",
       "Total Etaje  -0.012815  -0.041367  0.559217     1.000000  0.103467  0.036039   \n",
       "Sector       -0.183737  -0.240274  0.061581     0.103467  1.000000  0.577602   \n",
       "Scor         -0.215591  -0.299838  0.027381     0.036039  0.577602  1.000000   \n",
       "Pret          0.635789   0.807414  0.038719     0.006063 -0.409052 -0.531826   \n",
       "\n",
       "                 Pret  \n",
       "Nr Camere    0.635789  \n",
       "Suprafata    0.807414  \n",
       "Etaj         0.038719  \n",
       "Total Etaje  0.006063  \n",
       "Sector      -0.409052  \n",
       "Scor        -0.531826  \n",
       "Pret         1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_correlation_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to drop for Threshold 0.99 []\n"
     ]
    }
   ],
   "source": [
    "data = drop_highly_correlated_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data Methodology\n",
    "- First step: Will get a hold out set (train set - test set: 0.8 - 0.2)\n",
    "- Second step: Will use a cross-validation with 5 fold (4 training fold - 1 validation fold)\n",
    "\n",
    "- As note: This Methodology is typically used in deep learning for large datasets, this concludes that for our 3529 samples may not be fitted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels.values, train_size = 0.9, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets get a baseline model without cross-validation\n",
    "\n",
    "- To get a sense of the problem will display the accuracy and the feature importance of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Random Forest:  0.7818696883852692\n",
      "Features:  ['Nr Camere' 'Suprafata' 'Etaj' 'Total Etaje' 'Sector' 'Pret']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4448\n",
       "                \n",
       "                    &plusmn; 0.0424\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.92%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2425\n",
       "                \n",
       "                    &plusmn; 0.0223\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0555\n",
       "                \n",
       "                    &plusmn; 0.0257\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0544\n",
       "                \n",
       "                    &plusmn; 0.0181\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0249\n",
       "                \n",
       "                    &plusmn; 0.0264\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0057\n",
       "                \n",
       "                    &plusmn; 0.0238\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print(\"Baseline Random Forest: \", accuracy)\n",
    "\n",
    "importance = display_feature_importance(model, X_test, y_test)\n",
    "\n",
    "eli5.show_weights(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lets do the same for a neural network from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Neural Network:  0.24929178470254956\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes = (10, 10, 10, 10))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print(\"Baseline Neural Network: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Something went wrong...\n",
    "- As you can see the results are quite disappointing, and the reason for this difference in each model accuracy is that tree base models (such as Random Forrest) are invariant to features scaling, but the neural networks are not\n",
    "\n",
    "# Lets use a mean normalization over data and retry the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3176\n",
      "353\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, _ = preprocessing(X_train, X_test)\n",
    "print(len(X_train_scaled))\n",
    "print(len(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Neural Network:  0.7563739376770539\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes = (12, 12, 12, 12, 12), max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print(\"Baseline Neural Network: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's much better, now lets do that in Pytorch\n",
    "- But now with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 0\n",
      "Epoch: 1/100..  Training Loss: 1.076..  Test Loss: 0.804..  Test Accuracy: 0.692\n",
      "Epoch: 2/100..  Training Loss: 0.849..  Test Loss: 0.735..  Test Accuracy: 0.686\n",
      "Epoch: 3/100..  Training Loss: 0.792..  Test Loss: 0.652..  Test Accuracy: 0.728\n",
      "Epoch: 4/100..  Training Loss: 0.772..  Test Loss: 0.600..  Test Accuracy: 0.729\n",
      "Epoch: 5/100..  Training Loss: 0.768..  Test Loss: 0.677..  Test Accuracy: 0.715\n",
      "Epoch: 6/100..  Training Loss: 0.764..  Test Loss: 0.630..  Test Accuracy: 0.715\n",
      "Epoch: 7/100..  Training Loss: 0.753..  Test Loss: 0.617..  Test Accuracy: 0.738\n",
      "Epoch: 8/100..  Training Loss: 0.717..  Test Loss: 0.592..  Test Accuracy: 0.729\n",
      "Epoch: 9/100..  Training Loss: 0.702..  Test Loss: 0.573..  Test Accuracy: 0.741\n",
      "Epoch: 10/100..  Training Loss: 0.741..  Test Loss: 0.590..  Test Accuracy: 0.750\n",
      "Epoch: 11/100..  Training Loss: 0.696..  Test Loss: 0.599..  Test Accuracy: 0.707\n",
      "Epoch: 12/100..  Training Loss: 0.671..  Test Loss: 0.604..  Test Accuracy: 0.720\n",
      "Epoch: 13/100..  Training Loss: 0.677..  Test Loss: 0.572..  Test Accuracy: 0.741\n",
      "Epoch: 14/100..  Training Loss: 0.666..  Test Loss: 0.568..  Test Accuracy: 0.739\n",
      "Epoch: 15/100..  Training Loss: 0.688..  Test Loss: 0.565..  Test Accuracy: 0.731\n",
      "Epoch: 16/100..  Training Loss: 0.689..  Test Loss: 0.565..  Test Accuracy: 0.737\n",
      "Epoch: 17/100..  Training Loss: 0.686..  Test Loss: 0.565..  Test Accuracy: 0.756\n",
      "Epoch: 18/100..  Training Loss: 0.650..  Test Loss: 0.561..  Test Accuracy: 0.737\n",
      "Epoch: 19/100..  Training Loss: 0.660..  Test Loss: 0.555..  Test Accuracy: 0.752\n",
      "Epoch: 20/100..  Training Loss: 0.681..  Test Loss: 0.582..  Test Accuracy: 0.736\n",
      "Epoch: 21/100..  Training Loss: 0.650..  Test Loss: 0.600..  Test Accuracy: 0.743\n",
      "Epoch: 22/100..  Training Loss: 0.646..  Test Loss: 0.547..  Test Accuracy: 0.755\n",
      "Epoch: 23/100..  Training Loss: 0.671..  Test Loss: 0.564..  Test Accuracy: 0.726\n",
      "Epoch: 24/100..  Training Loss: 0.665..  Test Loss: 0.573..  Test Accuracy: 0.733\n",
      "Epoch: 25/100..  Training Loss: 0.655..  Test Loss: 0.552..  Test Accuracy: 0.738\n",
      "Epoch: 26/100..  Training Loss: 0.624..  Test Loss: 0.529..  Test Accuracy: 0.765\n",
      "Epoch: 27/100..  Training Loss: 0.656..  Test Loss: 0.553..  Test Accuracy: 0.736\n",
      "Epoch: 28/100..  Training Loss: 0.620..  Test Loss: 0.589..  Test Accuracy: 0.728\n",
      "Epoch: 29/100..  Training Loss: 0.634..  Test Loss: 0.553..  Test Accuracy: 0.743\n",
      "Epoch: 30/100..  Training Loss: 0.651..  Test Loss: 0.579..  Test Accuracy: 0.740\n",
      "Epoch: 31/100..  Training Loss: 0.630..  Test Loss: 0.555..  Test Accuracy: 0.727\n",
      "Epoch: 32/100..  Training Loss: 0.643..  Test Loss: 0.550..  Test Accuracy: 0.761\n",
      "Epoch: 33/100..  Training Loss: 0.644..  Test Loss: 0.580..  Test Accuracy: 0.716\n",
      "Epoch: 34/100..  Training Loss: 0.631..  Test Loss: 0.549..  Test Accuracy: 0.730\n",
      "Epoch: 35/100..  Training Loss: 0.633..  Test Loss: 0.536..  Test Accuracy: 0.749\n",
      "Epoch: 36/100..  Training Loss: 0.636..  Test Loss: 0.557..  Test Accuracy: 0.750\n",
      "Epoch: 37/100..  Training Loss: 0.608..  Test Loss: 0.540..  Test Accuracy: 0.738\n",
      "Epoch: 38/100..  Training Loss: 0.641..  Test Loss: 0.560..  Test Accuracy: 0.740\n",
      "Epoch: 39/100..  Training Loss: 0.637..  Test Loss: 0.561..  Test Accuracy: 0.737\n",
      "Epoch: 40/100..  Training Loss: 0.607..  Test Loss: 0.570..  Test Accuracy: 0.726\n",
      "Epoch: 41/100..  Training Loss: 0.625..  Test Loss: 0.548..  Test Accuracy: 0.741\n",
      "Epoch: 42/100..  Training Loss: 0.649..  Test Loss: 0.543..  Test Accuracy: 0.740\n",
      "Epoch: 43/100..  Training Loss: 0.624..  Test Loss: 0.536..  Test Accuracy: 0.764\n",
      "Epoch: 44/100..  Training Loss: 0.609..  Test Loss: 0.540..  Test Accuracy: 0.740\n",
      "Epoch: 45/100..  Training Loss: 0.640..  Test Loss: 0.525..  Test Accuracy: 0.769\n",
      "Epoch: 46/100..  Training Loss: 0.611..  Test Loss: 0.552..  Test Accuracy: 0.748\n",
      "Epoch: 47/100..  Training Loss: 0.627..  Test Loss: 0.578..  Test Accuracy: 0.738\n",
      "Epoch: 48/100..  Training Loss: 0.624..  Test Loss: 0.568..  Test Accuracy: 0.737\n",
      "Epoch: 49/100..  Training Loss: 0.624..  Test Loss: 0.576..  Test Accuracy: 0.704\n",
      "Epoch: 50/100..  Training Loss: 0.617..  Test Loss: 0.528..  Test Accuracy: 0.745\n",
      "Epoch: 51/100..  Training Loss: 0.625..  Test Loss: 0.538..  Test Accuracy: 0.738\n",
      "Epoch: 52/100..  Training Loss: 0.620..  Test Loss: 0.519..  Test Accuracy: 0.747\n",
      "Epoch: 53/100..  Training Loss: 0.611..  Test Loss: 0.605..  Test Accuracy: 0.701\n",
      "Epoch: 54/100..  Training Loss: 0.613..  Test Loss: 0.545..  Test Accuracy: 0.740\n",
      "Epoch: 55/100..  Training Loss: 0.616..  Test Loss: 0.530..  Test Accuracy: 0.735\n",
      "Epoch: 56/100..  Training Loss: 0.604..  Test Loss: 0.550..  Test Accuracy: 0.730\n",
      "Epoch: 57/100..  Training Loss: 0.625..  Test Loss: 0.534..  Test Accuracy: 0.759\n",
      "Epoch: 58/100..  Training Loss: 0.620..  Test Loss: 0.525..  Test Accuracy: 0.765\n",
      "Epoch: 59/100..  Training Loss: 0.608..  Test Loss: 0.539..  Test Accuracy: 0.739\n",
      "Epoch: 60/100..  Training Loss: 0.608..  Test Loss: 0.529..  Test Accuracy: 0.749\n",
      "Epoch: 61/100..  Training Loss: 0.606..  Test Loss: 0.533..  Test Accuracy: 0.740\n",
      "Epoch: 62/100..  Training Loss: 0.638..  Test Loss: 0.567..  Test Accuracy: 0.734\n",
      "Epoch: 63/100..  Training Loss: 0.616..  Test Loss: 0.584..  Test Accuracy: 0.741\n",
      "Epoch: 64/100..  Training Loss: 0.621..  Test Loss: 0.538..  Test Accuracy: 0.749\n",
      "Epoch: 65/100..  Training Loss: 0.617..  Test Loss: 0.542..  Test Accuracy: 0.754\n",
      "Epoch: 66/100..  Training Loss: 0.593..  Test Loss: 0.527..  Test Accuracy: 0.749\n",
      "Epoch: 67/100..  Training Loss: 0.616..  Test Loss: 0.549..  Test Accuracy: 0.742\n",
      "Epoch: 68/100..  Training Loss: 0.626..  Test Loss: 0.532..  Test Accuracy: 0.731\n",
      "Epoch: 69/100..  Training Loss: 0.605..  Test Loss: 0.522..  Test Accuracy: 0.736\n",
      "Epoch: 70/100..  Training Loss: 0.618..  Test Loss: 0.549..  Test Accuracy: 0.737\n",
      "Epoch: 71/100..  Training Loss: 0.613..  Test Loss: 0.528..  Test Accuracy: 0.757\n",
      "Epoch: 72/100..  Training Loss: 0.608..  Test Loss: 0.576..  Test Accuracy: 0.745\n",
      "Epoch: 73/100..  Training Loss: 0.608..  Test Loss: 0.529..  Test Accuracy: 0.731\n",
      "Epoch: 74/100..  Training Loss: 0.612..  Test Loss: 0.565..  Test Accuracy: 0.752\n",
      "Epoch: 75/100..  Training Loss: 0.606..  Test Loss: 0.549..  Test Accuracy: 0.744\n",
      "Epoch: 76/100..  Training Loss: 0.612..  Test Loss: 0.590..  Test Accuracy: 0.716\n",
      "Epoch: 77/100..  Training Loss: 0.620..  Test Loss: 0.530..  Test Accuracy: 0.755\n",
      "Epoch: 78/100..  Training Loss: 0.612..  Test Loss: 0.570..  Test Accuracy: 0.719\n",
      "Epoch: 79/100..  Training Loss: 0.596..  Test Loss: 0.558..  Test Accuracy: 0.712\n",
      "Epoch: 80/100..  Training Loss: 0.602..  Test Loss: 0.536..  Test Accuracy: 0.746\n",
      "Epoch: 81/100..  Training Loss: 0.603..  Test Loss: 0.526..  Test Accuracy: 0.750\n",
      "Epoch: 82/100..  Training Loss: 0.623..  Test Loss: 0.542..  Test Accuracy: 0.734\n",
      "Epoch: 83/100..  Training Loss: 0.600..  Test Loss: 0.549..  Test Accuracy: 0.745\n",
      "Epoch: 84/100..  Training Loss: 0.624..  Test Loss: 0.542..  Test Accuracy: 0.737\n",
      "Epoch: 85/100..  Training Loss: 0.598..  Test Loss: 0.527..  Test Accuracy: 0.738\n",
      "Epoch: 86/100..  Training Loss: 0.586..  Test Loss: 0.531..  Test Accuracy: 0.738\n",
      "Epoch: 87/100..  Training Loss: 0.608..  Test Loss: 0.520..  Test Accuracy: 0.762\n",
      "Epoch: 88/100..  Training Loss: 0.592..  Test Loss: 0.529..  Test Accuracy: 0.748\n",
      "Epoch: 89/100..  Training Loss: 0.631..  Test Loss: 0.530..  Test Accuracy: 0.754\n",
      "Epoch: 90/100..  Training Loss: 0.582..  Test Loss: 0.596..  Test Accuracy: 0.725\n",
      "Epoch: 91/100..  Training Loss: 0.610..  Test Loss: 0.567..  Test Accuracy: 0.733\n",
      "Epoch: 92/100..  Training Loss: 0.596..  Test Loss: 0.533..  Test Accuracy: 0.747\n",
      "Epoch: 93/100..  Training Loss: 0.616..  Test Loss: 0.546..  Test Accuracy: 0.754\n",
      "Epoch: 94/100..  Training Loss: 0.604..  Test Loss: 0.539..  Test Accuracy: 0.745\n",
      "Epoch: 95/100..  Training Loss: 0.609..  Test Loss: 0.548..  Test Accuracy: 0.732\n",
      "Epoch: 96/100..  Training Loss: 0.596..  Test Loss: 0.523..  Test Accuracy: 0.751\n",
      "Epoch: 97/100..  Training Loss: 0.590..  Test Loss: 0.548..  Test Accuracy: 0.717\n",
      "Epoch: 98/100..  Training Loss: 0.609..  Test Loss: 0.542..  Test Accuracy: 0.730\n",
      "Epoch: 99/100..  Training Loss: 0.588..  Test Loss: 0.551..  Test Accuracy: 0.727\n",
      "Epoch: 100/100..  Training Loss: 0.600..  Test Loss: 0.530..  Test Accuracy: 0.755\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd1hU19aH380w9N4FVBCx0FTEFntJMUZNLFHTq0luervxJrnpuTc3yc1nzDU9mmKiKSbRGCMpGntDxYYoiiBFBZTeB873x2ZggKGIoA7Z7/P4DHPOnnP2jDO/vfZaa68tNE1DoVAoFJaP1cXugEKhUCjaByXoCoVC0UlQgq5QKBSdBCXoCoVC0UlQgq5QKBSdBCXoCoVC0UloUdCFEIuEEFlCiANNnO8jhNgqhCgXQjzR/l1UKBQKRWtojYX+KXBVM+fPAg8Bb7ZHhxQKhULRNqxbaqBp2gYhRFAz57OALCHEpHO5sZeXlxYU1ORlFQqFQmGGXbt25Wia5m3uXIuC3lEEBQURFxd3sW6vUCgUFokQIrWpcxc0KCqEmCuEiBNCxGVnZ1/IWysUCkWn54IKuqZpH2qaFqNpWoy3t9kZg0KhUCjaiEpbVCgUik5Ciz50IcRSYAzgJYRIB54H9ACapr0vhPAD4gAXoFoI8QgQpmlaQYf1WqFQKBSNaE2Wy5wWzp8CAtutRwqFQqFoE8rlolAoFJ0EJegKhULRSbA4QT98qpD//nqYM0XlF7srCoVCcUlhcYKenF3EO2uPklWoBF2hsCTOnDlD//796d+/P35+fgQEBNQ+r6ioaNU1br/9dg4fPtxsm4ULF/Lll1+2R5cZMWIE8fHx7XKtC8FFWynaVuxsdACUVlZd5J4oFIpzwdPTs1YcX3jhBZycnHjiifr1/DRNQ9M0rKzM25qLFy9u8T7333//+XfWQrE4C93OWgp6mRJ0haJTcPToUSIiIrj33nuJjo7m5MmTzJ07l5iYGMLDw3nppZdq2xotZoPBgJubG/PmzaNfv34MGzaMrKwsAJ599lnmz59f237evHkMHjyY3r17s2XLFgCKi4uZPn06/fr1Y86cOcTExLRoiS9ZsoTIyEgiIiJ4+umnATAYDNx88821xxcsWADA//3f/xEWFka/fv246aab2v0zawqLs9DtbZSgKxTny4s/HSQhs32XioT5u/D85PA2vTYhIYHFixfz/vvvA/Daa6/h4eGBwWBg7NixzJgxg7CwsHqvyc/PZ/To0bz22ms89thjLFq0iHnz5jW6tqZp7Nixg5UrV/LSSy+xZs0a3nnnHfz8/Fi+fDl79+4lOjq62f6lp6fz7LPPEhcXh6urKxMmTGDVqlV4e3uTk5PD/v37AcjLywPg9ddfJzU1FRsbm9pjFwKLs9Dt9TUul4rqi9wThULRXoSEhDBo0KDa50uXLiU6Opro6GgOHTpEQkJCo9fY29szceJEAAYOHEhKSorZa0+bNq1Rm02bNjF79mwA+vXrR3h48wPR9u3bGTduHF5eXuj1em644QY2bNhAz549OXz4MA8//DCxsbG4uroCEB4ezk033cSXX36JXq8/p8/ifLA8C12vfOgKxfnSVku6o3B0dKz9OykpibfffpsdO3bg5ubGTTfdRFlZWaPX2NjY1P6t0+kwGAxmr21ra9uojaZp59S/ptp7enqyb98+fvnlFxYsWMDy5cv58MMPiY2NZf369axYsYJXXnmFAwcOoNPpzumebcHiLHQ7G9ll5XJRKDonBQUFODs74+LiwsmTJ4mNjW33e4wYMYJvvvkGgP3795udAZgydOhQ1q1bx5kzZzAYDCxbtozRo0eTnZ2NpmnMnDmTF198kd27d1NVVUV6ejrjxo3jjTfeIDs7m5KSknZ/D+awOAvdTq986ApFZyY6OpqwsDAiIiLo0aMHw4cPb/d7PPjgg9xyyy1ERUURHR1NRERErbvEHIGBgbz00kuMGTMGTdOYPHkykyZNYvfu3dx5551omoYQgv/85z8YDAZuuOEGCgsLqa6u5qmnnsLZ2bnd34M5xLlOPdqLmJgYrS0bXFRWVRP6zC88fnkvHhwf2gE9UygUnR2DwYDBYMDOzo6kpCSuuOIKkpKSsLa+9G1cIcQuTdNizJ279HvfAL3OCmsroXzoCoWizRQVFTF+/HgMBgOapvHBBx9YhJi3hEW+A3u9jrJKleWiUCjahpubG7t27brY3Wh3LC4oCmCr1ykLXaFQKBpgkYJub2OlgqIKhULRAMsUdL2O0gol6AqFQmGK5Qq6stAVCoWiHhYp6LZ6nXK5KBQWxpgxYxotEpo/fz5/+9vfmn2dk5MTAJmZmcyYMaPJa7eUBj1//vx6C3yuvvrqdqmz8sILL/Dmm2+e93XaA4sUdHsl6AqFxTFnzhyWLVtW79iyZcuYM6fZbYtr8ff357vvvmvz/RsK+urVq3Fzc2vz9S5FLFbQlctFobAsZsyYwapVqygvl5vTpKSkkJmZyYgRI2rzwqOjo4mMjGTFihWNXp+SkkJERAQApaWlzJ49m6ioKGbNmkVpaWltu/vuu6+29O7zzz8PwIIFC8jMzGTs2LGMHTsWgKCgIHJycgB46623iIiIICIiorb0bkpKCn379uXuu+8mPDycK664ot59zBEfH8/QoUOJioriuuuuIzc3t/b+YWFhREVF1RYFW79+fe0GHwMGDKCwsLDNn60Ry8xDt1GCrlCcF7/Mg1P72/eafpEw8bUmT3t6ejJ48GDWrFnD1KlTWbZsGbNmzUIIgZ2dHT/88AMuLi7k5OQwdOhQpkyZghDC7LXee+89HBwc2LdvH/v27atX/vbVV1/Fw8ODqqoqxo8fz759+3jooYd46623WLduHV5eXvWutWvXLhYvXsz27dvRNI0hQ4YwevRo3N3dSUpKYunSpXz00Udcf/31LF++vNn65rfccgvvvPMOo0eP5rnnnuPFF19k/vz5vPbaaxw/fhxbW9taN8+bb77JwoULGT58OEVFRdjZ2Z3Lp20Wi7TQ7fRWamGRQmGBmLpdTN0tmqbx9NNPExUVxYQJE8jIyOD06dNNXmfDhg21whoVFUVUVFTtuW+++Ybo6GgGDBjAwYMHWyy8tWnTJq677jocHR1xcnJi2rRpbNy4EYDg4GD69+8PNF+iF2R99ry8PEaPHg3ArbfeyoYNG2r7eOONN7JkyZLaFanDhw/nscceY8GCBeTl5bXLSlWLtNDt9DrKVNqiQtF2mrGkO5Jrr72Wxx57jN27d1NaWlprWX/55ZdkZ2eza9cu9Ho9QUFBZkvmmmLOej9+/DhvvvkmO3fuxN3dndtuu63F6zRXz8pYehdk+d2WXC5N8fPPP7NhwwZWrlzJyy+/zMGDB5k3bx6TJk1i9erVDB06lN9//50+ffq06fpGLNJCVz50hcIycXJyYsyYMdxxxx31gqH5+fn4+Pig1+tZt24dqampzV5n1KhRtRtBHzhwgH379gGy9K6joyOurq6cPn2aX375pfY1zs7OZv3Uo0aN4scff6SkpITi4mJ++OEHRo4cec7vzdXVFXd391rr/osvvmD06NFUV1eTlpbG2LFjef3118nLy6OoqIhjx44RGRnJU089RUxMDImJied8z4ZYpIVur9dhqNaorKpGr7PIMUmh+MsyZ84cpk2bVi/j5cYbb2Ty5MnExMTQv3//Fi3V++67j9tvv52oqCj69+/P4MGDAbn70IABAwgPD29Uenfu3LlMnDiRLl26sG7dutrj0dHR3HbbbbXXuOuuuxgwYECz7pWm+Oyzz7j33nspKSmhR48eLF68mKqqKm666Sby8/PRNI1HH30UNzc3/vnPf7Ju3Tp0Oh1hYWG1uy+dDxZXPhfg443JvPLzIfa/cAXOdhdueyeFQqG42DRXPrdF81YIsUgIkSWEONDEeSGEWCCEOCqE2CeEaH631XbAVm1Dp1AoFI1ojb/iU+CqZs5PBEJr/s0F3jv/bjWPcV/RMrVRtEKhUNTSoqBrmrYBONtMk6nA55pkG+AmhOjSXh00h9ooWqFQKBrTHhHFACDN5Hl6zbFGCCHmCiHihBBx2dnZbb6hfc1G0UrQFQqFoo72EHRzS7nMRlo1TftQ07QYTdNivL2923xDO2u1UbRCoVA0pD0EPR3oavI8EMhsh+s2iZ2NcrkoFApFQ9pD0FcCt9RkuwwF8jVNO9kO122SuqCoEnSFQqEw0uLCIiHEUmAM4CWESAeeB/QAmqa9D6wGrgaOAiXA7R3VWSMqKKpQKBSNaVHQNU1rtlixJlcm3d9uPWoFdkYLXRXoUigUilosct28stAVCoWiMRYp6HY1aYsqy0WhUCjqsEhBt9FZYSWgVAVFFQqFohaLFHQhhCqhq1AoFA2wSEGHmk0ulKArFApFLRYt6MpCVygUijosVtDtbZSFrlAoFKZYrqDrdSooqlAoFCZYrKDb6a3UwiKFQqEwwYIFXfnQFQqFwhSLFXR7leWiUCgU9bBcQbdRFrpCoVCYYrGCbmetLHSFQqEwxWIF3d5GZbkoFAqFKRYr6HKlqMpyUSgUCiMWK+j2eh0VVdUYqpSoKxQKBViyoBtL6BqUoCsUCgVYsKDX7Vqk/OgKhUIBnUDQVWBUoVAoJBYr6PbKQlcoFIp6WLygq8VFCoVCIbFYQa/zoaugqEKhUIAFC7oxy0VZ6AqFQiGxWEFXQVGFQqGoj8UKugqKKhQKRX0sVtBVHrpCoVDUp1WCLoS4SghxWAhxVAgxz8z57kKIP4QQ+4QQfwohAtu/q/VRWS4KhUJRnxYFXQihAxYCE4EwYI4QIqxBszeBzzVNiwJeAv7d3h1tiL2NEnSFQqEwpTUW+mDgqKZpyZqmVQDLgKkN2oQBf9T8vc7M+XbH1rqmlosKiioUCgXQOkEPANJMnqfXHDNlLzC95u/rAGchhOf5d69phBDY6a2Uha5QKBQ1tEbQhZljWoPnTwCjhRB7gNFABmBodCEh5goh4oQQcdnZ2efc2YbYq5roCoVCUUtrBD0d6GryPBDING2gaVqmpmnTNE0bADxTcyy/4YU0TftQ07QYTdNivL29z6PbEnu92ldUoVAojLRG0HcCoUKIYCGEDTAbWGnaQAjhJYQwXusfwKL27aZ57NRG0QqFQlFLi4KuaZoBeACIBQ4B32iadlAI8ZIQYkpNszHAYSHEEcAXeLWD+lsPe71OBUUVCoWiBuvWNNI0bTWwusGx50z+/g74rn271jJ2eh1lBiXoCoVCARa8UhRqfOjKQlcoFArAwgXdTq+jVGW5KBQKBWDhgm5vo1O1XBQKhaIGixZ0O2sr5XJRKBSKGixa0O1tVFBUoVAojFi2oKugqEKhUNRi0YJup9dRbqimurphJQKFQqH462Hxgg4ot4tCoVBg4YJur68poatSFxUKhcLCBV1tcqFQKBS1WLSgG10uKjCqUCgUFi7o9mqjaIVCoajFsgW9xuVSoix0hUKhsGxB93OxAyAjr+Qi90ShUCguPhYt6N08HbASkJxdfLG7olAoFBcdixZ0W2sdXT0clKArFAoFFi7oAD28HDmWXXSxu6FQKBQXHcsXdG8nUs4Uq+X/CoXiL08nEHRHyiqrOVlQdrG7olAoFBcVixf0YC9HAJKV20WhUPzFsXhBD/F2AlSmi0KhUFi8oPs42+Joo1MWukKh+Mtj8YIuhKCHtxPJOcpCVygUf20sXtBBBkaVy0WhUPzV6RyC7uVEZn6pKtKlUCj+0nQKQQ/2dkTT4LhyuygUir8wnULQe9SmLipBVygUf11aJehCiKuEEIeFEEeFEPPMnO8mhFgnhNgjhNgnhLi6/btqQlk+VNe5V3p4q1x0hUKhaFHQhRA6YCEwEQgD5gghwho0exb4RtO0AcBs4N327mgt+76F17rB2eO1hxxsrOniaqcyXRQKxV+a1ljog4GjmqYla5pWASwDpjZoowEuNX+7Apnt18UGuAbIx7zUeod7eDsqQVcoFH9pWiPoAUCayfP0mmOmvADcJIRIB1YDD5q7kBBirhAiTggRl52d3YbuAm7d5GPeiXqHe3g5kZxdhKapIl0KheKvSWsEXZg51lA15wCfapoWCFwNfCGEaHRtTdM+1DQtRtO0GG9v73PvLYBzF7DSm7XQC8sM5BRVtO26CoVCYeG0RtDTga4mzwNp7FK5E/gGQNO0rYAd4NUeHWyElQ5cAxtZ6MYiXao2ukKh+KvSGkHfCYQKIYKFEDbIoOfKBm1OAOMBhBB9kYLeRp9KK3Dr1kjQowLdsNFZ8fO+kx12W4VCobiUaVHQNU0zAA8AscAhZDbLQSHES0KIKTXNHgfuFkLsBZYCt2kd6cx26wa59V0uHo42TOnvz3e70skvqeywWysUCsWlinVrGmmathoZ7DQ99pzJ3wnA8PbtWjO4dYfiLKgsBb197eHbhwfx3a50vo47wdxRIResOwqFQnEpYJkrRd27y8e8tHqHw/1dGRLswWdbUjFUVV+EjikUCsXFwzIFvYnURYA7RgSTkVfKrwmnL3CnFAqF4uJi4YKe0ujUhL6+dPWwZ/Hm443OKRQKRWfGMgXdyQ90NmYtdJ2V4NZhQexMyWVFfIZaaKRQKP4yWKagW1mBa1ezgg4wa1BXevk68fCyeK5duJkNR7KVsCsUik6PZQo6mM1FN+Jsp2f1QyN5fXoUOUUV3LJoB1fN38jHG5PJLiy/wB1VKBSKC4NlC3qDXHRTrHVWXD+oK2ufGM2/p0Vib6PjlZ8PMezffyj/ukKh6JS0Kg/9ksStG5TkQEUx2Dg22czWWsecwd2YM7gbSacL+dfqQ7zy8yEiA1yJCfK4gB1WKBSKjsVyLXT3IPnYIBe9OUJ9nVkwZwCB7vY8tHQPucWqkJdCoeg8WK6gN5OL3hzOdnr+NyeanKIKnvxurwqWKhSKTkMnEPSm/ehNERnoytNX9+H3Q1ks2X5uA4JCoVBcqliuoDv6gM62TYIOcOtlQYT7u7AyPqOdO6ZQKBQXB8sVdCsrcGs6F70lhBCM6OnF3rR8yiqrWn6BQqFQXOJYrqCDrLrYRkEHGBzsQUVVNfFpee3YKYVCobg4WLigN5+L3hIx3T0QAnYcP9tkm0MnC9hyNKfN91AoFIoLheULeulZKC9s08tdHfT08XNpVtBf+imBR76Ob2sPFQqF4oJh+YIO55SL3pAhwR7sSs2l0kz9dEONOyarsJyswrI230OhUCguBJ1D0PPT23yJIcEelFZWsT8jv9G5xFOFlNYETA9mFrT5HgqFQnEhsGxBd/aTj4Vt3xh6ULBc/m/O7bL7RG7t3wfNCL5CoVBcSli2oDudv6B7OdkS4u1oVtB3pebi62JLd08HZaErFIpLHsstzgVgbQMOXlCQeV6XGRzsyap9mVRVa+isRO3xXam5DOzujkCYdckoFArFpYRlW+gALl2g8NR5XWJIsAeFZQYST9VZ4VkFZaTnlhLdzZ0wfxdOnC0hv7TyfHurUCgUHYblC7qzPxSer4Xe2I9u9J9Hd3cnIsAVgATldlEoFJcwnUDQ/c7bQvd3s6erhz2xB0/VVl/clZqLjbUV4f4uhPu7AHAwU7ldFArFpYvlC7qLPxRng+H8apvfflkw25LP8lvCaUAKelSAK7bWOrycbPF1sVWBUYVCcUlj+YJuTF0sOn1el7l5WHd6+Trx8s8JFJRVciCjgOju7rXnI/xdlYWuUCguaVol6EKIq4QQh4UQR4UQ88yc/z8hRHzNvyNCiAtX7crZXz6eR+oigF5nxQtTwkk7W8ojy+KpqKomuludoIf7u3Asu1hVZlQoFJcsLQq6EEIHLAQmAmHAHCFEmGkbTdMe1TStv6Zp/YF3gO87orNmaYfFRUYuC/FiUmQX1iZmARDd3a32XJi/K1XVGomn2lY3RqFQKDqa1ljog4GjmqYla5pWASwDpjbTfg6wtD061ypcaiz0gvMXdICnJ/XFTm9FNw8HfJztao8bA6MHVD66QqG4RGnNwqIAwLT6VTowxFxDIUR3IBhYe/5dayX2HmClP+/URSMBbva8PXsAosHxQHd7XO31KjCqUCguWVoj6A21DaCpnZVnA99pmmbW0SyEmAvMBejWrVurOtgiVlbgfP6Li0y5Mtyv0TEhBOH+LiowqlAoLlla43JJB7qaPA8EmjKHZ9OMu0XTtA81TYvRNC3G29u79b1sCZcu5738vzVEd3PnYGYBZ4rKO/xeCoVCca60RtB3AqFCiGAhhA1StFc2bCSE6A24A1vbt4utoB0WF7WGSVFdqKrWWH3g3O6laRonzpSw/kg2BWWqfIBCoegYWnS5aJpmEEI8AMQCOmCRpmkHhRAvAXGaphnFfQ6wTDMutbyQOPvD0T86/DZ9/JwJ9XFiZXwGNw/t3mL7rMIy5i3fz67U3No6MLbWVlwV4cfMgV0ZEerV0V1WKBR/IVpVbVHTtNXA6gbHnmvw/IX269Y54uwHFUVyKzpb5w67jRCCqf39efPXI2TklRLgZt9s+8WbU1h/JJvrYwKJDHAjwN2e3xJOsTI+kxXxmXxw80Cz/nqFQqFoC5a/UhTaPXWxOSb3k/f6aW/zPvvKqmq+jUtnbG8f/j0tihuGdGN0L29euTaSHc9MwNnOmj8PZzd7jfVHsjlxpqTd+q5QKDo3nUPQ23FxUUt093SkX1c3VsY3L+h/HMoip6icOYO7Njpnp9cxsLs7cSlNb06dVVDGnZ/u5N+/HDrvPisUir8GnUTQm1n+X1UJC4fAwR/b7XZT+/mTcLKAo1mFVFdrLNp0nDs/3Ul+SV3Ac9nOE/i62DK6l/lsnkFBHiRlFZFbbL6o2Nc70zBUa2w6moPBzAbWCoVC0ZBOIug1Frq51MWCDMhOhKTf2u1210R1wUrAB+uTmf3RNl5alcAfiVk88vUeqqs1MvNKa3znXbHWmf+IBwXJGuxxqbmNzlVVayzdcQJnW2sKywzEp1240jgKhcJy6RyCbusEti7mUxeNIn96f7vdzsfFjmEhnny7K51DmQW8MSOKl6aGs+5wNu+sPco3cXJh7fUxjd0tRqICXbHRWZl1u6xNzCIzv4xnr+mLlYANR5r2tX+xLZV/fL+fvJLzKx+sUCgsH8veU9QU5y7ml//nZ8jHrESoMoCufd7yw+N7EeCWxiMTeuHvZo+macSfyGP+H0dwtrVmRE8vuno4NPl6O72OqEBXdpgR9CXbUvF1sWV6dCBf70xjfVIOj13Ru1G7yqpq3vr1MLkllaxLzOK/1/djeE+VCqlQ/FXpHBY6NL24qCBdPlaVw5mkdrvd4GAPXp/RD/+a1EUhBK9eF0lvX2cKygzMHtRyaYOYIA8OZORTWlFXKeHEmRI2JGUze1A3rHVWjOrlzb70PM6a8bVvOppDbkklj13eCwdbHTd+vJ3X1yRyMZYCKBSKi0/nEXQXf/Npi6Z+9VPt53Yxh72Njk9uG8TTV/fhinDfFtsPCnKnskpjb3qdj/zLHalYCcGcwXJAGN3LG02T4t2Qn+IzcbXXc+/oEH5+cCSzYrry7p/HePuP9hu4FAqF5dB5BN3ZD4pOQXWDjJD8DPAMBZ1Nhws6yGqNc0eFoG8iGGpKTHcZGN1Zszl1VmEZ3+xMY0JfH/xcZeneqEA33Bz0jfzopRVVxB48xcQIP2ysrbC30fHa9EimRwcy//ckvtye2s7vTKFQXOp0IkH3h2oDlDSwZAsywL07ePeB0wcuTt+awNVBT29fZ3am5lJhqOa+Jbspq6zm0ct71bbRWQlG9PRiw5Hseq6UtYlZFFdUMaVmoRNIt89r0yMZ29ubf/54gNiDjV1QWQVlfLD+GNXVyi2jUHQ2Oo+gu3SRjw1z0QsywCUA/CLh1KUl6ACDgt3ZnZrL8ysPsCs1lzdmRtHHz6Vem1G9vMkqLK+3W9LKvRn4ONsypIdnvbZ6nRULb4wmMtCNJ77ZS7mhfiXjz7em8u9fEjmgygArFJ2OziPozjWCbuozN5RDcbYUdN8IKM6CoqyL078mGBTkQVG5gaU70rh3dAjXRPk3ajMqVC5O+mX/STRNI7+0knWJ2VwT5Y/OqnG5egcbax4Y25PCcgO7U+vnsG+s8cXvON70KtVyQxUL1x1tctHTxaJKzSoUimbpPILu0UM+5pgEBI3i7hoAfhHy7wvgRz8XBgd7IIS0wp+8snFqIoCfqx2Dgz1YsPYo09/bwhuxiVRUVTOlf2PxNzK0hwfWVoINSXW+9/ySSvbXBGB3NlN2YMm2E7wRe5iPNia38V21P3EpZwl/fg2Jp9SOUQpFU3QeQXfwACdfuSrUSEFNDrqLv7TQ4ZLzo3dxtefbe4bx/k3RZq1tI5/fMZiXp4aTVVjOkm0n6O7pQL9A1ybbO9vpie7uzkYTQd+afIZqDYK9HIlLyTWb3lhSYeC9P48CsvxAQ5eNabtDJwsoqzR/vr35ascJyiqrWb4r/YLcT6GwRDqPoAN4924g6DUWukugFHyXgEvSjx4T5IGDTfMLnuz0Om4eFsS6J8aw8IZo5s/qjxBNDwAAo0K9OJBRQE7NDkubjmbjaKPjjhHBnCmu4Fh2caPXfL41lZyiCh4eH8qZ4grWmGzmUW6o4rGv47ns338Q9lwsE9/eyMPL9rQp773CUN3q1a0lFQZia/qxat9JFdBVKJqgkwl6X8g+DEaBya+x5ozldX0jLjkL/VzR66yYFNWFAd3cW2w7qqYw2OYav/nmo2cY2sOTYTWB1IZlB4rKDXyw/hije3nz8PhQgr0c+XxrXfrjgj+S+H5PBtHd3Xn88l7cNLQbsQdP8/P+c69y+UZsIjGv/M6zP+4nq6Cs2ba/JZymuKKKG4Z042R+WZPuIk3TeO/PY52q5HB+aSXF5YaL3Q2FhdDJBL233OjCKOQFGWDnKmu9gPSjZx+GyuYFpLMQ7u+Ku4Oe9UeySc8t4XhOMcN7ehHi7Yino02jsgOfbj5eu/LUykpw45Bu7ErN5WBmPnvT8njvz2PMHBjI/26I5sHxobwwOZx+ga48v+Kg2X1WNU3j0MkCMvJKG53741AWbg42LNuRxqg31rFw3dEm38ePezLwd7Xj6av7Yq/XsbKJWvQHMgr4z5rES8r3f77cumgH9wHCt08AACAASURBVC7ZdbG7obAQOpeg+/SVj0a3S0GmdLcY8Y0Araq+W6YTo7MSjAj1ZmNSDpuSpJU+ItQLIQQxQe71LN380ko+3JDMhL6+9OvqBsDMgV2x01vxycbjPP7tXnxd7Hj2mrDa11jrrHh9Rj8Kyip58acEAAxV1exNy+PN2MOM++96Jr69kTs/3VmvXyfzS0nOKebe0T1Y+/gYLgvx4o3Yw6SdbWxZ5xSVsyEph6kDAnCytWZCmC+r95+k0kxJ4T8PywymtYlZnaL8QXZhOfFpeWxMyulUsw5Fx9G5BN27j3w0CnZ+ep27BWQuOli82+VcGBnqRXZhOYs3p+DjbEuoj5ytDAryIO1sKafy5WzlzdjDFJUbeMxkUZOrg56p/QL4fk8GR7OKeG16FK72+nrX7+3nzIPjQlm5N5Pr399Kvxd/ZerCzbz751EC3Oy5OtKPxFOF9QRp67EzAAwL8aSbpwPPTpID8brDjVNKV+3NpKpa47oBAQBM6edPbkml2VII6w5nIQRk5JXWy9m3VLYcq3uP3+1WweDzZVNSDrtSm87u6gx0LkF38ABHH1lZEaSF7hpQd96jB9i6woHldX72To4xh/3w6UJG9PSqDaQODpZlB3aknGX3iVyWbE/l1suCCPOvv6jp5mHdEQLmDO7a5GYd940J4bIQT/JLK5kWHcg7cwaw85kJLLlrCE9dJQfZ3w+drm2/9dgZ3Bz09K1ZQNXD24lgL0f+ONRY0H+IzyTc34VevnKv2FG9vHCxs+anBjtG5RZXEJ+Wx+xBsmTx2sT616qsqra4YOrGpBxc7fWMDPXiu7g0lYd/njy1fB8vr+rcO4B1LkGHukyXyjJZBsDU5WKlg7FPw7G1sP/bi9fHC4ifqx29fKVVblpaN6yLCw42OrYey+Hp7/fj52LH42ZK9EYEuPLbo6N4eWpEk/fQ66z46u6hxD46ipevjWByP388nWwBuWVfL18nfkuQgq5pGluOnWFYD0+sTNI0x/XxYeuxM/UCgMnZRexNy6u1zgFsrXVMjOhC7MFT9VImNyRlU63BzJiu9At0rTeAlFVWMf6/6xn22h+8siqB/en5VFZVU1JhIL+k0qzQ7zmRy7IdJ8y6ds6V/en555zeqWkam4/mcFmIJ7MGdSUzv6yexX6ubEs+w52f7vzL1s3PKigjI6+UI6cLLW5gPxc6n6D71GS6mOagmzL4bgiIgTXzoPjMhe/fRcBoWZsKurXOiuhu7ny9M43EU4W8OCUcJ1vzqZM9fZyb3HmpNUzo68uOlLPkl1SSdraUjLxSLgupX7JgfB8fKqqqazNyAD7dkoJeJ+rVqwGY2t+f4ooqlpu4IdYfzsbdQU+/QDfG9fElPi2vNl3z0y0pnDhbQoi3E59tTWHy/zYR+swvhD0XS7+XfuXK+RtIOl3nollz4CSzPtzGvO/3c9X8DWZdQa1lW/IZJv9vE+P/u57vd6e3WkyOZRdzMr+MEaFeXB7mi5uDnm/i6t6vpmmttthTcoq554td/JGYxbdxl77r5mhWETd/sr32/89IVmEZV83fwN427OC1+4R8TUlFFem5jYP0nYXOJ+jevaGiENJrAnGmLheQVvqUBVCWD78+c+H7dxG4f2xPltw5pLaCo5FBQR5Ua3BFmC9XhPt12P0nhPlSVa3x55GsWitzWEj9jThigjxwtrWudZVkFZSxbGcaMwYG4uNSv9/DQjwZHOTBW78eIb9UWtjrj2Qzqpc3OivB+L4+aBqsS8wiv6SSd9cdZUxvb766eyg7n5nAf6ZH8sQVvZg3sQ9PXdWH3JIKpvxvMz/sSefL7an87cvdhPu78M6cAVRrcPvincz9PK5e3frW8sXWVFzt9Xg42vDYN3uZ9M4mjmYVtfi6TTULwkb29MbWWse1/QOIPXiKvJIKtiWfYfx/19P/xV/539qkZtMaC8squevzOKwE9PZ1ZumOE40Cxu0xCzFF0zQ+2pDMv3851CY30bvrjrIxKafRIrLvd2eQeKqQr7afOOdr7jlRt9XjoU682rgTCnpNpsvRP+SjS0DjNr7hMOJR2LtUul86OW4ONowIbbyT0aSoLgzr4cmLU8M79P79A93wcrLht4TTbDl2Bh9nW0K8Heu1sbGWm3msTcyiulrjgw3JVFVr3De6Z6PrCSF4bnIYZ0sqeOePJPZn5HOmuIKxvX0ACPd3wc/FjrWJWby/4RiF5Qb+fqX05bs52DBrUDceGBfKvaNDuG9MCD8/NJLIAFce/Xovz/xwgDG9ffjqrqFM7udP7COjeOqqPvx26DRzv4hr0nWSW1xBXMrZemKZVVBG7MFTXB8TyIr7h/P27P5kFZRxzxdxLeaWbzqaQzcPB7p5yl2vZsYEUmGo5saPtzP7w20YqjUGBXvw5q9HGP3GOrMraKuqNR5eFk9KTjHv3jiQuaN6kJxTzNbkupnpjuNnCX8+lke/jier8PzTeTVN4+VVh3h19SE+WJ/ME9/uPSdRzyoo46d9Mj7y3a702s9T07Ta9xibcOqcB6E9J/LoXROHOdzKgLmmaW0axC8mnVDQazJdjEJtTtABRj4Bbt1g41sXpl+XID19nFg6dyhdXO079D5WVoLxfXxZfzibLcekX9jcKtdxfXzIKixnfVI2X25PZWp//1pBa0hEgCvXD+zKp1tSWLz5eG09HJCCP66vD+uPZLN483Gm9vNvFOw1xdfFjq/uHsIjE0K5a0QwH9w8EHsbHSAHmvvGhPD69Cg2JuVw35JdlBuq0DSN4znFLNmWyk0fbyfm1d+Z8f5Wvt6ZVnvdZTvTMFRr3DCkO1ZWgqn9A3hnzgCSc4r5548HmkytrKyqZlvy2XqDcLi/KxEBLiSeKuTe0SHEPjKKRbcNYvl9lxHo7sDfl+8ju7C+i+KrHSdYm5jF81PCGRbiyaSoLrja62st3HJDFf/4fh+ONjpW7ctk/H/X89mWlDYHX6uqNf7x/X4WbT7ObZcF8fjlvfhhTwaPfxPf6msu2X4CQ7XGPaN6kJRVxL50WRX0QEYBSVlFjOntTV5JZW2mVGuorKpmX0Yew3t60d3TodWCvnDdUQa/+ns9d9ylTucTdEdPcPSWAVF7d7BpYl9PvR30vxFSNtWv0KjoEC4P86Ww3EBOUQWXhZjf93RMb2+EoKbsbzX3j21snZvyxJW9sdPr+DE+k36Bbng42tSem9DXh5KKKqqqNbPB3oZY66x4ZEIvnr0mzOzmJDNjuvKv6yJZdzibaxZsIuaV3xn75p88++MBMvJKmTuqB4ODPHh5VQJpZ0swVFWzdMcJRoZ6EexVNxu5rKcXD48P5fs9GU36s/em5VFUbmBkg/1hP75lEH88Npp5E/vUDjgDu7vzxowoqqq1eguuNE3jy22pRAa4cvPQ7oAsHzEtWrpucorKef/PZI5lF/PWrP6seWQU/QLdeH7lQa5duLlJP/W+9DxeWHmQz7emYDCxkrMK5cxj2c40HhrXk+cnh/Hg+FCevLI3P8ZnMm/5vhb/D8oqq/hqeyrjevtw/7ie2Fpb1cZJlu9Ox8baitenR+Foo2P1OaxOTjxZSFllNQO6udHb17mRyyW/pLLR4reSCgMfbzpOYbmB+7/abTGWeufZJNoU7z51ZXObI3Im/Plv2P8dDH/owvTtL8rwnl7Y6a0oq6xmWIOAqBFPJ1sGdHVj94k8ronqQoi3U7PX9Ha25aHxPfnX6kTG9K6fUnlZiBduDnqmRwc2u1n3uXDDkG4IIf3io3t7E9Pdg8HB7oR4OyGEID23hKvmb+Txb/dyx/AgTuaX8cKUxu6sB8eFsjPlLP9ccYDknGLs9FbYWusI9nIkursbG5NyEIJGn1PDGIiRUF9nogJdWb4rnTtHBAOwPyOfxFOFvHxt/eykG4d0Y/HmFN6MPcz3uzO4JqpLravqizsHs2rfSV5elcC1727mxiHdiOnuQbmhisIyAz/tzWRvej56naCySuOr7Sd4aWoEqWeKeXlVAmWGal6YHMZtw4Nr73f/2J4UlRt4789jTIsObPL/HuCnvZnkFFVw+/BgXOz0XBnux4r4TJ66qg8r92ZyeV9ffFzsmBDmS+zBU7x8bYTZwTczrxR3B5vaQW93jf88urs7SacL+f3Qacoqq7DTy/P/+GEfW46d4Y/HRtdmZy3fnUFeSSUPjw9lwdoknl95gNdn9KOssor31x8j9uBpPrhpYJMzyHJDFa+vOcytw4KabNMRtErQhRBXAW8DOuBjTdNeM9PmeuAFQAP2app2Qzv289zw7gMpG1sWdM8QCBgoUxiVoHco9jY6xvXxIfFUYbMCe0W4H/FpeTwwrnnr3MhtlwVTVlnN7MFd6x230+tY/8RYnOza12aZE+nCHG8Ngvs3Ohfo7sDzk8N48rt9JJ4soIurHeP7+DRqp7MSzJ81gJs+3s5HG5MbuSOsrQRRAa64Odg0em1TTBsQwAs/JXDoZAF9u7jw9c40bK2tGmUI9fRxZnCQB8t2puFiZ81zk+tW/gohmNzPnzG9vXnrtyN8tiWFJdtOmLzWiRenhHNddABbjubw0k8JXP/BVkDuj/va9Cizg/DD40NZsSeDf60+xIr7h9dLVzWiaRqLN6fQy9eJ4T2l6M8YGMjKvZn888cDnC2uYPpA+Xu+OrILK+Iz2ZZ8hpGh9Qfy4nIDV83fwMhe3iy8IRqQAVEfZ1v8Xe3o08WFak1m0kQEuFJWWcW6xGxKK6t47ZdE3pjZj+pqjcWbjtMv0JVHJoRSVa3xv3VHcXe04deDpzmeU4xeJ/jHD/tYcucQs+7DH/dk8Mmm4xSWVfL6jH6t+j9sD1r8tgshdMBC4HIgHdgphFipaVqCSZtQ4B/AcE3TcoUQjb/FFxLvmil2wwwXc0TOlCmM2YfrXtcSxWekZZ+fDrO/AqvO57nqCP4zPYqyyuaDWXcMD2ZCXx96+ji36po21lY8ND7U7DlXB73Z4+dF3Cew9hX4e7J06TVgxsBAfk04zW8Jp7lrZI8m0z29nW2JfXQUIH3PpZVVHD5VyJ4TucSn5Znd6KQ5pvQP4NXVh1i+K53Hr+jNyvhMJkV2abSyF+DGod3YkXKWeRP74uPc2Op3ttPz/ORw7hsdQlG5AVu9DltrKzwdbWrF66qILozq5c0nG4/j6WTL7EFdzQo1yMH1iSt789g3e1m5N5Nra9YVlFVWseFINklZRRzMzCfhZAGvTYusvcfwnl74udjx/Z4MvJxsasV7dC/vWrdLQ0FftS+TgjIDP+87yV0jchnQzZ3dJ/KI7uaOEILefvJ7dehkAREBrmw5lkNpZRUDu7vz7a50rh/UlYLSSpJzilkwZwBCCB6ZEMqO42f5YH0yQZ4OfHHnYE6cLeGZHw7wbZx8jSnGoD7Ayr2ZPHN1WMd8F83QGvNlMHBU07RkACHEMmAqkGDS5m5goaZpuQCapl3cbYGMNV0a5qCbI3waxD4N+76B8f9svm1VJez8BP78l0x7BFlGoEvU+fW3NaRuBUcv8DIvXpaAs50eM/pRDxtrq1aL+UUhPx20ajibLGd3DRBC8Nq0SHr5OnHrsKBWXVJnJXCytWZgd3cGdm+5iqY5PBxtGNvbhx/jM+nl60xhuaGR0BiZ0s+f7p6OzdbTB/BxsaM5y8zBxpoHmxhMG3Jt/wA+2XScN2IPc1WEH0dOF/LI1/Ek15RwDnCz57oBAbViD/JzuS46gPf+PMaUfgG17hU7vY7xfX1Zc+AUL02t73ZZuiONHl6OFJQZ+PfqRN69KZoTZ0u4cUg3AII8HbG1tqoNjP6WcBonW2sW3TqIiW9v4NkfDuDqoMff1Y6JETKV11pnxfs3D2RtYhbXRHXBTq+julpjRXwmr/ycwJje3vVSa38/dJrk7GLuGd2DD9Yn8/2edG43cUMt2nScMb296dGCS7EttMa0DADSTJ6n1xwzpRfQSwixWQixrcZF0wghxFwhRJwQIi47O9tck/bBLxLcg6Hr0JbbOvtCjzHS7dJcOYCKElgyHdY8Bf4D4OYf5fFjf7RHj5un+AwsmQa/Pdfx91I0T2HNCtQzTVd09HSy5ckr+1wwq8zI9IGB5BSV869fDhHk6cCQmvIODRFC0L+rW4v19NsTKyvB01f3JSOvlNsX72Tau1sorajio1tiOPDilWyeN47/m9W/1q9t5IbB3YgMcOWmod3qHb86skujmj6HThYQn5bHDUO6Sas65Sxvxh4GpP8c5CDRy9eZwzUrRn8/lMXoXt64Ouh5fko4h08XsuP4WW4bHlRvoPBwtGHGwMDa/llZyYG73FDNcysO1uvbBxuSCXS358kretO/qxtfbq/L/V93OIuXViWwdMe559K3htYIurn/9YbKZw2EAmOAOcDHQgi3Ri/StA81TYvRNC3G29t8XZB2wc4VHo6H4JGtax85E/JS6xYjNaS8CL6cKf3yU96RYh4yFnzCL0we+7Z3obIEsjp3HQqLwLgJ+dlLr0Tv2N4+uDvoySup5PpBXS+oYLeG4T29GNvbm63JZ5gU1YU1D4/i8jDfJlcoA3T1cOCnB0c0smbH9PYmwM2eF1YepKgmp3/ZjhPY6KyYFh3IrEFd6eHtyLKdaVhbCSL862YjffycGZ/+LrlL7ya7sJzLw3wBucBufB8fnG2tmTWo/gBijh7eTjwyoRdrDp7iyW/3UlRuIC7lLLtSc7m7xt1245BuHM0qYvvxs2QXlvPkt3vp4+fcqsyrttAaQU8HTOdugUDDPL90YIWmaZWaph0HDiMF3jLocw1Y28HeZY3PlRfClzPgxFa47kOIvgWMP5SQsXBiG1Q03vmn3SjNgx0fgpU15KZAZeddtmwRFNbs4HT22MXthxlsrK24dkAAep1gRnRgyy+4CMyfNYBv7hnG27MHnNcMxk6vY/7s/qSdLeG5Hw9QVlnFD3syuDLCDw9HG/Q6q9rCcH27uNRmvICsEDqkajduSd/jalVamyElhOCdGwaw+uGRZmMP5pg7qgcPjO3J8t3pTFqwkVdXH8LdQc/MGPn5XxPlj4udNV9sS+Xv3+2loMzA27MHNJqJtBetEfSdQKgQIlgIYQPMBlY2aPMjMBZACOGFdMFceiZMU9i5QPh1UtBLc+ufW3G/tNxnfAJRM+uf6zkeqiogZXPH9W3Hh1BeAMMfAbT6m2CfL5WlEP8VVLfv0u9OS3UVFNW4XC5BCx3gySt7s+rBkY3KJVwQNr4Fm99utomrg7620uf5MijIg4dqcvofXLqHgjIDc0ziBleE+TJtQADXx9Qf3Pr4OtNVZKGjijt8j9bLJnKwsT6nNFedleCJK3vz9T3DMFRp7DmRxy3Dgmq3lLS30TFjYFd+3neSdYezeebqvrWB2Y6gRUHXNM0APADEAoeAbzRNOyiEeEkIMaWmWSxwRgiRAKwDntQ0zbIqX132IFQWy6Cnkcw9kLACRj0pBb8h3YZJy76j3C7lhdLd0msiREyXx3KOtN/19y6FH++TriRFy5SckRukWOnhzKVnoYMUpI4UjCbRNNj+PuxZckFv+8DYngwO8uC3hNN093RgaI+6PHchBG/N6s/NDYLTfd0qcBKyzMEk273t0o9BQR788shIXrk2gntG96h3zrh+YVwfH24Z1r1d7tcUrcq30zRttaZpvTRNC9E07dWaY89pmray5m9N07THNE0L0zQtUtM0M76LSxzfcOh5ufxSGreoW/cvmZo29G/mX6O3h+6XdVxgNG6RnDGMekLmzAtd++62lLJJPqZ24AyjM2H0nwdEQ+nZxrO5juaH++S/S5GCDDl7yU2RM5kLhLXOivmz+xPobs99o0OaTJ00xbNC/j9ma64E522FqvbZs9XFTs9NQ7s32vC9p48Tqx4cwcIbojs8rqESqE0Z/pBcYbp3KaTtgKRfYfjD0iXTFCHjpdWcl9Z0m7ZQXQVb35UZOIExYG0rN+hoL0HXtDpXUeqWxudLWrGzS+Jq+QP+q2D0n3cfLh8vpNslYzfs/QoOr740N2dJj5OPVRWQ386/hRbwd7Nn49/HMntwy4FMoPY7u8Z+ErqyXEjf0XGdqyHc37WeH7+jUIJuStBImZK45R1Y+7KsCTN4bvOvCRknH5PXtW9f0rZD0SkZhDXi3VsugGoPzibL6zt4yhiBwaSw0+kEeKMnHFrV9OtLzsLXN8IfL7dPfzqaTfMh8efzu0YjQT9+ftc7F/78t3wsy6vbBL2jqShu/eCREVf390VwR52T5Vsj6BNv+4d0nx3+pWM6dRFQgm6KEHDZQzKD4fgGGPEY2Dg2/xqfvuDcpa5cb3tx6CfQ2UDoFXXHvHtLITa0w64zRnfLsAfAUCYtQCP7v5W+4t2fNf36Y2vlAptjay/oFLtN5KfD78/D1zdD0u91x8uLZNB70/+17jpGQe86GBAXTrjS4+RssffV8vmp/R1/z/IieKsvxH/Zuvbpu8C1xkK+RAPGteSmgJMvXn7dIGg4HFlzsXvUbihBb0jfKeAeJEU65vaW2wshrfTkdZCxq336oGlS0EPGga1JgMu7D1QbzP9gNE0uSf/x/tbdI3WznIEMvK3m+aa66yTULJo6+gcUNbHoN+k3+Vh6Fk7Gt+6eF4uEFfLRIxi+uUUOXvkZsPgqGcSLW9y66xSeBAcv6YJzCbhwwrXuX3ImNfltQFwYQc9KkKuhW5PBVWWQ34E+V4ON0yUbMK4lNwXcaoKTvSZKl+ml3udWogS9ITpruHE53LJCBj1bQ8wdIKzgo3GwZAac2H5+fs6T8dIP2Xdy/eNeveRjQz+6psl6NBvegPgl9a3tpkjdIgO6Dh5ygZTRj35qvxSqoX+TVvr+7xq/troajv5e424S7Ts72fERfDQeytpxV5mDP4JvJNy2WpZX/nImfDwezqbIQHheauvuV3hKDvQAnj0uTC76iW0y6D78YXDykcHx0xdA0E8fqP/YHNmH5MK3gBg5aDb8XDa8Ae+P7Nj1GudCbqo02gB61yxqPxJ70brTnihBN4dXz9YX6gIZtHxkP0x4ATJ3w6IrYMEA+O15+YPM3CNFPmUznD4IRdnNuykO/SQzWnpNbNCvXoCon7poFPPt70PMnaB3rJ96aY7cVDlgdB8hn3e/TPavqhIO/iDvPfJx6NIf9plJWDq5R9ab7zdHxhyO/t64TVvY9RmsfkL6Yw+YGUjaQn66DHqFT5VlHm76XrqKrPRwZywMuku2O32w+euAjDk4y1WFePS4MBb6xv/KmZSxn36RF8ZCN34e2Ynye2FKVWX9tQvGgGhANHiENLZ2E1fDqX3y93CxqaqEgvQ6QXcPkrucHekcfnQl6O2FrbPc1u7hfTB5gbRUtrwDi66ED8dIkf/0anjvMnizJ7ziA9/cat6aP7RK+vYcG9SOtnGQuyyZWuh/vibFfOj9MOm/0G+WFMPmslSMaYpBw+seK4vh5F7pbgkeKQuB9ZstjzUsOZD0GyBkhk/PCTKoer4pfPu/g58eltfzCZfi3h4k1KyBC6tZR+AVCg/shL9tkamqfjX1wltjiRaeAueavVc9QmReeum5b1jcairLIHk9RM2qi+X4RUqXgbE4XEdhFPSqCjhztO64psH7I2D143XHMuLA3kMOcp4hcsZjTAWsLJMDkJ0b7Pyo/WNN50p+mhzQjYIOEDqhZsV3yUXrVnuhBL29sXWCgbfCzT/AE0myvO7spXDTclkDZuancPWb0uJKXieF/uPxdUHK7MOQc1j68s1hmulSeAo2z4eIGXDlq9KfH3OnDHLGf9V0H1M2y/x64/6rxqyN7e9LqzPsWvk8Yoa01huWREj6TVYadPSUAqxVS+E5F0rzpHvlt+fhuzvh+7myH9d/IWMXJ+PlzOZ8Sahxt3iZ1Fd39KqLTbgESLFpyeo1rhI1ulw8ahaPdKSVnr4Tqspl9pURv5rKnq2ZUbQVTZOZTt2GyeenTAa7vFRpUMQtrjuevkt+H4SQA121QbYDOVBWV8LVb4BXb1jxwIXP3zfFmGZrKujBo+XAlbb9YvSoXVGC3pE4ekKfSTJY1HOCrP0Sfh0Mvhsm/gceTZDiXpwNn14Dsc/U+az7TDJ/Te/ecvl/dZVcZl1VCeOeqasv4xchf4hxnzS9pD91E3S7rK6Ou5MPeIbK7Bahq/PdO3nLfu//ts5FVJwjg7/G7JuAgbIYWlNul1MHINNM0PSHe6R7ZetC6RIJmwI3LJOzkMiZYG1//lZ6frr8kYZPbbqNENLqbclCL86WA5dTjcvFM0Q+dqSgH98gYzPdh9Ud862ZUZxqxYyireSnQ3m+/K5a6et/NsZYi85GZg6VF0qBD4yRxxt+LkZ3TPfhcN37clBc/feO63tLmBP0bkNlraTjGy5Gj9oVJegXE1snKe73bZWB1a3/gw2vQ+Cgpmu5e/eRVlvaDrmSNGpWnbVoZNBd8gdlLjc+P0N+qY3uFiPG50Z3i5F+s+QqwF2LpeV2bC2gyWkqyCByjzFyKt3QdVRdLXPVl0yvP509c0wGoUY8Bs9myfjDzE/rrGZ7Nykm+7+V6XNtpaG7pSl8I6RF2lxcw5iyaLTQjYLQkYKeslHGMexM6pY7+8lMm1Mt79HZZozWf5f+0oBoKOh2btKIOPq7zO9HkwFRkBY61PnRM+LkZ+YaIH3swx+G/d9Ajokb50KSmyIHI+P/I8jvnX90pyiBoQT9UsDWCa55S2bXePWqC4CZw1tWkGPVo3KaOOqJxm36TpaBtJ0fNz5n/NJ2byDoxgCp0d1ipPckCBwMPz8us0P2LpWC0mVAXZueE6Aws7Gv/fif8gdUkiMHHyM7PwYrHQy5p+ndngbeBhVFcGC5+fOtIeFHKdam7hZz+EWAobR5cW4o6Hp7cAnsuHS3ihJp3TYsAW2cUXRkYNQo4D59awY7E/fOia3Soh18j8w73/imPB4gt3uT7iyXukyXjF31NwIZco+0hptb49CR5KbIOFTD713wKJkdMmY/hgAAER1JREFUVl54UbrVXihBv5QInSADdv1mN93GuGNR9iHpmjBOcU2xtpUrTI+sgYIGlY4PLJd+Y78Guyz1vQbGPy8tflP0dnDHGrjqNWmdHVsrBdz0BxEyXj4e/a3+a+MWyfzp7sOle6iyVP5g9iyRFrgxwGiOroPl4LXr06bbNEfBSeluCWvG3WKk1o3RjEga67iY9tkj2PwgkHUI5keeXwwgbZv0PQeNanzOL1Leo2H2SUPKClpOx6uqlLEM05nQ6YMyT9vORQaOC0/KTVaKsmSAtNsw+b0YX7PhikeITH+FGj96DznQlZxtvLOTsx/0nigXLJmuTm6K4jOyimNT6yHOldyU+u4WI8GjZJpu6tbWXedc0pJPJ8A7MXDg+9a/po0oQbc07FzB2V/6Vkc92XS7/jdKn+/epXXHirKlayRyZmMLRW8PIx+TPuyGWOlg6H3wwA5ZCuGyB+ufdw2QU+6t79ZlfRSekulq/W+Asc9AcZb0ie9dJssBD7m3+fcphHRDZe6GpXPO3bWRWFO2oGEuvzm8+8jYQXN+9KLTgJDxBiOeIeZz0be9C3kn4Nd/tn09wvGN0pLtZmbXLb9I6XZrqZTyhtfhq+ubD1gf/kXGMnZ8WHfs9EEp5GCSBbRfWucg01xBVgANGtk43mP8XIzrIYz+dSMDb5MZQsb/o6bISoSPx8EfL8KHY83HYs4V0xx0U7oOlq6Y4yafVfEZOSA2/D/c/gG8FSb/j03JT4d3L5NuKGOWT9Yh+GwynEmC9a93eB0eJeiWSNRMuWS/uf1FPUOkG2XPkrov0cHvpRXS3AygOVwDZbaC8UduyqQ3pWj/VrMv654v5L0G3i79891HyCX2296TFlvDH7k5Yu6Us4bk9bBwCPz+Ql0lzJZIXAWePetcVM2ht5OuruYCjYUnpTtBZ7LxgUcPKUym1mNpLuz7Fpz8pHurraWVj2+Qfl1bM/tO+kXKR+MApGmNrXVDBcTXDObrXm1aSIyiumuxjHlUlkkr3CjoxtnL6YPSerW2l751kEbBbavgigb1fDxCpNid2AKIuvZGeoyT7prmZl9Jv8Mnl0vX09R35bFFV52fC640V9bCMSfoenvoOqQuMFpdLVcVf3W9zMwxltuIWwy//F26GPd9U/8ae5dC1kEZLF50pawd9NlkOTCPfFzOqo3ZbB2EEnRL5PKXGv+IzDHgJmnZGi2rfV9LMTBuot2e+A+Qlvvuz6WI7fpcTmONLqHRf5cLc84ea9k6N6KzlrOGB3fJFMpN/wefXVO3rydIAToSW1/oS3PlD6fPNXXZPy3hF9G8hW6ag24k9Eo5U1r/n7pj8V9Jf/zsL6Vo/fHiuW8gUl4o3TVNbaHoGQo6W7lG4MD38O5QeCe6vtvkyBoZu+hzjXQ9Jf3W+DpVlbKds78U4GNrZcqsVlUn6E4+4OgjB7sTW2oqf9o0vla9/oXI2eGB7+WA2rBaqZUVDLxFiqe5GMTxjfDVTOn2uXstDLgR5q6DLv3guzvkwru2kFuTSmlO0EHONk7tl66iXYtkNljPCXL19edTYdv7MnYVeqVMXDAdXDRNDuTdhsH0T+T3fNkN8vtx2yo5m7Z3rz8T6gCUoHdmwqaAjbO00nOSZICqoY+8PRnzD2m1fn0L5J+Q1rmR4FEyVdLJr3HgtSVcusB178H1n0tL8aOx0p+/5X/wdj9pRa17pa79kViZC90ad4sR3wiZzWNckHXkVzm1NlJ4sn5mBIBPHxnAjlskBa+6WgZ8uw6Rwjf26brFWg2pKIavZtVZ0aakbpWiGmzGfw5yoPMNkymf390ug+N5J2SWlJHdn0uhnv6JFLC1Lze20lM3ywVKV/1LBrrjFtUFQH1NZmF+EdKnf2p/XW56cxgzXXKP1/efmzLgZunmahgcra6GX5+VAec71oBbzQ5ETj5w609y0VnsM63zvzfEXMqiKcGjAE0aPr89L7O3bvxOfoYZu+QG8T1Gy+9h1CxZ7+Z0gnzt6QNyMIycCZEz4G/bZRbXbavlTFpvL99z4s8y06yDUILembFxhIhpcjl/3CJASEu3o9Dby020Kwpllk2fa+rOCSGt1rt+b9nCa4qwqXBHLCBg8UT49Rn5Y+k5QYqv0QI79JMUM//o1l/bdMXo8Y3Suvrl75BdU2ah8HRdDropY/4h0/jWzIPktXJGZMxSiroefMJk0bSGLpH1/5HW8Yq/NS5TnLJB+nO7Dmn+s/CLlGLzQJx8vnmB7Gd+hqz/0v8G6U4aPU+mOTa0bBN/li6U0Csh+ma5/D3pV7kLl2kqrG+4fF9adf2c+KYwDdQHNiHoxuDoniX1VzUfWiEXlY19urG7ydpGzkzzUmUg91wxCrqxMFdDAgaC3gFin5aD3+QF8nsbOQP+v73zD46quuL45xAQQbQQAgyCnUAlQoYfAkGwUmVAKigFHMRSFEEoWqcMP3Tq2LGtY39YwQ5tbRmmoFClFVCgikxtq6Ci0wImYPlpBStUkB9BQJHOFJKc/nHeTjab3ewmYVn37fnM7Gze27e7976z+d57zz333LtfsZDLCc/ZPS0eaw1SJEXFjhfMtRLprFzaAW58pGaE1YBpdg/LUkwG1wBc0MNO30mWOGnTQutdXNYx+XsaQ+FgGDnPFk7FCnfL/OoeV0Pp2NuG34PnwNS/2XD2G0/a0HbDT83num+9TdQlComMR4fAL71zjcXOtyk0t8amBTbBdeZY7R56pE5DHzZ/+dqZ1tONRNY0ybNIkBMf1JwgPbLTRhe9brdGZ9VUG3FUVZnI7lxjQ/q6ksMNngPfecvEpkmezTVUnoU3HjO3j1aZyw2sYSkoMl96JNZe1b7rymE2Ed5vsp3b9SdzkzSJ2owhcm8kz0JYk9Ey3xo5qI5Pj8fXHjD30spJ5qOuPGf59dsXW5njcWWQbmLjvJoNQSqTjacOWIqCRBvWNL3IJqG1CoY/Cm2ihL9zf3N1RlIwtGpn/087Vtk93bHaor1i03VE06YQim6yuYOGjDBSwAU97HQusSXXKPRu4GRofRl4b/UeqOmgVXtLhPbloAf7pU6WHXLH8/D2fPNh9xhV1yfU5tIONqooW2pCfudqmzz+5wqbzNKqxGGW/e820fvskIWLNm1e/VrRCBh4H2xeaJtUVFVZzpoWbazRm/i8xUUvnwALBtjIoEkeDHmofuVv+xXrAW59Frb8ztwH+V3stSZ5MPQHtqLztSBB1sfbrLyRCJX8LiaWUNPdAtX+9I594k/SJipP0xYmzono1M8mPA+8bfdk2x+s8Rv2o5oNSizDf2INwcYnTNQ3/AzmFtpzLOXv20Tmq4/YPEIid0uEgffBgOk2IZ+MXuOtkfjHby3hV6/xyd9zzXRbdRxZ9HaeaZr8EierETGBfePx+otcNjF4tvljNz5hvcPYhVOp0LGP5bmZuMJ6Z9fOsM+MCEW8HjqY+IyaD+vur70oTARueszcUG/OtQnKQ6Vw66Lq2O1Ja2DpLZZL/LYl0GOM+cnry/UPWu/8TDn0/XnN14rHWNn+/hsT7ON7bVRTNKL6mpKptvqzQ4wIFxTZXEzXG1IvS89x1ptPVo/e4y2q5s3HzX1xxcCaZYpHh2IbeW5ZBFuX2b0tKLJee7urbNQCNlJbMdFyGzVpZja9emLdn130dXukQvdRkDfbRhXNWpoLKRldh9oakM+PJr+2AYhmaH/CkpISLS0tTX6h03giNk7zBrUZZ/MieOV70GeiTaLWl5P7LVIkOizzuW9W72gzfUPiSb5kVFWaa2X3i5YM6q6XatpD9fzYZ8tiE7p7N9Z22VSeg2W3WtqIlvkW1jklyn9fVWlzLT3HVTc2EU7ut2iXeOsUGosqrP62CfqUP9dOSxGP00ctsd3lfS2CpG03i0T5eKv5u/97wsS8oAhuf8Z65nX1+hvKyjttbqLXeBgXZ2V2PKqq6ucOjEFEylQ1ri/LBd0JD5XnbHKy/5TqWO3G8uFbFioJcP+exDl2UqHirCVNKx6b/rmMRJz5BBYPsaiYEXNhUIohpOmmssIajWRpGuri83KLgKr4n8Wbt+tuDWds43Q+2fOyifodq6Db8PR9TxQu6I7TUFRh0Q1weDv88HjDXCFfNI7uthwsI+fVTMQWBg5vt0U9BUWWwjqdYg72+ziy3dx1FwgXdMdpDAdLLWb7ulmZLomTCqeP2DxKs4szXZK0UJegh6C74ThppnNJaqkKnC8GdSV9Czketug4jhMSUhJ0ERkhIv8SkX0iUitAVkSmiEi5iLwbPOpI6O04juOkg6QuFxHJAxYAw4GDwDsislZVd8dculJVZ6ShjI7jOE4KpNJDvwbYp6r/VtWzwAoghV0DHMdxnAtJKoLeCfgo6vhgcC6WcSKyXURWiUgjE3Y4juM49SUVQY+3fC021vFloFBVewOvAXE3DBSRe0SkVERKy8vL61dSx3Ecp05SEfSDQHSPuzNQY6NKVf1EVSPpwxYDcddHq+oiVS1R1ZJ27do1pLyO4zhOAlIR9HeAbiLSRUQuAiYANVKFiUj0OubRQMz2747jOE66SRrloqoVIjID+CuQByxR1V0i8mOgVFXXAjNFZDRQAZwApiT73LKysuMicqCB5S4AjjfwvdlMLtY7F+sMuVnvXKwz1L/eCXboyODS/8YgIqWJlr6GmVysdy7WGXKz3rlYZzi/9faVoo7jOCHBBd1xHCckZKugL8p0ATJELtY7F+sMuVnvXKwznMd6Z6UP3XEcx6lNtvbQHcdxnBiyTtCTZX4MAyJyhYi8LiJ7RGSXiMwKzueLyKsisjd4bpPpsqYDEckTkW0isi447iIim4N6rwzWQ4QGEWkdpMx4L7D5tblgaxGZE/y+d4rIchG5OIy2FpElInJMRHZGnYtrXzGeDPRtu4j0q893ZZWgR2V+HAkUA98SkeK635WVVAAPqGoPYBDw3aCeDwHrVbUbsD44DiOzqLk4bS7wy6DeJ4FpGSlV+vg18BdV7Q70weoealuLSCdgJlCiqj2xNS4TCKetfw+MiDmXyL4jgW7B4x6gXrudZ5WgkyOZH1X1sKpuDf4+jf2Dd8LqGsmT8wwwNjMlTB8i0hm4BXgqOBZgKLAquCRU9RaRy4DrgacBVPWsqp4iB2yNLWxsISJNgZbAYUJoa1XdiC24jCaRfccAz6qxCWgdsxK/TrJN0FPN/BgaRKQQ6AtsBjqo6mEw0QfaZ65kaeNXwINAVXDcFjilqhXBcdhs3hUoB5YGbqanROQSQm5rVT0E/AL4DybknwJlhNvW0SSyb6M0LtsEPZXMj6FBRFoBq4HZqvpZpsuTbkRkFHBMVcuiT8e5NEw2bwr0Axaqal/gDCFzr8Qj8BmPAboAlwOXYO6GWMJk61Ro1O892wQ9aebHsCAizTAx/6OqrglOH40Mv4LnY5kqX5q4DhgtIvsxd9pQrMfeOhiWQ/hsfhA4qKqbg+NVmMCH3dY3Ah+qarmqngPWAF8l3LaOJpF9G6Vx2SboSTM/hoHAb/w0sEdV50e9tBaYHPw9GXjpQpctnajq91W1s6oWYrbdoKp3AK8DtwWXhareqnoE+EhErgpODQN2E3JbY66WQSLSMvi9R+odWlvHkMi+a4G7gmiXQcCnEddMSqhqVj2Am4H3gQ+AhzNdnjTVcTA2zNoOvBs8bsb8yeuBvcFzfqbLmsZ7MARYF/zdFdgC7ANeAJpnunznua5XA6WBvV8E2uSCrYFHgfeAncAyoHkYbQ0sx+YJzmE98GmJ7Iu5XBYE+rYDiwJK+bt8pajjOE5IyDaXi+M4jpMAF3THcZyQ4ILuOI4TElzQHcdxQoILuuM4TkhwQXccxwkJLuiO4zghwQXdcRwnJPwfvoAUH8vH/nUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 1\n",
      "Epoch: 1/100..  Training Loss: 1.148..  Test Loss: 0.965..  Test Accuracy: 0.616\n",
      "Epoch: 2/100..  Training Loss: 0.925..  Test Loss: 0.805..  Test Accuracy: 0.671\n",
      "Epoch: 3/100..  Training Loss: 0.786..  Test Loss: 0.654..  Test Accuracy: 0.709\n",
      "Epoch: 4/100..  Training Loss: 0.753..  Test Loss: 0.608..  Test Accuracy: 0.738\n",
      "Epoch: 5/100..  Training Loss: 0.737..  Test Loss: 0.647..  Test Accuracy: 0.690\n",
      "Epoch: 6/100..  Training Loss: 0.734..  Test Loss: 0.642..  Test Accuracy: 0.689\n",
      "Epoch: 7/100..  Training Loss: 0.695..  Test Loss: 0.619..  Test Accuracy: 0.717\n",
      "Epoch: 8/100..  Training Loss: 0.720..  Test Loss: 0.637..  Test Accuracy: 0.739\n",
      "Epoch: 9/100..  Training Loss: 0.701..  Test Loss: 0.625..  Test Accuracy: 0.731\n",
      "Epoch: 10/100..  Training Loss: 0.690..  Test Loss: 0.631..  Test Accuracy: 0.729\n",
      "Epoch: 11/100..  Training Loss: 0.667..  Test Loss: 0.624..  Test Accuracy: 0.717\n",
      "Epoch: 12/100..  Training Loss: 0.679..  Test Loss: 0.585..  Test Accuracy: 0.729\n",
      "Epoch: 13/100..  Training Loss: 0.677..  Test Loss: 0.598..  Test Accuracy: 0.727\n",
      "Epoch: 14/100..  Training Loss: 0.656..  Test Loss: 0.588..  Test Accuracy: 0.731\n",
      "Epoch: 15/100..  Training Loss: 0.657..  Test Loss: 0.606..  Test Accuracy: 0.737\n",
      "Epoch: 16/100..  Training Loss: 0.669..  Test Loss: 0.566..  Test Accuracy: 0.720\n",
      "Epoch: 17/100..  Training Loss: 0.668..  Test Loss: 0.599..  Test Accuracy: 0.729\n",
      "Epoch: 18/100..  Training Loss: 0.673..  Test Loss: 0.566..  Test Accuracy: 0.730\n",
      "Epoch: 19/100..  Training Loss: 0.631..  Test Loss: 0.584..  Test Accuracy: 0.715\n",
      "Epoch: 20/100..  Training Loss: 0.642..  Test Loss: 0.581..  Test Accuracy: 0.728\n",
      "Epoch: 21/100..  Training Loss: 0.634..  Test Loss: 0.559..  Test Accuracy: 0.702\n",
      "Epoch: 22/100..  Training Loss: 0.631..  Test Loss: 0.587..  Test Accuracy: 0.745\n",
      "Epoch: 23/100..  Training Loss: 0.635..  Test Loss: 0.582..  Test Accuracy: 0.720\n",
      "Epoch: 24/100..  Training Loss: 0.625..  Test Loss: 0.571..  Test Accuracy: 0.704\n",
      "Epoch: 25/100..  Training Loss: 0.635..  Test Loss: 0.577..  Test Accuracy: 0.727\n",
      "Epoch: 26/100..  Training Loss: 0.612..  Test Loss: 0.579..  Test Accuracy: 0.744\n",
      "Epoch: 27/100..  Training Loss: 0.646..  Test Loss: 0.567..  Test Accuracy: 0.728\n",
      "Epoch: 28/100..  Training Loss: 0.644..  Test Loss: 0.557..  Test Accuracy: 0.746\n",
      "Epoch: 29/100..  Training Loss: 0.626..  Test Loss: 0.597..  Test Accuracy: 0.733\n",
      "Epoch: 30/100..  Training Loss: 0.617..  Test Loss: 0.553..  Test Accuracy: 0.728\n",
      "Epoch: 31/100..  Training Loss: 0.622..  Test Loss: 0.574..  Test Accuracy: 0.736\n",
      "Epoch: 32/100..  Training Loss: 0.621..  Test Loss: 0.563..  Test Accuracy: 0.731\n",
      "Epoch: 33/100..  Training Loss: 0.622..  Test Loss: 0.561..  Test Accuracy: 0.739\n",
      "Epoch: 34/100..  Training Loss: 0.613..  Test Loss: 0.564..  Test Accuracy: 0.746\n",
      "Epoch: 35/100..  Training Loss: 0.600..  Test Loss: 0.565..  Test Accuracy: 0.731\n",
      "Epoch: 36/100..  Training Loss: 0.609..  Test Loss: 0.557..  Test Accuracy: 0.733\n",
      "Epoch: 37/100..  Training Loss: 0.606..  Test Loss: 0.547..  Test Accuracy: 0.742\n",
      "Epoch: 38/100..  Training Loss: 0.608..  Test Loss: 0.551..  Test Accuracy: 0.714\n",
      "Epoch: 39/100..  Training Loss: 0.621..  Test Loss: 0.562..  Test Accuracy: 0.711\n",
      "Epoch: 40/100..  Training Loss: 0.602..  Test Loss: 0.561..  Test Accuracy: 0.735\n",
      "Epoch: 41/100..  Training Loss: 0.617..  Test Loss: 0.593..  Test Accuracy: 0.738\n",
      "Epoch: 42/100..  Training Loss: 0.629..  Test Loss: 0.567..  Test Accuracy: 0.732\n",
      "Epoch: 43/100..  Training Loss: 0.618..  Test Loss: 0.601..  Test Accuracy: 0.693\n",
      "Epoch: 44/100..  Training Loss: 0.600..  Test Loss: 0.558..  Test Accuracy: 0.730\n",
      "Epoch: 45/100..  Training Loss: 0.607..  Test Loss: 0.561..  Test Accuracy: 0.724\n",
      "Epoch: 46/100..  Training Loss: 0.615..  Test Loss: 0.548..  Test Accuracy: 0.730\n",
      "Epoch: 47/100..  Training Loss: 0.603..  Test Loss: 0.565..  Test Accuracy: 0.739\n",
      "Epoch: 48/100..  Training Loss: 0.609..  Test Loss: 0.551..  Test Accuracy: 0.740\n",
      "Epoch: 49/100..  Training Loss: 0.606..  Test Loss: 0.568..  Test Accuracy: 0.719\n",
      "Epoch: 50/100..  Training Loss: 0.595..  Test Loss: 0.551..  Test Accuracy: 0.734\n",
      "Epoch: 51/100..  Training Loss: 0.593..  Test Loss: 0.576..  Test Accuracy: 0.717\n",
      "Epoch: 52/100..  Training Loss: 0.582..  Test Loss: 0.551..  Test Accuracy: 0.751\n",
      "Epoch: 53/100..  Training Loss: 0.603..  Test Loss: 0.567..  Test Accuracy: 0.746\n",
      "Epoch: 54/100..  Training Loss: 0.599..  Test Loss: 0.613..  Test Accuracy: 0.715\n",
      "Epoch: 55/100..  Training Loss: 0.598..  Test Loss: 0.549..  Test Accuracy: 0.748\n",
      "Epoch: 56/100..  Training Loss: 0.593..  Test Loss: 0.580..  Test Accuracy: 0.712\n",
      "Epoch: 57/100..  Training Loss: 0.591..  Test Loss: 0.547..  Test Accuracy: 0.755\n",
      "Epoch: 58/100..  Training Loss: 0.603..  Test Loss: 0.540..  Test Accuracy: 0.735\n",
      "Epoch: 59/100..  Training Loss: 0.588..  Test Loss: 0.551..  Test Accuracy: 0.739\n",
      "Epoch: 60/100..  Training Loss: 0.603..  Test Loss: 0.550..  Test Accuracy: 0.741\n",
      "Epoch: 61/100..  Training Loss: 0.589..  Test Loss: 0.563..  Test Accuracy: 0.743\n",
      "Epoch: 62/100..  Training Loss: 0.587..  Test Loss: 0.564..  Test Accuracy: 0.742\n",
      "Epoch: 63/100..  Training Loss: 0.586..  Test Loss: 0.532..  Test Accuracy: 0.744\n",
      "Epoch: 64/100..  Training Loss: 0.595..  Test Loss: 0.553..  Test Accuracy: 0.729\n",
      "Epoch: 65/100..  Training Loss: 0.600..  Test Loss: 0.549..  Test Accuracy: 0.754\n",
      "Epoch: 66/100..  Training Loss: 0.594..  Test Loss: 0.523..  Test Accuracy: 0.740\n",
      "Epoch: 67/100..  Training Loss: 0.591..  Test Loss: 0.562..  Test Accuracy: 0.730\n",
      "Epoch: 68/100..  Training Loss: 0.583..  Test Loss: 0.556..  Test Accuracy: 0.733\n",
      "Epoch: 69/100..  Training Loss: 0.587..  Test Loss: 0.568..  Test Accuracy: 0.704\n",
      "Epoch: 70/100..  Training Loss: 0.586..  Test Loss: 0.557..  Test Accuracy: 0.723\n",
      "Epoch: 71/100..  Training Loss: 0.605..  Test Loss: 0.565..  Test Accuracy: 0.747\n",
      "Epoch: 72/100..  Training Loss: 0.591..  Test Loss: 0.549..  Test Accuracy: 0.754\n",
      "Epoch: 73/100..  Training Loss: 0.577..  Test Loss: 0.532..  Test Accuracy: 0.729\n",
      "Epoch: 74/100..  Training Loss: 0.584..  Test Loss: 0.545..  Test Accuracy: 0.728\n",
      "Epoch: 75/100..  Training Loss: 0.593..  Test Loss: 0.554..  Test Accuracy: 0.745\n",
      "Epoch: 76/100..  Training Loss: 0.577..  Test Loss: 0.561..  Test Accuracy: 0.740\n",
      "Epoch: 77/100..  Training Loss: 0.573..  Test Loss: 0.537..  Test Accuracy: 0.733\n",
      "Epoch: 78/100..  Training Loss: 0.572..  Test Loss: 0.574..  Test Accuracy: 0.735\n",
      "Epoch: 79/100..  Training Loss: 0.591..  Test Loss: 0.541..  Test Accuracy: 0.744\n",
      "Epoch: 80/100..  Training Loss: 0.585..  Test Loss: 0.532..  Test Accuracy: 0.743\n",
      "Epoch: 81/100..  Training Loss: 0.562..  Test Loss: 0.547..  Test Accuracy: 0.718\n",
      "Epoch: 82/100..  Training Loss: 0.583..  Test Loss: 0.554..  Test Accuracy: 0.725\n",
      "Epoch: 83/100..  Training Loss: 0.587..  Test Loss: 0.539..  Test Accuracy: 0.721\n",
      "Epoch: 84/100..  Training Loss: 0.577..  Test Loss: 0.574..  Test Accuracy: 0.733\n",
      "Epoch: 85/100..  Training Loss: 0.574..  Test Loss: 0.554..  Test Accuracy: 0.738\n",
      "Epoch: 86/100..  Training Loss: 0.585..  Test Loss: 0.530..  Test Accuracy: 0.730\n",
      "Epoch: 87/100..  Training Loss: 0.576..  Test Loss: 0.587..  Test Accuracy: 0.715\n",
      "Epoch: 88/100..  Training Loss: 0.579..  Test Loss: 0.547..  Test Accuracy: 0.730\n",
      "Epoch: 89/100..  Training Loss: 0.572..  Test Loss: 0.541..  Test Accuracy: 0.751\n",
      "Epoch: 90/100..  Training Loss: 0.592..  Test Loss: 0.543..  Test Accuracy: 0.741\n",
      "Epoch: 91/100..  Training Loss: 0.593..  Test Loss: 0.536..  Test Accuracy: 0.727\n",
      "Epoch: 92/100..  Training Loss: 0.577..  Test Loss: 0.542..  Test Accuracy: 0.741\n",
      "Epoch: 93/100..  Training Loss: 0.577..  Test Loss: 0.539..  Test Accuracy: 0.746\n",
      "Epoch: 94/100..  Training Loss: 0.588..  Test Loss: 0.552..  Test Accuracy: 0.733\n",
      "Epoch: 95/100..  Training Loss: 0.575..  Test Loss: 0.569..  Test Accuracy: 0.747\n",
      "Epoch: 96/100..  Training Loss: 0.576..  Test Loss: 0.572..  Test Accuracy: 0.732\n",
      "Epoch: 97/100..  Training Loss: 0.586..  Test Loss: 0.553..  Test Accuracy: 0.741\n",
      "Epoch: 98/100..  Training Loss: 0.573..  Test Loss: 0.534..  Test Accuracy: 0.738\n",
      "Epoch: 99/100..  Training Loss: 0.584..  Test Loss: 0.543..  Test Accuracy: 0.744\n",
      "Epoch: 100/100..  Training Loss: 0.573..  Test Loss: 0.551..  Test Accuracy: 0.734\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 2\n",
      "Epoch: 1/100..  Training Loss: 1.175..  Test Loss: 1.054..  Test Accuracy: 0.528\n",
      "Epoch: 2/100..  Training Loss: 0.988..  Test Loss: 0.879..  Test Accuracy: 0.682\n",
      "Epoch: 3/100..  Training Loss: 0.854..  Test Loss: 0.789..  Test Accuracy: 0.678\n",
      "Epoch: 4/100..  Training Loss: 0.734..  Test Loss: 0.695..  Test Accuracy: 0.729\n",
      "Epoch: 5/100..  Training Loss: 0.740..  Test Loss: 0.684..  Test Accuracy: 0.712\n",
      "Epoch: 6/100..  Training Loss: 0.725..  Test Loss: 0.678..  Test Accuracy: 0.694\n",
      "Epoch: 7/100..  Training Loss: 0.708..  Test Loss: 0.670..  Test Accuracy: 0.712\n",
      "Epoch: 8/100..  Training Loss: 0.709..  Test Loss: 0.654..  Test Accuracy: 0.732\n",
      "Epoch: 9/100..  Training Loss: 0.680..  Test Loss: 0.661..  Test Accuracy: 0.709\n",
      "Epoch: 10/100..  Training Loss: 0.688..  Test Loss: 0.631..  Test Accuracy: 0.716\n",
      "Epoch: 11/100..  Training Loss: 0.654..  Test Loss: 0.623..  Test Accuracy: 0.715\n",
      "Epoch: 12/100..  Training Loss: 0.683..  Test Loss: 0.675..  Test Accuracy: 0.696\n",
      "Epoch: 13/100..  Training Loss: 0.650..  Test Loss: 0.633..  Test Accuracy: 0.716\n",
      "Epoch: 14/100..  Training Loss: 0.666..  Test Loss: 0.702..  Test Accuracy: 0.685\n",
      "Epoch: 15/100..  Training Loss: 0.651..  Test Loss: 0.624..  Test Accuracy: 0.718\n",
      "Epoch: 16/100..  Training Loss: 0.647..  Test Loss: 0.614..  Test Accuracy: 0.726\n",
      "Epoch: 17/100..  Training Loss: 0.645..  Test Loss: 0.617..  Test Accuracy: 0.744\n",
      "Epoch: 18/100..  Training Loss: 0.653..  Test Loss: 0.651..  Test Accuracy: 0.719\n",
      "Epoch: 19/100..  Training Loss: 0.646..  Test Loss: 0.675..  Test Accuracy: 0.683\n",
      "Epoch: 20/100..  Training Loss: 0.651..  Test Loss: 0.636..  Test Accuracy: 0.728\n",
      "Epoch: 21/100..  Training Loss: 0.622..  Test Loss: 0.609..  Test Accuracy: 0.754\n",
      "Epoch: 22/100..  Training Loss: 0.635..  Test Loss: 0.672..  Test Accuracy: 0.721\n",
      "Epoch: 23/100..  Training Loss: 0.638..  Test Loss: 0.694..  Test Accuracy: 0.702\n",
      "Epoch: 24/100..  Training Loss: 0.625..  Test Loss: 0.639..  Test Accuracy: 0.728\n",
      "Epoch: 25/100..  Training Loss: 0.630..  Test Loss: 0.623..  Test Accuracy: 0.707\n",
      "Epoch: 26/100..  Training Loss: 0.613..  Test Loss: 0.649..  Test Accuracy: 0.703\n",
      "Epoch: 27/100..  Training Loss: 0.650..  Test Loss: 0.626..  Test Accuracy: 0.727\n",
      "Epoch: 28/100..  Training Loss: 0.640..  Test Loss: 0.657..  Test Accuracy: 0.720\n",
      "Epoch: 29/100..  Training Loss: 0.638..  Test Loss: 0.699..  Test Accuracy: 0.690\n",
      "Epoch: 30/100..  Training Loss: 0.645..  Test Loss: 0.636..  Test Accuracy: 0.720\n",
      "Epoch: 31/100..  Training Loss: 0.628..  Test Loss: 0.625..  Test Accuracy: 0.734\n",
      "Epoch: 32/100..  Training Loss: 0.631..  Test Loss: 0.660..  Test Accuracy: 0.720\n",
      "Epoch: 33/100..  Training Loss: 0.622..  Test Loss: 0.647..  Test Accuracy: 0.733\n",
      "Epoch: 34/100..  Training Loss: 0.614..  Test Loss: 0.640..  Test Accuracy: 0.703\n",
      "Epoch: 35/100..  Training Loss: 0.612..  Test Loss: 0.632..  Test Accuracy: 0.739\n",
      "Epoch: 36/100..  Training Loss: 0.615..  Test Loss: 0.624..  Test Accuracy: 0.748\n",
      "Epoch: 37/100..  Training Loss: 0.622..  Test Loss: 0.600..  Test Accuracy: 0.711\n",
      "Epoch: 38/100..  Training Loss: 0.621..  Test Loss: 0.636..  Test Accuracy: 0.719\n",
      "Epoch: 39/100..  Training Loss: 0.618..  Test Loss: 0.647..  Test Accuracy: 0.723\n",
      "Epoch: 40/100..  Training Loss: 0.613..  Test Loss: 0.690..  Test Accuracy: 0.702\n",
      "Epoch: 41/100..  Training Loss: 0.619..  Test Loss: 0.623..  Test Accuracy: 0.711\n",
      "Epoch: 42/100..  Training Loss: 0.604..  Test Loss: 0.613..  Test Accuracy: 0.733\n",
      "Epoch: 43/100..  Training Loss: 0.601..  Test Loss: 0.646..  Test Accuracy: 0.723\n",
      "Epoch: 44/100..  Training Loss: 0.607..  Test Loss: 0.686..  Test Accuracy: 0.688\n",
      "Epoch: 45/100..  Training Loss: 0.607..  Test Loss: 0.672..  Test Accuracy: 0.716\n",
      "Epoch: 46/100..  Training Loss: 0.607..  Test Loss: 0.674..  Test Accuracy: 0.710\n",
      "Epoch: 47/100..  Training Loss: 0.639..  Test Loss: 0.624..  Test Accuracy: 0.723\n",
      "Epoch: 48/100..  Training Loss: 0.618..  Test Loss: 0.628..  Test Accuracy: 0.724\n",
      "Epoch: 49/100..  Training Loss: 0.605..  Test Loss: 0.637..  Test Accuracy: 0.721\n",
      "Epoch: 50/100..  Training Loss: 0.612..  Test Loss: 0.648..  Test Accuracy: 0.751\n",
      "Epoch: 51/100..  Training Loss: 0.594..  Test Loss: 0.620..  Test Accuracy: 0.735\n",
      "Epoch: 52/100..  Training Loss: 0.611..  Test Loss: 0.600..  Test Accuracy: 0.727\n",
      "Epoch: 53/100..  Training Loss: 0.601..  Test Loss: 0.613..  Test Accuracy: 0.750\n",
      "Epoch: 54/100..  Training Loss: 0.612..  Test Loss: 0.626..  Test Accuracy: 0.731\n",
      "Epoch: 55/100..  Training Loss: 0.608..  Test Loss: 0.617..  Test Accuracy: 0.736\n",
      "Epoch: 56/100..  Training Loss: 0.603..  Test Loss: 0.634..  Test Accuracy: 0.728\n",
      "Epoch: 57/100..  Training Loss: 0.606..  Test Loss: 0.590..  Test Accuracy: 0.726\n",
      "Epoch: 58/100..  Training Loss: 0.604..  Test Loss: 0.595..  Test Accuracy: 0.746\n",
      "Epoch: 59/100..  Training Loss: 0.579..  Test Loss: 0.621..  Test Accuracy: 0.705\n",
      "Epoch: 60/100..  Training Loss: 0.589..  Test Loss: 0.610..  Test Accuracy: 0.727\n",
      "Epoch: 61/100..  Training Loss: 0.601..  Test Loss: 0.619..  Test Accuracy: 0.710\n",
      "Epoch: 62/100..  Training Loss: 0.605..  Test Loss: 0.610..  Test Accuracy: 0.751\n",
      "Epoch: 63/100..  Training Loss: 0.595..  Test Loss: 0.629..  Test Accuracy: 0.732\n",
      "Epoch: 64/100..  Training Loss: 0.590..  Test Loss: 0.606..  Test Accuracy: 0.716\n",
      "Epoch: 65/100..  Training Loss: 0.602..  Test Loss: 0.609..  Test Accuracy: 0.736\n",
      "Epoch: 66/100..  Training Loss: 0.600..  Test Loss: 0.650..  Test Accuracy: 0.708\n",
      "Epoch: 67/100..  Training Loss: 0.598..  Test Loss: 0.607..  Test Accuracy: 0.727\n",
      "Epoch: 68/100..  Training Loss: 0.580..  Test Loss: 0.598..  Test Accuracy: 0.738\n",
      "Epoch: 69/100..  Training Loss: 0.613..  Test Loss: 0.626..  Test Accuracy: 0.720\n",
      "Epoch: 70/100..  Training Loss: 0.583..  Test Loss: 0.627..  Test Accuracy: 0.722\n",
      "Epoch: 71/100..  Training Loss: 0.590..  Test Loss: 0.605..  Test Accuracy: 0.742\n",
      "Epoch: 72/100..  Training Loss: 0.599..  Test Loss: 0.594..  Test Accuracy: 0.744\n",
      "Epoch: 73/100..  Training Loss: 0.594..  Test Loss: 0.643..  Test Accuracy: 0.715\n",
      "Epoch: 74/100..  Training Loss: 0.625..  Test Loss: 0.608..  Test Accuracy: 0.715\n",
      "Epoch: 75/100..  Training Loss: 0.588..  Test Loss: 0.649..  Test Accuracy: 0.709\n",
      "Epoch: 76/100..  Training Loss: 0.602..  Test Loss: 0.580..  Test Accuracy: 0.759\n",
      "Epoch: 77/100..  Training Loss: 0.585..  Test Loss: 0.617..  Test Accuracy: 0.720\n",
      "Epoch: 78/100..  Training Loss: 0.578..  Test Loss: 0.594..  Test Accuracy: 0.743\n",
      "Epoch: 79/100..  Training Loss: 0.586..  Test Loss: 0.603..  Test Accuracy: 0.728\n",
      "Epoch: 80/100..  Training Loss: 0.586..  Test Loss: 0.605..  Test Accuracy: 0.738\n",
      "Epoch: 81/100..  Training Loss: 0.604..  Test Loss: 0.613..  Test Accuracy: 0.727\n",
      "Epoch: 82/100..  Training Loss: 0.589..  Test Loss: 0.602..  Test Accuracy: 0.745\n",
      "Epoch: 83/100..  Training Loss: 0.599..  Test Loss: 0.583..  Test Accuracy: 0.715\n",
      "Epoch: 84/100..  Training Loss: 0.606..  Test Loss: 0.591..  Test Accuracy: 0.726\n",
      "Epoch: 85/100..  Training Loss: 0.592..  Test Loss: 0.622..  Test Accuracy: 0.729\n",
      "Epoch: 86/100..  Training Loss: 0.595..  Test Loss: 0.608..  Test Accuracy: 0.716\n",
      "Epoch: 87/100..  Training Loss: 0.584..  Test Loss: 0.603..  Test Accuracy: 0.727\n",
      "Epoch: 88/100..  Training Loss: 0.590..  Test Loss: 0.636..  Test Accuracy: 0.736\n",
      "Epoch: 89/100..  Training Loss: 0.587..  Test Loss: 0.630..  Test Accuracy: 0.722\n",
      "Epoch: 90/100..  Training Loss: 0.571..  Test Loss: 0.600..  Test Accuracy: 0.724\n",
      "Epoch: 91/100..  Training Loss: 0.584..  Test Loss: 0.637..  Test Accuracy: 0.724\n",
      "Epoch: 92/100..  Training Loss: 0.577..  Test Loss: 0.597..  Test Accuracy: 0.741\n",
      "Epoch: 93/100..  Training Loss: 0.580..  Test Loss: 0.606..  Test Accuracy: 0.738\n",
      "Epoch: 94/100..  Training Loss: 0.592..  Test Loss: 0.601..  Test Accuracy: 0.745\n",
      "Epoch: 95/100..  Training Loss: 0.572..  Test Loss: 0.603..  Test Accuracy: 0.732\n",
      "Epoch: 96/100..  Training Loss: 0.580..  Test Loss: 0.616..  Test Accuracy: 0.747\n",
      "Epoch: 97/100..  Training Loss: 0.601..  Test Loss: 0.605..  Test Accuracy: 0.737\n",
      "Epoch: 98/100..  Training Loss: 0.580..  Test Loss: 0.610..  Test Accuracy: 0.742\n",
      "Epoch: 99/100..  Training Loss: 0.574..  Test Loss: 0.608..  Test Accuracy: 0.749\n",
      "Epoch: 100/100..  Training Loss: 0.579..  Test Loss: 0.601..  Test Accuracy: 0.752\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3iUVfbA8e9N7wkpkEBooUMIEEKTXkRQkWIBxF74qei6thVd18Kqa1tFlFWxYEMQG6JSBEV6C0iHQCBAAglpBNKTyby/P+5M6qQSwEnO53l4kpl55507SThz33PPvVcZhoEQQgj753C5GyCEEKJ+SEAXQogGQgK6EEI0EBLQhRCigZCALoQQDYQEdCGEaCCqDehKqU+UUslKqX2VPD5NKbXH8m+TUqpH/TdTCCFEdWrSQ/8UGFPF43HAUMMwIoB/A/PqoV1CCCFqyam6AwzDWKeUalPF45tK3dwChNbkhQMDA402bSo9rRBCCBt27NiRahhGkK3Hqg3otXQ3sLwmB7Zp04bo6Oh6fnkhhGjYlFInKnus3gK6Umo4OqAPquKY6cB0gFatWtXXSwshhKCeqlyUUhHAR8B4wzDSKjvOMIx5hmFEGYYRFRRk84pBCCFEHV1wQFdKtQK+B241DOPwhTdJCCFEXVSbclFKLQSGAYFKqQTgOcAZwDCM94FngQDgf0opAJNhGFEXq8FCCCFsq0mVy9RqHr8HuKfeWiSEEKJOZKaoEEI0EBLQhRCigbC7gB6TlMkbK2NIzy643E0RQoi/FLsL6HGpWby7JpYz5/Mud1OEELWQlpZGz5496dmzJ8HBwbRo0aL4dkFBzTpod955JzExMVUeM3fuXBYsWFAfTWbQoEHs2rWrXs51KdT3TNGLzsNFNzk733SZWyKEqI2AgIDi4Pj888/j5eXF448/XuYYwzAwDAMHB9t9zfnz51f7OjNmzLjwxtopu+uhe7rqgJ4lAV2IBiE2Npbw8HDuu+8+IiMjSUxMZPr06URFRdGtWzdmzZpVfKy1x2wymfDz82PmzJn06NGDAQMGkJycDMAzzzzD7Nmzi4+fOXMmffv2pVOnTmzapJeeys7O5vrrr6dHjx5MnTqVqKioanviX375Jd27dyc8PJynn34aAJPJxK233lp8/5w5cwB466236Nq1Kz169OCWW26p959ZZeyuh+7lau2hF13mlghhv174aT8HTp+v13N2be7Dc+O61em5Bw4cYP78+bz//vsAvPLKK/j7+2MymRg+fDg33HADXbt2LfOcc+fOMXToUF555RUeffRRPvnkE2bOnFnh3IZhsG3bNpYuXcqsWbNYsWIF77zzDsHBwXz33Xfs3r2byMjIKtuXkJDAM888Q3R0NL6+vowaNYqff/6ZoKAgUlNT2bt3LwAZGRkAvPbaa5w4cQIXF5fi+y4FO+yhOwKSchGiIWnXrh19+vQpvr1w4UIiIyOJjIzk4MGDHDhwoMJz3N3dGTt2LAC9e/fm+PHjNs89adKkCsds2LCBKVOmANCjRw+6dav6g2jr1q2MGDGCwMBAnJ2dufnmm1m3bh3t27cnJiaGhx9+mJUrV+Lr6wtAt27duOWWW1iwYAHOzs61+llcCLvtoUvKRYi6q2tP+mLx9PQs/v7IkSO8/fbbbNu2DT8/P2655Rby8ioWQbi4uBR/7+joiMlkOya4urpWOMYwjFq1r7LjAwIC2LNnD8uXL2fOnDl89913zJs3j5UrV7J27Vp+/PFHXnzxRfbt24ejo2OtXrMu7LCHLoOiQjRk58+fx9vbGx8fHxITE1m5cmW9v8agQYNYvHgxAHv37rV5BVBa//79WbNmDWlpaZhMJhYtWsTQoUNJSUnBMAxuvPFGXnjhBXbu3ElRUREJCQmMGDGC119/nZSUFHJycur9Pdhidz10Z0cHXJwcyCqQgC5EQxQZGUnXrl0JDw8nLCyMgQMH1vtrPPTQQ9x2221EREQQGRlJeHh4cbrEltDQUGbNmsWwYcMwDINx48ZxzTXXsHPnTu6++24Mw0ApxauvvorJZOLmm28mMzMTs9nMk08+ibe3d72/B1tUbS896ktUVJRR1w0uIv+9iqu7B/PihO713CohRGNgMpkwmUy4ublx5MgRRo8ezZEjR3By+uv3cZVSOypbAPGv33obPFwcpcpFCFFnWVlZjBw5EpPJhGEYfPDBB3YRzKtjl+/Ay9VJcuhCiDrz8/Njx44dl7sZ9c7uBkVBD4xmSw5dCCHKsNuAniUpFyGEKMMuA7qXq6OkXIQQohy7DOieLpJDF0KI8uwzoLs6yUxRIezMsGHDKkwSmj17Ng888ECVz/Py8gLg9OnT3HDDDZWeu7oy6NmzZ5eZ4HP11VfXyzorzz//PG+88cYFn6c+2GVAt1a5XK4aeiFE7U2dOpVFixaVuW/RokVMnVrltsXFmjdvzrffflvn1y8f0JctW4afn1+dz/dXZJcB3dPVCbMBeYXmy90UIUQN3XDDDfz888/k5+cDcPz4cU6fPs2gQYOK68IjIyPp3r07P/74Y4XnHz9+nPDwcAByc3OZMmUKERERTJ48mdzc3OLj7r///uKld5977jkA5syZw+nTpxk+fDjDhw8HoE2bNqSmpgLw5ptvEh4eTnh4ePHSu8ePH6dLly7ce++9dOvWjdGjR5d5HVt27dpF//79iYiIYOLEiZw9e7b49bt27UpERETxomBr164t3uCjV69eZGZm1vlna2WXdejWFRez8k24u1z8BW+EaHCWz4SkvfV7zuDuMPaVSh8OCAigb9++rFixgvHjx7No0SImT56MUgo3Nzd++OEHfHx8SE1NpX///lx33XUopWye67333sPDw4M9e/awZ8+eMsvfvvTSS/j7+1NUVMTIkSPZs2cPf/vb33jzzTdZs2YNgYGBZc61Y8cO5s+fz9atWzEMg379+jF06FCaNGnCkSNHWLhwIR9++CE33XQT3333XZXrm99222288847DB06lGeffZYXXniB2bNn88orrxAXF4erq2txmueNN95g7ty5DBw4kKysLNzc3Grz07bJPnvosmuREHapdNqldLrFMAyefvppIiIiGDVqFKdOneLMmTOVnmfdunXFgTUiIoKIiIjixxYvXkxkZCS9evVi//791S68tWHDBiZOnIinpydeXl5MmjSJ9evXA9C2bVt69uwJVL1EL+j12TMyMhg6dCgAt99+O+vWrStu47Rp0/jyyy+LZ6QOHDiQRx99lDlz5pCRkVEvM1XttIduCegyuUiIuqmiJ30xTZgwgUcffZSdO3eSm5tb3LNesGABKSkp7NixA2dnZ9q0aWNzydzSbPXe4+LieOONN9i+fTtNmjThjjvuqPY8VY3FWZfeBb38bnUpl8r88ssvrFu3jqVLl/Lvf/+b/fv3M3PmTK655hqWLVtG//79Wb16NZ07d67T+a2q7aErpT5RSiUrpfZV8nhnpdRmpVS+UupxW8fUN9m1SAj75OXlxbBhw7jrrrvKDIaeO3eOpk2b4uzszJo1azhx4kSV5xkyZEjxRtD79u1jz549gF5619PTE19fX86cOcPy5cuLn+Pt7W0zTz1kyBCWLFlCTk4O2dnZ/PDDDwwePLjW783X15cmTZoU9+6/+OILhg4ditlsJj4+nuHDh/Paa6+RkZFBVlYWR48epXv37jz55JNERUVx6NChWr9meTXpoX8KvAt8Xsnj6cDfgAkX3Joakl2LhLBfU6dOZdKkSWUqXqZNm8a4ceOIioqiZ8+e1fZU77//fu68804iIiLo2bMnffv2BfTuQ7169aJbt24Vlt6dPn06Y8eOJSQkhDVr1hTfHxkZyR133FF8jnvuuYdevXpVmV6pzGeffcZ9991HTk4OYWFhzJ8/n6KiIm655RbOnTuHYRg88sgj+Pn58a9//Ys1a9bg6OhI165di3dfuhA1Wj5XKdUG+NkwjPAqjnkeyDIMo0YFmReyfO6RM5lc+dY63pnai3E9mtfpHEIIYY+qWj7XPgdFZdciIYSo4JIGdKXUdKVUtFIqOiUlpc7n8ZR9RYUQooJLGtANw5hnGEaUYRhRQUFBdT6Pp4s1hy6DokIIYWWXKRcnRwdcnRykbFEIIUqptspFKbUQGAYEKqUSgOcAZwDDMN5XSgUD0YAPYFZK/R3oahjG+YvWanTpoqRchBCiRLUB3TCMKlfOMQwjCQittxbVkKdsQyeEEGXYZcoFrAFdcuhCCGFltwFddi0SQoiy7Dagy0bRQghRll0HdBkUFUKIEnYb0L1kX1EhhCjDbgO6h6ujDIoKIUQpdhvQvSw5dNlXVAghNLsN6J6uThgG5BRIL10IIcDOAzrIiotCCGFlfwH9wI/wYjOCC04CsuKiEEJY2V9Ad3QFUx7eSu8TKCkXIYTQ7C+gu3oD4KX0Zq3SQxdCCM0OA7oXAJ6GDuiSQxdCCM0OA7ruoXsYOYD00IUQwsoOA7oPAG6WgC6Ti4QQQrPDgK576K5ma0CXHroQQoA9BnQnV3B0wcWUDUjKRQghrOwvoAO4eOFQkIm7s6yJLoQQVvYZ0F29IT9T1kQXQohS7DSg+0B+Fl6ujmTJoKgQQgB2G9C9If88nq5O5EjKRQghALsO6Jmya5EQQpRipwHdSwd0F0fJoQshhIWdBvRSg6KSQxdCCKAGAV0p9YlSKlkpta+Sx5VSao5SKlYptUcpFVn/zSzH1RsKsvCSlIsQQhSrSQ/9U2BMFY+PBTpY/k0H3rvwZlXD1QcKc/BykZmiQghhVW1ANwxjHZBexSHjgc8NbQvgp5QKqa8G2mSZ/t/EqYCcgiLMZtlXVAgh6iOH3gKIL3U7wXJfBUqp6UqpaKVUdEpKSt1f0UUvodvEwbKErgyMCiFEvQR0ZeM+m11mwzDmGYYRZRhGVFBQUN1f0dJD93XUuxbJwKgQQtRPQE8AWpa6HQqcrofzVs4S0L1VPiALdAkhBNRPQF8K3GapdukPnDMMI7Eezls5y5roXuiUS46kXIQQAqfqDlBKLQSGAYFKqQTgOcAZwDCM94FlwNVALJAD3HmxGluszL6iHmTmSUAXQohqA7phGFOredwAZtRbi2rCsq+ot2Wj6HO5hZf05YUQ4q/IfmeKAp6WbegyciSgCyGEfQZ0S9miu2UbuozcgsvZGiGE+Euwz4Du4AguXjiZsnFxcuCc9NCFEMJOAzqAqzeqIBM/d2dJuQghBPYc0F30Erp+Hs6SchFCCOw5oFuW0PVzd5EeuhBC0AACuq+Hs5QtCiEEdh/Qs/Bzl4AuhBBg9wHdkkOXlIsQQth7QD+Pn4cLuYVF5BXKiotCiMbNzgN6Jj5uevWC85J2EUI0cvYd0I0iAlx0zzxDAroQopGz74AO+DvrGnTJowshGjv7Deguln1FHfUmFxk5MrlICNG42W9AL96GTi+hKykXIURjZ/cBvXhNdEm5CCEaObsP6B7mHBwdlEwuEkI0enYf0FVBNr7uskCXEELYfUAn/7wsoSuEEDSIgC4LdAkhBNhzQHdyAwcnyxK60kMXQgj7DehKlSyhKzl0IYSw44AOOqAXZOHnIZtcCCFEjQK6UmqMUipGKRWrlJpp4/HWSqnflFJ7lFJ/KKVC67+pNriU9NAz80yYisyX5GWFEOKvqNqArpRyBOYCY4GuwFSlVNdyh70BfG4YRgQwC/hPfTfUpuIldJ0BOJ9nuiQvK4QQf0U16aH3BWINwzhmGEYBsAgYX+6YrsBvlu/X2Hj84ii1yQUglS5CiEatJgG9BRBf6naC5b7SdgPXW76fCHgrpQIuvHnVKLVRNMgCXUKIxq0mAV3ZuM8od/txYKhS6k9gKHAKqJD/UEpNV0pFK6WiU1JSat3YCiz7ivpaeuiyQJcQojGrSUBPAFqWuh0KnC59gGEYpw3DmGQYRi/gn5b7zpU/kWEY8wzDiDIMIyooKOgCmm1R3EO3pFyk0kUI0YjVJKBvBzoopdoqpVyAKcDS0gcopQKVUtZzPQV8Ur/NrISrNxRm4+fmCEjKRQjRuFUb0A3DMAEPAiuBg8BiwzD2K6VmKaWusxw2DIhRSh0GmgEvXaT2lmWZ/u/jkAdIykUI0bg51eQgwzCWAcvK3fdsqe+/Bb6t36bVgCWgOxVm4e3mJJOLhBCNmv3PFAUoyMLXXRboEkI0bvYd0C37ipKnJxdJDl0I0ZjZd0D3tJS6Z6fg5+4iOXQhRKNm3wHdu7n+mpkoa6ILIRo9+w7onoGgHCEzET93Z6lDF0I0avYd0B0cwTsYzifqHHpuIYZRfhKrEEI0DvYd0EEH9MxE/NxdKDIbZOXLiotCiMapAQT0kOIcOiC16EKIRsv+A7pP8+IcOsgSukKIxsv+A7p3MOSdw9+lCJAeuhCi8WoAAV2XLgaYUwE4K5OLhBCNVAMI6MEANClKB2TFRSFE42X/Ad1H99C9CpIBSMuWgC6EaJzsP6B7hwDglH0GHzcnzkpAF0I0UvYf0F29wdkTMhPx93QhXQZFhRCNlP0HdKXAJ6Q4oEsPXQjRWNl/QAeddjlv6aFLQBdCNFINJ6BnnqaJh4uULQohGq0GEtCDITMJfw9n0rMLZIEuIUSj1DACuk9zKCogxCWHfJOZnIKiy90iIYS45BpGQLeULoY4ZABIHl0I0Sg1qIAehJ4tKnl0IURj1DACuo8O6P5mHdClhy6EaIwaRkD30uu5+BamANJDF0I0TjUK6EqpMUqpGKVUrFJqpo3HWyml1iil/lRK7VFKXV3/Ta2Ckwt4BOKRr9dzSc+W2aJCiMan2oCulHIE5gJjga7AVKVU13KHPQMsNgyjFzAF+F99N7RaPiG45JzB0UHJbFEhRKNUkx56XyDWMIxjhmEUAIuA8eWOMQAfy/e+wOn6a2INeYegMhNp4uEsKy4KIRqlmgT0FkB8qdsJlvtKex64RSmVACwDHqqX1tWGdwhkJunZohLQhRCNUE0CurJxX/mpmFOBTw3DCAWuBr5QSlU4t1JqulIqWikVnZKSUvvWVsU7BLJTCPRwIF0GRYUQjVBNAnoC0LLU7VAqplTuBhYDGIaxGXADAsufyDCMeYZhRBmGERUUFFS3FlfGJwQwaOuaKT10IUSjVJOAvh3ooJRqq5RyQQ96Li13zElgJIBSqgs6oNdzF7walslFLZ3PSdmiEKJRqjagG4ZhAh4EVgIH0dUs+5VSs5RS11kOewy4Vym1G1gI3GFc6hWyLAG9uUMGZ3MKMZtlgS4hROPiVJODDMNYhh7sLH3fs6W+PwAMrN+m1ZJ1+r/KoMjcisw8E74ezpe1SUIIcSk1jJmiAB4B4OBEgDkNQAZGhRCNTsMJ6A4O4NUMH5MloGfnX+YGCSHEpdVwAjqAVzO8ClIBmf4vhGh8GlZA9w7BNc+yQJeULgohGpkGFtCb4ZxzBpAcuhCi8WlgAT0ElZuOl1OR9NCFEI1OwwroXs0A6OCRLZtcCCEanYYV0C216G1cs2S2qBCi0WlgAV330Fu7nJcldIUQjU4DC+iW6f+O5ySHLoRodBpWQPcIBOVIsDorOXQhRKPTsAK6ZbZogHGW83kmCovMl7tFQghxyTSsgA7g3Qy/Ij39PyNHZosKIRqPBhjQQ/C2rOdirXQ5l1PIpV7NVwghLrWGF9C9muFumf5/NDmLfy3ZR+SLq3h1RcxlbpgQQlxcNVoP3a54h+Ccn44zJh74aicOStE+yIt5645yTfcQuof6Xu4WCiHERdHweuiWWvQ2blkM6RDEiocHs/i+AQR6ufLkd3tkoFQI0WA1wICua9F/vbsjn93Vlw7NvPF1d2bW+G4cSDzPxxviLnMDhRDi4mh4Ad2ynovKSipz95jwEEZ3bcZbqw5zPDX7crRMCCEuqoYX0C09dDKTKjw0a3w4Lo4OzPr5wCVulBBCXHwNL6B7BoJysBnQg33deHBEe34/lMz6IymXoXFCCHHxNLyA7uCo0y5ZFQM6wB0D29DS352XfjlIkVlq04UQDUfDC+igA7qNHjqAq5MjT43twqGkTBZHx1/ihgkhxMXTMAO6dwhknqn04bHhwUS1bsJ/f40hM0/PIs3ON8lsUiGEXatRQFdKjVFKxSilYpVSM208/pZSapfl32GlVEb9N7UWvJtBZmKlDyul+Ne1XUnNKqDvS7/R7ulldHtuJU98u+cSNlIIIepXtTNFlVKOwFzgSiAB2K6UWmoYRnGpiGEYj5Q6/iGg10Voa815h0BOKhQVgqOzzUN6tPTjxQnhxCZn4e3mRPTxs/yyJ5EXJ4Tj5ux4iRsshBAXriY99L5ArGEYxwzDKAAWAeOrOH4qsLA+Gldnllp0sipPuwDc0r81z1/XjcdGd2LG8PbkFhax7vAFVr9kxMOyJ/SHiRBCXEI1CegtgNKjhwmW+ypQSrUG2gK/X3jTLkBxLXrVAb20fmH++Lo7s2K/7cHUGju4FLbNgzP7L+w8l1pOOnz/f/qrEMIu1SSgKxv3VTZ6OAX41jCMIpsnUmq6UipaKRWdknIR68At67lUlUcvz9nRgVFdmrH6wBkKTBew3ku6ZWmBc5eogiYrWV8VXKhDv8CeRRC39sLPJYS4LGoS0BOAlqVuhwKnKzl2ClWkWwzDmGcYRpRhGFFBQUE1b2VtNWkLTm6w4S0oqPk0/7HhwZzPM7HlWFrdX/usJaDXR5CtiYVT4etpF36e+K36a1rshZ9LCHFZ1CSgbwc6KKXaKqVc0EF7afmDlFKdgCbA5vptYh24+8H1H8HpnbD49hrnswd1CMTDxbFM2qXIbJBbYPOCwzZrDz3jZG1aXDendsCpaDhz4MJz9taAnnqZA/qhX2B2BBTkXN52CGGHqg3ohmGYgAeBlcBBYLFhGPuVUrOUUteVOnQqsMj4qxRzdxkH17wJsavgxwfBXH0axc3ZkeGdm/Lr/jMUmQ3i03MYM3sdUz7cUrPXNBeVBPJLkXLZ9pHldQsh7Wjdz5OTDqmH9feXu4d+aBlknID0Gr4fw4C930LeuYvbLiHsQI02uDAMYxmwrNx9z5a7/Xz9NaueRN0J2Smw5iXIz4Rr3wTv4CqfMjY8mF/2JDJ/Yxzvrz1Kapbexu5URi4t/NyLj0vOzONQYiZDOpZKHZ1L0MEVLn4PPTsN9n0HoX0hYRskH4Cmnet2roTt+mtQZ0g7ooOksjV0cgmcitZf0+MguHv1x5/+E767G7pNhBs/vahNE+KvrmHOFC1tyBMw+kU4+hvM7Qt/fqkDViWGdWqKi5MDL/5yEHcXR96/JRKgQjnjaytiuH3+NlKz8kvutObPAzpc/B76n19AUT6MfVUvRpZyqO7nit8KyhG636h7ujkXMIZwIfLOQ4plq8D0YzV7zklLhm//D7Dv+4vTLiHsRMMP6ErBFQ/BfRuhaTf4cQZ8cwcU5to83MvViZuiQhnYPoAfHhjIVd2CCfF1KxPQC0xmft2fhGHA2phSgd6aP287BHLPQn5W7dtbmFt9eshcBNEfQ+tB0CIS/MN0D72u4rdBSAQER+jblyvtcvpPiguoztZwI5KTm8G3FTSPhF8e01U/QjRSDT+gWwW2hzt+gVEvwIEl8Pl4nbaw4cUJ3VlwT38CvVxRSjGkQxAbYlMxWbav23wsjciCaN52fpffD5WqdT8bBw7O0Kq/vl3bXnp+JszuDlvfq/q4I6t0SqfvPfp20y6QXMceelGhHlxt2R8C2un7LldAt6ZbAtqXfDhWxTDgxGZoMxAmvKcrmn5+RP9s/lygvz/958VtsxB/IY0noAM4OMCgv8ONn0Hibvh4VI0u7Yd0DCIzz8SueL1EzfK9iVzvvJnxjpuIO7KvZJ/S9Dho0hr8WuvbtS1d3L9E5/wPr6z6uJ2fg1cwdL5W327aVQ8iFubV7vUAkvZCYQ607Kvb7eB8+QJ6wg4dzJtH1iygpx3VSzy06q/HD0b8Ew79rD8Uf3wAoj/R/4RoJBpXQLfqNgFu/0mnRb65s9oUx6D2gTgonUc3FZlZuT+J3m6nAOhUcJAdJ87qA8/GQZO2FHiH6tsZJ2rXrj+/0F/jt4GpoPLjEndBu+El69QEdQbDXFKpUhvx2/TXlv3A0Qn820Lqkdqf50IZhu6ht+it23A+AUz5VT/Hmj9vNUB/HfAgDJ0JY16F+zfp1FfS3ovbbiH+QhpnQAfdIx37mg6Ou6teesbXw5meLf1YeySVrXHpZOXkElygq1j6OB5hTUyyDkjpxzlSGETv2XswO7jULuWSEqMHJ0P7gilXX0HYUpAD50+VpEdA99ChbgOj8VvBJxR8Las5BLS/sBLIujqXoNfeaRGlxwQMc/WVQie3gLs/BHbUtx0cYfhT0P8+aNZNjwmcOQBFpovffiH+AhpvQAdd1RHaB357QeevrU5shlM7yxw6pGMQexIy+GrrScJdEnEwTODgzEDXo6w5lKwrQwoy+eGEC5n5ZpIIwHy2FqWLf34JDk4wbra+fXKT7eOsKSL/UgE9oJ1OldRlYDR+m/5wK32u9GN64PVSsubPQ3vrmb5Qfdrl5CbdO6+sxDI4QlcC1eXKRQg71LgDulL68jzrDKx/U6de/ngV5o/RM0xLlTcO6RiEYcAvexOZ0Nyy3HuXcbQyHef0mWSSTxwE4EhhII9e2ZG4Qn9SEmqYiy4q1FcJHcfonmVABzhRSUC35rcD2pfc5+gMgR1qPzB6LkGnNlr2K7kvoIMOgrauLkz5MLc/bP2gdq9TEwnR4OgKzbrrlAtUPb6ReUY/bh2AtiXEUrUjaRfRSDTugA66RxgxBTa/C1/dCH+8DEFd4NzJMoGgR6gfvu46Zz3YO0kHn543ozDo6XCU3zbpqfO9ekTy0Ij2GL4tUecSOJlWgynsh1fqwdBet+rbrQfoqwRbvWRrQPcPK3t/UOfa99CtHxpleujty75OafFbIeUgrHiq8g+cujq1UwdgJxfwDAIXr6pLF+Mts3et+XNbAjro31OSbFwiGgcJ6ACjntMpi6NrdI/99p/0ZJ1DPxcf4uigGNwhEHdnR1oXHtOlgi37YaAY4RlHYpzuod8ydjBKKXqEh9NUneW5H3ZUuRl1fHoOu396l1zXIGg/St/ZeiDknyM9bhd5heWCetpR8G4Orl5l72/aVQ/C1lh+XqQAACAASURBVKb2/fAK8AiEkB4l9xUHdBt59KNr9AQkv1bw7V2QVU8rZhaZ9FhGiyh9Wymddqkq5XJiMzi5l217eY5O0Kyr9NBFoyEBHcCnOdz6PdyzWg+oeQXpuuxDv5Q57F/XdmXh9P44phyA4HBw80E168YQ9zhaO5whx60ZPt4+AHg30z3oY0cPM+rNtSzadpJ8U9ngvCk2ldveWUa37K18mt2fJ77fT06BifRAHdjmzP+cF38p1+tOiy07IGrVtIv+mhpT8bHsVIhZAcD24+lc/fZ6Yk6lw5HVOs3jUGqHJq+m4Opju9Ll2Bo95jD5C10h9N3d9ZNrTz6gSydDo0ru829bdcrl5GZ9vJNL1ecO7q4Dek2WGCrM0+/Lnp3cAr88XrP3Wx9if5Na/78QCehWrfrrWZdWna+BM/vK9BKb+bjR0y9fp0eahes7Q/sQlneAQf7ncG9aKtD6tQLgtZF+eLo6MvP7vQx8ZQ33f7mDt1Yd5s1fY7j1k21c6XYAJ2XGt9ckvt2ZwNVvr2fIvKOcNgIY7HKYZXuTiic0AZaAXip/bmUN6MkHKz72+79h4WQ4s5/vd57iQOJ5Zn/yGeSfg05jyh6rFAS0oyC53EBiTjqc3gXtRuggefXreu30nx6uusSyJqzpmxa9S+7zb6uvOGx9YORn6jRKVflzq+AIyE2H85Wt+GyRdx4+GAKfjrt0wfBiiJ4P2z+Es8cv/msZBnw/HX5/8eK/lqgRCeiV6XyN/lqul84Zy+W7NaC37IdDQSbNzu9Hlc5r++kl5Pv5Z/PTg4P44u6+9G3bhENJmcz5/Qhzfo9lROemPNH+FLg34eaJ4/nirn4UmMz0D/PHu+NQBjkfJj07n+3HLb3GnHQdnGwF9CZt9Brw5QN6YR7s+0F/v/1jth5Lo1tzH64o2k4BTiQHXVHmcFORmX15QSQf38/i6FIDo8f+AAxd/w463z/4MV07/9m1kFnHnZ7it+kqo+a99Huw8g+DogJdolneyS26rLGq/LmVdYGvqtIuZjP88H/66ubMXtsfivbCOraQEF2/503aW3FFy/RjemJXTdfdERedBPTK+LfVQbtUHh0o2VquWTf91TqgaBSBf5uS43xa6Dx8RjxKKQZ3COJ/03qz5vFhHJw1hrVPDOODaZE4x/0BYcPBwZFBHQLZOHMEH93eB+9OQ3DNT6WjUzIrreuzW/PatgK6g6Ouxy4fjA4v1z3xgA6Ydy/iTGoqE3o05yaf/Ww1wpn62V4Wb48n+XweqVn53PLxVlad8aa5SuPdlXtK1oI/tgZcffUsTtA9+ZHPwg3z9X/2D4aWTFKqqTMHYMGNegXMmxeXLT+sqnTxyCqdP289sPrXsPye0o9Fcy6nkjXj174KMcv0Qm7KQS8NYY8yz5T0zBNq+buoSmEefDQK1rxc9n7r7zvj5KUvcxU2SUCvSudrdW+w9OBf0j4drD389W3/MD2wCCVBCHQpoXeIzfI/N2dHWgd44pByALKSoP3I4seUNai11j3nacEJrNiXhNlsFFeemP3bsfPkWf6z7CDDXl/DtI+26LRMcIReCrf0GjW7Fur2jp+LQ2E2Ex03MDQgA9fzx2nRbyK5BUX847s99H35N4a+toY/T2YwsH9/HDBwzzrJp5uO60vro39A28F6oLG08El67MHZDT69Vi/pWxNnj8MXE8HZHW5donP3pVmvdmxVuhz5VbfF2a3613H1xvAPY8fWdTz5nY1ql4M/wdpXoOc0GP5P/SFx4MeavYe/GmsQd29SsiRyfUjeD6Y8iF1d9n7r1YDZpEtg/4qSD1Y/nyH9GMTX48/rMpKAXpXO1wCG7r1ZndlXkm4B3au01nH7ty3zdHxbVr2ey9Hf9Nd2Iyo+FtgRPJsywmU/Sefz2HPqHKTFYihH7voxmUn/28THG+Jo4unCxtg0Plh3DK54UA8u/vaCPkdWsv5PGHETtOzLKfeO3O60mvYZGwAIG3gDG2eOYNnfBvPEVZ0Y1bUZ391/BX376p7vw0E7ee+PWDJPxegyTmu6pbxm3eCe33Xa5Nu7YP1/q89D//GKXkzr1h/0+jfl+TQHR5eKl/NpR3WQb39l1ecvJd2rEx3Mx/n1QBLx6aXKSHd9pVfebNFbb4aiFHQdr2fc1nWxM9D5+DX/qdtqmxfi5BZLOe00yxo9tlcUrTXrrOW02LKzd+O36as2qPnqmJeSuQg+Gwdz+8HGOZVfRSz7B3x1U402wfmrk4BeleDuenBzz9e6tM5kmXVoTbdYtR2i/yP5l6s+8WupA2FlYlfrckOf5hUfUwq6XEtoyjq8HApYsS8J0mI559aCP2IzeOKqTux45kq+v/8Kru4ezOzVhzlY1AL63Qc7PycnbhsZ2xbqVFDEFFCKr8yj6aDicdj8jn5vvqEopeja3IcZw9vz9pRehLfw1W3qfQdXn1/MVYWr2bzqGwCO+fTl7dVHOJR0vmJ7PQPgth8h/Ab4bRYsfbDywVLD0Dn5DleWDOaW5+Coc+rle1dHVumvHWoe0PeZW9HG4QzeKpcvtpzQr7/mP7DkfmgzSH+oWHv7XcYB6sJ66ete173+mOV1P0ddxG/TH6ptBule8+ld9XPexN16FjPo0lWA3Azd++02Xt+uyWJql1riLl3A0KQ1rPoXzB9bsZ2mAj0on5uuN3excxLQq6IU9J8BJzbC4lv1H7bZpEsWS+tzDzy4Te9lWppvS11dYWstkYJs3aOy1Tu36jYRVZjD9JBYVuxLJDfpMH9mB3BN9xAeGNYOXw9nlFK8OKE7vu4uPLp4N3kDHyfXNYBjn91P4tqPKWzWE5p2Jvl8Hh+f602+k5f+I+84tur3ffUbEDacV5w/pt3xr0hyaMaI+Sd5a/Vhbnx/M9HH0ys+z9lN7+U65B96KYMvJuqB3PLSYiEzEcKGVt4GsF2LHrtKjyGUvxqqwq/pzQC4PSyL6G0bMC2cVpJmufkbcPMtOdg7WA+21jWgZ5wsmUl7qp4HJjf/T1/92FKYpwNYy74l9fxVpV3MRTrtFbtap+WqXAxut/6ZeDeHo7/r+05FA4beKcrR5a/ZQ4/9HVBw53KYOE9fdS25v+wxp3dCoWUj+ZOXfzvkCyUBvTr979PBLWa5HsADPT29NEenshUaVn6t9AdAZmLFx45v0FUc1slEtrQeCJ5BjHfayom0LEg/SqJTC16aGF6Sawf8PV14ZVJ3Diae54q3onkq8ybCiaWLOsEyh2EAbIlLJw9XzneerJ9UvlyxPEdnuOkzzP7taadOs8ulF8+P68bPDw0iyMuVWz7eyh8xNjaTUEovYzvpQ53T/WhkxZr2Y3/or22HVN0G/zAdKKzpm4IciFtfq3TLqYxcVlkC+oxz/+V7HteprpHPwfi5tuvYu47XeePqVp088KNeCqF0HfbvL+qfQWDH+q00OZcAq5/TA5O2KooSd+m/p5b99DyKJm0qHxhN3AP/aQlv94Avr4cl9+kNU2wpKtSFAM176pRb3Fo2xJwhI2a9HkAOtSy7/FfsoR/9TU888wyEHpNhwAzdicostYfBsbWA0h/qJ2u4d/BfmAT0muh7L9z0uc5JOrlVnHZfGWvJ3G8vVMzPxf6mKzWqKr1zcISu42mVtoEwh0Tcyadv7z74eVQMQqO6NuO2Aa3xdnNi1OQHMVoNoEg5Met4Z46cyWTrsTS8XZ1oMuYZ3VtpHmnjBctx88X5tm8xQvsyZurfuWNgW8Jb+LL4vgGEBXpx7+fR/LjLRlkh6Lz97T/rfPLi28AwWHs4hf8sO8jhLb9w3jWE7+OcySmoYiVE/7ZQkFUSWI9v0OvM1CLd8kdMMsn4UejTChdTFgvcp3GT+0cYgx6pfFGvrpa9z6uqdkk7Cktm6KUQPrtOpzsSd+v0XP/7oeNVula+qiWAs1Jqnre1jkuYTbDj04qPx+ulJ4rHc0L76oE+W2MZuxfqvW/HzYE7lukxhO0f2W5LyiH9QRHSU19N5p5l9hffkLhvnR5LcvXSv6dL3UO3rrtU2cqgeef076RUwQFdrkWPiZUqRY5bp5ecaDtEeuiNStfr4O6VOrCXr/SoTGiULu3b+w0sKzd77+hvOtdZXaVGt4koUy4vB68HoH2XnpUeOmt8OGufGM61PVqgbvqc7ClLKHDx59UVh9hyLI0+bf1x8vLXvZWabgLt1wp1zyq9voxFoJcri/6vP71aNeHhRbuYvfowhq3A0aqfXlYh+QDzvlrE7Z9sY/7GozRN28aK7I48+s0e+r70G88s2WszL7/GiCTbwRvzl9frweXYVeDsUbNyRes5DqUQ2sQDp/vXoR49gNuop9mZ6sDG2Cr2TfVprgPjvu9tB0RTgR78dXCEu1bqHuDnE2DJA3o530GP6LRHUYGuirIlO1X3kL+eVnGwbv8SvdmHVcZJ2PkFRN6mr06iP6mYIonfpjsaXpZNy0P76Aqq8tUnZrM+f/sroffterenvv+n02Bxf1Rsp3VANKQntNUpsiuMP2mVewDD+uHRpC2kH7+0E7Lit+p1l769S19FlHdsrR4/Kn0F3LSrbutBSylyQY6+imk7RHeszh6H8zaupu2IBPTaaN5L97xqY9CjcMXf9CXtiqd0T+vDkfo/UFXpFqtWA8ArmH4ZlgE2WzXotng1xafTYO4b1o7VB5M5mpJNv7b+tWt7FXzcnPni7r5cHxnK7NVHeHhRxXVnTEVmtnsOIxt3/A99xT2D2rLvvub4qWwmXX8z39w3gNFdm7E4OoExs9dz96fb2RWfQVpWPjMW7OTOJclMzn2S/Mx0Xa1waBm0qWG5IpBvKmLT0VSGd2qKcm8Czu5c2yOEQC8X3vg1pmSnKVt63aqXJChfqgf6iitxF4x/V89WvXO5HgA/s0/Xsrv56oAKlefR932nc7cxy2DlP/V9hgG/vwTf3K4H8KyBZ90b+gN48GPQd7peHfTg0pJzGYZOF5ReNTO0kjx6/FbIPK1z31bdJujS220fVmxn4m69UJrlwyLBrQO3OK3GkzwSvCyrWfq3hYLMspuLr3kZvr3b9nuvDzHLAKV/DxtmV3z86G/g4l3ye4DiQgPi1ll68Fv1h27boSWzjuNrmXbJOw9b55VdfvsykoB+sSkFV86CyNv1XqG/zdKzHEc+C1F3Vf98S9oFc6FO0XjbqIipwl0D2xLsowNg/7CAuryDSrk6OfLGjRE8cVUnlu4+TcTzvzL+3Q3884e9zFiwk8h/r+LG+XtZoQYx0WUbz4xsjstJXTLp1G4ofdr48+bknmx7eiSPXdmR6BNnmTB3I4NfW8OvB5J44qpO9Bs4kqm5/6AoK0Uv9VuLdMv2uLPkFBQxvHNQmTa/cF04u+IzeGNl2XVvsvJNZORYer4Rk/Wg9trXyvY8D6/UK3P2uZfssLGsPnBGL6x2xzKdwuhj2efVt4Weh1BZHn3P13ospv8D+u9iy/uw/B+w7jU9WBsSoQfi174Guxbovx/fFroT0KRt2eBrnbFZOqAHd9fpwfIBff8PGE5uzD3dvmTSmJOr7q0fXlFxU5HE3Xp+g4MDRWaD1fldaar08tEb8y2px/KTwAxDD4rv+7ZkIl51YlbAV1Nq3kOOWaZz+uHX64lhpa+EDEMPiIYNLdnVy6rzOP1/6cgqvXSFg5PuNAVH6Ku/2uTRDQOWPgTLn9DLbdu6UrjEJKBfCkrBtW/piopHD8L0Nbq3Vd3CUlbW3lRAO70vai24uzjy/HXdGNQ+kG7NfWrZ8OoppZgxvD2LpvfnzoFt8HBxYumu00SfSOeqbsG8e3Mvrrp9Jo5FeTr1FLcWAjuBT0jxOfw8XHhoZAc2zhzBP8Z0YmSXZvz80GBmDG/PY6M7kurXnUecnqGo/Wj94VZDa2KScXFyYEBYYJn7r4kI4Zb+rfhg3bHiTb5/O3iGYa+vYfzcjXoRNScXGPgwJGxj3arvue2TbZxNOqGrJJqFYxo1i/sX7OSez6Pp+/Jqnv8tidiWk8r+Tlv0tt1DTz2iN+buMRlGvwidroEVT8K2efpqbvxcXQIaNhzWvKRXuBz8qH6ug4Me04nfooOttQQUygZ0R2d9RVk6oJuL4MCPnAwYyOt/nOaXvaWCZ+879dfSe7Cai3Q9u2VFy13xZ/k1X5fspip/Vp2yvFdrQYA1j55+rGTJhu0fVfbrKbF7ESy6Wc9qXjhZV4BVJfWIvsLtdLUuWHBvogd2rQE19Yhl3oSNCrLQPuDZVE8oi1unU2OuXvrnFRpVuzz6zs/0OEu7EfqK4OdHSj78z57QA+RrX9dVRMc3XpKAX6NksFJqDPA24Ah8ZBjGKzaOuQl4HjCA3YZh3FyP7bR/Do7QcXTdntuyH/i2qlj/XkNjwoMZEx5ct9euof5hAcVXAIZhlKnCgeY6B7v9Y90D7Gn7T8PL1YkHhpVNKXm4OPHihHDumJ9LWO+X+Hu5GaWJ53KZv/E4J9NySMnKJzUrHzcnR5p4OhOTlEn/sADcXRwp75lrurLjRAaPLd7N6K7BfB0dT2gTd06k5fD19nhuG9AGet2Kee3ruG36LxvynuLk6UfxU7moG+bz4so41h1O4aER7TmRlsOCrSf4dNNxbuwdyhNjOtHU200HiEM/M2/Fdtq2asWg9oG6LXu+1hUi3W/UfxfXfwg/3Kd/zwNm6A6AiydMXYR51bPQpA0Opecq9Jymg8U3d+qB+szT4BGg18QvLTRKl1CeO6V79ye3QFYSy911KmTVgSRu6G3Z/9avpQ6QOz/X+7I6u+mgWZhTHNBXHUhmF50wnNxJ9OzB1uNnMRWZcbJODLMuOxC3Vn9tNQB2fw2jni9bGlralvdgxUydx468Hb6/F767V6/o6VD293Y+r5DF2+O52fQTHgCdxuoZ29e+pccivrwernoZjuvxpjIDolYODtD5atizWM9+Hfx4yWOtBug5BPmZ4Oqtv6bE6A/m8mNOyQdh+ZP6Q3fadzqfv+51Xbqcd15fVRlm/a/499FXj8GV6szUt2oDulLKEZgLXAkkANuVUksNwzhQ6pgOwFPAQMMwziqlmto+m6gTBwc9IOvsfrlbUiPK1oBr79t1Dwaqrz8vZ1inpozr0Zz/rTlKenYB1/VoTtfmPny4Lo731x7FZDbTJsCTIG9XIkL9yC8s4mxOAc183LilXyub53RzdmTuzb0Y984Gvo6OZ/qQMB4b3ZHbPt7GnN9iuaF3KB4ubqxqMpmrsufwW6tPaZu8l7e9/o7rAUc+3XSEewa15bHRnQBIzerKh+uP8cmGOJbvS2Jav1Zkx7jxIrBp3a+8bO6Jm7MDQ9sHMDdtEU5hw3TNO+jgPfmLMu1Lzy7g883H+Tx6JG0CPPisZyHebpb0gbuf3hB79yJoPYDC0P6cDRlCkFKU+cn3mArRn8KnV+s1/vf/gOHkzodJHXF0UKw7nEpeYRFuzpbA2ecevXbRxrdh2JOlBkR1QF998Ay9woJRI74mOcmNrKWp7Dt9np4t/XQq0JpyiVuvb1/1Enw4Qrez3//px/KzdAlw/FZ9lZG0Fzpfy5nRc/lxXxp3jf4PTiufhF//BWNK1o45cPo8DyzYwfG0HIb5fUf74AjwtXwYdblW99R/fxHeH6SDfEB726XEoNMu1kqh0n+LrfrrAJywHYJ7wBfjdfuaR8LQf+ilpgtzdWXTkhl6melJ8/T/z+H/1APQm97Rdfm979SD4x7+ei7KiU36A2DeULjxszJFBvWpJj30vkCsYRjHAJRSi4DxQOmFuu8F5hqGcRbAMAwbBcrigtiaTWpPwm+Alc/oHl8tqlSsXriuG4Zh8PX2eD7ffAJnR0VhkcE13UOYObYzLf09an3OsCAvFk7vj8lsENmqCQBPXNWJG97fzGebTjA2PJgn4nox0M2XtsmrSWw1jndi+2JafoiRnZvy1NUls1wDvVx5amwXJke15N8/H+CDdcfoFtgGMw7MHWrmz7B+/Hogidjtv+LkFA8j/2WzTYZh8Oaqw3y4/hh5hWYGtg9g67F07vp0O5/e2RdPV8t/2RH/hBH/pMhscM+n21m75CjBPqfo09afPm2a0KtlEzqHdMH5th/hy4nwyVgw5ZHafChph525c2Br5m88zoYjqYzq2szyAxmmrxr+eBn8WlGUuBdHJzcI7EhcajaxyVlM69cKwtoSEZQPS1ez6WgqPVv6YTRpw9GYvby7cCez49fpXH+L3joYbv9ID+aeP6XnciQfAGdPfQVx5SzoP4PnF+5m+b4k8q4cyd/63Qdb5kKHUdBuBN9Ex/PMkn34eThzW4QXYTH7OdruQcrMy+57L3S/QRcdbP1AVwRVpu0QHYyLCsoOmob2sSzOthRWPK1TSEOe0L35hVP0TlrZqYChc+/TvilZg0gp8sa+xdrs9vQbeT1+IaUmvgW00/9a9NZXEp9dC9f8F3rfUYO/0tqpSUBvAZRekCQB6FfumI4ASqmN6LTM84ZhrCh/IqXUdGA6QKtWtntOooFy89GTtFKPlCxsVgv+ni68e3MkWfkmVh84w7bj6Yzv0Zx+FzjQGxFadnZvVBt/RnRuyvtrj7I1Lg2TowfmUS9AzHeETPkf7x3L5Zc9p3lxYnccHSpeiYQFeTH/zr6kZOYT6OWCeq8Lnim7GHRVIIM6BLI57j/knHVFtRuDreutTzYe553fYxnXozkPj2xP+6be/LInkYcW7uSez6L55I4+ZVJIb606zNrDKdzavzVncwrYFpfGT7v12u+uTg4M7hDE3Gk/4vrVJMhN5w+nQbg4OfDIlR35dkcCvx5IKgnoSsH4/0HWGcw/Pkiy2ZcslzbkJmaxLU7P+B3VRR8b5O1Kx2ZebD6axgPD2nO0KAjv3AMc2LMNXFP14mmgA+2S+3VqZdMcnR+f+rUO+Jby393xGSzfl0QTD2fe/T2Wq2c8QfuDP8Efr/JhQmteWn6IK9oFMGdqL/wOLcbhsMG/D7dmbr6p5AMOdC599Isw9EldQFAZJxf9AZN/Xg8IW7l668HkHfP1AOnNi3UPfuiTevzn6O+659+smx6fsF4hWCzckcQL+7rwf/55PGUrq9KsK9y7RqfX3Ouv4qzMW6vBMbYKlssXnDoBHYBhQCiwXikVbhhGRpknGcY8YB5AVFSUHe8iIOpk5LMXfAovVycm9GrBhF4t6qFBtj02uiPXzNnAHzEpPHplR3wGjIEBetDwyq4+XGkNgFUI8rYEitDeusdnNkPsavpkr2WpuQ9GTCbX9y6bV94Ym8rLyw5yVbdmvD25Jw6WD4xrIkIwmXvy9693MWXeZp6+ugv9wgJYuT+Jd9fEMqVPS/49QS9HYRgGCWdz2RWfwba4dL7YcoLP23bh3juXw97FfPRnJ/qH+eHj5szwTk357WAyRWaj5MPJyYXl3d6gzbEb6KJOstgUxT/e3Yi3mxOdg73LXAld0S6Qr7fHE5ucyc/xbvzdIYMbvPdBARS2GoQz6AH9lU/Dyqf0qp93rSgzFmQYBq+uOESApwvfP3AF4+du5B9LYvh24N9xWP4Evx/9jmu6j2LO1F66jbErKPBsztr0EP7762HuGxrG19vj+XH3aW4f0JpbB7TRgbk6lVwh0eEqSDsG0xYXr3iKo7Me96lk7Ad0ie5H63XK6autJ3lwRPuSFFlp7n4wdWHN54HUUk1KJhKAlqVuhwLlt39JAH40DKPQMIw4IAYd4IWwO92a+3JD71Ba+Xtwz+CarxljU4soyMuAuX3gqxtxdPflZ68b+br05iHAybQcZny1k3ZBnvz3ppJgbjW+ZwvenRpJ4rk8Js/bwq0fb+WxxbvpEerL89eVBEilFC39PRjXozn/nhDO4A6B/O+PWDJ92nGy5+PEpBYyvJMu4xzdrRlp2QXsPFmy7d4XW07wwHexzG72MqbQ/lw7eTozhrejwGRmfM+yH6L9wwLILSzi1o+3ccpBjwdMc1nPCXNTFhyy9Nec3XUPt81guHtVhYH9DbGpbDqaxoMj2tM6wJNnr+3KzpMZPB4bQZLRhGe9fuLNyT10MM89C0d/x6XrNUzr15r5m+K44pXf+e+qw2Tnm3hu6f4Ky1HEp+eUXWGzOkOfhMcPlwRzi1/3J3Hrx1vJzLNdqfLL3kROZeTyt5EdyMw38fX2KlZZvUjBHGrWQ98OdFBKtQVOAVOA8h9VS4CpwKdKqUB0Cka2MRF26/UbIsg3mUsGDOuqzSBddqgcYcJ7qO43ErX+BK+tiCEuNZu2gZ5k5BRw7+fRmM0G826NwsvV9n/LayJCGNG5KZ9tPs57fxzFzdmB927pXWUbn7iqE9e9u5GPN8Th76nLDId10nnfoR2DcHF04Nf9SUS2asJ/lh3kow1xjOrSlLdvjsTJeRxOwBOd4W8jO+BcrmS2f5g/SkHiuTzGXDkA1r+NZ9ZxtnmP4a3VR5jQq4VepqL//fpfOWaz7p2HNnHnZsvg9cReLViy6zTf702hS8BN3Jv9ASRs1jX9X03WpX89pvKPwM6cOptLx2beTOnbimY+rlz/3mYe+upPfpgxkFb+Hrz7+xHm/nGUIrNBz5Z+XBsRwvWRoTTxrKJc2NGpwkzwI2cy+fvXu8gpKGLRtnjuHVJ26Q/DMPhg7THaBXny95Ed2Hosjfkbj3P7FW1wdry0leHK5pTt8gcpdTUwG50f/8QwjJeUUrOAaMMwlipd1vBfYAxQBLxkGMaiqs4ZFRVlREfX82p0QvwVZSbp2mdLQEw+n8eAV35n+pAwZgxvz7SPtnLw9Hnm39mHge0DqzmZlpVvotBkrjo4Wdz3xQ42xKbSKdibtKx8/niiZF372z/ZxrHULMICvVh7OIU7rmjDM9d0wamGgWjaR1vwc3fh3YltUK/pq5lTI+YweHkgN/ZuyX8mdS++2jAMg883n2BxdDymIoOCIjNxqdm8eVMPJkWW5KOTzuUxf2Mc/3dFc/w/6qNnsWaeBhRM/lIvV2DDqYxcxr+7AS9XJzxcSJi6uAAACE5JREFUnDiQeJ5JkS3o2Mybn3afZv/p83Rr7sPSBweVGf9IzconPbuAjs0qpmoy8woZP3cj53MLae7nTkpmPmufGI6LU8nPZ8ORVG75eCuvXR/BTX1asvrAGe75PJq3p/SscFVTH5RSOwzDiLL5WE0C+sUgAV00Zvd8tp3dCedoF+TJ9uNneW9aJKO7XZy5AkfOZDJ69joMA+64ok2ZFM2CrSf45w/7cHJQzBofXtxTrilr/FAAr7TW2x0+FsPL688yb90xRnVpyn9v7Im7iyPPLd3Hwm3x9GjpR4iPGw4OEBboxSNXdrQ5wAzA5rk6Bx/YCW5eVO3CeDtOpDN13lZ83J35z6TuZcY7fvgzgUe+3s2r13dnch/9PvMKixj3zgaOpmTxxFWduW9oWHHZrWEYPLBgJ78eOMOXd/cjz1TEnfO3898be3B975IPoFs/3kpMUibrnxyOq5MjZrPBqLfW4uHiyE8PDrJdxnsBqgroNVxlSghRn26Kasnqg8mkZuUze3LPixbMATo082ZizxZ8/+cphnUKKvPYtd2bs+VYOtP6tarT0hBlglVAmK5i8Q7mqbHNaO7rxkvLDnLtu+sJ8XVnW1w6M4a347ErO1UYI6hUn3vBzU/vHlZ+vwEberf2Z8XfBxPg6YqvR9lByQk9W/DllpO8vvIwV3cPwdvNmbdWHeZIchZ92+pF7HacOMuTYzqx+Vgav+xJZGtcOk9f3ZkB7QIwDINOzbz5cP0xJkW2QCnFyv1JrD+SypNjOuPqpFNfDg6KewaF8fQPe/lk43HuvKJN8fstLDKz5M9TdAnx0ZvJ1DPpoQtxGRQWmXl40Z+M7NysTG/vYknOzGPh1ngeGN7u4uV1rftytiyp7d558iwzFuwkLauAV2/ozsReF/+9VmVXfAYT5m7k/mHtGNG5KTd9sJkpfVrx8sRw5m88zsvLDmIy65jYLsiT63uHcv/QdsUfXN/uSODxb3bz6Z19OJWRy7+W7KN7C18W3Nu/zNhHXmERd3+2nY2xafRs6cfz13XjYOJ5/vdHLPHpuRWulGpDUi5CiMvmfF4h53IK6zT562J49Otd/LwnkSBvVxwcYPnDQ4qD8Z6EDKKPn2VIxyDaN/Wq8NwCk5khr63BZDaTmlXA8E5BzJ0WiYdLxWSHYRgs2XWKl345SGqWXvStR6gvD43owMguTeucipGALoQQFonnchn+xh/km8x8PX0AfWu5rPSH647x0rKDTOnTkhcnhFc7gHwuV69B0zHYmyEdAi84py4BXQghSlmxL4msfFPJ4mS1YDYb7D11johQ33of8KwJGRQVQohSLmT1UQcHRY+W1Q/QXg6yHroQQjQQEtCFEKKBkIAuhBANhAR0IYRoICSgCyFEAyEBXQghGggJ6EII0UBIQBdCiAbiss0UVUqlACfq+PRAILUem2MvGuP7bozvGRrn+26M7xlq/75bG4YRZOuByxbQL4RSKrqyqa8NWWN8343xPUPjfN+N8T1D/b5vSbkIIUQDIQFdCCEaCHsN6PMudwMuk8b4vhvje4bG+b4b43uGenzfdplDF0IIUZG99tCFEEKUY3cBXSk1RikVo/6/vfMJsaoMw/jvYUxTI0aDpGYEFQZNAlMipj9EWIu0cFy0KIRcDLQJ0gjCaNUyiNJA3GhlERZNUoOLICbBVeOfEpsa0ekPOTU1QmnRRqWnxfcNXIa5MDJzOtxv3h8cznm/+8F53/uc+3DOe87lSCOSdtWdTxVIWi7pqKRhSd9K2pHHl0r6XNL5vF5Sd65VIKlN0teSjuR4paTBXPeHkubXneNsIqldUp+ks1nze+eC1pKez8f3kKRDkm4sUWtJb0kalzTUMDalvkq8mf3tjKQN17OvljJ0SW3AXmATsBZ4StLaerOqhGvAC7bvALqBZ3Odu4AB213AQI5LZAcw3BC/CryR6/4T6K0lq+rYA3xmew2wjlR70VpL6gCeA+62fSfQBjxJmVq/Azw6aayZvpuArrw8A+y7nh21lKED9wAjtn+wfQX4AOipOadZx/aY7a/y9t+kH3gHqdaDedpBYGs9GVaHpE7gMWB/jgVsBPrylKLqlnQz8CBwAMD2FduXmANak96YtlDSPGARMEaBWts+BvwxabiZvj3Au058CbRLum26+2o1Q+8ALjTEo3msWCStANYDg8Ay22OQTB+4tb7MKmM38CLwb45vAS7Zvpbj0jRfBVwE3s5tpv2SFlO41rZ/AV4DfiYZ+WXgFGVr3UgzfWfkca1m6FO9kbXYx3Qk3QR8DOy0/Vfd+VSNpMeBcdunGoenmFqS5vOADcA+2+uBfyisvTIVuWfcA6wEbgcWk9oNkylJ6+kwo+O91Qx9FFjeEHcCv9aUS6VIuoFk5u/bPpyHf5+4/Mrr8bryq4j7gS2SfiK10zaSztjb82U5lKf5KDBqezDHfSSDL13rR4AfbV+0fRU4DNxH2Vo30kzfGXlcqxn6CaAr3wmfT7qJ0l9zTrNO7hsfAIZtv97wUT+wPW9vBz79v3OrEtsv2e60vYKk7Re2twFHgSfytKLqtv0bcEHS6jz0MPAdhWtNarV0S1qUj/eJuovVehLN9O0Hns5Pu3QDlydaM9PCdkstwGbgHPA98HLd+VRU4wOky6wzwOm8bCb1kweA83m9tO5cK/wOHgKO5O1VwHFgBPgIWFB3frNc613Ayaz3J8CSuaA18ApwFhgC3gMWlKg1cIh0n+Aq6Qy8t5m+pJbL3uxv35CeApr2vuKfokEQBIXQai2XIAiCoAlh6EEQBIUQhh4EQVAIYehBEASFEIYeBEFQCGHoQRAEhRCGHgRBUAhh6EEQBIXwHyDA2Oixyf38AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 3\n",
      "Epoch: 1/100..  Training Loss: 1.169..  Test Loss: 0.993..  Test Accuracy: 0.565\n",
      "Epoch: 2/100..  Training Loss: 0.921..  Test Loss: 0.721..  Test Accuracy: 0.684\n",
      "Epoch: 3/100..  Training Loss: 0.814..  Test Loss: 0.689..  Test Accuracy: 0.706\n",
      "Epoch: 4/100..  Training Loss: 0.738..  Test Loss: 0.689..  Test Accuracy: 0.669\n",
      "Epoch: 5/100..  Training Loss: 0.763..  Test Loss: 0.652..  Test Accuracy: 0.700\n",
      "Epoch: 6/100..  Training Loss: 0.704..  Test Loss: 0.624..  Test Accuracy: 0.743\n",
      "Epoch: 7/100..  Training Loss: 0.706..  Test Loss: 0.635..  Test Accuracy: 0.715\n",
      "Epoch: 8/100..  Training Loss: 0.669..  Test Loss: 0.642..  Test Accuracy: 0.724\n",
      "Epoch: 9/100..  Training Loss: 0.718..  Test Loss: 0.656..  Test Accuracy: 0.723\n",
      "Epoch: 10/100..  Training Loss: 0.669..  Test Loss: 0.634..  Test Accuracy: 0.729\n",
      "Epoch: 11/100..  Training Loss: 0.677..  Test Loss: 0.619..  Test Accuracy: 0.753\n",
      "Epoch: 12/100..  Training Loss: 0.688..  Test Loss: 0.640..  Test Accuracy: 0.707\n",
      "Epoch: 13/100..  Training Loss: 0.647..  Test Loss: 0.630..  Test Accuracy: 0.743\n",
      "Epoch: 14/100..  Training Loss: 0.651..  Test Loss: 0.610..  Test Accuracy: 0.724\n",
      "Epoch: 15/100..  Training Loss: 0.643..  Test Loss: 0.669..  Test Accuracy: 0.711\n",
      "Epoch: 16/100..  Training Loss: 0.645..  Test Loss: 0.663..  Test Accuracy: 0.699\n",
      "Epoch: 17/100..  Training Loss: 0.657..  Test Loss: 0.641..  Test Accuracy: 0.728\n",
      "Epoch: 18/100..  Training Loss: 0.653..  Test Loss: 0.621..  Test Accuracy: 0.729\n",
      "Epoch: 19/100..  Training Loss: 0.648..  Test Loss: 0.622..  Test Accuracy: 0.733\n",
      "Epoch: 20/100..  Training Loss: 0.643..  Test Loss: 0.622..  Test Accuracy: 0.729\n",
      "Epoch: 21/100..  Training Loss: 0.633..  Test Loss: 0.592..  Test Accuracy: 0.740\n",
      "Epoch: 22/100..  Training Loss: 0.680..  Test Loss: 0.606..  Test Accuracy: 0.720\n",
      "Epoch: 23/100..  Training Loss: 0.629..  Test Loss: 0.624..  Test Accuracy: 0.731\n",
      "Epoch: 24/100..  Training Loss: 0.631..  Test Loss: 0.628..  Test Accuracy: 0.721\n",
      "Epoch: 25/100..  Training Loss: 0.638..  Test Loss: 0.621..  Test Accuracy: 0.715\n",
      "Epoch: 26/100..  Training Loss: 0.624..  Test Loss: 0.616..  Test Accuracy: 0.744\n",
      "Epoch: 27/100..  Training Loss: 0.648..  Test Loss: 0.625..  Test Accuracy: 0.717\n",
      "Epoch: 28/100..  Training Loss: 0.622..  Test Loss: 0.627..  Test Accuracy: 0.747\n",
      "Epoch: 29/100..  Training Loss: 0.609..  Test Loss: 0.606..  Test Accuracy: 0.715\n",
      "Epoch: 30/100..  Training Loss: 0.627..  Test Loss: 0.601..  Test Accuracy: 0.742\n",
      "Epoch: 31/100..  Training Loss: 0.643..  Test Loss: 0.615..  Test Accuracy: 0.728\n",
      "Epoch: 32/100..  Training Loss: 0.626..  Test Loss: 0.616..  Test Accuracy: 0.737\n",
      "Epoch: 33/100..  Training Loss: 0.647..  Test Loss: 0.587..  Test Accuracy: 0.721\n",
      "Epoch: 34/100..  Training Loss: 0.638..  Test Loss: 0.634..  Test Accuracy: 0.730\n",
      "Epoch: 35/100..  Training Loss: 0.616..  Test Loss: 0.611..  Test Accuracy: 0.731\n",
      "Epoch: 36/100..  Training Loss: 0.603..  Test Loss: 0.595..  Test Accuracy: 0.732\n",
      "Epoch: 37/100..  Training Loss: 0.604..  Test Loss: 0.612..  Test Accuracy: 0.717\n",
      "Epoch: 38/100..  Training Loss: 0.609..  Test Loss: 0.601..  Test Accuracy: 0.718\n",
      "Epoch: 39/100..  Training Loss: 0.613..  Test Loss: 0.616..  Test Accuracy: 0.725\n",
      "Epoch: 40/100..  Training Loss: 0.621..  Test Loss: 0.622..  Test Accuracy: 0.738\n",
      "Epoch: 41/100..  Training Loss: 0.609..  Test Loss: 0.605..  Test Accuracy: 0.728\n",
      "Epoch: 42/100..  Training Loss: 0.587..  Test Loss: 0.618..  Test Accuracy: 0.736\n",
      "Epoch: 43/100..  Training Loss: 0.595..  Test Loss: 0.630..  Test Accuracy: 0.717\n",
      "Epoch: 44/100..  Training Loss: 0.633..  Test Loss: 0.591..  Test Accuracy: 0.726\n",
      "Epoch: 45/100..  Training Loss: 0.618..  Test Loss: 0.615..  Test Accuracy: 0.724\n",
      "Epoch: 46/100..  Training Loss: 0.631..  Test Loss: 0.589..  Test Accuracy: 0.741\n",
      "Epoch: 47/100..  Training Loss: 0.582..  Test Loss: 0.592..  Test Accuracy: 0.739\n",
      "Epoch: 48/100..  Training Loss: 0.602..  Test Loss: 0.650..  Test Accuracy: 0.725\n",
      "Epoch: 49/100..  Training Loss: 0.600..  Test Loss: 0.609..  Test Accuracy: 0.728\n",
      "Epoch: 50/100..  Training Loss: 0.599..  Test Loss: 0.633..  Test Accuracy: 0.714\n",
      "Epoch: 51/100..  Training Loss: 0.605..  Test Loss: 0.601..  Test Accuracy: 0.739\n",
      "Epoch: 52/100..  Training Loss: 0.604..  Test Loss: 0.625..  Test Accuracy: 0.738\n",
      "Epoch: 53/100..  Training Loss: 0.612..  Test Loss: 0.592..  Test Accuracy: 0.730\n",
      "Epoch: 54/100..  Training Loss: 0.576..  Test Loss: 0.596..  Test Accuracy: 0.732\n",
      "Epoch: 55/100..  Training Loss: 0.601..  Test Loss: 0.581..  Test Accuracy: 0.733\n",
      "Epoch: 56/100..  Training Loss: 0.603..  Test Loss: 0.606..  Test Accuracy: 0.740\n",
      "Epoch: 57/100..  Training Loss: 0.597..  Test Loss: 0.591..  Test Accuracy: 0.735\n",
      "Epoch: 58/100..  Training Loss: 0.596..  Test Loss: 0.597..  Test Accuracy: 0.731\n",
      "Epoch: 59/100..  Training Loss: 0.611..  Test Loss: 0.604..  Test Accuracy: 0.722\n",
      "Epoch: 60/100..  Training Loss: 0.619..  Test Loss: 0.594..  Test Accuracy: 0.745\n",
      "Epoch: 61/100..  Training Loss: 0.604..  Test Loss: 0.603..  Test Accuracy: 0.710\n",
      "Epoch: 62/100..  Training Loss: 0.588..  Test Loss: 0.598..  Test Accuracy: 0.737\n",
      "Epoch: 63/100..  Training Loss: 0.631..  Test Loss: 0.612..  Test Accuracy: 0.755\n",
      "Epoch: 64/100..  Training Loss: 0.602..  Test Loss: 0.606..  Test Accuracy: 0.739\n",
      "Epoch: 65/100..  Training Loss: 0.592..  Test Loss: 0.607..  Test Accuracy: 0.720\n",
      "Epoch: 66/100..  Training Loss: 0.620..  Test Loss: 0.577..  Test Accuracy: 0.728\n",
      "Epoch: 67/100..  Training Loss: 0.601..  Test Loss: 0.581..  Test Accuracy: 0.739\n",
      "Epoch: 68/100..  Training Loss: 0.592..  Test Loss: 0.567..  Test Accuracy: 0.752\n",
      "Epoch: 69/100..  Training Loss: 0.605..  Test Loss: 0.618..  Test Accuracy: 0.736\n",
      "Epoch: 70/100..  Training Loss: 0.594..  Test Loss: 0.614..  Test Accuracy: 0.728\n",
      "Epoch: 71/100..  Training Loss: 0.601..  Test Loss: 0.619..  Test Accuracy: 0.737\n",
      "Epoch: 72/100..  Training Loss: 0.610..  Test Loss: 0.580..  Test Accuracy: 0.743\n",
      "Epoch: 73/100..  Training Loss: 0.616..  Test Loss: 0.630..  Test Accuracy: 0.724\n",
      "Epoch: 74/100..  Training Loss: 0.605..  Test Loss: 0.578..  Test Accuracy: 0.738\n",
      "Epoch: 75/100..  Training Loss: 0.588..  Test Loss: 0.586..  Test Accuracy: 0.764\n",
      "Epoch: 76/100..  Training Loss: 0.581..  Test Loss: 0.582..  Test Accuracy: 0.748\n",
      "Epoch: 77/100..  Training Loss: 0.595..  Test Loss: 0.604..  Test Accuracy: 0.742\n",
      "Epoch: 78/100..  Training Loss: 0.600..  Test Loss: 0.595..  Test Accuracy: 0.739\n",
      "Epoch: 79/100..  Training Loss: 0.598..  Test Loss: 0.576..  Test Accuracy: 0.726\n",
      "Epoch: 80/100..  Training Loss: 0.586..  Test Loss: 0.606..  Test Accuracy: 0.754\n",
      "Epoch: 81/100..  Training Loss: 0.586..  Test Loss: 0.603..  Test Accuracy: 0.718\n",
      "Epoch: 82/100..  Training Loss: 0.584..  Test Loss: 0.584..  Test Accuracy: 0.731\n",
      "Epoch: 83/100..  Training Loss: 0.578..  Test Loss: 0.605..  Test Accuracy: 0.751\n",
      "Epoch: 84/100..  Training Loss: 0.603..  Test Loss: 0.616..  Test Accuracy: 0.747\n",
      "Epoch: 85/100..  Training Loss: 0.599..  Test Loss: 0.574..  Test Accuracy: 0.755\n",
      "Epoch: 86/100..  Training Loss: 0.573..  Test Loss: 0.636..  Test Accuracy: 0.725\n",
      "Epoch: 87/100..  Training Loss: 0.600..  Test Loss: 0.621..  Test Accuracy: 0.719\n",
      "Epoch: 88/100..  Training Loss: 0.584..  Test Loss: 0.594..  Test Accuracy: 0.723\n",
      "Epoch: 89/100..  Training Loss: 0.585..  Test Loss: 0.628..  Test Accuracy: 0.728\n",
      "Epoch: 90/100..  Training Loss: 0.566..  Test Loss: 0.601..  Test Accuracy: 0.737\n",
      "Epoch: 91/100..  Training Loss: 0.575..  Test Loss: 0.624..  Test Accuracy: 0.747\n",
      "Epoch: 92/100..  Training Loss: 0.598..  Test Loss: 0.635..  Test Accuracy: 0.709\n",
      "Epoch: 93/100..  Training Loss: 0.582..  Test Loss: 0.576..  Test Accuracy: 0.750\n",
      "Epoch: 94/100..  Training Loss: 0.583..  Test Loss: 0.598..  Test Accuracy: 0.743\n",
      "Epoch: 95/100..  Training Loss: 0.577..  Test Loss: 0.594..  Test Accuracy: 0.736\n",
      "Epoch: 96/100..  Training Loss: 0.583..  Test Loss: 0.585..  Test Accuracy: 0.749\n",
      "Epoch: 97/100..  Training Loss: 0.605..  Test Loss: 0.601..  Test Accuracy: 0.756\n",
      "Epoch: 98/100..  Training Loss: 0.593..  Test Loss: 0.604..  Test Accuracy: 0.732\n",
      "Epoch: 99/100..  Training Loss: 0.580..  Test Loss: 0.615..  Test Accuracy: 0.730\n",
      "Epoch: 100/100..  Training Loss: 0.585..  Test Loss: 0.588..  Test Accuracy: 0.758\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3hUVfrA8e+ZyaSQThJqgIROGhACgiBNRBBRQQRRVFiVn72grljWtrr2hiKKrthYEQUVlWYBEaUllECAkNBDQhqk18nc3x8nvZAAAZzk/TxPniRzz9x7JuWdc9/TlGEYCCGEsH+mC10BIYQQjUMCuhBCNBES0IUQoomQgC6EEE2EBHQhhGgiHC7UhX19fY2AgIALdXkhhLBLUVFRaYZh+NV27IIF9ICAACIjIy/U5YUQwi4ppQ7XdUxSLkII0URIQBdCiCZCAroQQjQREtCFEKKJkIAuhBBNhAR0IYRoIiSgCyFEE2F3AT32eDavr44lPafwQldFCCH+VuwuoB9IzeGd3+JJyZaALoQ9SU9Pp0+fPvTp04c2bdrQvn378u+LiooadI4ZM2YQGxt7yjJz585l4cKFjVFlhgwZwvbt2xvlXOfDBZspeqacLWYACopLLnBNhBCnw8fHpzw4PvPMM7i5ufHwww9XKWMYBoZhYDLV3tZcsGBBvde5++67z76ydsruWuhlAT1fAroQTUJ8fDwhISHccccdhIeHk5SUxMyZM4mIiCA4OJjnnnuuvGxZi9lqteLl5cXs2bPp3bs3gwYNIiUlBYAnn3ySt956q7z87NmzGTBgAD169OCvv/4CIDc3l2uvvZbevXszdepUIiIi6m2Jf/HFF4SGhhISEsLjjz8OgNVq5aabbip/fM6cOQC8+eabBAUF0bt3b6ZNm9boP7O62F0L3cVRWuhCnK1nf4hhd2JWo54zqJ0HT48PPqPn7t69mwULFvD+++8D8NJLL9GyZUusVisjRoxg0qRJBAUFVXlOZmYmw4YN46WXXmLWrFl8/PHHzJ49u8a5DcNg8+bNLFu2jOeee46VK1fyzjvv0KZNG5YsWcKOHTsIDw8/Zf0SEhJ48skniYyMxNPTk1GjRvHjjz/i5+dHWloaO3fuBCAjIwOAV155hcOHD+Po6Fj+2Plghy10XeWCYtsFrokQorF06dKF/v37l3//5ZdfEh4eTnh4OHv27GH37t01nuPi4sLYsWMB6NevH4cOHar13BMnTqxRZv369Vx//fUA9O7dm+DgU78Rbdq0iZEjR+Lr64vFYuGGG25g3bp1dO3aldjYWO6//35WrVqFp6cnAMHBwUybNo2FCxdisVhO62dxNuyvhV6WcimSFroQZ+pMW9Lniqura/nXcXFxvP3222zevBkvLy+mTZtGQUFBjec4OjqWf202m7FarbWe28nJqUYZwzBOq351lffx8SE6OpoVK1YwZ84clixZwvz581m1ahW///4733//Pc8//zy7du3CbDaf1jXPhN210F0khy5Ek5aVlYW7uzseHh4kJSWxatWqRr/GkCFDWLx4MQA7d+6s9Q6gsoEDB7JmzRrS09OxWq0sWrSIYcOGkZqaimEYXHfddTz77LNs3bqVkpISEhISGDlyJK+++iqpqank5eU1+muojd210J1klIsQTVp4eDhBQUGEhITQuXNnBg8e3OjXuPfee7n55psJCwsjPDyckJCQ8nRJbfz9/XnuuecYPnw4hmEwfvx4xo0bx9atW7n11lsxDAOlFC+//DJWq5UbbriB7OxsbDYbjz76KO7u7o3+GmqjTvfWo7FEREQYZ7LBRZHVRvcnV/Dw6O7cM7LbOaiZEKKps1qtWK1WnJ2diYuLY/To0cTFxeHg8Pdv4yqlogzDiKjt2N+/9tVYzAqzSUnKRQhxxnJycrj00kuxWq0YhsEHH3xgF8G8Pnb3CpRSODuYZJSLEOKMeXl5ERUVdaGr0ejsrlMU9Fh0aaELIURVdhnQnS1mCmTYohBCVGG/Ad0qAV0IISqzy4DuYjHLxCIhhKjGfgO65NCFsCvDhw+vMUnorbfe4q677jrl89zc3ABITExk0qRJdZ67vmHQb731VpUJPldccUWjrLPyzDPP8Nprr531eRqDXQZ0J4uMchHC3kydOpVFixZVeWzRokVMnTq1Qc9v164d33zzzRlfv3pAX758OV5eXmd8vr8juwzoLhazzBQVws5MmjSJH3/8kcJCvTnNoUOHSExMZMiQIeXjwsPDwwkNDeX777+v8fxDhw4REhICQH5+Ptdffz1hYWFMmTKF/Pz88nJ33nln+dK7Tz/9NABz5swhMTGRESNGMGLECAACAgJIS0sD4I033iAkJISQkJDypXcPHTpEr169uP322wkODmb06NFVrlOb7du3M3DgQMLCwpgwYQInT54sv35QUBBhYWHli4L9/vvv5Rt89O3bl+zs7DP+2Zaxu3HoIMMWhThrK2bD8Z2Ne842oTD2pToP+/j4MGDAAFauXMnVV1/NokWLmDJlip5b4uzMt99+i4eHB2lpaQwcOJCrrroKpVSt55o3bx4tWrQgOjqa6OjoKsvfvvDCC7Rs2ZKSkhIuvfRSoqOjue+++3jjjTdYs2YNvr6+Vc4VFRXFggUL2LRpE4ZhcNFFFzFs2DC8vb2Ji4vjyy+/5MMPP2Ty5MksWbLklOub33zzzbzzzjsMGzaMp556imeffZa33nqLl156iYMHD+Lk5FSe5nnttdeYO3cugwcPJicnB2dn59P5adfKLlvozg7SQhfCHlVOu1ROtxiGweOPP05YWBijRo3i2LFjJCcn13medevWlQfWsLAwwsLCyo8tXryY8PBw+vbtS0xMTL0Lb61fv54JEybg6uqKm5sbEydO5I8//gAgMDCQPn36AKdeohf0+uwZGRkMGzYMgFtuuYV169aV1/HGG2/kiy++KJ+ROnjwYGbNmsWcOXPIyMholJmq9Z5BKfUxcCWQYhhGSC3HewILgHDgCcMwznnvgIujjHIR4qycoiV9Ll1zzTXMmjWLrVu3kp+fX96yXrhwIampqURFRWGxWAgICKh1ydzKamu9Hzx4kNdee40tW7bg7e3N9OnT6z3PqdazKlt6F/Tyu/WlXOry008/sW7dOpYtW8a///1vYmJimD17NuPGjWP58uUMHDiQX375hZ49e57R+cs0pIX+CTDmFMdPAPcB562b19lilk5RIeyQm5sbw4cP5x//+EeVztDMzExatWqFxWJhzZo1HD58+JTnGTp0aPlG0Lt27SI6OhrQS++6urri6elJcnIyK1asKH+Ou7t7rXnqoUOH8t1335GXl0dubi7ffvstl1xyyWm/Nk9PT7y9vctb959//jnDhg3DZrNx9OhRRowYwSuvvEJGRgY5OTns37+f0NBQHn30USIiIti7d+9pX7O6elvohmGsU0oFnOJ4CpCilBp31rVpIBeLmaISGyU2A7Op9hybEOLvaerUqUycOLHKiJcbb7yR8ePHExERQZ8+feptqd55553MmDGDsLAw+vTpw4ABAwC9+1Dfvn0JDg6usfTuzJkzGTt2LG3btmXNmjXlj4eHhzN9+vTyc9x222307dv3lOmVunz66afccccd5OXl0blzZxYsWEBJSQnTpk0jMzMTwzB48MEH8fLy4l//+hdr1qzBbDYTFBRUvvvS2WjQ8rmlAf3H2lIulco8A+ScKuWilJoJzATo2LFjv/rehevywe/7eXHFXmKevRxXJ7vs1xVCiDNyquVzz2unqGEY8w3DiDAMI8LPz++Mz1O2UbSMdBFCiAr2OcpF9hUVQoga7DqgF8oCXUIIUa4hwxa/BIYDvkqpBOBpwAJgGMb7Sqk2QCTgAdiUUg8AQYZhZJ2rSpdvFF0kI12EEKJMQ0a5nHKhBcMwjgP+jVajBigP6JJDF0KIcnaactHVltmiQghRwU4DurTQhRCiOrsM6GXDFqWFLoQQFewyoJe10CWgCyFEBbsM6C4yDl0IIWqw74AuC3QJIUQ5uwzoTg4yykUIIaqzy4BuMimcHEwS0IUQohK7DOgg29AJIUR1dhvQZRs6IYSoym4Dum6hS6eoEEKUsduA7myRfUWFEKIyOw7oJlk+VwghKrHbgO4iLXQhhKjCvgO6dIoKIUQ5uw3ozhYZ5SKEEJXZeUCXUS5CCFHGbgO6i6NJUi5CCFGJ3QZ0mVgkhBBV2W1AL5v6bxjGha6KEEL8LdhtQHe2mDEMKLRKHl0IIcDOAzpAoXSMCiEEYMcB3UU2ihZCiCrqDehKqY+VUilKqV11HFdKqTlKqXilVLRSKrzxq1mTi6OuugR0IYTQGtJC/wQYc4rjY4FupR8zgXlnX636OTvIRtFCCFFZvQHdMIx1wIlTFLka+MzQNgJeSqm2jVXBujg7SspFCCEqa4wcenvgaKXvE0ofO6fKcugFskCXEEIAjRPQVS2P1To4XCk1UykVqZSKTE1NPauLlo1yKZAldIUQAmicgJ4AdKj0vT+QWFtBwzDmG4YRYRhGhJ+f35ldLf5XmDcYj/xjAOQXybBFIYSAxgnoy4CbS0e7DAQyDcNIaoTz1q44D5J34WLLBSSHLoQQZRzqK6CU+hIYDvgqpRKApwELgGEY7wPLgSuAeCAPmHGuKguAgwsAThQCMspFCCHK1BvQDcOYWs9xA7i70WpUH4szAE6qGJCALoQQZexvpmhZC90oApBt6IQQopT9BfTSFrqDrRCzSckoFyGEKGV/Ad1BB3SKC0o3ipZRLkIIAfYc0K35OMtG0UIIUc7+ArpF59ApLsDZYqJQAroQQgD2GNDLW+ilKRcJ6EIIAdh7QHeUgC6EEGXsL6CbTGB2guJ82ShaCCEqsb+ADrqVbi3A2dFMvmxBJ4QQgL0GdIszFOfjYjHJ8rlCCFHKPgN6WQtdOkWFEKKcfQZ0i0v5KBfJoQshhGafAd3BuXQcurTQhRCijH0GdItL+UxRaaELIYRmnwHdwal8LZfiEgNriYx0EUIIOw3ouoXu4qirX2CVgC6EEPYZ0C3OYC0s3yha1kQXQgh7DegOLuWdoiC7FgkhBNhrQLc465SLBHQhhChnnwG90rBFQIYuCiEE9hzQrfm0cNQBPU9y6EIIYacB3eICNivezrr6J3OLLnCFhBDiwrPPgF66JrqfswFAWk7hhayNEEL8LdhnQC/dhs7bUada0nKkhS6EEA0K6EqpMUqpWKVUvFJqdi3HOymlflVKRSul1iql/Bu/qpWUttAdbIV4t7BIC10IIWhAQFdKmYG5wFggCJiqlAqqVuw14DPDMMKA54AXG7uiVVTahs7XzYl0aaELIUSDWugDgHjDMA4YhlEELAKurlYmCPi19Os1tRxvXJbSgF6cj4+bo7TQhRCChgX09sDRSt8nlD5W2Q7g2tKvJwDuSimf6idSSs1USkUqpSJTU1PPpL6ag86hl7fQZZSLEEI0KKCrWh4zqn3/MDBMKbUNGAYcA6w1nmQY8w3DiDAMI8LPz++0K1vOUjXlkpYtLXQhhHBoQJkEoEOl7/2BxMoFDMNIBCYCKKXcgGsNw8hsrErWUNZCLy7A182R7EIrBcUl5TNHhRCiOWpIC30L0E0pFaiUcgSuB5ZVLqCU8lVKlZ3rMeDjxq1mNeUt9Hx83ZwAJO0ihGj26g3ohmFYgXuAVcAeYLFhGDFKqeeUUleVFhsOxCql9gGtgRfOUX21slEuxQX4lAZ0SbsIIZq7hqRcMAxjObC82mNPVfr6G+Cbxq3aKThUaqF7OwKQnisBXQjRvNn1TFGdQy9roUvKRQjRvNlnQK80scjHTbfQ06SFLoRo5uw+oLdwdKCFo1la6EKIZs8+A7rJBGZHKM4HKJ1cJC10IUTzZp8BHfRYdGsBgEz/F0II7DmgW5yrttBlgS4hRDNnvwHdwbm8he4rLXQhhLDjgG5xqRTQnTiRW0SJrfoSM0II0XzYb0B3cIbiioBuM+BknqRdhBDNl30HdKvOoZeNRZc8uhCiObPfgG6p2kIH2SxaCNG82W9Ad3Apb6H7ls0WlYAuhGjG7Deg19pCl5SLEKL5st+A7uACVt0i93C24GBSpEsLXQjRjNlxQHcqT7mYTEpmiwohmj37DegWl/KUC4CPq8wWFUI0b/Yb0CsNWwTwdXeSFroQolmz34BucQGbFUqsAPi6OkqnqBCiWbPfgF5pGzqoaKEbhkz/F0I0T/Yb0Mu2oSsd6eLj6kih1UZOofUCVkoIIS4c+w3oDnrseeUldEGm/wshmi87DuhlLfTSyUXuMv1fCNG82W9At5Tm0IurTv9PzZaALoRonuw3oFdrobf30t8fy8iv6xlCCNGkNSigK6XGKKVilVLxSqnZtRzvqJRao5TappSKVkpd0fhVraZaC93TxYKbkwMJJyWgCyGap3oDulLKDMwFxgJBwFSlVFC1Yk8Ciw3D6AtcD7zX2BWtwaHqKBelFO29XKSFLoRothrSQh8AxBuGccAwjCJgEXB1tTIG4FH6tSeQ2HhVrEPZKJdKs0X9vV2khS6EaLYaEtDbA0crfZ9Q+lhlzwDTlFIJwHLg3tpOpJSaqZSKVEpFpqamnkF1Kykbh15pPRcd0PPO7rxCCGGnGhLQVS2PVZ+OORX4xDAMf+AK4HOlVI1zG4Yx3zCMCMMwIvz8/E6/tpVVmykK0N7bhewCK5n5xWd3biGEsEMNCegJQIdK3/tTM6VyK7AYwDCMDYAz4NsYFaxTrS30FgAck7SLEKIZakhA3wJ0U0oFKqUc0Z2ey6qVOQJcCqCU6oUO6GeZU6lHbS300qGLknYRQjRH9QZ0wzCswD3AKmAPejRLjFLqOaXUVaXFHgJuV0rtAL4EphvnepWs8oBeMZHI31vGogshmi+HhhQyDGM5urOz8mNPVfp6NzC4catWD5MJzI7l49ABWro64mIxy0gXIUSzZL8zRaF0X9GKHLpSivbeLpJDF0I0S/Yd0C3OVVroUDp0MUNy6EKI5se+A7qDc5UWOsjkIiFE82XfAd3iUqOF3t6rBRl5xbLRhRCi2bHvgO7gVGWUC1Qa6SKtdCFEM2PnAd2lyjh0qDx0sSKPvv1ohrTYhRBNnn0HdItzlZmioKf/A+V59MPpuUx4708+/evQ+a6dEEKcV/Yd0Gtpofu5OeHkYCoP6F9HJmAYsPd49oWooRBCnDf2HdBraaGXr4t+Mp8Sm8E3UQkAxKfkXIgaCiHEeWPfAb2WYYug0y4JJ/NYF5fK8awCAnxacCA1hxLbuV2NQAghLqQmGdD9vVtwLCOfryOP0tLVkX8MCaTQapORL0KIJs2+A7rFpUbKBfRIl7ScIn7encyEvu3p1VZvprQ/VdIuQoimy74DuoNzjU5RqBi6WFxiMDmiA1393ADJowshmrYGrbb4t2VxAZsVSqxgrngpZQG9t78nPdq4A+Dj6igBXQjRpNl/Cx1qtNIDfd1wcjAxbWCn8se6tHIjXlIuQogmzL5b6JU3uXByL3+4pasjm58YhaeLpfyxrq3c+Ck6CcMwUKq2bVKFEMK+2XcL3VIa0Itr5tErB3OArn5uZOYXk55bdD5qJoQQ5519B3SH0o2iaxm6WF2XVtIxKoRo2uw7oJ+ihV5dVwnoQogmzr4D+mm00Nt5OtPC0SwBXQjRZNl3QPf0159TdtdbVClFFz+3Bk0uWhKVwFdbjpxt7YQQ4ryy74Du1wM8O0Dczw0q3rWVG/sb0EKfuzaed9fEn23thBDivLLvgK4UdLsMDqytsXNRbbq2ciMxs4DcU2x2kVto5WBaLkdP5JOZX9yIlRVCiHPLvgM6QLfLoSgHDv9Vb9Eufq7Aqdd02ZOUhWFUfC2EEPaiQQFdKTVGKRWrlIpXSs2u5fibSqntpR/7lFIZjV/VOgReAmanBqVdyka6LNueyKur9nL9/A0s3ZpQpUxMYlatXwshxN9dvTNFlVJmYC5wGZAAbFFKLTMMo7wn0jCMByuVvxfoew7qWjtHVx3U41bBmP+csmgnH1ccHUx8tP4gZpPC0Wwiv9jGxHD/8jIxiZn4uDpiMil2S0AXQtiRhkz9HwDEG4ZxAEAptQi4GqhraMlU4OnGqV4DdRsNK/4J6fvBp0udxSxmE5/OGEBxiY1+nbx5//f9vLd2P9kFxbg765mlMYlZBLXzwKQUMYmZ5+sVCCHEWWtIyqU9cLTS9wmlj9WglOoEBAK/1XF8plIqUikVmZqaerp1rVu3y/Tn+F/qLTqoiw9Du/vh6uTAoM4+lNgMthw6AUCR1ca+5GyC23kS3M6D+JQcCq0ljVdPIYQ4hxoS0GtbyaquvdyuB74xDKPWKGgYxnzDMCIMw4jw8/NraB3r17Iz+HSDfatO62nhnbxxNJvYsD8dgH3J2RSXGAS38yC4nSdWm0FcskxEEkLYh4YE9ASgQ6Xv/YHEOspeD3x5tpU6I91Gw6H1cPIwZCVBblq9T3G2mOnb0YsNB3RAL8uZB7fzIKid3uVI0i5CCHvRkIC+BeimlApUSjmig/ay6oWUUj0Ab2BD41axgbqPhpJCeDsM3ugJr3aBmG/rfdqgLj7EJGaRmVdMTGImro5mAnxc6dSyBW5ODnWOdPlw3QGunfcXNtl4WgjxN1FvQDcMwwrcA6wC9gCLDcOIUUo9p5S6qlLRqcAiwzAuTIQLHAYTP4Rxr8O4N6CFD8SurPdpgzr7YBiw6WB6RYeoSWEyKXq1da91pMvKXcd5Yfkeog6flH1KhRB/Gw3a4MIwjOXA8mqPPVXt+2car1pnQCkIm1zx/aH1cHAdGIY+Voc+Hb1wcjDx1/50didlMTmiIrsU1NaDb6ISsNkMTCZ9jr3Hs5i1eDuBvq4cTMsl8vBJurV2r+v050RBse6icLaYz+t1hRB/b/Y/U7QugUMhO1EPZTwFJwczEQHefLf9GHlFJeW5c4Dgdp7kFpVw+EQeACdyi7jt00jcnBz48vaBtHR1JOrwyXP6Mmrzf59H8eBX28/7dYUQf29NO6ADHPy93qKDOvuQkafXbQmuFNArd4wmZuRzw4cbSckuZP7NEbTxdCa8o/d5D+jWEhubDqaz+eAJLlR2Swjx99R0A3rLzuDhr9Mu9RjUxQcAi1nRrVVF+qRbazccTIrvtycy4b0/STiZz0c3R9CngxcAEQHeHEzLJT2n/oXBGsv+1FwKim2k5xaRmn3+riuE+PtrugFdKd1KP/QH2GynLBrm70ULRzPdW7vj6FDxI3FyMNOttTs/707GrBTf3DmIod0rxs/36+QNUHcrvSgP/nwbMo+d/espFZ1QsUzOblk8TAhRSdMN6KADel56vRtgWMwm7h3ZjekXB9Q4Nr53WwZ39eHbuwfTs41HlWOh7T2xmBVRR+oI6Ht/gp+fgrkD4K93oeTsl+PdeSwTZ4v+tUlAF0JU1qBRLnYr8BL9+eA6aBNyyqJ3Dq99DZi7hnflruFdaz3mbDET0t6TqEN1BPTUvaDM0OliWP0E7PgSpi0F99YNfgnVRSdk0tvfi4ST+exJyj7j8wghmp6m3UL39IeWXRqURz9TEZ28iT6WWfuaL2mx0DIQblgMU77Qdwqb5p3xtYpLbOxOyiK0vSe92nrIeu1CiCqadkAHnXY5/CeU1L1LUQ0JkXB0c4OK9uvkTZHVxq5jtQTXtDjw7aHz+b3GQ48rYOtnFBbkMndNPL/vS6XkNGaaxiXnUGS1EervSVA7Dw6k5pSPSRdCiOYR0AuzIGlHw8pnHIHProYvp0JxQb3Fw8s7Rk9UPVBi1WPgfbtVPDbgdshL59vP5/Lqqlhu+XgzQ17+jVdX7SUlq/5r7TymO0TD/L0IauuOzYDY45J2EUJoTT+gB5Tm0ff/Wn9Zw4Bl94K1APLSIGZpvU9p5e5Mx5YtiDp8kpTsAub8Gsf0BZs5sn8X2Ir1RtZlAoeR4RpIz6OLuHN4F967MZyebdyZt3Y/w19by9u/xJFXVPedRHRCJu7ODnRq2YJebXUHraRdzkBWEuSf/wlhQpxrTT+gu/lBh4Gw+/v6y279VG84PfZl8OsJmz6ABkzeiejkzZrYVAa/9Btv/LyPzQdP8Mb/ftQHfSsC+oYDJ3g7cyh9TPt5JCSPK0LbsmDGANY8PJzhPfx485d9jHhtLQs3HabIWnOo5c5jmYS298RkUnTw1ouHne5Il8hDJ5g6fyM5p9gou6EOpuWSVWCHG2l/cS388MCFroUQja7pB3SA4AmQvAtS99VdJuMorHpSp2j6/QMGzISk7Q3KpY8JaYOXi4WbBgbw20PDWPXAUEKdjgPwWbwjizYf4anvd3HnwiiivC7HsLhiivyo/PmdfFx578Z+fHPHINp7ufDEt7sY8dpavtx8hOISHdiLrDb2JmUT2t4TAJNJ0bON+2m30Oet3c+GA+ms2nW8wc+pbUZqanYhY99ex1XvrOdIet5p1eGCKi6A1D16foLMtBVNTPMI6EFXAQp2f1f78ZwU+OYfYNjgqnfAZIKwKeDkCZs/qP051iI4eQiA0cFt2PzEKJ4aH0RnPzc6tGzBTV0LOWH25amVR5i9dCdLtx4jqK0Hb08fjuo9BXYtgbyqefeIgJYsufNiPpnRHz93Jx5bupPpCzZTUFzCvuRsikp0h2gZPdIlu8FL+CZl5rMmNgWA77Y3bLLT0RN5jHz9d5bvTKry+Kd/HaLQauNkXjET5/3FrmN2sm58erz+Peel66+FaEKaR0D3aAcdB9W+PvqhP+H9S+B4NFwzF7wD9ONObhB+k07VZCXVfN7KR2FOOMT9XOslHU/G4dUxhC9vH8jah4cT/fRo/nf7QAJ9XaH/7TpPv+W/NZ6nlGJ4j1Z8e9fFvHxtKH/tT+fOL6KILN0mL6y9V3nZoHYe5BRaSTiZX+M8a2NT+OD3/VVa199EJmAzYHzvdvwZn0ZKdv0dsc/+EMPBtFyeWRZDbmmaJrfQyucbD3N5UBuW3DkIR7Pi+vkb2XzwRD1n+xtIi634+sjGC1cPIc6B5hHQQaddUnZDyt6KxzbMhU/Hg6Mr3ParLlNZ/9vAVgKRH1d9PDcNti3UXy++GRKiqh43DEiLw+TXg0FdfAjwdS1ffheA1kHQ7XLY+B4U1r6eulKKKf078p8JoayJTeU/K8Eoh88AACAASURBVPbi6WKhQ0uX8jJlHaOV8+jWEhuvrNzL9AVbeHHFXpZu1S1xm83gq8ijDO7qw30ju2Iz4McdtbxRVbI65ji/7Enh6j7tSMku5P3f9cqVX205SmZ+MTOHdaZrK3eW3jWYri7ZvPz9lr//gmGpsaBM4OwJRyWgNwk2GyycDDF13IGfjoTImv/vdqT5BPTqaZeoT2DV49DzCpi5tvaZpC0DocdYnXbJSal4fMtHenekW5aBWyv433WQVun2PesYFOWAX/e66zP0Ycg/AVELTlntqQM68sz4ID3+vL0nqtLa7j1au2NSeqSLYRgcSM3h5o83897a/VzfvwMRnbx59ocYkrMK+HN/Ggkn85nSvyPdWrsT3M7jlGmX3EIrzyyLoWcbd167rjdX92nH/HUHOJyey3/XH6R/gDfhHfWQzTaeznyunubW9NfYeiSjznOeC4XWEp78bmetG43UmopKjdV3YR0HwZFNVY/98TqsmH1uKtoIrCW2WjvLm73sRIhbBT8+WCONeVpOHtId5ssfaZRlOi6E5hPQ3dvoKfgx30LcL/DjLOg6CiZ9As4edT/vsuegOF8Hf9Cdaps/1C3sgCF6Kj8KvpioF+MCHTSgygiXGjoM0Lss/fVOvePdpw8O5N0b+vLw5VXP5+JoJtDXlYWbjtD/hV+Z8PpPJB6O45VJYbx0bRivXtebohIbjy3dyaLNR/FuYeHyYL3swDV92hOdkMmBOnZcmvNrHImZBTx/TQgWs4lHx/REKbjhw00cy8jn/4ZWWiohOxn3/ARGmyL5fl3kKV9Lo0iOgXlDIDWWzQdP8MXGIzz89Y4qATw5q4DBL//G5xsPV31uaqz+vXS4CNLjKvaeLcyBP97Qb9YFf8+hoA98tZ1/fLLlwlx8xWw4+MeFuXZ90uL05/wT8Nu/T122rjvIojxYNA0KMsBmhRMHG7eO50nzCeigUyqpe+GrG6F1MFz3CZjrWc7GtxsMmQU7v4b9v0H0V3qM+qC79XGfLjDpY8g4DNu+0I+llY6m8TtFQAcY+gjkJMO2z+ut+pVh7cqX7a1sXGhbulrSeNP9C6Jc72ON00NMNq0BINDXlX9e3pPf9qbw084kJob746RssPcnpmZ+xNeOz9LyvwP0ZKpK9qfm8N/1B5kS0YGIgJYAtPNyYebQLhzLyKeLnysje7aqeELppC0HZcNr39ekncvlhAuzdZoreSfs/ZGNpRt8bzuSwcLN+nXYbAazFm8nKbOA9XGpFc8tseqOUL8euoUOcLS0lb77O31XZSuGA2tqXrMsaFwgNpvBH3FprI9PIzGjZp/JOZWdrJes2L7w/F63oco6t4MnQOQCSNxWe7n/XQ/f/l/Nxw0DfrhPj4Qb8aR+LO0UI+L+xppXQO91lc6ftvDV66s4NXDruCEPgk9X3arf8C60Ca3YQAOg8zA91v2vOfpWLTUWnL3A1a/uc4Ju4XcYWLrEboJOAUQvhq2fQdSn+nNtHbKVzHL5kUUFd3JJ5o84hE5CdRyoJ0d9fw8UFzD94gAGlAbl68NbwVc3waIbcNv+IV5OJtwKjmNsmFvlnG/9Eoejg4lHxlR9Q7pjWGcGdm7JP8f0rNonUBrQC1r1ZbLpVxZvPnTq130qeSfg8F+1HzMM+OF+OHEAXFrC4Q1sPHCCPh28GNLVl1dW7CU5q4AP1h3gz/h0fN2cqm7yffJgxWSvdn3B7FjRMbr1M/07dvaEfaurXnflY/DBsIo7sAvgQFoumfk6DVB9xNE5d3xn6edd5/e6DZUWB47uMP5t/T/300M1l8wuyIS41Xp0WW561WNbPtINtpFPwsA7Ss8Ziz1qXgHdvTVMWwIzloNH24Y/z+IMV76pA0LaPhh0T819Si+ZBZlHYec3uoxfj1PuZQro40Mf1s97Mxg+Hg1Lb9cB+Yf79OfVT9T9/BMHYc2L0H0MPFA6Suemb+GSh3Sr/6NLMR1ax9wbw5l/Yyjd1t4D+1bAmJfgsQS2X/41y0oGURL1GeTr3Hfs8Wx+jE5k+sUB+Lo5VblcC0cHFs0cxOXBbarWI2k7+HTFeeh9+Ks04jf8cFpr1JTbvYyCt/rBgrFk7K1lp6nIj/U/5IgnIOgqjKMb2Xn0BIO6+PD8NSEUlti484soXl8dy7jQttw6JJCEk/lk5BXp55elwvx66N9p2z66hZ4aqz+H36zTcHGrKwJCQZa+ZnFu3W80jeBYRv4p1+XZVrpEc0tXR1acYg7BjqMZvLxy75l3TuedqJmWOB6tP6fu/XvmltPj9J2ysyeMfh6ORdW8mzjwOxglOp2yu9Jot5JiWPeanlF+yUO6kefe7oLfkZ2p5hXQAbqMBO9Op/+8wKEQcSv4dofgiTWPdxsNrYLhz7dK87Sn6BCtrOsouOI1/XHD13D3ZngwRn+ETdHDIq1FtT93zQtgcoBxb+ihmQAmM1z6FEz9SrdKPrsKv2XTGB39kA7m416HgXeCgxPX9G3PH75TcLDmkbH+QwDe/Hkfbo4OzBzaueI6BVm60zdxu76LsFZLqSTt0MGx55UUOrVkdMFKft2T3LDXD5B3AtvXM2DxTcQXeJBieJG09HGslVewTIrWLeWuo3QKrOPFqMJsuhqHGdhZjyS6b2RXth7JoLWHM/+ZGFq+neDuslZ6aukIp7LfTceL9O35lo/0z7H3VN03kpsCSaW37buWQHEeoBq2fMQZWLo1geGvruGe/22tMxBvPZKBu7MD0y8OIOrwSZIya0+7zF0Tz7y1+/llT0qtxwFI2QMvB8L3d1fsuZsaC19Ng1cCa86qLgvotuILG+hsNti7vGafU1p8xZpJYZOhdWjNkSrxv4CTh+4/iV5c8fieZZBzHC6+t6IB5ttNUi7NwpVvwJ1/gYNjzWNK6dRM6l6dY68vf175eQNu1x/dR+vnefrrj+AJemGxw+trPi9ph75NHHhn7XcbPcbAPZG6U/fIJt3qvOI1PRSzlMVsYtZNk9hohFKyYR7Rh1JYGXOcfwwJxKtF6WtM3g1vBMG7/WD+MH0Xsf7Niuvkpus7jLa9wcERS/g0Rpmj+OznTbUvKVydYWBdege2mGW8WjyZpf0+42jIPfQq2sWSxZ/oMkV5sOQ2cPGGCR/oiV+ddA78InMsEaULpM0c4MsOjwdZdPExPF0s5QG9PO2Stk9vS1iWauswEEqK9HyA7mP0iKWuowBVkXbZ+hm0CtINgfhfABr2uhrAMAzmroln1uId+Lo58cuelDpb39uOnKRPBy/Ghenf9YqdNcvlFFpZu0/3Gcz5Na7uVvqB33UHYvTX8G4E/PdyeG8g7F8Llhb6b6XUidwiUuMiOWjTd2XFidFn8YrP0rpXYNFU2FkpIBfn678/n9KArhT0ngKJWyverAxD938FDoU+U/XdWFmn56b54B0IXS+rOKdfDz2rvLGG4GYm6J9x6d/PuSQB/XSZLXUfC54AXqWt/1ONcGmozsPBwQViV9Q89suzOk8/+P66n29x1sfv3w63/6bfNKrp0LIFxsV342NLZ9Enb+PpYuHWSwL1QVuJTvs4OMGE+XD9/6B9v6rjfZO2689tewNgipiOAzb6pP7Ai8v3Vr3Yqifg4zHlo0gOpOaw6PN5OMSv4mXrFFqNe4Knru5Nvwn3c8KxLcF757A8+hisflLnNCe8D66++lxeHUk1+THKdT+uTrpj23HPEjyLkukQpzunfdycaOPhTExi6SzW1L1Vh5J2uEh/Nkog/Bb9tasP+PeHfSt1zjhxa2kq5lJI28fsj39i0Iu/nfVaOIZh8NT3Mby6KpZr+rTjt4eGE9zOg2eWxdRYHyen0Mq+5GzutS2ky5q7GdKqgBW7aubR1+xNochq49pwf3Yey2RtbGqNMoDu/GvhAw/shIvv0x3zA++C+3dA5xFw+E8Mw2DhpsNc8eoKfAoT2O0zikLDgTXr1jR4ZnKjil0Ja1/UX1cebnriAGCAb6VNaIInAkqnP0G/kWce1b/D0Ov0Yzu/1o2ioxv1/4WpUij07Q5F2ZDd8OUx6pR/Er6YpK/z55yzP189JKA3JrODzombLPXukNQgFhfdMty7vGpr4eA6fft/yUPgUnPkSw0tWupAXIdBo6/nuFMA02w/MPOSQDycS9+0Ns+HY5F6sbLeU6DnOAidrNdCKbv1LluWuG2Y/uzTBbqO4m7nlSz7K5oVZR14x3fqiVxHNpD1xU3M/GQjV72+guH7X+WYU1eumvlvbinbAtDBEfcxTxFiOkTekrsh8r+636LLiPI65xVZ+au4O71teyp+NmWjjI5uLF+WIaS9B7sSs/TtelqcXnStjJuf7gh1b6f/2ct0v1y/Ua17VXechk0htfUQfWz/b5zILWLLoXrGO9ezj+1324/x+cbD3DYkkDcm98HF0cyLE0NJyynklZVV3wijj2YwTG1jwLFPYff3fJx7Lz2OLiY5M08Pt0zZC5kJrNx1HF83J16YEEJ7LxferquVnrwLWofoPqXLntVv+Je/oN/MAgbDyUO8/e3vPPHtLkb7pmFSBuPGXEm2exec0nbz3I+7z+8EsvT9sHQmtAnTjZyESusrlf0d+lRaptqzvR5wsPNr/bcRX5oq63KpvvMNuAR2LNKtc0sL6HNj1euVpW/ONu1SXACLbtSjcLqN1v+3jfEmcQoNCuhKqTFKqVilVLxSqtaZF0qpyUqp3UqpGKXU/xq3mnYk/GZ4eF9FTvts9RgLWQkVIw1KrLql6+GvFxBrDErhPWoWQabD3JH2gt7U+uRh+PXf+g8x5NqKsr2u1J/3/KA/J+3QE3VcvCvKjH4BZyOfl72W8s9vook6lE7Gd49SaPHgS8/b8UhYy6WH3uCLwNW0Vidpf9N8Qjv6VKmSpc8Uilr2YJJaQ4prd90vUEnU4ZNstvXArThdt9KO79L58EH36AI7vwYgqJ2n3ggk7bDOhVdPhY2fA5P+q/seStm6jtZf7P6OnR5DefH3ZMZ/mUqS4cMDAUdwNJvYsL/aSIlKbMe2YfynHexfU+vx1OxCnl0Ww4zWB3hseKvyEUNh/l5MvziQhZuOVNl4fPeBI7xo+YgS315w92asbcN53rKAlnM6w4vt4b2LMN6/hD/2JjImpDXOFjN3j+jK9qMZrItLq3rxEiu25D38kdW61uGPJR0uBuBA5M9MvziAZ/qXvjG1CcWnS1/CnRP55K9DfLbhcI3nVpEco1M7p7JrKbzSRa+jtGtp7eP/i/J0UDSZ4fqFFHUYrANt2QSi9LKAXm0LydBJ+ljSDp3q8OlW0XcWNhlO7Icd/4Pe19dsFJXdXZ9mQC8oLmHumniSswr0m9CSW/XmOhPeh9EvAIZ+nedQvQFdKWUG5gJjgSBgqlIqqFqZbsBjwGDDMIKB5r02aYuWjXeu7mMABbHL9fcb3tWdVJc/r1MqjcSp3zQYNhvzvhU6r7rwOp2PHPdG1dE6nv7QLhz2li4PnLS9PN1SrlVP1MA7uaxgNb3VPubM/wCv43/yUt5VvJ57Ods73sIUVtEnaTFqwO3gX8vdg8mM47iXOWbpxJ35d1FgVJ0vsPFAOlGUtraPbNCtc7OjvmvpNFh3fBkGwe08sBmQEFfayenbg5W7jjNv7X5W7jrOPpcwctoMKG9xRh0+yYSlWSQa+nf49slBLPjzEM6OZpx7XkabtE1EdHTnz/iqgdJmM/hu2zHuX7SN7z56AWXNJ+Wre8nKqTlx64Xvo3im5B2eznwS86dXVpnd+PDFHixzfhbb5xOxHtN3P712vIifysQ8cR74dafFrT/wssuDrHYYScnIp2DILFT+CXqX7OSKEJ1jn9TPn3aezrz9y74qKRJrWjymkgK+S2rJ7Z9FVll/v9BawsN/WMk2XPhHh2M8PT4IU3K0frP2aI9qHYp7cRrjulh4bXUsJ3Pr6Kw3DFh8C3x2FUQuwGYzah/Bs+1zPerkwO/wzQx4K1SvelpZ1Cf6jvDaD4kvasmtv+qQtXn9KqwlNt0h6uGvl+8olZlfTHGP8fpOedvnOqhWvgPrdRWYnfQibbU1itzb6GGQpxnQv9l8gPxfXqLg7QHwTun/yOUv6jcXv+76/2TXN6d1ztPVkBb6ACDeMIwDhmEUAYuAq6uVuR2YaxjGSQDDME7RxS5Oi5ufnlUau1z/8a59EXpeCUHXNO51TGYY8ZgeZdN1lM5Zj3oGvDrULNtrvB4alhyjUxvVAzrAsEfBvS0f+X3FHJ+l5Lt1ZMb9z7PxsUvpM/0tCJmkO6NGPll3nbqM4PCU34jKa8WyHYlVDm08cIIW7YJ0sDnwu57w1eMK/WYaep3+Z0zaXt4xmnFEj6FOdenEfYu28fLKvdzxRRSj31xHyNOr6PHkSvq/8AvXzvuLpMwCsrteg9E6mI+emsW+58ey9pEReIeNgcJMrml1nN1JWVUC2uLIozzw1XYi444xVv1FinMgrYqOsvCtR9l0oKI1v27zFm7fdwdXm9brvP3Jg3qWcUEWpO+nxedX0Mt0lG7FsZg/HIbxxSQG565mje80PXYeQCm6j76NuzNv5InUyzCGPkKhcuYqp60MCNRvRI4OJu67tBtbj2Twr+93lQf11b/pjrkuIRexJymLhxbrGbbJWQVMnb+Rb3ekcMKnL31KdutlJo7v1KkOpfRkPGB23xJyC63MXVPHapUHf4f0OAyvTvDjA7z78j/p9dRKRr6+lvsXbeP77cf0CKyDf+gF8B7eBzcv03dQ69+oOE9JsU7TdRoMXUfxdeRRdtg6U4KJjetWMuL1teQf31uldV5ktTHqjd95bEWCvruMXKAXwus6quK8Ll7Q7xZ959mqV5WqJ5zM44/4tJojXWwl+v+vjlSTYRhkr3uPhy1fc7zYhaWt7sV4YCcMuquiUOh1+v+mrLP2HKhnmiQA7YHKb5sJwEXVynQHUEr9CZiBZwzDWFn9REqpmcBMgI4dO55JfZunHmPhl2fgm+m6ZTHu9frHuJ8p704w5XM9O9C9de1leo2HX5+FNf/R37ftU7OMkzuMfh7nJbfiDHDdp3RsVenWdtJ/dfqonpm6g7r40KO1Owv+PMR1/fxRSpFbaGXH0QxuH9oZTg7SrR7DpoMDQPA1sOKfEL2Y9pf/B08XC0bKXnD1479RWVhLbPx47xBshsGB1FySswo4kVdERm4xHVq6MGNwIK6Ol+p/3sqdZZ2HgzIxhO2Yjf4cXftfvNkPo//Noi1H6d7ajZWXpmJamovL5LfIWDuX6Ue+ZuT8i8h09GOSZQOzrB9hNkPJlEU49Byj+yUW3QCfT9CzjW0lmGf8wCPLTzIo8TOmH1zJXltH0vpVvemd0Nef/Sm5vLsmnlYezoTYenO5JQqHSn8WU/p34PCJPOat3Y/NgGvD23MwZjMlDmbumjwOxw7HeP6nPTzyTTTr4lLJLbTy3o3hdMq4TP9+s4/rUU5lneltQgHoULSfa8Mv4bMNh7nl4gA6tGxR9Ze2+UOszi25yfw6M0pe5L7C+QT3cGeR6Qo27E/n++2JdBx6nL62YugxTjcmOg+DvtNg6+f6LsvTXy/TkZUA417HWmLj223HGNCjA6b8EG60JfNhchEUxEOn68svvT4+ldTsQr6JSuCuMWPoHPuT/p/pNLhqHa94tda/t6e+j2FtbApbQwLxOr6h4sCGd+Hnp3R6MeRaPaS4Uvpuc8w+bixYxPFWQ9jS6y1eW72PtOhiZlaaf0jwRFj9Lz0Udtg/a73+2WpIC722yFH9bcoB6AYMB6YCHymlavTWGYYx3zCMCMMwIvz86plFKSr0GKc/H9+pO6/c25y6fGOoK5iDbr349axIu9TWQgf9h99jnG4dBVW/qaP+ZRfQq07OGBzAnqQsNh08wcncIm79dAtWm8GIHq30FH7DBh7t9QgN0K32bqNh1xKUrYTebZ3xyorF6tOdLzYeZmxoW0LaexLm78U1fdvzf8O68NjYXrw8KYx7RnbTo2aUqhrMy87bPoK2B5fyh9ODhG2ZDVs+5MSK59l+NIPr+nXAFP2lTgEEDMVrwms4Oyi+ar+Yb1vO5bmStznZIoD0G1brYA66A3bifN1yc3CGf6xC+Ufwz6sH8p+iqYw3v8/koqfoE1jz/+Wh0d25pk875vwax0/F/fCwpuvzVPrZ/fPyHtw9ogtfbj7CDR9toq9jgr79d3Di1iGBTI7wZ8nWBFo4mvn2rsFcEdq2IvhFfaoXoSv7/br6gltrSI5h1ujuKAVv/FwtLZGZgBG7nIVFw4jPUmRc+SG27mO59MjbfHhVa9Y/OpLeHbxI2rSEEhcfffdZZsgs/Xn9m/rN9M85Op/dbTTr49NIyS7k2nB/VIcB+GTsZGqQIy62HIq8KuZM/LAjCU8XC209nflndDsMRzc9xNWx2ptOLRJO5rEmNgWbAT8luetFvwqz9Z3Cpg90R3LLzrD+LZh7kR7SWipv9fO0UAV4T3iFu0d0ZVxoW15asbdqaq6ss7Y0HXguNCSgJwCV77v9gcRaynxvGEaxYRgHgVh0gBeNwbeb/mPqcqluxfwd9BqvP3v4VwwlrE4puH6hnjB1FncU1/Rtj3cLC6+vjuXquX+y9UgGb07prdMLnXQnHn1uqNKxSdgUPRzv0yv56PhkupXEs8PaiZxCK3cO61L7hRqix1hU1jGynNvxhMu/oPdUPLfNI8h8lIndzHq8c+/r9ZuBdyfUJQ/TMf0PeuRsgdEvEPjIHwR0qzYCKuRaPax05tryYZXdWrszY3AAMVnOGE4edGtVc5kKpRQvTwpjYOeWxLgOwjA5wN4fapR5eHQP7ru0Gw4mRYRLEubSEVhKKZ6/JpTXruvN93cPpkeb0mu066vfXCJL1+svbZkD+u8weSdtPfWdzHfbj1UMCwWIXIBhGHyUP5yPbo5g8kVdMF3xij624V0cHUy8OzmYIWoba2zhFNkq/V14ddC/x62f6ZmeyTv1hB+TiSVb9dyCkb1agf8AKMrhBnfdxxCZo//+CopLWB1znDHBbXjsil5EJhbya/g7ev5FA3y15SgKuG9kV9adKO3kT4vTDZesYzo9eNO38FCszskvuxeiPuF43FaGZv7AjtbX4tQuGKUUr14XRqCvKw9/vaPqMNSQa3Vn7fFzM56/IQF9C9BNKRWolHIErgeWVSvzHTACQCnli07BHGjMijZrSsGtq2HqonOXajldPUtHu9TVOi9TW0v3NDlbzEwd0JEth06SX1zCVzMHMqGvvz7Yvh9cM0+Pp66s22jw7ABZxzjW6WpuLXqIm4+MZVh3P0Lae9a8SENdfC/cu5W1F3/KwpO9OD7wSbIMV95x+wSf+CX6bqH31Iryg++DUc/CHevh4nuqvulU1j68xhvjfZd2w8/difBO3phNtf/enRzM/O+2gSyZNRYVcAns+bFG608pxazLurP9kf445ibqoFzK0cHEpH7+FRPJQE+c8++v3xAdnKsOCWwdrGeVlhRz5/AuXOJ8gHmff8mBlGywFlK8ZQG/lvTl8sED6F22mJxXR/0GG/Up5KTSIWsrHuSxKDuM2UujWbo1gcWRR/lu2zESQu7CMGyw7D5wawNhk8kqKGZ1zHGu7tMOJwczdOgPQKcEPaN1yWG9R8Da2BRyi0oY37sd48PaMiCgJf/c4k5miwAMw6DQWlLncMviEhtfbTnK8B6teGBUdxxa6TfWguN7devcO0D/TYHu15qyUH//w/04f3Mj2bSg3TXPlp+vhaMDr0/uQ0p2Ic8u211xoaCrMUwWirZXmhzViOq95zUMw6qUugdYhc6Pf2wYRoxS6jkg0jCMZaXHRiuldgMlwCOGYdQ9rkucvkq9+H8LbXvrNEr1TUHOkZlDO2MANw/qRFvPik0+UEq36qqzOOuJM0BJag6/7lkHNrh7RNeaZU+H2QI+XRjcVbdKX1ibikPRjbzJPFj7kp6sVHmSi4MTDDmzQV/uzha+u3swFvOp38RNJoWni0UPKf3pIR1wW/WsUc4xrTSwtG7AHImAIXrf1VZBVVNjbUL17Nq0ODz3/8anxr9Q+QZ733uPhMD++Beks8Llbp4fXW3pi8EPwPb/6VUbC7LAwYXAvuP4cMOx8k1YysxxGcpVxm+khszAz8GJn7YeobB0whSgO9Nb+KISt1GsnPjuoGJ2diE/7EjC182RgZ1bopTi6auCGP/Oevr/5xesJTZshl6ddO6N4TVe7q97kknJLuSGAR0xmRS3XTOK4gVmDq35lJ45G9na6xEO70jiyrB2WMwm/fc15QtKFk3DK341X/new5S27aucs08HL+4a3oV3fovn8uDWDO/Rii+2ZrLPuJsuRcOoOc3v7DWkUxTDMJYDy6s99lSlrw1gVumHaA6Ugsmf1V+ukXi1cOTRMTWD1CmV3s0E+rrh6mimV1uP8lEgZ6tXWw88XSz8sCMRX9eR2DruwXRwbdXWeSNo7+VSf6EyPcbpgL73Bz3aZ+unOriPf1s3CJJjdLmGTHorS2VVTrdA+UgXltwGKTGoXldxsu1gHH+fh//Bbzhoa801106jhWO10OLXXW8ys/lDXZcuI3n8qnBuGpKPgYHZpMgtLCHy8Aki991J7n4LL63rysTiGLYeyaBrKzfCyvbTVap85JfNO5CSRBNfbTnCr3uTmRzRAQezviMMbufJ3BvCiTp8EhdHM/EpOfy0M4k7EjKr7M0LsHDTEdp6OjO8h+6r6BvQihSn9vTM2Uiu4cT0bd3J2raD/64/yGvX9aZnGw82HcnhqeMzaV3Ul3uuqD083zuyG7/sSeGxpTtxc3bgcHoeg7uOZVpEr1rLn60GBXQh7JnZpPjolv74e59GcGzAOQd2bsmqmGQmhPtjGvyO7swrm1p+IXi0hfYRetOUtS/rxbRALxc99iWdk27hozs26+PfXy82131M1cd9uunx3Skxej3/4Y/jbTLhdNGtvLf4GyxuPtzeo47zD5mlF/4qzIKeV6CUoqNP1c7KHm3cARX9gwAABv1JREFU4aJOnMgdzq7VsXzy1yEMg9INVirdqfj3h9jlOLXpQYjyYM5v8RRZbVwZVnVC39jQtowN1WPzswqK+TM+jTm/xfHhzRHlZY6k5/FHXBoPjupe/mYA4BMQAvuOUBQyhVWjx7O9dAjo+HfWM6SrL2tiU/H3duHW6bczoEvtgzwcHUy8Mbk318z9Ex83RxbM6M/w7n5VX0sjkoAumoVBXXzqL3SahnVvxc+7k7kuogN4ueslli+08Jv1ENf+t+mPzR/Apvd1eiw5RqdbGhJMLC5wVy3LBTs46qUgXP1Kt3XUWjhZuOumeu5O2vXRI572/1bzjaKalq6OvDAhlKkDOvLdtmPcMKDaMOey0TE+XbmmbXue/2kPbTycyxdqq42Hs4Vbh3TmzV/2EZOYSXA7z/IF0swmxZT+VedcmFv3gn3L8R5+D3i60DbUhYs6+/D0shh+ik7k9ksCefCy7jXvRqrp1daDjY9dioeLpc6+kMaiLtSmvhEREUZk5HnYrkyIc6TEZnA4PZfOfm4Xuip1K8yBeRfr5YGzjukloMf858LVJzNBj23vPvrszlOcr8fvD3+cFK9QBr/0GzMGB/L4FadOZWTmFzPk5d+4uIsP70/rx79/3MPHfx7ktiGBPHllUNXCuen6rqbz8BrnyS8qwcWxjg7uc0wpFWUYRkStxySgC9HEHfhdT8MHPSKotk5kO7cvOZsO3i0aFGTf+Hkfc36NY0xwG1bGHGfG4ACeujLonKVBGtupArqstihEU9d5GPSbob9uE3Zh63KOdG/t3uAW862DA3F3cmBlzHH+b2hnuwrm9ZEcuhDNwZiX9NyBxljW2c55trDw6nVhpOYUMe2ijk0mmIMEdCGaB4szdBtVf7lmYkzIaewpbEck5SKEEE2EBHQhhGgiJKALIUQTIQFdCCGaCAnoQgjRREhAF0KIJkICuhBCNBES0IUQoom4YGu5KKVSgcNn+HRfIK3eUk1Pc3zdzfE1Q/N83c3xNcPpv+5OhmHUul7vBQvoZ0MpFVnX4jRNWXN83c3xNUPzfN3N8TVD475uSbkIIUQTIQFdCCGaCHsN6PMvdAUukOb4upvja4bm+bqb42uGRnzddplDF0IIUZO9ttCFEEJUIwFdCCGaCLsL6Or/2zuf0DqqKIz/PtI/2orECgomhbYQ1CJoi0iqIlJd9I8YFy4UwS4KbgqtIkjFlUtB1Aqlm1atIrUYi4YuChILroxalRpNtakVG42moK3ipi1+Lu4NPEKepCTjMDfnB8PMue8+5pz3zft4c2YeI22Q9J2kUUk7686nCiQtl3RU0oikbyTtyOPLJH0o6WRet3/EeYOR1CHpS0mHc7xS0lCu+6CkRXXnOJdI6pTUL+lE1nzdfNBa0lP5+B6WdEDSFSVqLek1SROShlvGptVXiVezvx2XtPZy9tUoQ5fUAewGNgKrgUclrf7vdzWSS8DTtm8GeoFtuc6dwKDtHmAwxyWyAxhpiV8AXs51/wFsrSWr6tgFHLF9E3ArqfaitZbUBWwHbrd9C9ABPEKZWr8BbJgy1k7fjUBPXp4A9lzOjhpl6MAdwKjtH2xfAN4B+mrOac6xPW77i7z9F+kL3kWqdX+eth94qJ4Mq0NSN7AZ2JtjAeuB/jylqLolXQ3cA+wDsH3B9jnmgdakR2BeKWkBsAQYp0CtbX8M/D5luJ2+fcCbTnwCdEqa8fPymmboXcCZlngsjxWLpBXAGmAIuN72OCTTB66rL7PKeAV4Bvgnx9cC52xfynFpmq8CzgKv5zbTXklLKVxr2z8DLwI/kYz8PHCMsrVupZ2+s/K4phn6dI/nLva+S0lXAe8BT9r+s+58qkbSA8CE7WOtw9NMLUnzBcBaYI/tNcDfFNZemY7cM+4DVgI3AEtJ7YaplKT1TJjV8d40Qx8DlrfE3cAvNeVSKZIWksz8bduH8vBvk6dfeT1RV34VcRfwoKQfSe209aRf7J35tBzK03wMGLM9lON+ksGXrvX9wGnbZ21fBA4Bd1K21q2003dWHtc0Q/8M6MlXwheRLqIM1JzTnJP7xvuAEdsvtbw0AGzJ21uAD/7v3KrE9rO2u22vIGn7ke3HgKPAw3laUXXb/hU4I+nGPHQf8C2Fa01qtfRKWpKP98m6i9V6Cu30HQAez3e79ALnJ1szM8J2oxZgE/A9cAp4ru58KqrxbtJp1nHgq7xsIvWTB4GTeb2s7lwr/AzuBQ7n7VXAp8Ao8C6wuO785rjW24DPs97vA9fMB62B54ETwDDwFrC4RK2BA6TrBBdJv8C3ttOX1HLZnf3ta9JdQDPeV/z1PwiCoBCa1nIJgiAI2hCGHgRBUAhh6EEQBIUQhh4EQVAIYehBEASFEIYeBEFQCGHoQRAEhfAvsVRs5Ovo/B8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 4\n",
      "Epoch: 1/100..  Training Loss: 1.156..  Test Loss: 1.006..  Test Accuracy: 0.578\n",
      "Epoch: 2/100..  Training Loss: 0.869..  Test Loss: 0.679..  Test Accuracy: 0.710\n",
      "Epoch: 3/100..  Training Loss: 0.720..  Test Loss: 0.620..  Test Accuracy: 0.711\n",
      "Epoch: 4/100..  Training Loss: 0.696..  Test Loss: 0.599..  Test Accuracy: 0.733\n",
      "Epoch: 5/100..  Training Loss: 0.680..  Test Loss: 0.628..  Test Accuracy: 0.705\n",
      "Epoch: 6/100..  Training Loss: 0.698..  Test Loss: 0.624..  Test Accuracy: 0.710\n",
      "Epoch: 7/100..  Training Loss: 0.662..  Test Loss: 0.612..  Test Accuracy: 0.712\n",
      "Epoch: 8/100..  Training Loss: 0.652..  Test Loss: 0.632..  Test Accuracy: 0.699\n",
      "Epoch: 9/100..  Training Loss: 0.657..  Test Loss: 0.593..  Test Accuracy: 0.719\n",
      "Epoch: 10/100..  Training Loss: 0.648..  Test Loss: 0.632..  Test Accuracy: 0.716\n",
      "Epoch: 11/100..  Training Loss: 0.669..  Test Loss: 0.626..  Test Accuracy: 0.702\n",
      "Epoch: 12/100..  Training Loss: 0.647..  Test Loss: 0.619..  Test Accuracy: 0.697\n",
      "Epoch: 13/100..  Training Loss: 0.629..  Test Loss: 0.594..  Test Accuracy: 0.726\n",
      "Epoch: 14/100..  Training Loss: 0.625..  Test Loss: 0.604..  Test Accuracy: 0.732\n",
      "Epoch: 15/100..  Training Loss: 0.649..  Test Loss: 0.621..  Test Accuracy: 0.708\n",
      "Epoch: 16/100..  Training Loss: 0.632..  Test Loss: 0.593..  Test Accuracy: 0.719\n",
      "Epoch: 17/100..  Training Loss: 0.625..  Test Loss: 0.600..  Test Accuracy: 0.720\n",
      "Epoch: 18/100..  Training Loss: 0.651..  Test Loss: 0.608..  Test Accuracy: 0.709\n",
      "Epoch: 19/100..  Training Loss: 0.622..  Test Loss: 0.586..  Test Accuracy: 0.705\n",
      "Epoch: 20/100..  Training Loss: 0.616..  Test Loss: 0.606..  Test Accuracy: 0.697\n",
      "Epoch: 21/100..  Training Loss: 0.659..  Test Loss: 0.567..  Test Accuracy: 0.733\n",
      "Epoch: 22/100..  Training Loss: 0.637..  Test Loss: 0.577..  Test Accuracy: 0.716\n",
      "Epoch: 23/100..  Training Loss: 0.628..  Test Loss: 0.573..  Test Accuracy: 0.717\n",
      "Epoch: 24/100..  Training Loss: 0.618..  Test Loss: 0.570..  Test Accuracy: 0.723\n",
      "Epoch: 25/100..  Training Loss: 0.627..  Test Loss: 0.593..  Test Accuracy: 0.719\n",
      "Epoch: 26/100..  Training Loss: 0.623..  Test Loss: 0.620..  Test Accuracy: 0.705\n",
      "Epoch: 27/100..  Training Loss: 0.607..  Test Loss: 0.608..  Test Accuracy: 0.717\n",
      "Epoch: 28/100..  Training Loss: 0.617..  Test Loss: 0.573..  Test Accuracy: 0.734\n",
      "Epoch: 29/100..  Training Loss: 0.600..  Test Loss: 0.574..  Test Accuracy: 0.728\n",
      "Epoch: 30/100..  Training Loss: 0.620..  Test Loss: 0.574..  Test Accuracy: 0.727\n",
      "Epoch: 31/100..  Training Loss: 0.604..  Test Loss: 0.585..  Test Accuracy: 0.699\n",
      "Epoch: 32/100..  Training Loss: 0.602..  Test Loss: 0.580..  Test Accuracy: 0.735\n",
      "Epoch: 33/100..  Training Loss: 0.607..  Test Loss: 0.578..  Test Accuracy: 0.715\n",
      "Epoch: 34/100..  Training Loss: 0.626..  Test Loss: 0.621..  Test Accuracy: 0.706\n",
      "Epoch: 35/100..  Training Loss: 0.620..  Test Loss: 0.561..  Test Accuracy: 0.727\n",
      "Epoch: 36/100..  Training Loss: 0.609..  Test Loss: 0.584..  Test Accuracy: 0.709\n",
      "Epoch: 37/100..  Training Loss: 0.594..  Test Loss: 0.568..  Test Accuracy: 0.735\n",
      "Epoch: 38/100..  Training Loss: 0.620..  Test Loss: 0.564..  Test Accuracy: 0.732\n",
      "Epoch: 39/100..  Training Loss: 0.590..  Test Loss: 0.604..  Test Accuracy: 0.720\n",
      "Epoch: 40/100..  Training Loss: 0.595..  Test Loss: 0.561..  Test Accuracy: 0.723\n",
      "Epoch: 41/100..  Training Loss: 0.598..  Test Loss: 0.576..  Test Accuracy: 0.720\n",
      "Epoch: 42/100..  Training Loss: 0.602..  Test Loss: 0.591..  Test Accuracy: 0.727\n",
      "Epoch: 43/100..  Training Loss: 0.614..  Test Loss: 0.569..  Test Accuracy: 0.715\n",
      "Epoch: 44/100..  Training Loss: 0.610..  Test Loss: 0.558..  Test Accuracy: 0.738\n",
      "Epoch: 45/100..  Training Loss: 0.591..  Test Loss: 0.600..  Test Accuracy: 0.712\n",
      "Epoch: 46/100..  Training Loss: 0.597..  Test Loss: 0.588..  Test Accuracy: 0.714\n",
      "Epoch: 47/100..  Training Loss: 0.605..  Test Loss: 0.565..  Test Accuracy: 0.719\n",
      "Epoch: 48/100..  Training Loss: 0.581..  Test Loss: 0.560..  Test Accuracy: 0.735\n",
      "Epoch: 49/100..  Training Loss: 0.590..  Test Loss: 0.563..  Test Accuracy: 0.735\n",
      "Epoch: 50/100..  Training Loss: 0.593..  Test Loss: 0.574..  Test Accuracy: 0.724\n",
      "Epoch: 51/100..  Training Loss: 0.585..  Test Loss: 0.575..  Test Accuracy: 0.721\n",
      "Epoch: 52/100..  Training Loss: 0.599..  Test Loss: 0.567..  Test Accuracy: 0.702\n",
      "Epoch: 53/100..  Training Loss: 0.595..  Test Loss: 0.581..  Test Accuracy: 0.730\n",
      "Epoch: 54/100..  Training Loss: 0.590..  Test Loss: 0.580..  Test Accuracy: 0.724\n",
      "Epoch: 55/100..  Training Loss: 0.577..  Test Loss: 0.556..  Test Accuracy: 0.725\n",
      "Epoch: 56/100..  Training Loss: 0.589..  Test Loss: 0.569..  Test Accuracy: 0.719\n",
      "Epoch: 57/100..  Training Loss: 0.577..  Test Loss: 0.616..  Test Accuracy: 0.677\n",
      "Epoch: 58/100..  Training Loss: 0.592..  Test Loss: 0.577..  Test Accuracy: 0.703\n",
      "Epoch: 59/100..  Training Loss: 0.590..  Test Loss: 0.580..  Test Accuracy: 0.706\n",
      "Epoch: 60/100..  Training Loss: 0.614..  Test Loss: 0.562..  Test Accuracy: 0.724\n",
      "Epoch: 61/100..  Training Loss: 0.584..  Test Loss: 0.543..  Test Accuracy: 0.715\n",
      "Epoch: 62/100..  Training Loss: 0.595..  Test Loss: 0.600..  Test Accuracy: 0.710\n",
      "Epoch: 63/100..  Training Loss: 0.582..  Test Loss: 0.568..  Test Accuracy: 0.733\n",
      "Epoch: 64/100..  Training Loss: 0.581..  Test Loss: 0.552..  Test Accuracy: 0.735\n",
      "Epoch: 65/100..  Training Loss: 0.593..  Test Loss: 0.552..  Test Accuracy: 0.723\n",
      "Epoch: 66/100..  Training Loss: 0.582..  Test Loss: 0.551..  Test Accuracy: 0.728\n",
      "Epoch: 67/100..  Training Loss: 0.603..  Test Loss: 0.563..  Test Accuracy: 0.724\n",
      "Epoch: 68/100..  Training Loss: 0.588..  Test Loss: 0.564..  Test Accuracy: 0.719\n",
      "Epoch: 69/100..  Training Loss: 0.596..  Test Loss: 0.558..  Test Accuracy: 0.705\n",
      "Epoch: 70/100..  Training Loss: 0.578..  Test Loss: 0.539..  Test Accuracy: 0.743\n",
      "Epoch: 71/100..  Training Loss: 0.576..  Test Loss: 0.556..  Test Accuracy: 0.723\n",
      "Epoch: 72/100..  Training Loss: 0.584..  Test Loss: 0.585..  Test Accuracy: 0.731\n",
      "Epoch: 73/100..  Training Loss: 0.576..  Test Loss: 0.582..  Test Accuracy: 0.715\n",
      "Epoch: 74/100..  Training Loss: 0.579..  Test Loss: 0.591..  Test Accuracy: 0.713\n",
      "Epoch: 75/100..  Training Loss: 0.585..  Test Loss: 0.571..  Test Accuracy: 0.726\n",
      "Epoch: 76/100..  Training Loss: 0.583..  Test Loss: 0.561..  Test Accuracy: 0.731\n",
      "Epoch: 77/100..  Training Loss: 0.591..  Test Loss: 0.570..  Test Accuracy: 0.732\n",
      "Epoch: 78/100..  Training Loss: 0.612..  Test Loss: 0.564..  Test Accuracy: 0.769\n",
      "Epoch: 79/100..  Training Loss: 0.574..  Test Loss: 0.555..  Test Accuracy: 0.741\n",
      "Epoch: 80/100..  Training Loss: 0.586..  Test Loss: 0.563..  Test Accuracy: 0.738\n",
      "Epoch: 81/100..  Training Loss: 0.583..  Test Loss: 0.545..  Test Accuracy: 0.760\n",
      "Epoch: 82/100..  Training Loss: 0.573..  Test Loss: 0.548..  Test Accuracy: 0.749\n",
      "Epoch: 83/100..  Training Loss: 0.562..  Test Loss: 0.550..  Test Accuracy: 0.732\n",
      "Epoch: 84/100..  Training Loss: 0.574..  Test Loss: 0.565..  Test Accuracy: 0.760\n",
      "Epoch: 85/100..  Training Loss: 0.580..  Test Loss: 0.557..  Test Accuracy: 0.746\n",
      "Epoch: 86/100..  Training Loss: 0.566..  Test Loss: 0.554..  Test Accuracy: 0.734\n",
      "Epoch: 87/100..  Training Loss: 0.597..  Test Loss: 0.574..  Test Accuracy: 0.724\n",
      "Epoch: 88/100..  Training Loss: 0.582..  Test Loss: 0.544..  Test Accuracy: 0.748\n",
      "Epoch: 89/100..  Training Loss: 0.575..  Test Loss: 0.549..  Test Accuracy: 0.737\n",
      "Epoch: 90/100..  Training Loss: 0.580..  Test Loss: 0.538..  Test Accuracy: 0.746\n",
      "Epoch: 91/100..  Training Loss: 0.562..  Test Loss: 0.553..  Test Accuracy: 0.734\n",
      "Epoch: 92/100..  Training Loss: 0.602..  Test Loss: 0.553..  Test Accuracy: 0.732\n",
      "Epoch: 93/100..  Training Loss: 0.571..  Test Loss: 0.538..  Test Accuracy: 0.763\n",
      "Epoch: 94/100..  Training Loss: 0.581..  Test Loss: 0.567..  Test Accuracy: 0.716\n",
      "Epoch: 95/100..  Training Loss: 0.583..  Test Loss: 0.545..  Test Accuracy: 0.737\n",
      "Epoch: 96/100..  Training Loss: 0.586..  Test Loss: 0.550..  Test Accuracy: 0.734\n",
      "Epoch: 97/100..  Training Loss: 0.578..  Test Loss: 0.546..  Test Accuracy: 0.717\n",
      "Epoch: 98/100..  Training Loss: 0.574..  Test Loss: 0.568..  Test Accuracy: 0.732\n",
      "Epoch: 99/100..  Training Loss: 0.566..  Test Loss: 0.566..  Test Accuracy: 0.750\n",
      "Epoch: 100/100..  Training Loss: 0.586..  Test Loss: 0.564..  Test Accuracy: 0.731\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv = cv.split(X_train_scaled, y_train)\n",
    "\n",
    "m_hidden_layers = 1\n",
    "n_input = 6\n",
    "n_hidden = 12\n",
    "n_output = 5\n",
    "network_type = \"classification\"\n",
    "\n",
    "bs = 16\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "models = []\n",
    "max_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "    print(\"Model for Fold: \" + str(fold))\n",
    "\n",
    "    train_set, train_labels = X_train_scaled[train_idx], y_train[train_idx]\n",
    "    valid_set, valid_labels = X_train_scaled[val_idx], y_train[val_idx]\n",
    "    \n",
    "    trainset = HousePriceDataset(train_set, train_labels)\n",
    "    trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    validset = HousePriceDataset(valid_set, valid_labels)\n",
    "    validloader = DataLoader(validset, batch_size = bs, shuffle = True)\n",
    "    \n",
    "    model = NeuralNetwork(m_hidden_layers, n_input, n_hidden, n_output, network_type).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "    epochs = 100\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model_checkpoint = None\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "    \n",
    "        for features, labels in trainloader:\n",
    "            model.train()\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_ps = model(features.float())\n",
    "\n",
    "            loss = criterion(log_ps, labels)\n",
    "        \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for features, labels in validloader:\n",
    "                    \n",
    "                    model.eval()\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    log_ps = model(features.float())\n",
    "\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    \n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))\n",
    "            \n",
    "            if (accuracy / len(validloader)) > best_accuracy:\n",
    "                best_accuracy = accuracy/len(validloader)\n",
    "                best_model_checkpoint = model\n",
    "            \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(validloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(validloader)))\n",
    "            \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "    models.append(best_model_checkpoint)\n",
    "    max_scores.append(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, with score: 0.769\n",
      "Fold: 1, with score: 0.755\n",
      "Fold: 2, with score: 0.759\n",
      "Fold: 3, with score: 0.764\n",
      "Fold: 4, with score: 0.769\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for score in max_scores:\n",
    "    print(\"Fold: {}, with score: {:.3f}\" .format(index, score.item()))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Testing Score: 0.7393767705382436\n"
     ]
    }
   ],
   "source": [
    "evalset = HousePriceDataset(X_test_scaled, y_test)\n",
    "loader  = DataLoader(evalset, batch_size=len(X_test_scaled))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in loader: \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        logs = 0\n",
    "        index = 0\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            log_ps = model(features.float())\n",
    "            logs += (log_ps * max_scores[index]) / sum(max_scores)\n",
    "            index += 1\n",
    "        \n",
    "        logs = logs / len(models)\n",
    "        \n",
    "        ps = torch.exp(logs)\n",
    "            \n",
    "        _, indices = torch.max(ps, dim = 1)\n",
    "        \n",
    "y_predict = indices.cpu().numpy()\n",
    "print(\"Final Model Testing Score: \" + str(accuracy_score(y_predict, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_predict)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Part \n",
    "- The differences will be: \n",
    "1. The loss function: Mean Squared Error\n",
    "2. Number of neurons in the final layer will one (a continuous value)\n",
    "3. Will need to find some optim thresholds to map that continuous value in the discrete labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 0\n",
      "Epoch: 1/100..  Training Loss: 4.495..  Test Loss: 4.607.. \n",
      "Epoch: 2/100..  Training Loss: 4.071..  Test Loss: 4.090.. \n",
      "Epoch: 3/100..  Training Loss: 3.662..  Test Loss: 3.699.. \n",
      "Epoch: 4/100..  Training Loss: 3.323..  Test Loss: 3.252.. \n",
      "Epoch: 5/100..  Training Loss: 3.039..  Test Loss: 2.991.. \n",
      "Epoch: 6/100..  Training Loss: 2.849..  Test Loss: 2.761.. \n",
      "Epoch: 7/100..  Training Loss: 2.699..  Test Loss: 2.622.. \n",
      "Epoch: 8/100..  Training Loss: 2.599..  Test Loss: 2.517.. \n",
      "Epoch: 9/100..  Training Loss: 2.548..  Test Loss: 2.439.. \n",
      "Epoch: 10/100..  Training Loss: 2.499..  Test Loss: 2.351.. \n",
      "Epoch: 11/100..  Training Loss: 2.469..  Test Loss: 2.314.. \n",
      "Epoch: 12/100..  Training Loss: 2.444..  Test Loss: 2.274.. \n",
      "Epoch: 13/100..  Training Loss: 2.429..  Test Loss: 2.252.. \n",
      "Epoch: 14/100..  Training Loss: 2.418..  Test Loss: 2.252.. \n",
      "Epoch: 15/100..  Training Loss: 2.403..  Test Loss: 2.236.. \n",
      "Epoch: 16/100..  Training Loss: 2.380..  Test Loss: 2.230.. \n",
      "Epoch: 17/100..  Training Loss: 2.389..  Test Loss: 2.217.. \n",
      "Epoch: 18/100..  Training Loss: 2.373..  Test Loss: 2.208.. \n",
      "Epoch: 19/100..  Training Loss: 2.346..  Test Loss: 2.210.. \n",
      "Epoch: 20/100..  Training Loss: 2.336..  Test Loss: 2.206.. \n",
      "Epoch: 21/100..  Training Loss: 2.334..  Test Loss: 2.184.. \n",
      "Epoch: 22/100..  Training Loss: 2.326..  Test Loss: 2.186.. \n",
      "Epoch: 23/100..  Training Loss: 2.318..  Test Loss: 2.176.. \n",
      "Epoch: 24/100..  Training Loss: 2.322..  Test Loss: 2.175.. \n",
      "Epoch: 25/100..  Training Loss: 2.307..  Test Loss: 2.164.. \n",
      "Epoch: 26/100..  Training Loss: 2.305..  Test Loss: 2.163.. \n",
      "Epoch: 27/100..  Training Loss: 2.302..  Test Loss: 2.145.. \n",
      "Epoch: 28/100..  Training Loss: 2.287..  Test Loss: 2.147.. \n",
      "Epoch: 29/100..  Training Loss: 2.269..  Test Loss: 2.141.. \n",
      "Epoch: 30/100..  Training Loss: 2.285..  Test Loss: 2.147.. \n",
      "Epoch: 31/100..  Training Loss: 2.270..  Test Loss: 2.123.. \n",
      "Epoch: 32/100..  Training Loss: 2.271..  Test Loss: 2.131.. \n",
      "Epoch: 33/100..  Training Loss: 2.261..  Test Loss: 2.120.. \n",
      "Epoch: 34/100..  Training Loss: 2.262..  Test Loss: 2.109.. \n",
      "Epoch: 35/100..  Training Loss: 2.242..  Test Loss: 2.118.. \n",
      "Epoch: 36/100..  Training Loss: 2.246..  Test Loss: 2.127.. \n",
      "Epoch: 37/100..  Training Loss: 2.233..  Test Loss: 2.122.. \n",
      "Epoch: 38/100..  Training Loss: 2.233..  Test Loss: 2.134.. \n",
      "Epoch: 39/100..  Training Loss: 2.241..  Test Loss: 2.117.. \n",
      "Epoch: 40/100..  Training Loss: 2.231..  Test Loss: 2.118.. \n",
      "Epoch: 41/100..  Training Loss: 2.228..  Test Loss: 2.101.. \n",
      "Epoch: 42/100..  Training Loss: 2.223..  Test Loss: 2.119.. \n",
      "Epoch: 43/100..  Training Loss: 2.225..  Test Loss: 2.116.. \n",
      "Epoch: 44/100..  Training Loss: 2.209..  Test Loss: 2.119.. \n",
      "Epoch: 45/100..  Training Loss: 2.209..  Test Loss: 2.119.. \n",
      "Epoch: 46/100..  Training Loss: 2.214..  Test Loss: 2.120.. \n",
      "Epoch: 47/100..  Training Loss: 2.208..  Test Loss: 2.105.. \n",
      "Epoch: 48/100..  Training Loss: 2.206..  Test Loss: 2.107.. \n",
      "Epoch: 49/100..  Training Loss: 2.207..  Test Loss: 2.110.. \n",
      "Epoch: 50/100..  Training Loss: 2.199..  Test Loss: 2.106.. \n",
      "Epoch: 51/100..  Training Loss: 2.201..  Test Loss: 2.101.. \n",
      "Epoch: 52/100..  Training Loss: 2.201..  Test Loss: 2.101.. \n",
      "Epoch: 53/100..  Training Loss: 2.187..  Test Loss: 2.107.. \n",
      "Epoch: 54/100..  Training Loss: 2.200..  Test Loss: 2.103.. \n",
      "Epoch: 55/100..  Training Loss: 2.186..  Test Loss: 2.104.. \n",
      "Epoch: 56/100..  Training Loss: 2.180..  Test Loss: 2.103.. \n",
      "Epoch: 57/100..  Training Loss: 2.182..  Test Loss: 2.101.. \n",
      "Epoch: 58/100..  Training Loss: 2.175..  Test Loss: 2.114.. \n",
      "Epoch: 59/100..  Training Loss: 2.180..  Test Loss: 2.103.. \n",
      "Epoch: 60/100..  Training Loss: 2.174..  Test Loss: 2.101.. \n",
      "Epoch: 61/100..  Training Loss: 2.175..  Test Loss: 2.103.. \n",
      "Epoch: 62/100..  Training Loss: 2.163..  Test Loss: 2.098.. \n",
      "Epoch: 63/100..  Training Loss: 2.172..  Test Loss: 2.097.. \n",
      "Epoch: 64/100..  Training Loss: 2.169..  Test Loss: 2.094.. \n",
      "Epoch: 65/100..  Training Loss: 2.156..  Test Loss: 2.095.. \n",
      "Epoch: 66/100..  Training Loss: 2.159..  Test Loss: 2.099.. \n",
      "Epoch: 67/100..  Training Loss: 2.163..  Test Loss: 2.098.. \n",
      "Epoch: 68/100..  Training Loss: 2.160..  Test Loss: 2.093.. \n",
      "Epoch: 69/100..  Training Loss: 2.160..  Test Loss: 2.091.. \n",
      "Epoch: 70/100..  Training Loss: 2.157..  Test Loss: 2.093.. \n",
      "Epoch: 71/100..  Training Loss: 2.149..  Test Loss: 2.091.. \n",
      "Epoch: 72/100..  Training Loss: 2.148..  Test Loss: 2.094.. \n",
      "Epoch: 73/100..  Training Loss: 2.147..  Test Loss: 2.088.. \n",
      "Epoch: 74/100..  Training Loss: 2.153..  Test Loss: 2.085.. \n",
      "Epoch: 75/100..  Training Loss: 2.148..  Test Loss: 2.094.. \n",
      "Epoch: 76/100..  Training Loss: 2.147..  Test Loss: 2.096.. \n",
      "Epoch: 77/100..  Training Loss: 2.147..  Test Loss: 2.092.. \n",
      "Epoch: 78/100..  Training Loss: 2.145..  Test Loss: 2.092.. \n",
      "Epoch: 79/100..  Training Loss: 2.146..  Test Loss: 2.089.. \n",
      "Epoch: 80/100..  Training Loss: 2.137..  Test Loss: 2.091.. \n",
      "Epoch: 81/100..  Training Loss: 2.139..  Test Loss: 2.085.. \n",
      "Epoch: 82/100..  Training Loss: 2.134..  Test Loss: 2.086.. \n",
      "Epoch: 83/100..  Training Loss: 2.136..  Test Loss: 2.086.. \n",
      "Epoch: 84/100..  Training Loss: 2.128..  Test Loss: 2.087.. \n",
      "Epoch: 85/100..  Training Loss: 2.129..  Test Loss: 2.087.. \n",
      "Epoch: 86/100..  Training Loss: 2.125..  Test Loss: 2.087.. \n",
      "Epoch: 87/100..  Training Loss: 2.121..  Test Loss: 2.085.. \n",
      "Epoch: 88/100..  Training Loss: 2.123..  Test Loss: 2.087.. \n",
      "Epoch: 89/100..  Training Loss: 2.132..  Test Loss: 2.084.. \n",
      "Epoch: 90/100..  Training Loss: 2.125..  Test Loss: 2.088.. \n",
      "Epoch: 91/100..  Training Loss: 2.125..  Test Loss: 2.084.. \n",
      "Epoch: 92/100..  Training Loss: 2.116..  Test Loss: 2.080.. \n",
      "Epoch: 93/100..  Training Loss: 2.127..  Test Loss: 2.086.. \n",
      "Epoch: 94/100..  Training Loss: 2.120..  Test Loss: 2.082.. \n",
      "Epoch: 95/100..  Training Loss: 2.123..  Test Loss: 2.083.. \n",
      "Epoch: 96/100..  Training Loss: 2.123..  Test Loss: 2.081.. \n",
      "Epoch: 97/100..  Training Loss: 2.124..  Test Loss: 2.081.. \n",
      "Epoch: 98/100..  Training Loss: 2.118..  Test Loss: 2.082.. \n",
      "Epoch: 99/100..  Training Loss: 2.117..  Test Loss: 2.082.. \n",
      "Epoch: 100/100..  Training Loss: 2.108..  Test Loss: 2.084.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 1\n",
      "Epoch: 1/100..  Training Loss: 7.544..  Test Loss: 6.710.. \n",
      "Epoch: 2/100..  Training Loss: 6.846..  Test Loss: 6.247.. \n",
      "Epoch: 3/100..  Training Loss: 6.249..  Test Loss: 5.778.. \n",
      "Epoch: 4/100..  Training Loss: 5.776..  Test Loss: 5.378.. \n",
      "Epoch: 5/100..  Training Loss: 5.339..  Test Loss: 5.081.. \n",
      "Epoch: 6/100..  Training Loss: 4.932..  Test Loss: 4.746.. \n",
      "Epoch: 7/100..  Training Loss: 4.568..  Test Loss: 4.412.. \n",
      "Epoch: 8/100..  Training Loss: 4.276..  Test Loss: 4.120.. \n",
      "Epoch: 9/100..  Training Loss: 3.998..  Test Loss: 3.878.. \n",
      "Epoch: 10/100..  Training Loss: 3.754..  Test Loss: 3.674.. \n",
      "Epoch: 11/100..  Training Loss: 3.549..  Test Loss: 3.480.. \n",
      "Epoch: 12/100..  Training Loss: 3.375..  Test Loss: 3.346.. \n",
      "Epoch: 13/100..  Training Loss: 3.264..  Test Loss: 3.209.. \n",
      "Epoch: 14/100..  Training Loss: 3.165..  Test Loss: 3.088.. \n",
      "Epoch: 15/100..  Training Loss: 3.052..  Test Loss: 2.999.. \n",
      "Epoch: 16/100..  Training Loss: 2.971..  Test Loss: 2.930.. \n",
      "Epoch: 17/100..  Training Loss: 2.908..  Test Loss: 2.852.. \n",
      "Epoch: 18/100..  Training Loss: 2.849..  Test Loss: 2.760.. \n",
      "Epoch: 19/100..  Training Loss: 2.806..  Test Loss: 2.706.. \n",
      "Epoch: 20/100..  Training Loss: 2.765..  Test Loss: 2.629.. \n",
      "Epoch: 21/100..  Training Loss: 2.644..  Test Loss: 2.535.. \n",
      "Epoch: 22/100..  Training Loss: 2.601..  Test Loss: 2.452.. \n",
      "Epoch: 23/100..  Training Loss: 2.537..  Test Loss: 2.422.. \n",
      "Epoch: 24/100..  Training Loss: 2.486..  Test Loss: 2.334.. \n",
      "Epoch: 25/100..  Training Loss: 2.486..  Test Loss: 2.279.. \n",
      "Epoch: 26/100..  Training Loss: 2.444..  Test Loss: 2.318.. \n",
      "Epoch: 27/100..  Training Loss: 2.426..  Test Loss: 2.244.. \n",
      "Epoch: 28/100..  Training Loss: 2.437..  Test Loss: 2.217.. \n",
      "Epoch: 29/100..  Training Loss: 2.398..  Test Loss: 2.200.. \n",
      "Epoch: 30/100..  Training Loss: 2.415..  Test Loss: 2.222.. \n",
      "Epoch: 31/100..  Training Loss: 2.391..  Test Loss: 2.177.. \n",
      "Epoch: 32/100..  Training Loss: 2.385..  Test Loss: 2.162.. \n",
      "Epoch: 33/100..  Training Loss: 2.391..  Test Loss: 2.184.. \n",
      "Epoch: 34/100..  Training Loss: 2.373..  Test Loss: 2.174.. \n",
      "Epoch: 35/100..  Training Loss: 2.358..  Test Loss: 2.162.. \n",
      "Epoch: 36/100..  Training Loss: 2.336..  Test Loss: 2.151.. \n",
      "Epoch: 37/100..  Training Loss: 2.332..  Test Loss: 2.146.. \n",
      "Epoch: 38/100..  Training Loss: 2.357..  Test Loss: 2.150.. \n",
      "Epoch: 39/100..  Training Loss: 2.316..  Test Loss: 2.149.. \n",
      "Epoch: 40/100..  Training Loss: 2.332..  Test Loss: 2.136.. \n",
      "Epoch: 41/100..  Training Loss: 2.315..  Test Loss: 2.150.. \n",
      "Epoch: 42/100..  Training Loss: 2.293..  Test Loss: 2.153.. \n",
      "Epoch: 43/100..  Training Loss: 2.310..  Test Loss: 2.125.. \n",
      "Epoch: 44/100..  Training Loss: 2.308..  Test Loss: 2.133.. \n",
      "Epoch: 45/100..  Training Loss: 2.296..  Test Loss: 2.165.. \n",
      "Epoch: 46/100..  Training Loss: 2.290..  Test Loss: 2.137.. \n",
      "Epoch: 47/100..  Training Loss: 2.284..  Test Loss: 2.138.. \n",
      "Epoch: 48/100..  Training Loss: 2.289..  Test Loss: 2.138.. \n",
      "Epoch: 49/100..  Training Loss: 2.263..  Test Loss: 2.125.. \n",
      "Epoch: 50/100..  Training Loss: 2.282..  Test Loss: 2.135.. \n",
      "Epoch: 51/100..  Training Loss: 2.278..  Test Loss: 2.136.. \n",
      "Epoch: 52/100..  Training Loss: 2.263..  Test Loss: 2.139.. \n",
      "Epoch: 53/100..  Training Loss: 2.247..  Test Loss: 2.135.. \n",
      "Epoch: 54/100..  Training Loss: 2.247..  Test Loss: 2.138.. \n",
      "Epoch: 55/100..  Training Loss: 2.235..  Test Loss: 2.136.. \n",
      "Epoch: 56/100..  Training Loss: 2.247..  Test Loss: 2.119.. \n",
      "Epoch: 57/100..  Training Loss: 2.241..  Test Loss: 2.138.. \n",
      "Epoch: 58/100..  Training Loss: 2.227..  Test Loss: 2.139.. \n",
      "Epoch: 59/100..  Training Loss: 2.222..  Test Loss: 2.133.. \n",
      "Epoch: 60/100..  Training Loss: 2.228..  Test Loss: 2.138.. \n",
      "Epoch: 61/100..  Training Loss: 2.228..  Test Loss: 2.145.. \n",
      "Epoch: 62/100..  Training Loss: 2.215..  Test Loss: 2.150.. \n",
      "Epoch: 63/100..  Training Loss: 2.210..  Test Loss: 2.141.. \n",
      "Epoch: 64/100..  Training Loss: 2.198..  Test Loss: 2.143.. \n",
      "Epoch: 65/100..  Training Loss: 2.197..  Test Loss: 2.144.. \n",
      "Epoch: 66/100..  Training Loss: 2.190..  Test Loss: 2.146.. \n",
      "Epoch: 67/100..  Training Loss: 2.187..  Test Loss: 2.142.. \n",
      "Epoch: 68/100..  Training Loss: 2.184..  Test Loss: 2.136.. \n",
      "Epoch: 69/100..  Training Loss: 2.196..  Test Loss: 2.136.. \n",
      "Epoch: 70/100..  Training Loss: 2.185..  Test Loss: 2.135.. \n",
      "Epoch: 71/100..  Training Loss: 2.179..  Test Loss: 2.127.. \n",
      "Epoch: 72/100..  Training Loss: 2.176..  Test Loss: 2.133.. \n",
      "Epoch: 73/100..  Training Loss: 2.178..  Test Loss: 2.132.. \n",
      "Epoch: 74/100..  Training Loss: 2.173..  Test Loss: 2.137.. \n",
      "Epoch: 75/100..  Training Loss: 2.172..  Test Loss: 2.131.. \n",
      "Epoch: 76/100..  Training Loss: 2.163..  Test Loss: 2.125.. \n",
      "Epoch: 77/100..  Training Loss: 2.165..  Test Loss: 2.126.. \n",
      "Epoch: 78/100..  Training Loss: 2.158..  Test Loss: 2.124.. \n",
      "Epoch: 79/100..  Training Loss: 2.162..  Test Loss: 2.117.. \n",
      "Epoch: 80/100..  Training Loss: 2.157..  Test Loss: 2.123.. \n",
      "Epoch: 81/100..  Training Loss: 2.160..  Test Loss: 2.123.. \n",
      "Epoch: 82/100..  Training Loss: 2.157..  Test Loss: 2.112.. \n",
      "Epoch: 83/100..  Training Loss: 2.151..  Test Loss: 2.118.. \n",
      "Epoch: 84/100..  Training Loss: 2.148..  Test Loss: 2.115.. \n",
      "Epoch: 85/100..  Training Loss: 2.140..  Test Loss: 2.114.. \n",
      "Epoch: 86/100..  Training Loss: 2.143..  Test Loss: 2.112.. \n",
      "Epoch: 87/100..  Training Loss: 2.142..  Test Loss: 2.108.. \n",
      "Epoch: 88/100..  Training Loss: 2.136..  Test Loss: 2.112.. \n",
      "Epoch: 89/100..  Training Loss: 2.138..  Test Loss: 2.115.. \n",
      "Epoch: 90/100..  Training Loss: 2.132..  Test Loss: 2.108.. \n",
      "Epoch: 91/100..  Training Loss: 2.129..  Test Loss: 2.112.. \n",
      "Epoch: 92/100..  Training Loss: 2.130..  Test Loss: 2.109.. \n",
      "Epoch: 93/100..  Training Loss: 2.128..  Test Loss: 2.108.. \n",
      "Epoch: 94/100..  Training Loss: 2.126..  Test Loss: 2.109.. \n",
      "Epoch: 95/100..  Training Loss: 2.126..  Test Loss: 2.106.. \n",
      "Epoch: 96/100..  Training Loss: 2.124..  Test Loss: 2.107.. \n",
      "Epoch: 97/100..  Training Loss: 2.127..  Test Loss: 2.100.. \n",
      "Epoch: 98/100..  Training Loss: 2.121..  Test Loss: 2.106.. \n",
      "Epoch: 99/100..  Training Loss: 2.119..  Test Loss: 2.102.. \n",
      "Epoch: 100/100..  Training Loss: 2.118..  Test Loss: 2.096.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 2\n",
      "Epoch: 1/100..  Training Loss: 7.046..  Test Loss: 6.696.. \n",
      "Epoch: 2/100..  Training Loss: 6.366..  Test Loss: 6.079.. \n",
      "Epoch: 3/100..  Training Loss: 5.820..  Test Loss: 5.594.. \n",
      "Epoch: 4/100..  Training Loss: 5.280..  Test Loss: 5.074.. \n",
      "Epoch: 5/100..  Training Loss: 4.790..  Test Loss: 4.602.. \n",
      "Epoch: 6/100..  Training Loss: 4.322..  Test Loss: 4.216.. \n",
      "Epoch: 7/100..  Training Loss: 3.965..  Test Loss: 3.792.. \n",
      "Epoch: 8/100..  Training Loss: 3.678..  Test Loss: 3.507.. \n",
      "Epoch: 9/100..  Training Loss: 3.478..  Test Loss: 3.248.. \n",
      "Epoch: 10/100..  Training Loss: 3.215..  Test Loss: 2.993.. \n",
      "Epoch: 11/100..  Training Loss: 3.146..  Test Loss: 2.852.. \n",
      "Epoch: 12/100..  Training Loss: 3.021..  Test Loss: 2.717.. \n",
      "Epoch: 13/100..  Training Loss: 2.934..  Test Loss: 2.609.. \n",
      "Epoch: 14/100..  Training Loss: 2.817..  Test Loss: 2.534.. \n",
      "Epoch: 15/100..  Training Loss: 2.811..  Test Loss: 2.482.. \n",
      "Epoch: 16/100..  Training Loss: 2.806..  Test Loss: 2.428.. \n",
      "Epoch: 17/100..  Training Loss: 2.730..  Test Loss: 2.404.. \n",
      "Epoch: 18/100..  Training Loss: 2.792..  Test Loss: 2.358.. \n",
      "Epoch: 19/100..  Training Loss: 2.752..  Test Loss: 2.351.. \n",
      "Epoch: 20/100..  Training Loss: 2.698..  Test Loss: 2.321.. \n",
      "Epoch: 21/100..  Training Loss: 2.719..  Test Loss: 2.340.. \n",
      "Epoch: 22/100..  Training Loss: 2.654..  Test Loss: 2.285.. \n",
      "Epoch: 23/100..  Training Loss: 2.625..  Test Loss: 2.285.. \n",
      "Epoch: 24/100..  Training Loss: 2.641..  Test Loss: 2.284.. \n",
      "Epoch: 25/100..  Training Loss: 2.617..  Test Loss: 2.276.. \n",
      "Epoch: 26/100..  Training Loss: 2.618..  Test Loss: 2.290.. \n",
      "Epoch: 27/100..  Training Loss: 2.604..  Test Loss: 2.255.. \n",
      "Epoch: 28/100..  Training Loss: 2.613..  Test Loss: 2.252.. \n",
      "Epoch: 29/100..  Training Loss: 2.581..  Test Loss: 2.259.. \n",
      "Epoch: 30/100..  Training Loss: 2.570..  Test Loss: 2.246.. \n",
      "Epoch: 31/100..  Training Loss: 2.574..  Test Loss: 2.245.. \n",
      "Epoch: 32/100..  Training Loss: 2.538..  Test Loss: 2.244.. \n",
      "Epoch: 33/100..  Training Loss: 2.556..  Test Loss: 2.235.. \n",
      "Epoch: 34/100..  Training Loss: 2.532..  Test Loss: 2.237.. \n",
      "Epoch: 35/100..  Training Loss: 2.533..  Test Loss: 2.239.. \n",
      "Epoch: 36/100..  Training Loss: 2.503..  Test Loss: 2.230.. \n",
      "Epoch: 37/100..  Training Loss: 2.503..  Test Loss: 2.230.. \n",
      "Epoch: 38/100..  Training Loss: 2.510..  Test Loss: 2.217.. \n",
      "Epoch: 39/100..  Training Loss: 2.484..  Test Loss: 2.208.. \n",
      "Epoch: 40/100..  Training Loss: 2.462..  Test Loss: 2.210.. \n",
      "Epoch: 41/100..  Training Loss: 2.474..  Test Loss: 2.206.. \n",
      "Epoch: 42/100..  Training Loss: 2.458..  Test Loss: 2.198.. \n",
      "Epoch: 43/100..  Training Loss: 2.437..  Test Loss: 2.207.. \n",
      "Epoch: 44/100..  Training Loss: 2.458..  Test Loss: 2.205.. \n",
      "Epoch: 45/100..  Training Loss: 2.420..  Test Loss: 2.188.. \n",
      "Epoch: 46/100..  Training Loss: 2.413..  Test Loss: 2.176.. \n",
      "Epoch: 47/100..  Training Loss: 2.400..  Test Loss: 2.183.. \n",
      "Epoch: 48/100..  Training Loss: 2.397..  Test Loss: 2.174.. \n",
      "Epoch: 49/100..  Training Loss: 2.373..  Test Loss: 2.191.. \n",
      "Epoch: 50/100..  Training Loss: 2.369..  Test Loss: 2.176.. \n",
      "Epoch: 51/100..  Training Loss: 2.366..  Test Loss: 2.168.. \n",
      "Epoch: 52/100..  Training Loss: 2.353..  Test Loss: 2.164.. \n",
      "Epoch: 53/100..  Training Loss: 2.357..  Test Loss: 2.158.. \n",
      "Epoch: 54/100..  Training Loss: 2.341..  Test Loss: 2.158.. \n",
      "Epoch: 55/100..  Training Loss: 2.329..  Test Loss: 2.160.. \n",
      "Epoch: 56/100..  Training Loss: 2.322..  Test Loss: 2.152.. \n",
      "Epoch: 57/100..  Training Loss: 2.330..  Test Loss: 2.154.. \n",
      "Epoch: 58/100..  Training Loss: 2.309..  Test Loss: 2.143.. \n",
      "Epoch: 59/100..  Training Loss: 2.318..  Test Loss: 2.190.. \n",
      "Epoch: 60/100..  Training Loss: 2.304..  Test Loss: 2.157.. \n",
      "Epoch: 61/100..  Training Loss: 2.295..  Test Loss: 2.146.. \n",
      "Epoch: 62/100..  Training Loss: 2.286..  Test Loss: 2.140.. \n",
      "Epoch: 63/100..  Training Loss: 2.289..  Test Loss: 2.156.. \n",
      "Epoch: 64/100..  Training Loss: 2.266..  Test Loss: 2.132.. \n",
      "Epoch: 65/100..  Training Loss: 2.265..  Test Loss: 2.128.. \n",
      "Epoch: 66/100..  Training Loss: 2.258..  Test Loss: 2.125.. \n",
      "Epoch: 67/100..  Training Loss: 2.249..  Test Loss: 2.122.. \n",
      "Epoch: 68/100..  Training Loss: 2.235..  Test Loss: 2.119.. \n",
      "Epoch: 69/100..  Training Loss: 2.249..  Test Loss: 2.124.. \n",
      "Epoch: 70/100..  Training Loss: 2.229..  Test Loss: 2.122.. \n",
      "Epoch: 71/100..  Training Loss: 2.223..  Test Loss: 2.112.. \n",
      "Epoch: 72/100..  Training Loss: 2.221..  Test Loss: 2.116.. \n",
      "Epoch: 73/100..  Training Loss: 2.223..  Test Loss: 2.115.. \n",
      "Epoch: 74/100..  Training Loss: 2.216..  Test Loss: 2.115.. \n",
      "Epoch: 75/100..  Training Loss: 2.224..  Test Loss: 2.101.. \n",
      "Epoch: 76/100..  Training Loss: 2.210..  Test Loss: 2.108.. \n",
      "Epoch: 77/100..  Training Loss: 2.218..  Test Loss: 2.096.. \n",
      "Epoch: 78/100..  Training Loss: 2.198..  Test Loss: 2.107.. \n",
      "Epoch: 79/100..  Training Loss: 2.208..  Test Loss: 2.102.. \n",
      "Epoch: 80/100..  Training Loss: 2.205..  Test Loss: 2.102.. \n",
      "Epoch: 81/100..  Training Loss: 2.188..  Test Loss: 2.107.. \n",
      "Epoch: 82/100..  Training Loss: 2.187..  Test Loss: 2.101.. \n",
      "Epoch: 83/100..  Training Loss: 2.189..  Test Loss: 2.099.. \n",
      "Epoch: 84/100..  Training Loss: 2.185..  Test Loss: 2.105.. \n",
      "Epoch: 85/100..  Training Loss: 2.184..  Test Loss: 2.101.. \n",
      "Epoch: 86/100..  Training Loss: 2.188..  Test Loss: 2.099.. \n",
      "Epoch: 87/100..  Training Loss: 2.172..  Test Loss: 2.096.. \n",
      "Epoch: 88/100..  Training Loss: 2.181..  Test Loss: 2.100.. \n",
      "Epoch: 89/100..  Training Loss: 2.166..  Test Loss: 2.101.. \n",
      "Epoch: 90/100..  Training Loss: 2.168..  Test Loss: 2.099.. \n",
      "Epoch: 91/100..  Training Loss: 2.172..  Test Loss: 2.096.. \n",
      "Epoch: 92/100..  Training Loss: 2.165..  Test Loss: 2.098.. \n",
      "Epoch: 93/100..  Training Loss: 2.163..  Test Loss: 2.099.. \n",
      "Epoch: 94/100..  Training Loss: 2.166..  Test Loss: 2.089.. \n",
      "Epoch: 95/100..  Training Loss: 2.155..  Test Loss: 2.095.. \n",
      "Epoch: 96/100..  Training Loss: 2.152..  Test Loss: 2.098.. \n",
      "Epoch: 97/100..  Training Loss: 2.158..  Test Loss: 2.092.. \n",
      "Epoch: 98/100..  Training Loss: 2.146..  Test Loss: 2.094.. \n",
      "Epoch: 99/100..  Training Loss: 2.146..  Test Loss: 2.087.. \n",
      "Epoch: 100/100..  Training Loss: 2.146..  Test Loss: 2.091.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 3\n",
      "Epoch: 1/100..  Training Loss: 3.998..  Test Loss: 3.924.. \n",
      "Epoch: 2/100..  Training Loss: 3.669..  Test Loss: 3.609.. \n",
      "Epoch: 3/100..  Training Loss: 3.371..  Test Loss: 3.367.. \n",
      "Epoch: 4/100..  Training Loss: 3.164..  Test Loss: 3.119.. \n",
      "Epoch: 5/100..  Training Loss: 2.955..  Test Loss: 2.975.. \n",
      "Epoch: 6/100..  Training Loss: 2.862..  Test Loss: 2.800.. \n",
      "Epoch: 7/100..  Training Loss: 2.720..  Test Loss: 2.683.. \n",
      "Epoch: 8/100..  Training Loss: 2.646..  Test Loss: 2.581.. \n",
      "Epoch: 9/100..  Training Loss: 2.634..  Test Loss: 2.492.. \n",
      "Epoch: 10/100..  Training Loss: 2.539..  Test Loss: 2.431.. \n",
      "Epoch: 11/100..  Training Loss: 2.527..  Test Loss: 2.361.. \n",
      "Epoch: 12/100..  Training Loss: 2.434..  Test Loss: 2.279.. \n",
      "Epoch: 13/100..  Training Loss: 2.389..  Test Loss: 2.233.. \n",
      "Epoch: 14/100..  Training Loss: 2.368..  Test Loss: 2.194.. \n",
      "Epoch: 15/100..  Training Loss: 2.391..  Test Loss: 2.169.. \n",
      "Epoch: 16/100..  Training Loss: 2.333..  Test Loss: 2.169.. \n",
      "Epoch: 17/100..  Training Loss: 2.331..  Test Loss: 2.152.. \n",
      "Epoch: 18/100..  Training Loss: 2.316..  Test Loss: 2.151.. \n",
      "Epoch: 19/100..  Training Loss: 2.297..  Test Loss: 2.145.. \n",
      "Epoch: 20/100..  Training Loss: 2.297..  Test Loss: 2.142.. \n",
      "Epoch: 21/100..  Training Loss: 2.305..  Test Loss: 2.149.. \n",
      "Epoch: 22/100..  Training Loss: 2.293..  Test Loss: 2.152.. \n",
      "Epoch: 23/100..  Training Loss: 2.279..  Test Loss: 2.144.. \n",
      "Epoch: 24/100..  Training Loss: 2.260..  Test Loss: 2.140.. \n",
      "Epoch: 25/100..  Training Loss: 2.283..  Test Loss: 2.134.. \n",
      "Epoch: 26/100..  Training Loss: 2.265..  Test Loss: 2.144.. \n",
      "Epoch: 27/100..  Training Loss: 2.258..  Test Loss: 2.143.. \n",
      "Epoch: 28/100..  Training Loss: 2.250..  Test Loss: 2.149.. \n",
      "Epoch: 29/100..  Training Loss: 2.238..  Test Loss: 2.133.. \n",
      "Epoch: 30/100..  Training Loss: 2.232..  Test Loss: 2.135.. \n",
      "Epoch: 31/100..  Training Loss: 2.233..  Test Loss: 2.139.. \n",
      "Epoch: 32/100..  Training Loss: 2.227..  Test Loss: 2.135.. \n",
      "Epoch: 33/100..  Training Loss: 2.235..  Test Loss: 2.127.. \n",
      "Epoch: 34/100..  Training Loss: 2.220..  Test Loss: 2.128.. \n",
      "Epoch: 35/100..  Training Loss: 2.214..  Test Loss: 2.140.. \n",
      "Epoch: 36/100..  Training Loss: 2.222..  Test Loss: 2.128.. \n",
      "Epoch: 37/100..  Training Loss: 2.204..  Test Loss: 2.130.. \n",
      "Epoch: 38/100..  Training Loss: 2.204..  Test Loss: 2.123.. \n",
      "Epoch: 39/100..  Training Loss: 2.219..  Test Loss: 2.126.. \n",
      "Epoch: 40/100..  Training Loss: 2.197..  Test Loss: 2.121.. \n",
      "Epoch: 41/100..  Training Loss: 2.203..  Test Loss: 2.123.. \n",
      "Epoch: 42/100..  Training Loss: 2.202..  Test Loss: 2.129.. \n",
      "Epoch: 43/100..  Training Loss: 2.197..  Test Loss: 2.120.. \n",
      "Epoch: 44/100..  Training Loss: 2.189..  Test Loss: 2.118.. \n",
      "Epoch: 45/100..  Training Loss: 2.186..  Test Loss: 2.120.. \n",
      "Epoch: 46/100..  Training Loss: 2.189..  Test Loss: 2.123.. \n",
      "Epoch: 47/100..  Training Loss: 2.184..  Test Loss: 2.111.. \n",
      "Epoch: 48/100..  Training Loss: 2.175..  Test Loss: 2.112.. \n",
      "Epoch: 49/100..  Training Loss: 2.172..  Test Loss: 2.117.. \n",
      "Epoch: 50/100..  Training Loss: 2.168..  Test Loss: 2.108.. \n",
      "Epoch: 51/100..  Training Loss: 2.169..  Test Loss: 2.109.. \n",
      "Epoch: 52/100..  Training Loss: 2.167..  Test Loss: 2.110.. \n",
      "Epoch: 53/100..  Training Loss: 2.164..  Test Loss: 2.109.. \n",
      "Epoch: 54/100..  Training Loss: 2.162..  Test Loss: 2.103.. \n",
      "Epoch: 55/100..  Training Loss: 2.154..  Test Loss: 2.104.. \n",
      "Epoch: 56/100..  Training Loss: 2.150..  Test Loss: 2.102.. \n",
      "Epoch: 57/100..  Training Loss: 2.150..  Test Loss: 2.106.. \n",
      "Epoch: 58/100..  Training Loss: 2.151..  Test Loss: 2.100.. \n",
      "Epoch: 59/100..  Training Loss: 2.143..  Test Loss: 2.099.. \n",
      "Epoch: 60/100..  Training Loss: 2.157..  Test Loss: 2.108.. \n",
      "Epoch: 61/100..  Training Loss: 2.137..  Test Loss: 2.105.. \n",
      "Epoch: 62/100..  Training Loss: 2.143..  Test Loss: 2.101.. \n",
      "Epoch: 63/100..  Training Loss: 2.142..  Test Loss: 2.109.. \n",
      "Epoch: 64/100..  Training Loss: 2.138..  Test Loss: 2.100.. \n",
      "Epoch: 65/100..  Training Loss: 2.138..  Test Loss: 2.096.. \n",
      "Epoch: 66/100..  Training Loss: 2.136..  Test Loss: 2.095.. \n",
      "Epoch: 67/100..  Training Loss: 2.132..  Test Loss: 2.101.. \n",
      "Epoch: 68/100..  Training Loss: 2.132..  Test Loss: 2.096.. \n",
      "Epoch: 69/100..  Training Loss: 2.124..  Test Loss: 2.095.. \n",
      "Epoch: 70/100..  Training Loss: 2.125..  Test Loss: 2.096.. \n",
      "Epoch: 71/100..  Training Loss: 2.122..  Test Loss: 2.093.. \n",
      "Epoch: 72/100..  Training Loss: 2.123..  Test Loss: 2.095.. \n",
      "Epoch: 73/100..  Training Loss: 2.121..  Test Loss: 2.096.. \n",
      "Epoch: 74/100..  Training Loss: 2.115..  Test Loss: 2.090.. \n",
      "Epoch: 75/100..  Training Loss: 2.119..  Test Loss: 2.092.. \n",
      "Epoch: 76/100..  Training Loss: 2.115..  Test Loss: 2.095.. \n",
      "Epoch: 77/100..  Training Loss: 2.119..  Test Loss: 2.092.. \n",
      "Epoch: 78/100..  Training Loss: 2.118..  Test Loss: 2.091.. \n",
      "Epoch: 79/100..  Training Loss: 2.113..  Test Loss: 2.091.. \n",
      "Epoch: 80/100..  Training Loss: 2.113..  Test Loss: 2.089.. \n",
      "Epoch: 81/100..  Training Loss: 2.113..  Test Loss: 2.094.. \n",
      "Epoch: 82/100..  Training Loss: 2.108..  Test Loss: 2.094.. \n",
      "Epoch: 83/100..  Training Loss: 2.110..  Test Loss: 2.091.. \n",
      "Epoch: 84/100..  Training Loss: 2.110..  Test Loss: 2.090.. \n",
      "Epoch: 85/100..  Training Loss: 2.106..  Test Loss: 2.090.. \n",
      "Epoch: 86/100..  Training Loss: 2.108..  Test Loss: 2.089.. \n",
      "Epoch: 87/100..  Training Loss: 2.104..  Test Loss: 2.092.. \n",
      "Epoch: 88/100..  Training Loss: 2.104..  Test Loss: 2.090.. \n",
      "Epoch: 89/100..  Training Loss: 2.103..  Test Loss: 2.088.. \n",
      "Epoch: 90/100..  Training Loss: 2.101..  Test Loss: 2.087.. \n",
      "Epoch: 91/100..  Training Loss: 2.104..  Test Loss: 2.089.. \n",
      "Epoch: 92/100..  Training Loss: 2.099..  Test Loss: 2.091.. \n",
      "Epoch: 93/100..  Training Loss: 2.102..  Test Loss: 2.086.. \n",
      "Epoch: 94/100..  Training Loss: 2.102..  Test Loss: 2.086.. \n",
      "Epoch: 95/100..  Training Loss: 2.100..  Test Loss: 2.089.. \n",
      "Epoch: 96/100..  Training Loss: 2.093..  Test Loss: 2.084.. \n",
      "Epoch: 97/100..  Training Loss: 2.099..  Test Loss: 2.086.. \n",
      "Epoch: 98/100..  Training Loss: 2.100..  Test Loss: 2.086.. \n",
      "Epoch: 99/100..  Training Loss: 2.099..  Test Loss: 2.087.. \n",
      "Epoch: 100/100..  Training Loss: 2.096..  Test Loss: 2.086.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 4\n",
      "Epoch: 1/100..  Training Loss: 5.080..  Test Loss: 5.044.. \n",
      "Epoch: 2/100..  Training Loss: 4.656..  Test Loss: 4.513.. \n",
      "Epoch: 3/100..  Training Loss: 4.240..  Test Loss: 4.146.. \n",
      "Epoch: 4/100..  Training Loss: 3.892..  Test Loss: 3.902.. \n",
      "Epoch: 5/100..  Training Loss: 3.617..  Test Loss: 3.571.. \n",
      "Epoch: 6/100..  Training Loss: 3.313..  Test Loss: 3.324.. \n",
      "Epoch: 7/100..  Training Loss: 3.083..  Test Loss: 3.101.. \n",
      "Epoch: 8/100..  Training Loss: 2.962..  Test Loss: 2.894.. \n",
      "Epoch: 9/100..  Training Loss: 2.818..  Test Loss: 2.742.. \n",
      "Epoch: 10/100..  Training Loss: 2.724..  Test Loss: 2.639.. \n",
      "Epoch: 11/100..  Training Loss: 2.612..  Test Loss: 2.557.. \n",
      "Epoch: 12/100..  Training Loss: 2.592..  Test Loss: 2.494.. \n",
      "Epoch: 13/100..  Training Loss: 2.559..  Test Loss: 2.436.. \n",
      "Epoch: 14/100..  Training Loss: 2.514..  Test Loss: 2.412.. \n",
      "Epoch: 15/100..  Training Loss: 2.494..  Test Loss: 2.354.. \n",
      "Epoch: 16/100..  Training Loss: 2.453..  Test Loss: 2.363.. \n",
      "Epoch: 17/100..  Training Loss: 2.454..  Test Loss: 2.327.. \n",
      "Epoch: 18/100..  Training Loss: 2.436..  Test Loss: 2.315.. \n",
      "Epoch: 19/100..  Training Loss: 2.395..  Test Loss: 2.340.. \n",
      "Epoch: 20/100..  Training Loss: 2.409..  Test Loss: 2.292.. \n",
      "Epoch: 21/100..  Training Loss: 2.371..  Test Loss: 2.292.. \n",
      "Epoch: 22/100..  Training Loss: 2.390..  Test Loss: 2.287.. \n",
      "Epoch: 23/100..  Training Loss: 2.362..  Test Loss: 2.283.. \n",
      "Epoch: 24/100..  Training Loss: 2.357..  Test Loss: 2.303.. \n",
      "Epoch: 25/100..  Training Loss: 2.331..  Test Loss: 2.276.. \n",
      "Epoch: 26/100..  Training Loss: 2.339..  Test Loss: 2.269.. \n",
      "Epoch: 27/100..  Training Loss: 2.339..  Test Loss: 2.257.. \n",
      "Epoch: 28/100..  Training Loss: 2.320..  Test Loss: 2.257.. \n",
      "Epoch: 29/100..  Training Loss: 2.343..  Test Loss: 2.232.. \n",
      "Epoch: 30/100..  Training Loss: 2.313..  Test Loss: 2.253.. \n",
      "Epoch: 31/100..  Training Loss: 2.317..  Test Loss: 2.256.. \n",
      "Epoch: 32/100..  Training Loss: 2.311..  Test Loss: 2.240.. \n",
      "Epoch: 33/100..  Training Loss: 2.292..  Test Loss: 2.246.. \n",
      "Epoch: 34/100..  Training Loss: 2.310..  Test Loss: 2.240.. \n",
      "Epoch: 35/100..  Training Loss: 2.298..  Test Loss: 2.223.. \n",
      "Epoch: 36/100..  Training Loss: 2.302..  Test Loss: 2.205.. \n",
      "Epoch: 37/100..  Training Loss: 2.280..  Test Loss: 2.211.. \n",
      "Epoch: 38/100..  Training Loss: 2.276..  Test Loss: 2.193.. \n",
      "Epoch: 39/100..  Training Loss: 2.270..  Test Loss: 2.204.. \n",
      "Epoch: 40/100..  Training Loss: 2.268..  Test Loss: 2.199.. \n",
      "Epoch: 41/100..  Training Loss: 2.249..  Test Loss: 2.202.. \n",
      "Epoch: 42/100..  Training Loss: 2.244..  Test Loss: 2.200.. \n",
      "Epoch: 43/100..  Training Loss: 2.258..  Test Loss: 2.191.. \n",
      "Epoch: 44/100..  Training Loss: 2.243..  Test Loss: 2.193.. \n",
      "Epoch: 45/100..  Training Loss: 2.245..  Test Loss: 2.169.. \n",
      "Epoch: 46/100..  Training Loss: 2.258..  Test Loss: 2.181.. \n",
      "Epoch: 47/100..  Training Loss: 2.245..  Test Loss: 2.183.. \n",
      "Epoch: 48/100..  Training Loss: 2.245..  Test Loss: 2.168.. \n",
      "Epoch: 49/100..  Training Loss: 2.244..  Test Loss: 2.172.. \n",
      "Epoch: 50/100..  Training Loss: 2.222..  Test Loss: 2.175.. \n",
      "Epoch: 51/100..  Training Loss: 2.228..  Test Loss: 2.177.. \n",
      "Epoch: 52/100..  Training Loss: 2.223..  Test Loss: 2.178.. \n",
      "Epoch: 53/100..  Training Loss: 2.221..  Test Loss: 2.153.. \n",
      "Epoch: 54/100..  Training Loss: 2.214..  Test Loss: 2.174.. \n",
      "Epoch: 55/100..  Training Loss: 2.209..  Test Loss: 2.182.. \n",
      "Epoch: 56/100..  Training Loss: 2.212..  Test Loss: 2.164.. \n",
      "Epoch: 57/100..  Training Loss: 2.206..  Test Loss: 2.176.. \n",
      "Epoch: 58/100..  Training Loss: 2.198..  Test Loss: 2.162.. \n",
      "Epoch: 59/100..  Training Loss: 2.196..  Test Loss: 2.171.. \n",
      "Epoch: 60/100..  Training Loss: 2.194..  Test Loss: 2.161.. \n",
      "Epoch: 61/100..  Training Loss: 2.183..  Test Loss: 2.160.. \n",
      "Epoch: 62/100..  Training Loss: 2.183..  Test Loss: 2.164.. \n",
      "Epoch: 63/100..  Training Loss: 2.191..  Test Loss: 2.170.. \n",
      "Epoch: 64/100..  Training Loss: 2.184..  Test Loss: 2.153.. \n",
      "Epoch: 65/100..  Training Loss: 2.181..  Test Loss: 2.173.. \n",
      "Epoch: 66/100..  Training Loss: 2.179..  Test Loss: 2.166.. \n",
      "Epoch: 67/100..  Training Loss: 2.178..  Test Loss: 2.164.. \n",
      "Epoch: 68/100..  Training Loss: 2.167..  Test Loss: 2.156.. \n",
      "Epoch: 69/100..  Training Loss: 2.168..  Test Loss: 2.179.. \n",
      "Epoch: 70/100..  Training Loss: 2.173..  Test Loss: 2.155.. \n",
      "Epoch: 71/100..  Training Loss: 2.164..  Test Loss: 2.167.. \n",
      "Epoch: 72/100..  Training Loss: 2.158..  Test Loss: 2.168.. \n",
      "Epoch: 73/100..  Training Loss: 2.161..  Test Loss: 2.153.. \n",
      "Epoch: 74/100..  Training Loss: 2.156..  Test Loss: 2.154.. \n",
      "Epoch: 75/100..  Training Loss: 2.146..  Test Loss: 2.157.. \n",
      "Epoch: 76/100..  Training Loss: 2.160..  Test Loss: 2.152.. \n",
      "Epoch: 77/100..  Training Loss: 2.152..  Test Loss: 2.154.. \n",
      "Epoch: 78/100..  Training Loss: 2.152..  Test Loss: 2.159.. \n",
      "Epoch: 79/100..  Training Loss: 2.147..  Test Loss: 2.145.. \n",
      "Epoch: 80/100..  Training Loss: 2.145..  Test Loss: 2.139.. \n",
      "Epoch: 81/100..  Training Loss: 2.142..  Test Loss: 2.142.. \n",
      "Epoch: 82/100..  Training Loss: 2.143..  Test Loss: 2.146.. \n",
      "Epoch: 83/100..  Training Loss: 2.142..  Test Loss: 2.131.. \n",
      "Epoch: 84/100..  Training Loss: 2.137..  Test Loss: 2.147.. \n",
      "Epoch: 85/100..  Training Loss: 2.144..  Test Loss: 2.133.. \n",
      "Epoch: 86/100..  Training Loss: 2.138..  Test Loss: 2.143.. \n",
      "Epoch: 87/100..  Training Loss: 2.133..  Test Loss: 2.129.. \n",
      "Epoch: 88/100..  Training Loss: 2.138..  Test Loss: 2.141.. \n",
      "Epoch: 89/100..  Training Loss: 2.132..  Test Loss: 2.136.. \n",
      "Epoch: 90/100..  Training Loss: 2.138..  Test Loss: 2.128.. \n",
      "Epoch: 91/100..  Training Loss: 2.127..  Test Loss: 2.137.. \n",
      "Epoch: 92/100..  Training Loss: 2.129..  Test Loss: 2.143.. \n",
      "Epoch: 93/100..  Training Loss: 2.124..  Test Loss: 2.131.. \n",
      "Epoch: 94/100..  Training Loss: 2.128..  Test Loss: 2.125.. \n",
      "Epoch: 95/100..  Training Loss: 2.125..  Test Loss: 2.133.. \n",
      "Epoch: 96/100..  Training Loss: 2.126..  Test Loss: 2.120.. \n",
      "Epoch: 97/100..  Training Loss: 2.126..  Test Loss: 2.117.. \n",
      "Epoch: 98/100..  Training Loss: 2.122..  Test Loss: 2.131.. \n",
      "Epoch: 99/100..  Training Loss: 2.123..  Test Loss: 2.118.. \n",
      "Epoch: 100/100..  Training Loss: 2.119..  Test Loss: 2.119.. \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXzU1b3/8ddnZrJvk5UkJCFssoUAMQKKFUFrxbVarVpx6bX1ahf91d7bYm+vrba91dZrlV7rUm+trV6p1VqtVawLioqAgBhAQLYkhOz7PsnMnN8f3yENIStMGDLzeT4eeWSWM9/5fGfgnTPne75nxBiDUkqpsc8W6AKUUkr5hwa6UkoFCQ10pZQKEhroSikVJDTQlVIqSDgC9cQpKSkmNzc3UE+vlFJj0ubNm2uNMan93RewQM/NzWXTpk2BenqllBqTRKRkoPt0yEUppYKEBrpSSgUJDXSllAoSGuhKKRUkNNCVUipIaKArpVSQ0EBXSqkgMeYCfVdlM79YvYum9u5Al6KUUieVMRfoJXXt/OadfZTWtwe6FKXUCNTV1TF37lzmzp1Leno648eP77ne1dU1rG189atfZffu3YO2efjhh3nmmWf8UTJnnnkmW7du9cu2ToSAnSl6rDLi7KRTR1VjC7OzEgJdjlJqmJKTk3vC8cc//jGxsbH827/92xFtjDEYY7DZ+u9rPvnkk0M+zze/+c3jL3aMGlYPXUSKRWSbiGwVkaPO1xfLShHZKyJFIlLg/1ItEyr/wfrIb9NWsWe0nkIpdQLt3buXvLw8brnlFgoKCqioqODmm2+msLCQWbNmcc899/S0PdxjdrvdOJ1OVqxYwZw5czj99NOprq4G4Ic//CEPPvhgT/sVK1Ywf/58pk2bxrp16wBoa2vjS1/6EnPmzOGaa66hsLBwyJ74008/zezZs8nLy+MHP/gBAG63m+uuu67n9pUrVwLwq1/9ipkzZzJnzhyWL1/u99dsICPpoS8xxtQOcN8yYKrvZwHwiO+338UlZQLQ1lA5GptXKiTc/bcdfFre7NdtzsyM50cXzzqmx3766ac8+eSTPProowDce++9JCUl4Xa7WbJkCVdccQUzZ8484jFNTU0sXryYe++9lzvuuIPf/e53rFix4qhtG2PYuHEjL7/8Mvfccw+rV6/m17/+Nenp6bzwwgt88sknFBQM3gctKyvjhz/8IZs2bSIhIYFzzz2XV155hdTUVGpra9m2bRsAjY2NAPziF7+gpKSE8PDwnttOBH+NoV8K/MFY1gNOEcnw07aPYItLA6C7SQNdqWAxefJkTjvttJ7rzz77LAUFBRQUFLBz504+/fTTox4TFRXFsmXLADj11FMpLi7ud9uXX375UW3ef/99rr76agDmzJnDrFmD/yHasGEDS5cuJSUlhbCwML7yla+wdu1apkyZwu7du7n99tt5/fXXSUiwhoFnzZrF8uXLeeaZZwgLCxvRa3E8httDN8A/RMQAjxljHu9z/3jgYK/rZb7bKo6/xD5irFUjPa01ft+0UqHiWHvSoyUmJqbn8p49e3jooYfYuHEjTqeT5cuX09nZedRjwsPDey7b7Xbcbne/246IiDiqjTFmRPUN1D45OZmioiJee+01Vq5cyQsvvMDjjz/O66+/zrvvvstLL73ET3/6U7Zv347dbh/Rcx6L4fbQFxljCrCGVr4pImf1uV/6ecxRr4CI3Cwim0RkU03NMQZyVBJeBHv7QKM/SqmxrLm5mbi4OOLj46moqOD111/3+3OceeaZPPfccwBs27at308AvS1cuJA1a9ZQV1eH2+1m1apVLF68mJqaGowxXHnlldx9991s2bIFj8dDWVkZS5cu5Ze//CU1NTW0t5+YWXnD6qEbY8p9v6tF5EVgPrC2V5MyILvX9SygvJ/tPA48DlBYWDiyP5GH2R10OBKIcNVjjEGkv78lSqmxqqCggJkzZ5KXl8ekSZNYtGiR35/j29/+Ntdffz35+fkUFBSQl5fXM1zSn6ysLO655x7OPvtsjDFcfPHFXHjhhWzZsoWbbrqpJ4vuu+8+3G43X/nKV2hpacHr9fL973+fuLg4v+9Df2Sojx4iEgPYjDEtvstvAPcYY1b3anMh8C3gAqyDoSuNMfMH225hYaE51i+4aPjlPNY3J3PGna+REH3ixqeUUsHB7XbjdruJjIxkz549nHfeeezZsweH4+SfyS0im40xhf3dN5zqxwEv+nrCDuD/jDGrReQWAGPMo8CrWGG+F2gHvuqPwgfiiU4lpaWBiuYODXSl1Ii1trZyzjnn4Ha7Mcbw2GOPjYkwH8qQe2CM2Q/M6ef2R3tdNsAJm81vi00luaqEkqZOpqfHn6inVUoFCafTyebNmwNdht+NuVP/AcITxpEizVQ2HX3kWymlQtWY/IwR5UzHLu3UNPj3xAillBrLxmQP3R5rzUVvrdeTi5RS6rAxGeiHTy7qaKoKcCFKKXXyGJuBHmud/u9t1kBXaqw4++yzjzpJ6MEHH+Qb3/jGoI+LjY0FoLy8nCuuuGLAbQ81DfrBBx884gSfCy64wC/rrPz4xz/m/vvvP+7t+MPYDPSYFOt3u57+r9RYcc0117Bq1aojblu1ahXXXHPNsB6fmZnJ888/f8zP3zfQX331VZxO5zFv72Q0RgPdGnKJ6W6gzdX/+g1KqZPLFVdcwSuvvILL5QKguLiY8vJyzjzzzJ554QUFBcyePZuXXnrpqMcXFxeTl5cHQEdHB1dffTX5+flcddVVdHR09LS79dZbe5be/dGPfgTAypUrKS8vZ8mSJSxZsgSA3NxcamutJUQeeOAB8vLyyMvL61l6t7i4mBkzZvD1r3+dWbNmcd555x3xPP3ZunUrCxcuJD8/n8suu4yGhoae5585cyb5+fk9i4K9++67PV/wMW/ePFpaWo75tT1sTM5yITwWjy2CZGmmsrmTyamxga5IqbHltRVQuc2/20yfDcvuHfDu5ORk5s+fz+rVq7n00ktZtWoVV111FSJCZGQkL774IvHx8dTW1rJw4UIuueSSAZf2eOSRR4iOjqaoqIiioqIjlr/92c9+RlJSEh6Ph3POOYeioiJuu+02HnjgAdasWUNKSsoR29q8eTNPPvkkGzZswBjDggULWLx4MYmJiezZs4dnn32W3/72t3z5y1/mhRdeGHR98+uvv55f//rXLF68mLvuuou7776bBx98kHvvvZcDBw4QERHRM8xz//338/DDD7No0SJaW1uJjIwcyavdr7HZQxfBHZWsc9GVGmN6D7v0Hm4xxvCDH/yA/Px8zj33XA4dOkRV1cDHyNauXdsTrPn5+eTn5/fc99xzz1FQUMC8efPYsWPHkAtvvf/++1x22WXExMQQGxvL5ZdfznvvvQfAxIkTmTt3LjD4Er1grc/e2NjI4sWLAbjhhhtYu3ZtT43XXnstTz/9dM8ZqYsWLeKOO+5g5cqVNDY2+uVM1bHZQweISSOluYkKDXSlRm6QnvRo+uIXv8gdd9zBli1b6Ojo6OlZP/PMM9TU1LB582bCwsLIzc3td8nc3vrrvR84cID777+fjz76iMTERG688cYhtzPYelaHl94Fa/ndoYZcBvL3v/+dtWvX8vLLL/OTn/yEHTt2sGLFCi688EJeffVVFi5cyJtvvsn06dOPafuHjc0eOuCIT7OGXJqO7QVWSp14sbGxnH322fzLv/zLEQdDm5qaSEtLIywsjDVr1lBSUjLods4666yeL4Levn07RUVFgLX0bkxMDAkJCVRVVfHaa6/1PCYuLq7fceqzzjqLv/71r7S3t9PW1saLL77I5z73uRHvW0JCAomJiT29+z/+8Y8sXrwYr9fLwYMHWbJkCb/4xS9obGyktbWVffv2MXv2bL7//e9TWFjIrl27RvycfY3ZHro9No1U2yYqm7WHrtRYcs0113D55ZcfMePl2muv5eKLL6awsJC5c+cO2VO99dZb+epXv0p+fj5z585l/nxrcdc5c+Ywb948Zs2addTSuzfffDPLli0jIyODNWvW9NxeUFDAjTfe2LONr33ta8ybN2/Q4ZWBPPXUU9xyyy20t7czadIknnzySTweD8uXL6epqQljDN/5zndwOp3853/+J2vWrMFutzNz5syeb186HkMunztajmf5XADe+BHdH/wPt+a+xhM3DrpSr1JKBY3Bls8ds0MuxKQShpvmxrpAV6KUUieFsRvovrNFu5urA1yIUkqdHMZuoPvOFnV01NLZ7QlwMUopFXhjONCts0WTpZnqZleAi1FKqcAb84GeIk1U6NRFpZQaw4EenQxAMs06dVEppRjLgW4Pw0QlkSzNeraoUkoxlgMdkJhU0h3NVDTqkItSSo3pQCcmlQx7i/bQlVKKMR/oKSSLBrpSSsGYD/RUnKZRA10ppRjrgR6bRrSnhabWNrrc3kBXo5RSATXsQBcRu4h8LCKv9HPfjSJSIyJbfT9f82+ZA/CdLZpIC1U6dVEpFeJGsnzu7cBOIH6A+/9kjPnW8Zc0Ar6Ti1LF+qKL7KToE/r0Sil1MhlWD11EsoALgSdGt5wRik0HYJzU69miSqmQN9whlweB7wGDDVR/SUSKROR5Ecnur4GI3Cwim0RkU01NzUhrPZozB4AsqdEDo0qpkDdkoIvIRUC1MWbzIM3+BuQaY/KBN4Gn+mtkjHncGFNojClMTU09poKPEJsGjkgmhdXpl0UrpULecHroi4BLRKQYWAUsFZGnezcwxtQZYw4vefhb4FS/VjkQEXDmMNlRT7meLaqUCnFDBrox5k5jTJYxJhe4GnjbGLO8dxsRyeh19RKsg6cnhjOHLFuNLtCllAp5xzwPXUTuEZFLfFdvE5EdIvIJcBtwoz+KGxZnDmmeKsobNdCVUqFtJNMWMca8A7zju3xXr9vvBO70Z2HD5swhxtNMZ2cDXW4v4Y6xfa6UUkodq7Gffs4JAIyXWj25SCkV0oIm0HXqolIq1AVBoB+ei16rJxcppULa2A/0mBSMI4psqdYeulIqpI39QBdBnDnk2vXkIqVUaBv7gQ6QOIEJ9lo9uUgpFdKCI9CdOWSgJxcppUJb0AR6rLeF5sa6QFeilFIBEzSBDhDdfki/uUgpFbKCKtDHU6MnFymlQlaQBHouoCcXKaVCW3AEenQSXkc0WVLLocb2QFejlFIBERyBLgKJOWRLNQfrdeqiUio0BUegAzbnBHIddRys1x66Uio0BU2g48xhPDWUaqArpUJU8AR64gRiTBsNdX748mmllBqDgifQfVMXw1oP4nJ7AlyMUkqdeEEU6Na66DlUcahBD4wqpUJP8AR66jSM2JhuK9VxdKVUSAqeQA+LwpM0lVlSrDNdlFIhKXgCHbBnzmGWrUR76EqpkBRUgS7ps8mQeuprKgNdilJKnXBBFeikzwYgonZHgAtRSqkTL8gCPR+ApJZdGGMCXIxSSp1Yww50EbGLyMci8ko/90WIyJ9EZK+IbBCRXH8WOWwxybRGjGOy9wCN7d0BKUEppQJlJD3024GdA9x3E9BgjJkC/Aq473gLO1YdSTOZJcV6YFQpFXKGFegikgVcCDwxQJNLgad8l58HzhEROf7yRk4y85ks5ZTV1Afi6ZVSKmCG20N/EPgeMND3u40HDgIYY9xAE5Dct5GI3Cwim0RkU03N6Ky5EjthHnYxtB8sGpXtK6XUyWrIQBeRi4BqY8zmwZr1c9tRRyWNMY8bYwqNMYWpqakjKHP4IrPnAWCv3j4q21dKqZPVcHroi4BLRKQYWAUsFZGn+7QpA7IBRMQBJACBGfNwTqBNoolrHGi4XymlgtOQgW6MudMYk2WMyQWuBt42xizv0+xl4Abf5St8bQIzb1CEisipZHR8FpCnV0qpQDnmeegico+IXOK7+r9AsojsBe4AVvijuGPV5JzBJE8J3d06dVEpFTocI2lsjHkHeMd3+a5et3cCV/qzsOPhScsjumIV5SU7yZySH+hylFLqhAiuM0V9IrKsA6PNBwY7jquUUsElKAM9deIsvEZwVek4ulIqdARloGckO6kiCer3B7oUpZQ6YYIy0EWE2vDxRLaWBroUpZQ6YYIy0AHaY3JI6ToU6DKUUuqECdpAJ3kSyTTR0KBruiilQkPQBnpM+hQAyvbpl10opUJD0AZ62oSZADSU7QpwJUopdWIEbaCn5kwDwFW1N8CVKKXUiRG0gS6R8TSKE3tTcaBLUUqpEyJoAx2gMSqL+I6DgS5DKaVOiKAO9K74XDK9FdS3dQW6FKWUGnVBHehhqZPIlHr2HBqdb0dSSqmTSVAHunP8dACqSnSmi1Iq+AV3oGdZM11aKnSRLqVU8AvqQJekSQB4anWRLqVU8AvqQCcqkXZbLJEtJYGuRCmlRl1wB7oIbTE5pLvLqWt1BboapZQaVcEd6IBJnEiOVPNZVWugS1FKqVEV9IEelT6VLKlhb6WuuqiUCm5BH+ixGVNxiJeGQ3pgVCkV3II+0A/PdOms1kW6lFLBLegDHV+gOxoPBLgQpZQaXcEf6LHj6LTHkebaT2e3J9DVKKXUqBky0EUkUkQ2isgnIrJDRO7up82NIlIjIlt9P18bnXKPgQitidOZKSUU17UFuhqllBo1w+mhu4Clxpg5wFzgfBFZ2E+7Pxlj5vp+nvBrlccrfTbT5SD7q5sDXYlSSo2aIQPdWA5P4g7z/ZhRrcrP4nLnES0u6kt1kS6lVPAa1hi6iNhFZCtQDbxhjNnQT7MviUiRiDwvItl+rfI4RYyfA4CnoijAlSil1OgZVqAbYzzGmLlAFjBfRPL6NPkbkGuMyQfeBJ7qbzsicrOIbBKRTTU1J3CN8tTpuLETU7/zxD2nUkqdYCOa5WKMaQTeAc7vc3udMebwYim/BU4d4PGPG2MKjTGFqampx1DuMXJEUBOZy7iOPRgzpkaLlFJq2IYzyyVVRJy+y1HAucCuPm0yel29BDjpusJtzhlMNcXU6dfRKaWC1HB66BnAGhEpAj7CGkN/RUTuEZFLfG1u801p/AS4DbhxdMo9DhmzSZcGSkt1KV2lVHByDNXAGFMEzOvn9rt6Xb4TuNO/pflXfG4BfAxNB7bAzFMCXY5SSvld8J8p6pM82RrW91ZuD3AlSik1OkIm0O2xydRICjH1nwa6FKWUGhUhE+gAFVFTGNexJ9BlKKXUqAipQG9NnEG2p4xuV3ugS1FKKb8LqUCX9Nk4xEv1vk8CXYpSSvldSAV63ARrsk7Tgc0BrkQppfwvpAI9a/JMWk0kplzXdFFKBZ+QCnRnTCS7ZTKxdRroSqngE1KBDlAdP5OMzj3g1iUAlFLBJeQC3ZMxj3DcdBzSXrpSKriEXKAnTF4AQPWuDwNciVJK+VfIBfop02ZRb2JxlWwKdClKKeVXIRfo4xKi2GWbqgdGlVJBJ+QCHaA2fhbjXMXQ1RboUpRSym9CMtBN5jzseOko/TjQpSillN+EZKAnTV0IQM1uPTCqlAoeIRno06ZModwk0X1QlwBQSgWPkAz0tPhIdtumEle/LdClKKWU34RkoAPUO2eR1lUGHY2BLkUppfwiZANdxltfSdeh89GVUkEiZAM95RTrjNHaz9YHuBKllPKPkA306ROz2efNwFP6UaBLUUopvwjZQE+Li+QzxzSS6reCMYEuRymljlvIBjqA5Mwn3ttIbdnuQJeilFLHLaQDfeb8cwEo+vCNAFeilFLHb8hAF5FIEdkoIp+IyA4RubufNhEi8icR2SsiG0QkdzSK9bec6YV0SBTNe9ZhdNhFKTXGDaeH7gKWGmPmAHOB80VkYZ82NwENxpgpwK+A+/xb5iix2WlOymey61O2HtT56EqpsW3IQDeWVt/VMN9P3+7spcBTvsvPA+eIiPitylHknLaIGVLKixv3BLoUpZQ6LsMaQxcRu4hsBaqBN4wxG/o0GQ8cBDDGuIEmILmf7dwsIptEZFNNTc3xVe4nEbmn4xAvB7d9QEeXJ9DlKKXUMRtWoBtjPMaYuUAWMF9E8vo06a83ftSgtDHmcWNMoTGmMDU1deTVjoasQgCmu3exekdFgItRSqljN6JZLsaYRuAd4Pw+d5UB2QAi4gASgHo/1Df6opMwyVM5I3Iff9lyKNDVKKXUMRvOLJdUEXH6LkcB5wK7+jR7GbjBd/kK4G0zhqaNSPZ8TpU9fLivlqb27kCXo5RSx2Q4PfQMYI2IFAEfYY2hvyIi94jIJb42/wski8he4A5gxeiUO0qyTiPa3ch4U8lbu6oCXY1SSh0Tx1ANjDFFwLx+br+r1+VO4Er/lnYCZc8HYGlMMau3V3J5QVaAC1JKqZEL6TNFe6ROh/A4LnAe5N3Pamjvcge6IqWUGjENdACbHSaczmzXFlxuD+/uPjmmVCql1EhooB82bRmRLSWcGl3D6h2Vga5GKaVGTAP9sFOsmZg3pe7k7Z3VdLm9AS5IKaVGRgP9sPhMyJjLGZ6PaHG5WbevNtAVKaXUiGig9zZtGQm1H5MT0cbq7TrsopQaWzTQe5u2DMHwjfH7eWlrOXWtrkBXpJRSw6aB3lt6PsSP56KIrXS6PTzx/oFAV6SUUsOmgd6bCJxyPrFl7/LFvGT+sK6YhrauQFellFLDooHe17QLoLud706toq3Lw+8+0F66Umps0EDva+LnIDyWrKo1LMtL5/cfFNPUoQt2KaVOfhrofTki4JQvwI6/cNvnMmhxufn9B8WBrkoppYakgd6fBbdAZxMzKv/GuTPS+P26A3R267cZKaVObhro/cmeD1nzYf1vuHFhDg3t3by2Xb/NSCl1ctNAH8jp34SGYs5wr2diSgxPry8NdEVKKTUoDfSBzLgYnBOwrX+YaxfksLmkgZ0VzYGuSimlBqSBPhCbHRZ+Aw5u4KqMSiIcNp5eXxLoqpRSakAa6IOZdy1EJBC35VEunpPJXz8+RKtLv/xCKXVy0kAfTEQczP86fPoSX5/cSFuXhxc/PhToqpRSql8a6ENZdDvEpHLK1p+TlxnHw2/v5bmPDuo0RqXUSUcDfSiR8bDkP5DSD3loThkJUWF874UiTv/5Wzzwj9243BrsSqmTgwb6cMy7DtJmMnnrfaz+1nye/fpC5k9MYuXbe7ns4XXsq2kNdIVKKaWBPix2B5z3U2goRj56gtMnJ/PYdYU8cX0hFU0dXLTyff686WCgq1RKhTgN9OGacg5M+Ty8cy/UWyswnjtzHK/dfhbzcpz8+/NF/PqtPQEuUikVyoYMdBHJFpE1IrJTRHaIyO39tDlbRJpEZKvv567RKTfALnoAxAZ/+Tp4rBUY0xMi+eNNC7h83nj++43P+O9/7MYYE+BClVKhyDGMNm7gu8aYLSISB2wWkTeMMZ/2afeeMeYi/5d4EnHmwCUPwZ9vtHrq5/wnAHab8Msr5xDusPHrt/fS0eXh38+fRoTDHth6lVIhZchAN8ZUABW+yy0ishMYD/QN9NAw6zLY+xa8998w6Wxr/XSsUP+vy2YT7rDxxPsH+OvWcq4/fQLXLsghOTYioCUrpULDiMbQRSQXmAds6Ofu00XkExF5TURmDfD4m0Vkk4hsqqmpGXGxJ41l90HyFGvopbW652abTbj7klk8fdMC8sbH88Abn7Hovrd5dZuu1KiUGn0y3PFeEYkF3gV+Zoz5S5/74gGvMaZVRC4AHjLGTB1se4WFhWbTpk3HWPZJoHIbPPF5yJwL178MjvCjmuytbuH7L2xjS2kDP7poJjcumhiAQpVSwURENhtjCvu7b1g9dBEJA14Anukb5gDGmGZjTKvv8qtAmIikHEfNJ7/02XDp/0Dph/D6nf02mZIWxzNfW8C5M8bx4799yk9f+ZQ1u6p5dVsFL209RHVL5wkuWikVzIYcQxcRAf4X2GmMeWCANulAlTHGiMh8rD8UdX6t9GQ0+wqoLIIPHoKMOVBw/VFNIsPsPLr8VH708naeeP8AT7z/zy+ddtiEL+Sls3zBBBZOSsJ6qZVS6tgMOeQiImcC7wHbAK/v5h8AOQDGmEdF5FvArVgzYjqAO4wx6wbb7pgfcjnM64FnroD978Cca+DsFdZsmD6MMewob6bb4yUq3E632/DXrYd4fnMZTR3dXD5vPPd+KZ9wh54aoJQa2GBDLsMeQ/e3oAl0gM5mePc+2PhbwMBpX4fP3w32sKEf2u3hkXf28dBbezhzSgqPLC8gLjKMbo+XorImJqXEkBhz9Pi8Uio0aaCfKE1l8M7P4eOnrS/HOP/nw37onzcdZMVftnHKuDhOGRfLml3VNHe6SYuL4NHrTqUgJ7GnrddrEEGHaJQKQYMF+nBOLFLDlZAFlz4M4bGw/jeQWQD5Vw7roVcWZpMaF8G3/u9jqpo7+cKsdBZMSuahtz7j6sfW87PL8jgtN4n/21jKc5sOEh8Zxt2XzGLJ9LRR3iml1FihPfTR4OmGP1wKh7bA196wZsS010PzIUibBbaBx8m73F7sNsFus3rfDW1dfOvZLXyw1zrGbLcJn58xjj3VLeyraWNZXjq3nTOVCcnRRIfr32elgp0OuQRCazU8thi83RAWDY2+7yOd+gW4/DGIShz88b24PV5+98EButxerizMZlx8JF1uL799bz8r39qDy20dq06ICiM/K4HvnjeNudnO0dgrpVSAaaAHStlm+PsdkDTRmtbo9VhrwMRnwJf/AJnzjmxf8Qm89wDkfQlmXjKspyhv7GDjgXrKmzoob+xg9fZKalu7uHhOJtfMz6a8sZO91a1UNnXgNeA1htgIB5fMzeT0ScmICNUtnTz+7n7e3FnFNfNzuOnMiTjsOttGqZORBvrJpGwTPHcDtFXDKefD5CWQMRc+egK2/p/VxmaHq56GactGvPlWl5vH3t3Hb9/bT2e31XMPswvpCZE4bDYEqGl10dLpZmJKDKdOSOSVonK63F5mZMSzo7yZOVkJ/OKKOUxIjqamxUVDexfJsRFkxEdis+mBWKUCSQP9ZNNWB2//BPa8Ac1l1m32cFhwCyz4V/jTdVC1A679M0xaPPzttlSBuwMSc6lq7mRHeRO5yTFkJ0UT1qvH3dnt4dVtFTy7sZQtpY1cOjeTby+dSm5yNK8UVfCjl3dQ39Z11OYjHDZyk2NYMj2Nr8zPISc5GrnKg4cAAA/WSURBVGMMGw7U89ePDxFmt3HG5GROn5xMfGQY9e1dVDV3khobQVp85PG+akopNNBPXsZA7R4o+whyF0FirnV7ez38/kJoKIHTbgIMeL0QEQcJ463ZNHGZEJtmjcVXFsGHv4HtL4DXDafeAEvvgpjkIUvweE3PAdjD6lpdPL2+FIddSI2LIDE6nOqWTkrq2tlV2cIHe2vxGsOiySkcbGinpK6d2AgHXmNo7/IgYp0F2+2x/m2F2YXL5o3nlsWTmZQa6+cXUanQooE+FrVUWmeg1uwGsVvDMF1tQJ/3yxZmHXgNj7W++xRg4+NW+J/xbWs4J2UKJGRb2/CDyqZOnt1YyosfHyI9IZKrCrO5YHYGDrtQVNbIur11tHd7SI+PJC0ugvX761j10UG6PV5Oy00iKzGajIRI0hMiyXRGkumMIjU2guhwBxEOmw7rKDUIDfRg4e6ClnJoOgQtFdZMmtZKiE2HuV+BKN/Mluqd8Nr34MDafz42PBZyz7TWcM+eDzaHdZA2LBrSpvf/fB43dDZCV+tx/0GoaXHx5AcHWLevjqrmTqpbXHi8/f/bS4mN4EsF41m+cALZSdFH3d/mcrP9UBMzM+OJi+z/bNwut5ft5U1kJESSkRB1zHUrdbLRQA9VrdVQt9ca1qn4BPavgfr9R7ebtATO+4k1X76lCjY8Alv+CO21/2wTl2mdJDX7y1aw1+21thUWDYkTreGipInDDn2P11DT4uqZnVPb4qKj20tHt4fdlc28ubO6Z1hnSlos4+IjiXDYWLunhnV76+jyeAl32Dj7lFTOz0snOtxBq8tNY3sXGw7Us25vLW1dHgBmZMSzdHoqWYnReLwGr7GGmSIddiLD7MzIiNOhIDVmaKCrf2oosdZyByt8az+zpkp2NsHEs6B0vTWEM/1CGDfb6vXbHLDnH7D3TWuMfiBxGZB/FcxbDimDLoc/pIqmDp7dUMrqHZVUNHXS0mk9b05SNJ+fOY7TchPZcKCeV7dVUNXsOuKx2UlRnDU1lTN8Y/xv76xmc2nDgJ8IAM6dMY5bz55EQU4idW1dlNa309nlId03NKQnbamThQa6GlxHA6y9H7Y9D9POhzNug+TJR7drq4Xdr4Ijyro/eTJ0d0BDsdVj3/k3a+aO8UDWfCi4zvrKvog46wBwa7X1RSAjOKmq56ldblpd1to2vdew8XoNOyubAYiLCCMu0oEzOuyodW6aO7tp7XRjtwk2ETxeQ2e3h/YuD6t3VPKHD4tpbO8mMszWM92zt9gIh/UT6cAZFUZOUjQTkmOYkBxNVmIUWYnRpMZF0Opy09TeTavLzbj4CJJiwnXNHeVXGujqxGmpgqJV1gJltZ9ZQzLOCdaZst3tVm9/2gXWTJzMAmuGT+l6a2GzuHHW0E50knUA2NVi/cGwO6xpnWHRkDbDGhqKTPBr2W0uN3/edJDiunZfWEcTFW6nqrmTiqZOalpctLnctLk81LW5KK1rp6K5k6H++8SE28lOimZKWixT0+KYOi6WpJjwnj8Q0eF2IsLsRIXZdelkNSwa6OrEM8Y6iWrrM9Ba9c9x9sYS+ORZaO/1/Sdih/hMqwfvcQ24ySM4c6zHebqs58q7HM78DsT0+qKszibrU0VXK3S1W58oYv23mFlnt4eyhnbKGjqoqq6io74Cd+JknDERRIfbqWzqpLS+nZK6NvbWtHKwvmPQ7eUkRbNgYhILJyWTnhBJt8eLx2uoanaxv6aV/bVteLyGCcnR5CRFM94ZRVJMOEkx4cRHhRHhsBHhsOtMoSCnga5OLm6XNXTTUAzjT7V+wmOsYO5osH7CYyEi1hreMR4ruDubrROuKj62pnMiVs/d1QS7/m714E/7mjXOf+BdqNzOkdM8BXJOt5ZVSMi2/qi011rz/tvrreuuZt8fgDbo7rSe2+u2jg987rsw84vW4mpuF2z7szVMVb3Tmm0EkHIKnHqj1a5ujzXTqHwrjJtFZ+5S9kXm0drSjK16O2H1u2l2JFMeM5Nqktle3syGA/U0dXT3qtmQQjOTHLXMi2+m3R7H31qm0thp7VckLi6zv88pUsZ+k8Eek0WJdxwuewzesChioyKZk+3ktAmJzM5KIKK1jNStv8FZ9jYlGefzfvp1VLpjyUmKZlZ6NDNsB4k0Lt/rJjBuFkTGn4B/FGq4NNBV8Kv5DN75L9jxItgjrKmZE8+yhnvCY8ARaQ3v7HwZqj898rFh0RCVBNGJEOm0/piEx0BY5D/PASj5EGp2WmvyTP0CfPxHa+po8lTIKoTU6dZjiv5kPc9hYrdCvm6vdbDZHtH/p5CYNIgbh7FH0OG1Y1xthHXW4uisw+btPqKpiUnDNf1yWtyCc+ezhHU14rZF4vAe/R21nRJFMRnsdGcgGC6yrceDjY+80zjd9ikdRPBn71LSqOVztu3ES/sRj++WMHZEzOU9+wI6ItNIj4a0aBvjoz1kR3eTIB102SLY1eFkfX00zW4HU+K85Ma5SZYWwtoqCG+rwOaIIGLWMqKnfx7CdBrp8dBAV6GjpdIaXx8sNOr3W739mBQryMOPnut+FK/H6pGv+Rk0llrz+c+4DSYvhb4HPat2WAeH02bChNOtg8KuFqu3XvwBxKZaM4jSplv1Htps9eI76q2ev6fL+uMQk2a1jcuExAnWp4r6ffDJKvjsdevTw/SLYOGt1iePlgrr00Jjqe8TRrv1qaP2M9zVu6GjgcpJV1CR969IfCaZ3SWM2/Tf2Hf/DXdsJpWpZ1AUPo+SjkhqW1w0tbYzn22c5dlAurey35fFjQ0HRx9EPsxjhCoSiaWDeOmgnQi2OfKodmRSH5aOKywRp72DRFsb8aaF6K56orvrcXhd7Is7jZ1J59IUP5WplDCn8U0yaz+kLmYy26JPZ73kk2FvIs+7mwlde3CkTCZi1sUkZU2l2+2hoXQH3XvfJVw8ODMnE5mSC0mTaHCHc6CujXC7jRkZ8djbqqFml/W6NZZar2vOGZCz0PqUeJLRQFfKX9xd1jBNfGZg6+hosGqJGzf8xxhz9B8fsP64RcT1f9/hx9V+Bq5WcITjMg72NglFtYaiqi6SIrx8fnw3eTFNOIybDlsMpW0O6kwM3ZGpGJuD9o4OzIH3SDv0BhnNRSR3VxJljvw00GKiqBcn9eLEhiHPfIYdL3UmnmRpxm1sbDVTmCKHcErbEY9tNxFEi/XJZ7c3m3hpI0Pq+92dUm8qu431vb/5tv2Mk4ae+7zYMAh2PHjFTkPcNOojs6l2ZNJKNJndxWR07COmq5oa5xxKkhZx0Dmf5vB0vDY7GEOut5RT6t8hrW4jnc4p1GWcTUPaQqJj40iOCSc52k50mG1YX1HZHw10pdTJxRjrLOT2eusTVWTC0QHXWg07X8aUrKMzYwHl479AlSeWtBgHOe3bCS/9ABOXTktqAQftWTQd2kPEvtWkVK6lKyyBpowz6c79HK3eKJoq9tJZU8y47lIme0tJ69yHMYZ99il82JHNps5Mah3pNIWnYfe6yW7bzqnsYI7sY4JUkSU12MVQa+L51DuBGhJYaNvJePnnwf1GE4OLMMZJIwA7vTnkSBUx4sJlHLgII5IuwsXDuowbOONfVx7TS6eBrpRSI2CMobnDTWuXG2dUGNF2L9LViolKpL3LQ5vLjV0gvHEf4WXrsLVVIx114GqhLe1UKjKWUmUSsXlcJNV+RFLlOrq7XLR5HbR4woiesoi8M4f3nQd9aaArpVSQGCzQ9UwGpZQKEhroSikVJDTQlVIqSAwZ6CKSLSJrRGSniOwQkdv7aSMislJE9opIkYgUjE65SimlBjKcNUHdwHeNMVtEJA7YLCJvGGN6n263DJjq+1kAPOL7rZRS6gQZsodujKkwxmzxXW4BdgLj+zS7FPiDsawHnCKS4fdqlVJKDWhEY+gikgvMAzb0uWs8cLDX9TKODn1E5GYR2SQim2pqakZWqVJKqUENO9BFJBZ4Afh/xpjmvnf385CjJrgbYx43xhQaYwpTU1NHVqlSSqlBDet7tUQkDCvMnzHG/KWfJmVAdq/rWUD5YNvcvHlzrYiUDLfQPlKA2iFbBZ9Q3O9Q3GcIzf0OxX2Gke/3hIHuGDLQxfr+rP8FdhpjHhig2cvAt0RkFdbB0CZjTMVg2zXGHHMXXUQ2DXSmVDALxf0OxX2G0NzvUNxn8O9+D6eHvgi4DtgmIlt9t/0AyAEwxjwKvApcAOwF2oGv+qM4pZRSwzdkoBtj3qf/MfLebQzwTX8VpZRSauTG6pmijwe6gAAJxf0OxX2G0NzvUNxn8ON+B2y1RaWUUv41VnvoSiml+tBAV0qpIDHmAl1EzheR3b6FwFYEup7RMNCCaCKSJCJviMge3+/EQNc6GkTELiIfi8grvusTRWSDb7//JCLhga7Rn0TEKSLPi8gu33t+eii81yLyHd+/7+0i8qyIRAbjey0ivxORahHZ3uu2ft/f413ocEwFuojYgYexFgObCVwjIjMDW9WoOLwg2gxgIfBN336uAN4yxkwF3vJdD0a3Y60ZdNh9wK98+90A3BSQqkbPQ8BqY8x0YA7Wvgf1ey0i44HbgEJjTB5gB64mON/r3wPn97ltoPe390KHN2MtdDhsYyrQgfnAXmPMfmNMF7AKa2GwoDLIgmiXAk/5mj0FfDEwFY4eEckCLgSe8F0XYCnwvK9JUO23iMQDZ2GdvIcxpssY00gIvNdY06ajRMQBRAMVBOF7bYxZC9T3uXmg9/e4Fjoca4E+rEXAgkmfBdHGHT4D1/c7LXCVjZoHge8BXt/1ZKDRGOP2XQ+293wSUAM86RtmekJEYgjy99oYcwi4HyjFCvImYDPB/V73NtD7e1wZN9YCfViLgAWLIRZECzoichFQbYzZ3PvmfpoG03vuAAqAR4wx84A2gmx4pT++MeNLgYlAJhCDNdzQVzC918NxXP/ex1qgj3gRsLFqgAXRqg5//PL9rg5UfaNkEXCJiBRjDactxeqxO30fyyH43vMyoMwYc3hJ6uexAj7Y3+tzgQPGmBpjTDfwF+AMgvu97m2g9/e4Mm6sBfpHwFTfkfBwrIMoLwe4Jr8bZEG0l4EbfJdvAF460bWNJmPMncaYLGNMLtZ7+7Yx5lpgDXCFr1lQ7bcxphI4KCLTfDedA3xKkL/XWEMtC0Uk2vfv/fB+B+173cdA7+/LwPW+2S4LGcZCh0cwxoypH6xFwD4D9gH/Eeh6Rmkfz8T6mFUEbPX9XIA1nvwWsMf3OynQtY7ia3A28Irv8iRgI9bib38GIgJdn5/3dS6wyfd+/xVIDIX3Grgb2AVsB/4IRATjew08i3WcoBurB37TQO8v1pDLw75824Y1C2jYz6Wn/iulVJAYa0MuSimlBqCBrpRSQUIDXSmlgoQGulJKBQkNdKWUChIa6EopFSQ00JVSKkj8f8QtNzSRgiNEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv = cv.split(X_train_scaled, y_train)\n",
    "\n",
    "m_hidden_layers = 1\n",
    "\n",
    "n_input = 6\n",
    "n_hidden = 4\n",
    "n_output = 1\n",
    "\n",
    "bs = 64\n",
    "device = \"cuda:0\"\n",
    "epochs = 100\n",
    "\n",
    "network_type = \"regression\"\n",
    "\n",
    "regressors = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "    print(\"Model for Fold: \" + str(fold))\n",
    "\n",
    "    train_set, train_labels = X_train_scaled[train_idx], y_train[train_idx]\n",
    "    valid_set, valid_labels = X_train_scaled[val_idx], y_train[val_idx]\n",
    "    \n",
    "    trainset = HousePriceDataset(train_set, train_labels)\n",
    "    trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    validset = HousePriceDataset(valid_set, valid_labels)\n",
    "    validloader = DataLoader(validset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    regressor = NeuralNetwork(m_hidden_layers, n_input, n_hidden, n_output, network_type).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(regressor.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        for features, labels in trainloader:\n",
    "\n",
    "            regressor.train()\n",
    "\n",
    "            features = features.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = regressor(features.float())\n",
    "\n",
    "            loss = criterion(output, labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for features, labels in validloader:\n",
    "                    regressor.eval()\n",
    "\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    output = regressor(features.float())\n",
    "\n",
    "                    test_loss += criterion(output, labels)\n",
    "\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(validloader)))\n",
    "        \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The regression problem \n",
    "- As you will see below, my regression model has a tendency to predict values close to the mean (labels are from 0 to 4)\n",
    "- The reason for that could be that the label distribution for the \"Scor\" feature is a bimodal distribution, this could represent that my model is uncertain what to predict between (0 or 1) and (3, 4) so for minimizing the loss he chooses the center value, in this case (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOKklEQVR4nO3dbaykZ13H8e+PbitPagt7qOtu9ZRkg1YiUk9qsQkhlBeFkm4TS1KisJCSTRSkiAksvLDRVyUxgKiBrBRdtJY2pbFrC5rahxBfsHpaCrQs2LXWdu3KHh7aohhx5e+LuYsnhzk9M3PPnDl75ftJTuZ+uGauf67d+zf3ueae+6SqkCS15VnzLkCSNH2GuyQ1yHCXpAYZ7pLUIMNdkhq0bd4FAGzfvr0WFxfnXYYknVLuvffeb1TVwrB9WyLcFxcXWV5enncZknRKSfKv6+1zWkaSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhq0Jb6hKmnrWNx/+9z6fuTaS+fWd2s2PHNP8okkJ5I8sGrbC5LckeSh7vGsbnuSfCTJ0SRfSnL+LIuXJA03yrTMnwGXrNm2H7izqnYDd3brAK8Fdnc/+4CPTqdMSdI4Ngz3qvoc8K01m/cAB7vlg8Dlq7Z/sgY+D5yZZMe0ipUkjWbSD1TPrqrjAN3ji7rtO4HHVrU71m37IUn2JVlOsryysjJhGZKkYaZ9tUyGbKthDavqQFUtVdXSwsLQ2xFLkiY0abh//enplu7xRLf9GHDOqna7gMcnL0+SNIlJw/0QsLdb3gvcumr7m7urZi4Ennx6+kaStHk2vM49yQ3Aq4DtSY4B1wDXAjcluQp4FHhD1/wzwOuAo8B3gbfOoGZJ0gY2DPeqeuM6uy4e0raAt/ctSpLUj7cfkKQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoA3/zJ62nsX9t8+t70euvXRufUsanWfuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWpQr3BP8ltJHkzyQJIbkjw7yblJDid5KMmNSc6YVrGSpNFMHO5JdgLvBJaq6qXAacCVwAeAD1XVbuDbwFXTKFSSNLq+0zLbgOck2QY8FzgOvBq4udt/ELi8Zx+SpDFNHO5V9W/A7wOPMgj1J4F7gSeq6mTX7Biwc9jzk+xLspxkeWVlZdIyJElD9JmWOQvYA5wL/CTwPOC1Q5rWsOdX1YGqWqqqpYWFhUnLkCQN0Wda5jXAv1TVSlX9D3AL8MvAmd00DcAu4PGeNUqSxtQn3B8FLkzy3CQBLga+AtwNXNG12Qvc2q9ESdK4+sy5H2bwwel9wJe71zoAvBd4d5KjwAuB66ZQpyRpDL3+QHZVXQNcs2bzw8AFfV5XktSP31CVpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBva5zl6QWLO6/fW59P3LtpTN5Xc/cJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatApfz/3Fu/DLEl9eeYuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJalCvcE9yZpKbk3w1yZEkr0jygiR3JHmoezxrWsVKkkbT98z9D4C/qaqfAV4GHAH2A3dW1W7gzm5dkrSJJg73JD8GvBK4DqCqvldVTwB7gINds4PA5X2LlCSNp8+Z+4uBFeBPk3whyceTPA84u6qOA3SPLxr25CT7kiwnWV5ZWelRhiRprT7hvg04H/hoVb0c+E/GmIKpqgNVtVRVSwsLCz3KkCSt1SfcjwHHqupwt34zg7D/epIdAN3jiX4lSpLGNXG4V9W/A48leUm36WLgK8AhYG+3bS9wa68KJUlj63s/998Erk9yBvAw8FYGbxg3JbkKeBR4Q88+JElj6hXuVXU/sDRk18V9XleS1I/fUJWkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUG9wz3JaUm+kOS2bv3cJIeTPJTkxiRn9C9TkjSOaZy5Xw0cWbX+AeBDVbUb+DZw1RT6kCSNoVe4J9kFXAp8vFsP8Grg5q7JQeDyPn1IksbX98z9w8B7gO936y8Enqiqk936MWBnzz4kSWOaONyTvB44UVX3rt48pGmt8/x9SZaTLK+srExahiRpiD5n7hcBlyV5BPgUg+mYDwNnJtnWtdkFPD7syVV1oKqWqmppYWGhRxmSpLUmDveqel9V7aqqReBK4K6q+lXgbuCKrtle4NbeVUqSxjKL69zfC7w7yVEGc/DXzaAPSdIz2LZxk41V1T3APd3yw8AF03hdSdJk/IaqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDts27AGkrW9x/+9z6fuTaS+fWt059nrlLUoMMd0lq0MThnuScJHcnOZLkwSRXd9tfkOSOJA91j2dNr1xJ0ij6nLmfBH67qn4WuBB4e5LzgP3AnVW1G7izW5ckbaKJw72qjlfVfd3yd4AjwE5gD3Cwa3YQuLxvkZKk8Uxlzj3JIvBy4DBwdlUdh8EbAPCidZ6zL8lykuWVlZVplCFJ6vQO9yTPBz4NvKuqnhr1eVV1oKqWqmppYWGhbxmSpFV6hXuS0xkE+/VVdUu3+etJdnT7dwAn+pUoSRpXn6tlAlwHHKmqD67adQjY2y3vBW6dvDxJ0iT6fEP1IuBNwJeT3N9tez9wLXBTkquAR4E39CtRkjSuicO9qv4eyDq7L570dSVJ/fkNVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDZhLuSS5J8rUkR5Psn0UfkqT1TT3ck5wG/DHwWuA84I1Jzpt2P5Kk9c3izP0C4GhVPVxV3wM+BeyZQT+SpHWkqqb7gskVwCVV9bZu/U3AL1XVO9a02wfs61ZfAnxtwi63A9+Y8LmzZF3jsa7xbdXarGs8fer66apaGLZj2+T1rCtDtv3QO0hVHQAO9O4sWa6qpb6vM23WNR7rGt9Wrc26xjOrumYxLXMMOGfV+i7g8Rn0I0laxyzC/R+B3UnOTXIGcCVwaAb9SJLWMfVpmao6meQdwN8CpwGfqKoHp93PKr2ndmbEusZjXePbqrVZ13hmUtfUP1CVJM2f31CVpAYZ7pLUoFMm3De6pUGSH0lyY7f/cJLFLVLXW5KsJLm/+3nbJtX1iSQnkjywzv4k+UhX95eSnL9F6npVkidXjdfvbEJN5yS5O8mRJA8muXpIm00frxHrmsd4PTvJPyT5YlfX7w5ps+nH44h1zeV47Po+LckXktw2ZN/0x6uqtvwPgw9m/xl4MXAG8EXgvDVtfgP4WLd8JXDjFqnrLcAfzWHMXgmcDzywzv7XAZ9l8L2EC4HDW6SuVwG3bfJY7QDO75Z/FPinIf+Omz5eI9Y1j/EK8Pxu+XTgMHDhmjbzOB5HqWsux2PX97uBvxz27zWL8TpVztxHuaXBHuBgt3wzcHGSYV+o2uy65qKqPgd86xma7AE+WQOfB85MsmML1LXpqup4Vd3XLX8HOALsXNNs08drxLo2XTcG/9Gtnt79rL0yY9OPxxHrmosku4BLgY+v02Tq43WqhPtO4LFV68f44f/kP2hTVSeBJ4EXboG6AH6l+1X+5iTnDNk/D6PWPg+v6H61/mySn9vMjrtfh1/O4KxvtbmO1zPUBXMYr26K4X7gBHBHVa07Xpt4PI5SF8znePww8B7g++vsn/p4nSrhPsotDUa67cGUjdLnXwOLVfXzwN/x/+/O8zaP8RrFfQzul/Ey4A+Bv9qsjpM8H/g08K6qemrt7iFP2ZTx2qCuuYxXVf1vVf0Cg2+gX5DkpWuazGW8Rqhr04/HJK8HTlTVvc/UbMi2XuN1qoT7KLc0+EGbJNuAH2f2v/5vWFdVfbOq/rtb/RPgF2dc06i25G0iquqpp3+1rqrPAKcn2T7rfpOcziBAr6+qW4Y0mct4bVTXvMZrVf9PAPcAl6zZNY/jccO65nQ8XgRcluQRBlO3r07yF2vaTH28TpVwH+WWBoeAvd3yFcBd1X06Mc+61szLXsZg3nQrOAS8ubsK5ELgyao6Pu+ikvzE03ONSS5g8H/0mzPuM8B1wJGq+uA6zTZ9vEapa07jtZDkzG75OcBrgK+uabbpx+Modc3jeKyq91XVrqpaZJARd1XVr61pNvXxmsVdIaeu1rmlQZLfA5ar6hCDg+DPkxxl8I535Rap651JLgNOdnW9ZdZ1ASS5gcGVFNuTHAOuYfABE1X1MeAzDK4AOQp8F3jrFqnrCuDXk5wE/gu4chPepC8C3gR8uZuvBXg/8FOr6prHeI1S1zzGawdwMIM/zPMs4Kaqum3ex+OIdc3leBxm1uPl7QckqUGnyrSMJGkMhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0P8BVpvKxWac4fMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on Testing Data: 2.1267471313476562\n",
      "Lets see predictions\n",
      "[1.9966602 1.9715163 2.0063026 1.9663528 2.0136096 1.9411181 1.9981827\n",
      " 1.9786215 1.9991101 2.0252674 2.0170407 2.0067143 2.0054827 2.0084043\n",
      " 2.0000548 2.0203931 1.9775524 1.9765606 2.0129545 2.010404  2.0071394\n",
      " 2.0260932 2.0016515 2.0107484 1.9255625 2.0120971 2.0144887 2.0225875\n",
      " 2.0150409 2.002734  2.002887  2.011324  2.019319  2.032951  1.9984248\n",
      " 1.9737996 2.0237672 2.0161862 2.0161283 1.9696201 1.950283  2.027004\n",
      " 1.9997395 1.9507477 2.0079124 1.9586753 2.0065873 1.9698664 2.015665\n",
      " 1.9607089 1.998559  2.0222871 2.0108922 2.0133078 2.004092  1.9668964\n",
      " 2.0134509 1.961471  1.9264239 1.9537106 1.9691366 2.0101402 2.0030963\n",
      " 2.0178335 1.9350033 1.9776516 2.010427  2.0075407 2.0151317 1.9693645\n",
      " 1.9823407 2.0248744 1.9383892 2.0058126 2.0186098 1.9998896 2.0062244\n",
      " 1.9554032 2.0069745 2.0190785 1.9161671 1.9968554 2.0199568 1.9994048\n",
      " 2.0217004 1.9998194 1.9524937 2.0031965 2.0123498 2.0155873 1.9882952\n",
      " 1.9431957 2.0202935 1.9303551 1.9486271 2.0238817 2.003816  2.0123765\n",
      " 2.0054283 1.98288   2.0188925 1.9736931 1.9666033 2.024123  1.9603344\n",
      " 2.021382  1.9915447 1.9149523 2.0001945 1.9647025 2.0128124 1.961076\n",
      " 2.016647  1.9255962 2.00712   1.9863875 1.9750305 1.9415928 2.0188115\n",
      " 2.0153127 2.0121312 2.01747   2.0110157 2.002701  1.9651718 2.0052342\n",
      " 1.9968712 2.009844  2.0022342 1.9936068 2.015083  2.0229366 1.9539261\n",
      " 2.0239942 1.9980109 2.015021  1.9928541 2.0193264 1.9824278 1.9263254\n",
      " 2.017227  1.9430666 1.9622649 2.0141914 1.996476  2.0105915 2.0058818\n",
      " 2.0216305 2.0239449 2.001619  1.912541  2.0087276 2.0137937 1.9215144\n",
      " 1.9744139 2.0128772 2.013304  1.957495  2.013458  2.0207841 2.020479\n",
      " 1.9567587 2.012592  2.0240295 1.9865481 1.9531535 1.9657633 2.0052726\n",
      " 2.012653  1.9906164 1.9577751 1.9537814 2.0186465 1.9549145 1.9681839\n",
      " 2.0155427 2.022185  2.0236156 2.0196168 1.9662918 2.0183237 1.9256219\n",
      " 2.0011559 2.0052235 2.0126822 2.0171838 1.9329493 1.997078  2.0105028\n",
      " 2.023318  1.9785506 2.0288277 1.9985605 1.9998747 1.9579102 1.9338135\n",
      " 2.0224552 1.996775  1.9706347 2.0086377 2.0069697 1.9241453 2.0140216\n",
      " 2.0275178 1.972279  1.9892664 1.9256877 2.0212333 2.0270288 2.0052342\n",
      " 2.013601  2.020848  1.9790066 2.0165362 2.0121853 2.0171106 2.0182493\n",
      " 2.0147138 2.0009906 2.0285134 2.0005093 2.022328  2.0128162 2.000641\n",
      " 1.9508585 1.9420322 2.0195377 1.9443913 1.8534163 1.9324057 1.9279499\n",
      " 1.9688952 1.9762877 1.9969314 2.0180986 2.0080469 1.9249595 1.9715252\n",
      " 2.0195167 1.9476575 1.9860786 1.9257042 1.9486065 1.9702132 2.0205076\n",
      " 2.0107486 2.0157812 2.0165431 1.999629  2.0155094 2.0162277 2.0251348\n",
      " 2.0166955 2.0157971 1.9985605 1.9984486 1.9743694 1.9014683 1.9709466\n",
      " 2.0134153 1.9997934 1.9729973 2.0167768 2.0230362 2.0067966 2.0126503\n",
      " 2.018622  1.9716711 2.0091903 1.9450963 2.0109754 1.9529232 2.022868\n",
      " 2.0111387 1.9849457 2.000592  1.927482  2.000288  2.0096395 2.0043995\n",
      " 2.0047224 2.0076716 2.015663  1.9997925 2.012737  2.0216305 2.014689\n",
      " 1.9464219 1.9267367 1.9867438 2.014261  1.9245459 1.992114  1.9997944\n",
      " 1.9478188 2.0143747 2.021568  2.0053685 1.9255778 1.9571915 2.016602\n",
      " 2.0164928 2.0157812 1.9536558 2.019189  2.0152733 1.9811696 2.0131938\n",
      " 1.956184  1.9920969 2.0107918 2.0132828 1.9570096 2.0156476 2.0158136\n",
      " 2.000433  2.0168262 2.023424  1.9758313 1.9355574 2.0044987 2.0221684\n",
      " 2.0204856 2.0148551 2.0084655 2.0267422 1.9801077 2.0205085 1.9791287\n",
      " 2.0070534 1.9983109 1.9645833 2.0220675 2.0155132 2.0102742 2.0045223\n",
      " 1.9794648 1.9880612 2.0251071 2.013586  1.9900044 2.0106905 2.0100868\n",
      " 2.0076432 2.0175483 2.022743  2.0066721 2.00503   2.0099344 1.9314421\n",
      " 2.0131407 1.9883908 2.0242395]\n",
      "Thresholds: [1.  2.1 3.  4. ]\n",
      "Regerssion Accuracy with Rounded Values: 0.06515580736543909\n",
      "Regerssion Accuracy with Optimized Thresholds: 0.24929178470254956\n"
     ]
    }
   ],
   "source": [
    "evalset = HousePriceDataset(X_test_scaled, y_test)\n",
    "loader  = DataLoader(evalset, batch_size=len(X_test_scaled))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in loader: \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        \n",
    "        outputs = 0\n",
    "        for regressor in regressors:\n",
    "            output = regressor(features.float())\n",
    "            outputs += output\n",
    "        \n",
    "        outputs = outputs / len(models)\n",
    "        \n",
    "Ypred = outputs.cpu().numpy().squeeze()\n",
    "Yreal = labels.cpu().numpy()\n",
    "\n",
    "print(\"Loss on Testing Data:\", criterion(outputs, labels).item())\n",
    "\n",
    "print(\"Lets see predictions\")\n",
    "print(Ypred)\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "\n",
    "optR.fit(Ypred, Yreal)\n",
    "\n",
    "coefficients = optR.coefficients()\n",
    "\n",
    "print(\"Thresholds:\", coefficients)\n",
    "\n",
    "optimized = optR.predict(Ypred)\n",
    "rounded   = np.round(Ypred)\n",
    "\n",
    "print(\"Regerssion Accuracy with Rounded Values:\", accuracy_score(rounded, y_test))\n",
    "print(\"Regerssion Accuracy with Optimized Thresholds:\", accuracy_score(optimized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, optimized)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still one more question to ask\n",
    "- To verify myself, I trained a neural network from Sklearn, which obtains a smaller loss (approx. 0.6) then the pytorch model (approx. 2.1), and the question is \"What is different?\"\n",
    "- Both models use Adam as default with the default momentum hyperparameters, with constant learning rate and sam preprocessing methodology, relu activation and batch_size (at the moment of writing this I did not add LeakyReLU, BN or DropOut Regularization)\n",
    "# And a possible answer:\n",
    "- The MLPRegressor uses as loss function \"squared_errors\" with the regularization term that the MSELoss from Pytorch does not use, but I tried to simulate that regularization term by adding weight_decay to the Adam Optimizer... And it showed the same result.. so the question remains... What is different?\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/blob/95d4f0841/sklearn/neural_network/_multilayer_perceptron.py#L1083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Neural Network Sklearn:  0.8216090452173699\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes = (4), batch_size = 64, max_iter = 100)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Mean Squared Error Neural Network Sklearn: \", mean_squared_error(y_predict, y_test))\n",
    "\n",
    "plt.hist(y_predict)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_test)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And a simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Linear Regression Sklearn 1.1400216456050454\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "y_predict = regressor.predict(X_test_scaled)\n",
    "print(\"Mean Squared Error Linear Regression Sklearn\", mean_squared_error(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And  now a more suitable regression problem for Price\n",
    "- With Root Mean Square Log Error as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr Camere</th>\n",
       "      <th>Suprafata</th>\n",
       "      <th>Etaj</th>\n",
       "      <th>Total Etaje</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scor</th>\n",
       "      <th>Pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>108.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63.52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>84900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>62.00</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>132.00</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>349990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>49.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>36500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>92.00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>68.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>110.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nr Camere  Suprafata  Etaj  Total Etaje  Sector  Scor    Pret\n",
       "0          4     108.00     2            3       4     5   83000\n",
       "1          1      41.00     1            8       1     1   39900\n",
       "2          3      63.52     1            3       2     3   84900\n",
       "3          1      33.00     3           10       5     1   45500\n",
       "4          2      62.00     5            9       5     5   54900\n",
       "5          3     132.00     2            6       1     2  349990\n",
       "6          2      49.00     6            6       6     4   36500\n",
       "7          3      92.00     4            8       2     2  119000\n",
       "8          3      68.00     3            5       4     5   67500\n",
       "9          3     110.00     1            2       1     1  133000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Bucharest_HousePriceDataset.csv\")\n",
    "\n",
    "display(data.head(n = 10))\n",
    "\n",
    "features = data.drop(['Pret'], axis = 1, inplace = False)\n",
    "\n",
    "labels   = data[\"Pret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features.values, labels.values, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, _ = preprocessing(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to MSE\n",
    "- I choose to use RMSLE Loss function to to get a better sense of the problem, but in some situations it was not well defined and it returned \"nan\" as loss value for training and validating steps, so I went back to MSE Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 0\n",
      "Epoch: 1/1000..  Training Loss: 13374974112.914..  Test Loss: 12780661760.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13581542955.886..  Test Loss: 13057370112.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13451718992.457..  Test Loss: 12841475072.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13462210560.000..  Test Loss: 12924775424.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13500724838.400..  Test Loss: 12814572544.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13461612017.371..  Test Loss: 12923874304.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13510779084.800..  Test Loss: 12799073280.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13559331401.143..  Test Loss: 12916927488.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13407894089.143..  Test Loss: 12833338368.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13447797877.029..  Test Loss: 12747672576.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13518435006.171..  Test Loss: 12918100992.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13418448954.514..  Test Loss: 12839652352.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13511441993.143..  Test Loss: 12945402880.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13427527826.286..  Test Loss: 12817014784.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13596206226.286..  Test Loss: 13013489664.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13468123545.600..  Test Loss: 12877774848.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13532896548.571..  Test Loss: 12962300928.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13392281073.371..  Test Loss: 12867359744.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13480371989.943..  Test Loss: 12974299136.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13474117339.429..  Test Loss: 12875627520.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13503485981.257..  Test Loss: 12919412736.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13459574754.743..  Test Loss: 12825616384.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13397313887.086..  Test Loss: 12762147840.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13430731658.971..  Test Loss: 12858730496.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13385932946.286..  Test Loss: 12843527168.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13394685981.257..  Test Loss: 12799075328.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13310151299.657..  Test Loss: 12921347072.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13375147242.057..  Test Loss: 12845761536.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13506370413.714..  Test Loss: 12859850752.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13435431672.686..  Test Loss: 12773770240.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13326174529.829..  Test Loss: 12887321600.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13448333077.943..  Test Loss: 12727794688.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13521990100.114..  Test Loss: 12930195456.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13308531346.286..  Test Loss: 12744911872.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13642442825.143..  Test Loss: 12667672576.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13502548640.914..  Test Loss: 12722723840.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13306861114.514..  Test Loss: 12928637952.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13353034430.171..  Test Loss: 12771345408.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13400201962.057..  Test Loss: 12710947840.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13364816705.829..  Test Loss: 12711741440.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13379168504.686..  Test Loss: 12704581632.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13388037866.057..  Test Loss: 12844440576.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13526104941.714..  Test Loss: 12660947968.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13403439513.600..  Test Loss: 12813333504.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13444329940.114..  Test Loss: 12915592192.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13480280678.400..  Test Loss: 12851581952.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13430845454.629..  Test Loss: 12671669248.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13337300128.914..  Test Loss: 12760566784.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13242247299.657..  Test Loss: 12640010240.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13230712802.743..  Test Loss: 12613200896.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13303749456.457..  Test Loss: 12983198720.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13284943989.029..  Test Loss: 12678939648.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13229084584.229..  Test Loss: 12964882432.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13282041943.771..  Test Loss: 12796704768.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13403718392.686..  Test Loss: 12870949888.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13279470826.057..  Test Loss: 12625850368.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13381496071.314..  Test Loss: 12697362432.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13216478573.714..  Test Loss: 12727232512.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13168092203.886..  Test Loss: 12713761792.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13329819209.143..  Test Loss: 12686730240.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13333207961.600..  Test Loss: 12557646848.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13200564575.086..  Test Loss: 12534163456.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13172204383.086..  Test Loss: 12698347520.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13243297777.371..  Test Loss: 12664755200.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13273910023.314..  Test Loss: 12572749824.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13138537706.057..  Test Loss: 12583022592.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13244329296.457..  Test Loss: 12786712576.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13184830142.171..  Test Loss: 12506140672.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13170530362.514..  Test Loss: 12601918464.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13114475724.800..  Test Loss: 12550155264.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13158464950.857..  Test Loss: 12762234880.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13136627946.057..  Test Loss: 12623358976.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13161531596.800..  Test Loss: 12715133952.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13175956948.114..  Test Loss: 12559902720.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13123672444.343..  Test Loss: 12691814400.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13085909855.086..  Test Loss: 12515602432.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13176756004.571..  Test Loss: 12686519296.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13042171450.514..  Test Loss: 12590787584.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13172299220.114..  Test Loss: 12611010560.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13211116895.086..  Test Loss: 12613448704.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13061772697.600..  Test Loss: 12477954048.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13187749741.714..  Test Loss: 12556166144.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13107210298.514..  Test Loss: 12523521024.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13121362885.486..  Test Loss: 12620795904.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13226896413.257..  Test Loss: 12530270208.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13046117493.029..  Test Loss: 12388482048.000.. \n",
      "Epoch: 87/1000..  Training Loss: 12987319954.286..  Test Loss: 12563946496.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13130071040.000..  Test Loss: 12655959040.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13097987393.829..  Test Loss: 12448177152.000.. \n",
      "Epoch: 90/1000..  Training Loss: 12991303153.371..  Test Loss: 12594449408.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13041255394.743..  Test Loss: 12562416640.000.. \n",
      "Epoch: 92/1000..  Training Loss: 12944211953.371..  Test Loss: 12417027072.000.. \n",
      "Epoch: 93/1000..  Training Loss: 13000272369.371..  Test Loss: 12489074688.000.. \n",
      "Epoch: 94/1000..  Training Loss: 13010794291.200..  Test Loss: 12727517184.000.. \n",
      "Epoch: 95/1000..  Training Loss: 13040014994.286..  Test Loss: 12301366272.000.. \n",
      "Epoch: 96/1000..  Training Loss: 13010527875.657..  Test Loss: 12640205824.000.. \n",
      "Epoch: 97/1000..  Training Loss: 12883682830.629..  Test Loss: 12473531392.000.. \n",
      "Epoch: 98/1000..  Training Loss: 12944636533.029..  Test Loss: 12333150208.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12916133361.371..  Test Loss: 12593746944.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12963138004.114..  Test Loss: 12463753216.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000..  Training Loss: 12967962141.257..  Test Loss: 12512989184.000.. \n",
      "Epoch: 102/1000..  Training Loss: 12920208223.086..  Test Loss: 12294696960.000.. \n",
      "Epoch: 103/1000..  Training Loss: 13046954276.571..  Test Loss: 12308025344.000.. \n",
      "Epoch: 104/1000..  Training Loss: 13050155373.714..  Test Loss: 12499088384.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12822409186.743..  Test Loss: 12407974912.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12851602856.229..  Test Loss: 12372408320.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12977759831.771..  Test Loss: 12232043520.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12790891198.171..  Test Loss: 12529155072.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12825526740.114..  Test Loss: 12403020800.000.. \n",
      "Epoch: 110/1000..  Training Loss: 13007699002.514..  Test Loss: 12425765888.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12841263674.514..  Test Loss: 12381257728.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12787153817.600..  Test Loss: 12330194944.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12816008133.486..  Test Loss: 12353481728.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12746612092.343..  Test Loss: 12232338432.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12708138730.057..  Test Loss: 12280601600.000.. \n",
      "Epoch: 116/1000..  Training Loss: 12913764615.314..  Test Loss: 12249478144.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12781699496.229..  Test Loss: 12189672448.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12914973476.571..  Test Loss: 12148692992.000.. \n",
      "Epoch: 119/1000..  Training Loss: 12821947684.571..  Test Loss: 12264545280.000.. \n",
      "Epoch: 120/1000..  Training Loss: 12870225598.171..  Test Loss: 12220648448.000.. \n",
      "Epoch: 121/1000..  Training Loss: 12758792528.457..  Test Loss: 12218244096.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12671212675.657..  Test Loss: 12152466432.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12806362170.514..  Test Loss: 12233313280.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12732536334.629..  Test Loss: 12306545664.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12676570126.629..  Test Loss: 12154961920.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12684969062.400..  Test Loss: 12154015744.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12589291739.429..  Test Loss: 12293067776.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12603336265.143..  Test Loss: 12213043200.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12639205697.829..  Test Loss: 12033258496.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12615017676.800..  Test Loss: 12201851904.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12628644191.086..  Test Loss: 12060205056.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12525385201.371..  Test Loss: 12195528704.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12678883620.571..  Test Loss: 12231937024.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12592923443.200..  Test Loss: 12063413248.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12563725370.514..  Test Loss: 12047410176.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12532464098.743..  Test Loss: 12276870144.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12494206317.714..  Test Loss: 12023977984.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12498040407.771..  Test Loss: 12257037312.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12499612467.200..  Test Loss: 12172823552.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12488777362.286..  Test Loss: 11970093056.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12480534542.629..  Test Loss: 12130372608.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12583170165.029..  Test Loss: 12078900224.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12458618675.200..  Test Loss: 12171776000.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12414409216.000..  Test Loss: 12100049920.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12549769903.543..  Test Loss: 12058283008.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12456622899.200..  Test Loss: 12047575040.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12489142096.457..  Test Loss: 12140570624.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12548677456.457..  Test Loss: 11985148928.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12484571574.857..  Test Loss: 11994696704.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12473061083.429..  Test Loss: 12197830656.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12530701209.600..  Test Loss: 11907077120.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12514764565.943..  Test Loss: 11998185472.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12409848510.171..  Test Loss: 11966700544.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12364245664.914..  Test Loss: 11787857920.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12389916086.857..  Test Loss: 11884760064.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12414117302.857..  Test Loss: 11800796160.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12318087548.343..  Test Loss: 11945040896.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12338160742.400..  Test Loss: 11785767936.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12243134537.143..  Test Loss: 11803058176.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12427753574.400..  Test Loss: 11926459392.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12231563073.829..  Test Loss: 11780710400.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12267096181.029..  Test Loss: 11869669376.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12272002516.114..  Test Loss: 11746171904.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12269037319.314..  Test Loss: 11835114496.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12432015711.086..  Test Loss: 11688084480.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12207424336.457..  Test Loss: 11904244736.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12285507510.857..  Test Loss: 11717732352.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12171562452.114..  Test Loss: 11762004992.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12303841177.600..  Test Loss: 11679205376.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12144349652.114..  Test Loss: 11928916992.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12212874561.829..  Test Loss: 11755648000.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12166650455.771..  Test Loss: 11824638976.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12169003329.829..  Test Loss: 11784413184.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12124262634.057..  Test Loss: 11853786112.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12151290850.743..  Test Loss: 11597602816.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12074551968.914..  Test Loss: 11623586816.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12073630281.143..  Test Loss: 11648171008.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12108912815.543..  Test Loss: 11622402048.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12176656969.143..  Test Loss: 11776537600.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12086441150.171..  Test Loss: 11681848320.000.. \n",
      "Epoch: 181/1000..  Training Loss: 11991775261.257..  Test Loss: 11454184448.000.. \n",
      "Epoch: 182/1000..  Training Loss: 11945589291.886..  Test Loss: 11696098304.000.. \n",
      "Epoch: 183/1000..  Training Loss: 11939997491.200..  Test Loss: 11527720960.000.. \n",
      "Epoch: 184/1000..  Training Loss: 12000150601.143..  Test Loss: 11631990784.000.. \n",
      "Epoch: 185/1000..  Training Loss: 11966696126.171..  Test Loss: 11652813824.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11920826455.771..  Test Loss: 11606318080.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11986395355.429..  Test Loss: 11748520960.000.. \n",
      "Epoch: 188/1000..  Training Loss: 12076467843.657..  Test Loss: 11513351168.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11977856541.257..  Test Loss: 11614201856.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11912119208.229..  Test Loss: 11527624704.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11908199409.371..  Test Loss: 11319542784.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11892467009.829..  Test Loss: 11388180480.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11957079771.429..  Test Loss: 11629683712.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11896578560.000..  Test Loss: 11561652224.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11987786693.486..  Test Loss: 11607495680.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11977345784.686..  Test Loss: 11366084608.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11784250426.514..  Test Loss: 11556076544.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11907921861.486..  Test Loss: 11402320896.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11773721351.314..  Test Loss: 11402501120.000.. \n",
      "Epoch: 200/1000..  Training Loss: 12012034852.571..  Test Loss: 11361037312.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/1000..  Training Loss: 11868522261.943..  Test Loss: 11290524672.000.. \n",
      "Epoch: 202/1000..  Training Loss: 11743390164.114..  Test Loss: 11261991936.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11681184533.943..  Test Loss: 11373341696.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11659501860.571..  Test Loss: 11383070720.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11666945726.171..  Test Loss: 11271813120.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11757073115.429..  Test Loss: 11619338240.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11661314925.714..  Test Loss: 11454401536.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11765208766.171..  Test Loss: 11398079488.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11717966204.343..  Test Loss: 11463416832.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11653786229.029..  Test Loss: 11385732096.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11531238253.714..  Test Loss: 11193512960.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11598470758.400..  Test Loss: 11438492672.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11626092821.943..  Test Loss: 11260145664.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11633387841.829..  Test Loss: 11284110336.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11518315300.571..  Test Loss: 11365577728.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11498030211.657..  Test Loss: 11428596736.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11593591442.286..  Test Loss: 11104970752.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11680933917.257..  Test Loss: 11306839040.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11580524383.086..  Test Loss: 11160600576.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11540396192.914..  Test Loss: 11249186816.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11604533291.886..  Test Loss: 11272505344.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11537417698.743..  Test Loss: 11016479744.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11557331924.114..  Test Loss: 10948253696.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11597484061.257..  Test Loss: 11071134720.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11471766674.286..  Test Loss: 10972904448.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11392601834.057..  Test Loss: 11152262144.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11389234717.257..  Test Loss: 11067743232.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11390369821.257..  Test Loss: 11045830656.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11450060156.343..  Test Loss: 11017399296.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11376515774.171..  Test Loss: 10952008704.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11315254652.343..  Test Loss: 11106804736.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11404782840.686..  Test Loss: 11038592000.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11326118443.886..  Test Loss: 10883229696.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11290183416.686..  Test Loss: 10935770112.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11294922488.686..  Test Loss: 10902188032.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11355562203.429..  Test Loss: 10944763904.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11244838897.371..  Test Loss: 10902294528.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11234968020.114..  Test Loss: 10851690496.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11437247590.400..  Test Loss: 10883082240.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11218650038.857..  Test Loss: 10829422592.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11220740183.771..  Test Loss: 10943301632.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11156858762.971..  Test Loss: 10793458688.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11186671893.943..  Test Loss: 10871337984.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11217392435.200..  Test Loss: 10764094464.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11113351636.114..  Test Loss: 10939726848.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11151417153.829..  Test Loss: 10910289920.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11086638328.686..  Test Loss: 11043210240.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11020850278.400..  Test Loss: 10718985216.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11136547415.771..  Test Loss: 10856684544.000.. \n",
      "Epoch: 250/1000..  Training Loss: 11030367626.971..  Test Loss: 10765851648.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11041197597.257..  Test Loss: 10671893504.000.. \n",
      "Epoch: 252/1000..  Training Loss: 10979468317.257..  Test Loss: 10728316928.000.. \n",
      "Epoch: 253/1000..  Training Loss: 10930480391.314..  Test Loss: 10693192704.000.. \n",
      "Epoch: 254/1000..  Training Loss: 11205437571.657..  Test Loss: 10719321088.000.. \n",
      "Epoch: 255/1000..  Training Loss: 11051207021.714..  Test Loss: 10601999360.000.. \n",
      "Epoch: 256/1000..  Training Loss: 10926349180.343..  Test Loss: 10779953152.000.. \n",
      "Epoch: 257/1000..  Training Loss: 11035145947.429..  Test Loss: 10606648320.000.. \n",
      "Epoch: 258/1000..  Training Loss: 11015921605.486..  Test Loss: 10604734464.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10897951129.600..  Test Loss: 10754552832.000.. \n",
      "Epoch: 260/1000..  Training Loss: 10866352508.343..  Test Loss: 10626685952.000.. \n",
      "Epoch: 261/1000..  Training Loss: 11076893066.971..  Test Loss: 10533144576.000.. \n",
      "Epoch: 262/1000..  Training Loss: 11069018916.571..  Test Loss: 10495395840.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10821291168.914..  Test Loss: 10694300672.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10956594249.143..  Test Loss: 10559264768.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10915514645.943..  Test Loss: 10725176320.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10788729914.514..  Test Loss: 10526644224.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10939533970.286..  Test Loss: 10423855104.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10963849391.543..  Test Loss: 10529482752.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10830279080.229..  Test Loss: 10549414912.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10753421458.286..  Test Loss: 10452139008.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10667634497.829..  Test Loss: 10425869312.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10695764011.886..  Test Loss: 10423016448.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10808876426.971..  Test Loss: 10584090624.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10692141480.229..  Test Loss: 10313094144.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10776681808.457..  Test Loss: 10323803136.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10698349875.200..  Test Loss: 10732539904.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10639539770.514..  Test Loss: 10466376704.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10814888784.457..  Test Loss: 10370501632.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10604346353.371..  Test Loss: 10260164608.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10718608954.514..  Test Loss: 10504504320.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10593846784.000..  Test Loss: 10192985088.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10534624548.571..  Test Loss: 10216641536.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10573715777.829..  Test Loss: 10421243904.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10580299644.343..  Test Loss: 10260648960.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10590978208.914..  Test Loss: 10527284224.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10650403722.971..  Test Loss: 10229158912.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10433757696.000..  Test Loss: 10189708288.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10719189240.686..  Test Loss: 10247145472.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10533770415.543..  Test Loss: 10179444736.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10551953027.657..  Test Loss: 10189758464.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10460258245.486..  Test Loss: 10010747904.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10693828944.457..  Test Loss: 10100546560.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10421405461.943..  Test Loss: 10110226432.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10345910886.400..  Test Loss: 10170797056.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10456871511.771..  Test Loss: 10190252032.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10397278544.457..  Test Loss: 10158869504.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10370067499.886..  Test Loss: 10080824320.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10432477315.657..  Test Loss: 10029678592.000.. \n",
      "Epoch: 299/1000..  Training Loss: 10355194016.914..  Test Loss: 10139731968.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300/1000..  Training Loss: 10318955549.257..  Test Loss: 9945738240.000.. \n",
      "Epoch: 301/1000..  Training Loss: 10352509293.714..  Test Loss: 10094970880.000.. \n",
      "Epoch: 302/1000..  Training Loss: 10390355880.229..  Test Loss: 10042948608.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10301036778.057..  Test Loss: 9987934208.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10351410161.371..  Test Loss: 9896537088.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10269415584.914..  Test Loss: 9905204224.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10215107832.686..  Test Loss: 9909925888.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10221952073.143..  Test Loss: 9950311424.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10153957639.314..  Test Loss: 9982522368.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10172984276.114..  Test Loss: 9893203968.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10178550564.571..  Test Loss: 9771788288.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10140044858.514..  Test Loss: 9877994496.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10164487972.571..  Test Loss: 9912401920.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10124800643.657..  Test Loss: 9934445568.000.. \n",
      "Epoch: 314/1000..  Training Loss: 10069914726.400..  Test Loss: 9877436416.000.. \n",
      "Epoch: 315/1000..  Training Loss: 10094805723.429..  Test Loss: 9795154944.000.. \n",
      "Epoch: 316/1000..  Training Loss: 10109750052.571..  Test Loss: 9633340416.000.. \n",
      "Epoch: 317/1000..  Training Loss: 10057896433.371..  Test Loss: 9766888448.000.. \n",
      "Epoch: 318/1000..  Training Loss: 10057928718.629..  Test Loss: 9918936064.000.. \n",
      "Epoch: 319/1000..  Training Loss: 10006872736.914..  Test Loss: 9683751936.000.. \n",
      "Epoch: 320/1000..  Training Loss: 9964262400.000..  Test Loss: 9640639488.000.. \n",
      "Epoch: 321/1000..  Training Loss: 9905054017.829..  Test Loss: 9768790016.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9966877344.914..  Test Loss: 9851522048.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9897275889.371..  Test Loss: 9678656512.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9863465720.686..  Test Loss: 9645472768.000.. \n",
      "Epoch: 325/1000..  Training Loss: 10012449455.543..  Test Loss: 9735235584.000.. \n",
      "Epoch: 326/1000..  Training Loss: 10095226002.286..  Test Loss: 9596115968.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9861505696.914..  Test Loss: 9729020928.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9983238319.543..  Test Loss: 9484854272.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9851633152.000..  Test Loss: 9619511296.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9784618378.971..  Test Loss: 9585675264.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9833457444.571..  Test Loss: 9571867648.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9739273830.400..  Test Loss: 9780997120.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9836779315.200..  Test Loss: 9433647104.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9699549184.000..  Test Loss: 9647112192.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9781226276.571..  Test Loss: 9607386112.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9750187914.971..  Test Loss: 9526682624.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9666641217.829..  Test Loss: 9563316224.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9644343354.514..  Test Loss: 9499380736.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9731519370.971..  Test Loss: 9442632704.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9647641994.971..  Test Loss: 9342181376.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9700593298.286..  Test Loss: 9570000896.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9687707618.743..  Test Loss: 9414575104.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9517999440.457..  Test Loss: 9274088448.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9589836434.286..  Test Loss: 9315931136.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9536806034.286..  Test Loss: 9456926720.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9542637670.400..  Test Loss: 9386985472.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9485524450.743..  Test Loss: 9223382016.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9514878156.800..  Test Loss: 9280747520.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9560420834.743..  Test Loss: 9391006720.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9490319491.657..  Test Loss: 9251612672.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9422304680.229..  Test Loss: 9368444928.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9524888415.086..  Test Loss: 9232587776.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9491446067.200..  Test Loss: 9357036544.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9412786073.600..  Test Loss: 9222039552.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9418908496.457..  Test Loss: 9076872192.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9537808998.400..  Test Loss: 9109801984.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9362594157.714..  Test Loss: 9165373440.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9428833733.486..  Test Loss: 9199132672.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9352392133.486..  Test Loss: 9300828160.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9399696515.657..  Test Loss: 9157020672.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9446425000.229..  Test Loss: 9241152512.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9233926933.943..  Test Loss: 9148988416.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9271866038.857..  Test Loss: 9055542272.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9298475783.314..  Test Loss: 9102880768.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9215558831.543..  Test Loss: 8957021184.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9205120936.229..  Test Loss: 8873646080.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9310259448.686..  Test Loss: 9160076288.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9231035743.086..  Test Loss: 9080384512.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9316153446.400..  Test Loss: 8949402624.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9175015160.686..  Test Loss: 8970059776.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9303697671.314..  Test Loss: 8971926528.000.. \n",
      "Epoch: 372/1000..  Training Loss: 9150743083.886..  Test Loss: 9022233600.000.. \n",
      "Epoch: 373/1000..  Training Loss: 9124319392.914..  Test Loss: 8952953856.000.. \n",
      "Epoch: 374/1000..  Training Loss: 9099450528.914..  Test Loss: 9077560320.000.. \n",
      "Epoch: 375/1000..  Training Loss: 9035177969.371..  Test Loss: 8898413568.000.. \n",
      "Epoch: 376/1000..  Training Loss: 9149684150.857..  Test Loss: 9047301120.000.. \n",
      "Epoch: 377/1000..  Training Loss: 9100274132.114..  Test Loss: 8892229632.000.. \n",
      "Epoch: 378/1000..  Training Loss: 9090308081.371..  Test Loss: 8783192064.000.. \n",
      "Epoch: 379/1000..  Training Loss: 8973492297.143..  Test Loss: 8820653056.000.. \n",
      "Epoch: 380/1000..  Training Loss: 8989108004.571..  Test Loss: 8848591872.000.. \n",
      "Epoch: 381/1000..  Training Loss: 9051324562.286..  Test Loss: 8685989888.000.. \n",
      "Epoch: 382/1000..  Training Loss: 9004214564.571..  Test Loss: 8846149632.000.. \n",
      "Epoch: 383/1000..  Training Loss: 9106960384.000..  Test Loss: 8657584128.000.. \n",
      "Epoch: 384/1000..  Training Loss: 8948350727.314..  Test Loss: 8801467392.000.. \n",
      "Epoch: 385/1000..  Training Loss: 9071122709.943..  Test Loss: 8734837760.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8905688576.000..  Test Loss: 8778017792.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8907249854.171..  Test Loss: 8619444224.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8853164500.114..  Test Loss: 8721859584.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8990590244.571..  Test Loss: 8676877312.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8813926005.029..  Test Loss: 8575155712.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8813428692.114..  Test Loss: 8493810688.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8901811668.114..  Test Loss: 8699572224.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8847262325.029..  Test Loss: 8648919040.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8742353598.171..  Test Loss: 8562960896.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8751151396.571..  Test Loss: 8429388800.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8690155710.171..  Test Loss: 8500446720.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8744877743.543..  Test Loss: 8434892800.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8838082867.200..  Test Loss: 8570188800.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8724587490.743..  Test Loss: 8447271936.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8667884924.343..  Test Loss: 8580996608.000.. \n",
      "Epoch: 401/1000..  Training Loss: 8782765231.543..  Test Loss: 8508018176.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 402/1000..  Training Loss: 8624675693.714..  Test Loss: 8261144064.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8678835865.600..  Test Loss: 8349934592.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8576995328.000..  Test Loss: 8557981696.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8621975946.971..  Test Loss: 8380301312.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8545155569.371..  Test Loss: 8359468544.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8584222529.829..  Test Loss: 8486875136.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8542607828.114..  Test Loss: 8298112000.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8560624771.657..  Test Loss: 8324514816.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8559731799.771..  Test Loss: 8221687808.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8557534412.800..  Test Loss: 8309011456.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8458546775.771..  Test Loss: 8298940928.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8567920991.086..  Test Loss: 8081571328.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8437318626.743..  Test Loss: 8293222912.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8490527744.000..  Test Loss: 8324440064.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8389556721.371..  Test Loss: 8638826496.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8362579507.200..  Test Loss: 8251076096.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8385252410.514..  Test Loss: 8143481344.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8485974367.086..  Test Loss: 8303192576.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8325681400.686..  Test Loss: 8112249344.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8407327129.600..  Test Loss: 8098791424.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8332915609.600..  Test Loss: 8133414912.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8545087641.600..  Test Loss: 8337806848.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8400764401.371..  Test Loss: 8097125888.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8385466675.200..  Test Loss: 8043686400.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8226037057.829..  Test Loss: 7986799616.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8288232901.486..  Test Loss: 8052627968.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8275896554.057..  Test Loss: 8014286848.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8278321239.771..  Test Loss: 8102179840.000.. \n",
      "Epoch: 430/1000..  Training Loss: 8129825199.543..  Test Loss: 7917868032.000.. \n",
      "Epoch: 431/1000..  Training Loss: 8208912720.457..  Test Loss: 8086539776.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8279670827.886..  Test Loss: 8118655488.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8122343789.714..  Test Loss: 7925348864.000.. \n",
      "Epoch: 434/1000..  Training Loss: 8070014464.000..  Test Loss: 8018889216.000.. \n",
      "Epoch: 435/1000..  Training Loss: 8176605052.343..  Test Loss: 7858761728.000.. \n",
      "Epoch: 436/1000..  Training Loss: 8198516194.743..  Test Loss: 7885924864.000.. \n",
      "Epoch: 437/1000..  Training Loss: 8100617450.057..  Test Loss: 7859464704.000.. \n",
      "Epoch: 438/1000..  Training Loss: 8140258508.800..  Test Loss: 7997062656.000.. \n",
      "Epoch: 439/1000..  Training Loss: 8065015061.943..  Test Loss: 7842428416.000.. \n",
      "Epoch: 440/1000..  Training Loss: 8138647317.943..  Test Loss: 7931916288.000.. \n",
      "Epoch: 441/1000..  Training Loss: 8143595732.114..  Test Loss: 7865683456.000.. \n",
      "Epoch: 442/1000..  Training Loss: 8002781959.314..  Test Loss: 7777173504.000.. \n",
      "Epoch: 443/1000..  Training Loss: 7985625994.971..  Test Loss: 7908381696.000.. \n",
      "Epoch: 444/1000..  Training Loss: 8079857576.229..  Test Loss: 7893492736.000.. \n",
      "Epoch: 445/1000..  Training Loss: 8025181301.029..  Test Loss: 7854493184.000.. \n",
      "Epoch: 446/1000..  Training Loss: 8008140251.429..  Test Loss: 7793590272.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7907703734.857..  Test Loss: 8102107648.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7939728296.229..  Test Loss: 7766253568.000.. \n",
      "Epoch: 449/1000..  Training Loss: 7973420909.714..  Test Loss: 7703832064.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7912579379.200..  Test Loss: 7861648896.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7895667214.629..  Test Loss: 7588254720.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7916009333.029..  Test Loss: 7663449600.000.. \n",
      "Epoch: 453/1000..  Training Loss: 8087776387.657..  Test Loss: 7754651136.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7839400660.114..  Test Loss: 7581950976.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7889870328.686..  Test Loss: 7499351552.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7869572746.971..  Test Loss: 7620088832.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7748849963.886..  Test Loss: 7583645696.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7861003322.514..  Test Loss: 7633861120.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7819702944.914..  Test Loss: 7622319616.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7708836439.771..  Test Loss: 7528427008.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7891823601.371..  Test Loss: 7634834944.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7731232650.971..  Test Loss: 7380430336.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7784723821.714..  Test Loss: 7643821568.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7630139472.457..  Test Loss: 7514912256.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7681612653.714..  Test Loss: 7690420224.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7655545863.314..  Test Loss: 7373630976.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7613294526.171..  Test Loss: 7514632192.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7614880607.086..  Test Loss: 7511851008.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7658621966.629..  Test Loss: 7418348544.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7649564342.857..  Test Loss: 7446700032.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7514301578.971..  Test Loss: 7326213632.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7771394954.971..  Test Loss: 7490647040.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7624936184.686..  Test Loss: 7381597696.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7569640638.171..  Test Loss: 7142835200.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7443239614.171..  Test Loss: 7309825536.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7459379697.371..  Test Loss: 7295336448.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7622170521.600..  Test Loss: 7365413376.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7402592928.914..  Test Loss: 7271403520.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7403567637.943..  Test Loss: 7213529600.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7486813666.743..  Test Loss: 7233961984.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7442561184.914..  Test Loss: 7039052288.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7395686034.286..  Test Loss: 7316776448.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7398124704.914..  Test Loss: 7123796992.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7466085727.086..  Test Loss: 7277064192.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7339373151.086..  Test Loss: 7147688960.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7385710738.286..  Test Loss: 7129382400.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7277964664.686..  Test Loss: 7107949568.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7438256193.829..  Test Loss: 7030681600.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7379905887.086..  Test Loss: 7162909696.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7323812322.743..  Test Loss: 7071982592.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7269050792.229..  Test Loss: 6997675520.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7364185402.514..  Test Loss: 7034179072.000.. \n",
      "Epoch: 493/1000..  Training Loss: 7292178958.629..  Test Loss: 7058137088.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7288169859.657..  Test Loss: 6992236032.000.. \n",
      "Epoch: 495/1000..  Training Loss: 7244901858.743..  Test Loss: 7213645312.000.. \n",
      "Epoch: 496/1000..  Training Loss: 7180725664.914..  Test Loss: 7144401408.000.. \n",
      "Epoch: 497/1000..  Training Loss: 7274031718.400..  Test Loss: 7061517824.000.. \n",
      "Epoch: 498/1000..  Training Loss: 7264994574.629..  Test Loss: 6735243776.000.. \n",
      "Epoch: 499/1000..  Training Loss: 7156309145.600..  Test Loss: 6847201280.000.. \n",
      "Epoch: 500/1000..  Training Loss: 7133056555.886..  Test Loss: 6817579008.000.. \n",
      "Epoch: 501/1000..  Training Loss: 7289222769.371..  Test Loss: 6938744320.000.. \n",
      "Epoch: 502/1000..  Training Loss: 7096722373.486..  Test Loss: 6978790912.000.. \n",
      "Epoch: 503/1000..  Training Loss: 7225291710.171..  Test Loss: 7016607232.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 504/1000..  Training Loss: 7156512870.400..  Test Loss: 6825805312.000.. \n",
      "Epoch: 505/1000..  Training Loss: 7159343828.114..  Test Loss: 7011023360.000.. \n",
      "Epoch: 506/1000..  Training Loss: 7083628163.657..  Test Loss: 6800619008.000.. \n",
      "Epoch: 507/1000..  Training Loss: 6982054304.914..  Test Loss: 6759948288.000.. \n",
      "Epoch: 508/1000..  Training Loss: 7053921382.400..  Test Loss: 6800555520.000.. \n",
      "Epoch: 509/1000..  Training Loss: 7025863497.143..  Test Loss: 6909244416.000.. \n",
      "Epoch: 510/1000..  Training Loss: 7071926337.829..  Test Loss: 6684717568.000.. \n",
      "Epoch: 511/1000..  Training Loss: 7003987302.400..  Test Loss: 6722583552.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6973994130.286..  Test Loss: 6851345408.000.. \n",
      "Epoch: 513/1000..  Training Loss: 7141972216.686..  Test Loss: 6574023680.000.. \n",
      "Epoch: 514/1000..  Training Loss: 7064879616.000..  Test Loss: 6777167872.000.. \n",
      "Epoch: 515/1000..  Training Loss: 7049120757.029..  Test Loss: 6738915840.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6962852790.857..  Test Loss: 6652580864.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6949235982.629..  Test Loss: 6764736000.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6901302491.429..  Test Loss: 6512736768.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6887798403.657..  Test Loss: 6714605568.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6945390943.086..  Test Loss: 6602508288.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6938381721.600..  Test Loss: 6496230912.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6932874861.714..  Test Loss: 6508861440.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6814128683.886..  Test Loss: 6324755968.000.. \n",
      "Epoch: 524/1000..  Training Loss: 7108617303.771..  Test Loss: 6506640896.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6867385526.857..  Test Loss: 6699449856.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6818557571.657..  Test Loss: 6496373248.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6813452551.314..  Test Loss: 6554488832.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6813349207.771..  Test Loss: 6564140544.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6830953757.257..  Test Loss: 6593302016.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6816763092.114..  Test Loss: 6689428480.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6775948880.457..  Test Loss: 6568187392.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6809533622.857..  Test Loss: 6383709696.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6858995755.886..  Test Loss: 6560547328.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6721672769.829..  Test Loss: 6714642432.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6678648802.743..  Test Loss: 6507947520.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6812187567.543..  Test Loss: 6405576192.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6761634625.829..  Test Loss: 6522873344.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6780232828.343..  Test Loss: 6177010688.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6639773973.943..  Test Loss: 6416238080.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6655061057.829..  Test Loss: 6481267200.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6590286789.486..  Test Loss: 6190024192.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6657295989.029..  Test Loss: 6125780480.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6652707466.971..  Test Loss: 6203346432.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6623068116.114..  Test Loss: 6336089088.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6523725297.371..  Test Loss: 6398998016.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6602288420.571..  Test Loss: 6271563264.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6542623524.571..  Test Loss: 6250508288.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6586470005.029..  Test Loss: 6066423808.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6496914717.257..  Test Loss: 6231088640.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6554730810.514..  Test Loss: 6228302848.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6486010104.686..  Test Loss: 6471206400.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6513210609.371..  Test Loss: 6349696512.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6554354176.000..  Test Loss: 6283909632.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6464427344.457..  Test Loss: 6084656128.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6475596053.943..  Test Loss: 5988791296.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6389914645.943..  Test Loss: 6231272448.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6439809667.657..  Test Loss: 6143068672.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6522661332.114..  Test Loss: 6358990336.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6409817183.086..  Test Loss: 6127534080.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6497711440.457..  Test Loss: 5991022080.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6388101851.429..  Test Loss: 6057389056.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6377180262.400..  Test Loss: 5991775744.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6367343594.057..  Test Loss: 5999494144.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6349212686.629..  Test Loss: 6000385024.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6356169874.286..  Test Loss: 5963631104.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6348422144.000..  Test Loss: 5982622720.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6376816742.400..  Test Loss: 5897192448.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6242368819.200..  Test Loss: 5808546304.000.. \n",
      "Epoch: 569/1000..  Training Loss: 6250939231.086..  Test Loss: 5884289536.000.. \n",
      "Epoch: 570/1000..  Training Loss: 6491989218.743..  Test Loss: 5834034688.000.. \n",
      "Epoch: 571/1000..  Training Loss: 6278790019.657..  Test Loss: 6023863808.000.. \n",
      "Epoch: 572/1000..  Training Loss: 6237720832.000..  Test Loss: 5799236608.000.. \n",
      "Epoch: 573/1000..  Training Loss: 6376330788.571..  Test Loss: 5904444928.000.. \n",
      "Epoch: 574/1000..  Training Loss: 6214576479.086..  Test Loss: 5898516992.000.. \n",
      "Epoch: 575/1000..  Training Loss: 6187234186.971..  Test Loss: 5757493760.000.. \n",
      "Epoch: 576/1000..  Training Loss: 6131269610.057..  Test Loss: 5778542080.000.. \n",
      "Epoch: 577/1000..  Training Loss: 6326924558.629..  Test Loss: 5743414784.000.. \n",
      "Epoch: 578/1000..  Training Loss: 6188761468.343..  Test Loss: 5804483072.000.. \n",
      "Epoch: 579/1000..  Training Loss: 6265675128.686..  Test Loss: 5918373888.000.. \n",
      "Epoch: 580/1000..  Training Loss: 6145424713.143..  Test Loss: 5783329792.000.. \n",
      "Epoch: 581/1000..  Training Loss: 6116295643.429..  Test Loss: 5765347840.000.. \n",
      "Epoch: 582/1000..  Training Loss: 6085627882.057..  Test Loss: 5745010176.000.. \n",
      "Epoch: 583/1000..  Training Loss: 6129027210.971..  Test Loss: 5667735552.000.. \n",
      "Epoch: 584/1000..  Training Loss: 6163043971.657..  Test Loss: 5719818240.000.. \n",
      "Epoch: 585/1000..  Training Loss: 6109262811.429..  Test Loss: 5850027008.000.. \n",
      "Epoch: 586/1000..  Training Loss: 6077572395.886..  Test Loss: 5735660544.000.. \n",
      "Epoch: 587/1000..  Training Loss: 6007695484.343..  Test Loss: 5617183744.000.. \n",
      "Epoch: 588/1000..  Training Loss: 6161614818.743..  Test Loss: 5598248448.000.. \n",
      "Epoch: 589/1000..  Training Loss: 6075831610.514..  Test Loss: 5590860288.000.. \n",
      "Epoch: 590/1000..  Training Loss: 6150475951.543..  Test Loss: 5634832896.000.. \n",
      "Epoch: 591/1000..  Training Loss: 6074625828.571..  Test Loss: 5704124928.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5923680599.771..  Test Loss: 5726950912.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5989685942.857..  Test Loss: 5632368128.000.. \n",
      "Epoch: 594/1000..  Training Loss: 6067374460.343..  Test Loss: 5551407616.000.. \n",
      "Epoch: 595/1000..  Training Loss: 6134121186.743..  Test Loss: 5588252160.000.. \n",
      "Epoch: 596/1000..  Training Loss: 6014726846.171..  Test Loss: 5571948544.000.. \n",
      "Epoch: 597/1000..  Training Loss: 6000046957.714..  Test Loss: 5447707136.000.. \n",
      "Epoch: 598/1000..  Training Loss: 6079833095.314..  Test Loss: 5608024064.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5999359795.200..  Test Loss: 5572104192.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5870067668.114..  Test Loss: 5561441792.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5842917573.486..  Test Loss: 5560345600.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5955342175.086..  Test Loss: 5465669120.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5909347415.771..  Test Loss: 5560031744.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5923419392.000..  Test Loss: 5480029184.000.. \n",
      "Epoch: 605/1000..  Training Loss: 5922144789.943..  Test Loss: 5380922880.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 606/1000..  Training Loss: 5912513440.914..  Test Loss: 5459739136.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5859402276.571..  Test Loss: 5475392512.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5959117502.171..  Test Loss: 5400735232.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5820144376.686..  Test Loss: 5508504064.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5852240800.914..  Test Loss: 5460409856.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5774400672.914..  Test Loss: 5347901952.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5819193856.000..  Test Loss: 5539993088.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5809126582.857..  Test Loss: 5619537408.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5729027605.943..  Test Loss: 5666221056.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5772936630.857..  Test Loss: 5530405376.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5786854582.857..  Test Loss: 5352729088.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5749472007.314..  Test Loss: 5317847040.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5720990705.371..  Test Loss: 5316412928.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5809010358.857..  Test Loss: 5302341632.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5869082594.743..  Test Loss: 5292285440.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5668936996.571..  Test Loss: 5267406336.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5691932938.971..  Test Loss: 5357313536.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5801798319.543..  Test Loss: 5320241664.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5573775813.486..  Test Loss: 5216354304.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5652405606.400..  Test Loss: 5224789504.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5724782489.600..  Test Loss: 5191132672.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5639815745.829..  Test Loss: 5186018816.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5615253138.286..  Test Loss: 5175311872.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5752559429.486..  Test Loss: 5337124352.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5644126149.486..  Test Loss: 5231460352.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5640842276.571..  Test Loss: 5172385792.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5624959868.343..  Test Loss: 5184954368.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5486500981.029..  Test Loss: 5082322944.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5609494805.943..  Test Loss: 5177180160.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5549489565.257..  Test Loss: 5106657792.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5644314521.600..  Test Loss: 5065515008.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5476846496.914..  Test Loss: 5139502080.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5444005482.057..  Test Loss: 5039242752.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5498375826.286..  Test Loss: 5071234048.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5571815380.114..  Test Loss: 4997987840.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5568344802.743..  Test Loss: 5097941504.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5513686111.086..  Test Loss: 5138253312.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5399754737.371..  Test Loss: 5047859200.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5506240138.971..  Test Loss: 5073293312.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5592540240.457..  Test Loss: 5088805888.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5539447537.371..  Test Loss: 5156497408.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5420984678.400..  Test Loss: 4968322048.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5506539541.943..  Test Loss: 5003286528.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5433553349.486..  Test Loss: 5016882176.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5328806268.343..  Test Loss: 5060658176.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5397900119.771..  Test Loss: 4909758976.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5439253986.743..  Test Loss: 4852542464.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5525899958.857..  Test Loss: 4966666240.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5359018276.571..  Test Loss: 5192841216.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5331673753.600..  Test Loss: 4976117248.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5406180037.486..  Test Loss: 4870642688.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5393176283.429..  Test Loss: 4956359680.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5382721923.657..  Test Loss: 4776294912.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5287581527.771..  Test Loss: 5007310848.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5317775498.971..  Test Loss: 4806177280.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5298065678.629..  Test Loss: 4736140800.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5340211185.371..  Test Loss: 4880098816.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5301972560.457..  Test Loss: 4752795648.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5310816994.743..  Test Loss: 4853959168.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5342982751.086..  Test Loss: 4787584000.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5309163439.543..  Test Loss: 4820511232.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5368779622.400..  Test Loss: 4714526208.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5295736949.029..  Test Loss: 4848700416.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5250062145.829..  Test Loss: 4774418432.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5257232917.943..  Test Loss: 4795392000.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5264419730.286..  Test Loss: 4720152064.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5320422560.914..  Test Loss: 4690524672.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5190979748.571..  Test Loss: 4774096384.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5285240312.686..  Test Loss: 4677541376.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5250476668.343..  Test Loss: 4692293120.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5312854549.943..  Test Loss: 4653390336.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5147428183.771..  Test Loss: 4670948864.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5216744842.971..  Test Loss: 4677030400.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5134207451.429..  Test Loss: 4623797248.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5155920219.429..  Test Loss: 4737856512.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5169538764.800..  Test Loss: 4640904704.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5230478474.971..  Test Loss: 4597126656.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5150230674.286..  Test Loss: 4597861888.000.. \n",
      "Epoch: 684/1000..  Training Loss: 5141462074.514..  Test Loss: 4623583744.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5289540227.657..  Test Loss: 4549298688.000.. \n",
      "Epoch: 686/1000..  Training Loss: 5263418675.200..  Test Loss: 4580962304.000.. \n",
      "Epoch: 687/1000..  Training Loss: 5270764968.229..  Test Loss: 4823011328.000.. \n",
      "Epoch: 688/1000..  Training Loss: 5146153918.171..  Test Loss: 4667438080.000.. \n",
      "Epoch: 689/1000..  Training Loss: 5183624341.943..  Test Loss: 4646381056.000.. \n",
      "Epoch: 690/1000..  Training Loss: 5054188357.486..  Test Loss: 4544990720.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5116230356.114..  Test Loss: 4533067264.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5122891527.314..  Test Loss: 4608067072.000.. \n",
      "Epoch: 693/1000..  Training Loss: 5183241969.371..  Test Loss: 4587634176.000.. \n",
      "Epoch: 694/1000..  Training Loss: 5126972324.571..  Test Loss: 4660993536.000.. \n",
      "Epoch: 695/1000..  Training Loss: 5146050282.057..  Test Loss: 4554487808.000.. \n",
      "Epoch: 696/1000..  Training Loss: 5059439674.514..  Test Loss: 4526795776.000.. \n",
      "Epoch: 697/1000..  Training Loss: 5099613933.714..  Test Loss: 4424079360.000.. \n",
      "Epoch: 698/1000..  Training Loss: 5105061405.257..  Test Loss: 4509341696.000.. \n",
      "Epoch: 699/1000..  Training Loss: 5090994790.400..  Test Loss: 4465794560.000.. \n",
      "Epoch: 700/1000..  Training Loss: 5048346572.800..  Test Loss: 4534613504.000.. \n",
      "Epoch: 701/1000..  Training Loss: 5014828317.257..  Test Loss: 4576941568.000.. \n",
      "Epoch: 702/1000..  Training Loss: 5054996004.571..  Test Loss: 4466851328.000.. \n",
      "Epoch: 703/1000..  Training Loss: 4946871043.657..  Test Loss: 4485395968.000.. \n",
      "Epoch: 704/1000..  Training Loss: 5124154909.257..  Test Loss: 4487427584.000.. \n",
      "Epoch: 705/1000..  Training Loss: 4945950047.086..  Test Loss: 4513523712.000.. \n",
      "Epoch: 706/1000..  Training Loss: 5013229205.943..  Test Loss: 4428762624.000.. \n",
      "Epoch: 707/1000..  Training Loss: 5049692050.286..  Test Loss: 4470449664.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 708/1000..  Training Loss: 4983742244.571..  Test Loss: 4392167936.000.. \n",
      "Epoch: 709/1000..  Training Loss: 5065506823.314..  Test Loss: 4478956544.000.. \n",
      "Epoch: 710/1000..  Training Loss: 5071791623.314..  Test Loss: 4444559360.000.. \n",
      "Epoch: 711/1000..  Training Loss: 5025816151.771..  Test Loss: 4341454848.000.. \n",
      "Epoch: 712/1000..  Training Loss: 5025572520.229..  Test Loss: 4402181632.000.. \n",
      "Epoch: 713/1000..  Training Loss: 5020895729.371..  Test Loss: 4336264192.000.. \n",
      "Epoch: 714/1000..  Training Loss: 5006501642.971..  Test Loss: 4367377408.000.. \n",
      "Epoch: 715/1000..  Training Loss: 5050372136.229..  Test Loss: 4380777984.000.. \n",
      "Epoch: 716/1000..  Training Loss: 4946935764.114..  Test Loss: 4375560704.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4981889938.286..  Test Loss: 4285151232.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4929836540.343..  Test Loss: 4338330112.000.. \n",
      "Epoch: 719/1000..  Training Loss: 5077103286.857..  Test Loss: 4318554112.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4983896758.857..  Test Loss: 4303448064.000.. \n",
      "Epoch: 721/1000..  Training Loss: 4908494255.543..  Test Loss: 4316267520.000.. \n",
      "Epoch: 722/1000..  Training Loss: 5065067534.629..  Test Loss: 4326772736.000.. \n",
      "Epoch: 723/1000..  Training Loss: 5027787560.229..  Test Loss: 4392099328.000.. \n",
      "Epoch: 724/1000..  Training Loss: 5056035620.571..  Test Loss: 4336129536.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4905831226.514..  Test Loss: 4314066944.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4952339953.371..  Test Loss: 4321391616.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4973941533.257..  Test Loss: 4427245056.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4955640064.000..  Test Loss: 4294946816.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4899953181.257..  Test Loss: 4259872768.000.. \n",
      "Epoch: 730/1000..  Training Loss: 5018704669.257..  Test Loss: 4295552000.000.. \n",
      "Epoch: 731/1000..  Training Loss: 5027182350.629..  Test Loss: 4399121920.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4948702566.400..  Test Loss: 4290927360.000.. \n",
      "Epoch: 733/1000..  Training Loss: 5022114421.029..  Test Loss: 4390811648.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4958816076.800..  Test Loss: 4230051840.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4902450878.171..  Test Loss: 4310118912.000.. \n",
      "Epoch: 736/1000..  Training Loss: 5017668622.629..  Test Loss: 4223144704.000.. \n",
      "Epoch: 737/1000..  Training Loss: 5033588750.629..  Test Loss: 4239064320.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4961468050.286..  Test Loss: 4159117056.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4903069136.457..  Test Loss: 4235756800.000.. \n",
      "Epoch: 740/1000..  Training Loss: 5011873492.114..  Test Loss: 4253720320.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4874189363.200..  Test Loss: 4197485312.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4947192905.143..  Test Loss: 4211993344.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4869750345.143..  Test Loss: 4225571584.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4812782405.486..  Test Loss: 4336307712.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4905699569.371..  Test Loss: 4212579072.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4843696142.629..  Test Loss: 4249837312.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4848888956.343..  Test Loss: 4157950464.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4912586320.457..  Test Loss: 4278529792.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4850708772.571..  Test Loss: 4211453952.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4824538726.400..  Test Loss: 4302312448.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4812730159.543..  Test Loss: 4168444416.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4846680619.886..  Test Loss: 4190874880.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4879543610.514..  Test Loss: 4163248128.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4905530016.914..  Test Loss: 4172756736.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4836276853.029..  Test Loss: 4114227712.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4859929241.600..  Test Loss: 4069700352.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4955931808.914..  Test Loss: 4291111424.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4958416325.486..  Test Loss: 4156852992.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4829037290.057..  Test Loss: 4058141952.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4814575890.286..  Test Loss: 4121758976.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4894157692.343..  Test Loss: 4179410176.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4882849587.200..  Test Loss: 4139627008.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4752470111.086..  Test Loss: 4110062080.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4804288102.400..  Test Loss: 4177605376.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4828026887.314..  Test Loss: 4087757312.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4851319252.114..  Test Loss: 4085186304.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4823635602.286..  Test Loss: 4177924864.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4884509396.114..  Test Loss: 4094467328.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4837629388.800..  Test Loss: 4202984192.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4824706976.914..  Test Loss: 4091060992.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4805688546.743..  Test Loss: 4045993728.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4818475754.057..  Test Loss: 4229644288.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4762094577.371..  Test Loss: 4072210176.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4761626814.171..  Test Loss: 4113447680.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4744881020.343..  Test Loss: 4139915008.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4846648978.286..  Test Loss: 3984734976.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4901330848.914..  Test Loss: 4283547648.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4852604459.886..  Test Loss: 3999340544.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4769963168.914..  Test Loss: 4094969600.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4930678996.114..  Test Loss: 4108612864.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4773318122.057..  Test Loss: 4002993408.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4811567506.286..  Test Loss: 4044766464.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4836874254.629..  Test Loss: 4088029952.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4879288853.943..  Test Loss: 4055388928.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4801672118.857..  Test Loss: 4055307008.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4746598904.686..  Test Loss: 3973008128.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4889381712.457..  Test Loss: 3977092352.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4769403717.486..  Test Loss: 3934345984.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4780005449.143..  Test Loss: 3999715328.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4808524565.943..  Test Loss: 4047849216.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4829691794.286..  Test Loss: 3998501376.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4743939276.800..  Test Loss: 3920451584.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4779931596.800..  Test Loss: 3961219584.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4730294191.543..  Test Loss: 3929586176.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4757963146.971..  Test Loss: 4020156160.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4710931247.543..  Test Loss: 3959063808.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4760056744.229..  Test Loss: 3918967296.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4771215191.771..  Test Loss: 3941071360.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4840078716.343..  Test Loss: 3972707072.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4808855456.914..  Test Loss: 3942630144.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4863621617.371..  Test Loss: 3878275072.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4767350849.829..  Test Loss: 3897568512.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4720060255.086..  Test Loss: 3932393216.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4814512640.000..  Test Loss: 4016412672.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4794987388.343..  Test Loss: 3911744768.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4757785804.800..  Test Loss: 3908445952.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4695380648.229..  Test Loss: 3931899136.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4778431422.171..  Test Loss: 4027677184.000.. \n",
      "Epoch: 809/1000..  Training Loss: 4750405284.571..  Test Loss: 3940311808.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 810/1000..  Training Loss: 4813899242.057..  Test Loss: 3964653312.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4733367310.629..  Test Loss: 3904709120.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4669906746.514..  Test Loss: 4024268800.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4712437065.143..  Test Loss: 3908739840.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4704078467.657..  Test Loss: 3845638656.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4774092997.486..  Test Loss: 3911614464.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4689220714.057..  Test Loss: 3840020224.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4741322686.171..  Test Loss: 3837566976.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4783762358.857..  Test Loss: 3898118912.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4825590476.800..  Test Loss: 3855481344.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4920179079.314..  Test Loss: 3916801280.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4800452447.086..  Test Loss: 3902484480.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4732404779.886..  Test Loss: 3819923200.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4798319718.400..  Test Loss: 3948075008.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4794290775.771..  Test Loss: 3935641344.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4707389308.343..  Test Loss: 3962916864.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4778604017.371..  Test Loss: 3863466496.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4728936725.943..  Test Loss: 3853265408.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4824097843.200..  Test Loss: 3903431424.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4787937777.371..  Test Loss: 3896961024.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4750513792.000..  Test Loss: 3843550464.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4872480025.600..  Test Loss: 3929254400.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4736157637.486..  Test Loss: 3869901568.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4796992270.629..  Test Loss: 3845300992.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4854419170.743..  Test Loss: 3928732160.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4721543840.914..  Test Loss: 3816891648.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4731331569.371..  Test Loss: 3807770368.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4724416512.000..  Test Loss: 3882869504.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4780782635.886..  Test Loss: 3885088768.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4688351034.514..  Test Loss: 3874942976.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4700512146.286..  Test Loss: 3777990400.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4813680610.743..  Test Loss: 3912752896.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4840196754.286..  Test Loss: 3847567872.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4744138283.886..  Test Loss: 3877262080.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4700198070.857..  Test Loss: 3827962624.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4737184607.086..  Test Loss: 3874557952.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4749869933.714..  Test Loss: 4009128448.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4785835059.200..  Test Loss: 3836552960.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4731562452.114..  Test Loss: 3945590784.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4669695232.000..  Test Loss: 3771165184.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4707436763.429..  Test Loss: 3786352640.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4776110877.257..  Test Loss: 3843550464.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4703865702.400..  Test Loss: 3866415872.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4790137190.400..  Test Loss: 3913863936.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4714145590.857..  Test Loss: 3879449856.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4731451713.829..  Test Loss: 3811553024.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4681768316.343..  Test Loss: 3846875648.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4714711442.286..  Test Loss: 3852750080.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4749552409.600..  Test Loss: 3875405824.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4746660973.714..  Test Loss: 3932905984.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4781031424.000..  Test Loss: 3803147008.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4757102036.114..  Test Loss: 3759583744.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4815567038.171..  Test Loss: 3828058624.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4793536596.114..  Test Loss: 3764984576.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4750349421.714..  Test Loss: 3755110400.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4744142160.457..  Test Loss: 3761733376.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4707906413.714..  Test Loss: 3872040192.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4764735151.543..  Test Loss: 3777194496.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4693103996.343..  Test Loss: 3750988544.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4676937874.286..  Test Loss: 3842161920.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4719268534.857..  Test Loss: 3850883840.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4756442057.143..  Test Loss: 3835066880.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4745267836.343..  Test Loss: 3806630656.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4672827472.457..  Test Loss: 3827165696.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4660697475.657..  Test Loss: 3752996608.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4717241695.086..  Test Loss: 3856066560.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4682088546.743..  Test Loss: 3785004800.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4725212909.714..  Test Loss: 3744135936.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4706565690.514..  Test Loss: 4023399680.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4739622699.886..  Test Loss: 3829705216.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4711394311.314..  Test Loss: 3745462784.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4711271628.800..  Test Loss: 3803236096.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4750208672.914..  Test Loss: 3756978944.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4697670930.286..  Test Loss: 3757301504.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4704522477.714..  Test Loss: 3738103040.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4680920824.686..  Test Loss: 3851807232.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4743437059.657..  Test Loss: 3775718656.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4666924536.686..  Test Loss: 3895955200.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4791633912.686..  Test Loss: 3794932480.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4746014639.543..  Test Loss: 3784075264.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4719257011.200..  Test Loss: 3801994496.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4651896733.257..  Test Loss: 3805063936.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4688689510.400..  Test Loss: 3776359680.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4790550842.514..  Test Loss: 3810408960.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4785977051.429..  Test Loss: 3748528640.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4719003172.571..  Test Loss: 3739846400.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4690868772.571..  Test Loss: 3831986176.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4707099819.886..  Test Loss: 3891681792.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4686190061.714..  Test Loss: 3894135296.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4725189076.114..  Test Loss: 3723203072.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4802251724.800..  Test Loss: 3764383744.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4791359246.629..  Test Loss: 3838553856.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4677049943.771..  Test Loss: 3881448704.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4776536817.371..  Test Loss: 3783936512.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4710836962.743..  Test Loss: 3740082944.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4673351043.657..  Test Loss: 3778506752.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4774776232.229..  Test Loss: 3763625728.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4673728351.086..  Test Loss: 3815698944.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4746111619.657..  Test Loss: 3801336576.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4750621132.800..  Test Loss: 3773972992.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4770846800.457..  Test Loss: 3863449344.000.. \n",
      "Epoch: 911/1000..  Training Loss: 4756344846.629..  Test Loss: 3764124416.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 912/1000..  Training Loss: 4710324041.143..  Test Loss: 3756514048.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4673558703.543..  Test Loss: 3778316288.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4718587560.229..  Test Loss: 3868568064.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4819143753.143..  Test Loss: 3775479808.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4691478337.829..  Test Loss: 3871633408.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4729405842.286..  Test Loss: 3713640192.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4814014734.629..  Test Loss: 3748972544.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4732845238.857..  Test Loss: 3815357184.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4670567614.171..  Test Loss: 3852237568.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4792584396.800..  Test Loss: 3811974912.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4648534506.057..  Test Loss: 3805277952.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4681934423.771..  Test Loss: 3787614208.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4697669112.686..  Test Loss: 3706565888.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4782572587.886..  Test Loss: 3775406592.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4747220867.657..  Test Loss: 3701175552.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4660418479.543..  Test Loss: 3766183936.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4714351469.714..  Test Loss: 3745420032.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4801316805.486..  Test Loss: 3758718976.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4688159616.000..  Test Loss: 3747917056.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4701864908.800..  Test Loss: 3831529984.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4730951328.914..  Test Loss: 3747432448.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4700833484.800..  Test Loss: 3769895424.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4724310922.971..  Test Loss: 3778334720.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4728281600.000..  Test Loss: 3708701184.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4701864806.400..  Test Loss: 3758705152.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4705904003.657..  Test Loss: 3818338816.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4676685736.229..  Test Loss: 3770117376.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4677804690.286..  Test Loss: 3755403264.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4701663078.400..  Test Loss: 3720591104.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4702745782.857..  Test Loss: 3692113664.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4656454195.200..  Test Loss: 3721438976.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4719978510.629..  Test Loss: 3717773056.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4629853670.400..  Test Loss: 3759484672.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4716956262.400..  Test Loss: 3825751808.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4683241442.743..  Test Loss: 3761093888.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4708642720.914..  Test Loss: 3837366272.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4703749533.257..  Test Loss: 3844904192.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4657458190.629..  Test Loss: 3756900096.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4721141983.086..  Test Loss: 3870759680.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4707035904.000..  Test Loss: 3799062272.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4617233737.143..  Test Loss: 3793767680.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4651962404.571..  Test Loss: 3681940736.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4714854312.229..  Test Loss: 3816287488.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4720013121.829..  Test Loss: 3715101184.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4683091390.171..  Test Loss: 3756795648.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4830558054.400..  Test Loss: 3817431808.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4773185272.686..  Test Loss: 3712626688.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4681113998.629..  Test Loss: 3756040960.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4698212403.200..  Test Loss: 3877759744.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4663808533.943..  Test Loss: 3737935104.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4714276074.057..  Test Loss: 3712612864.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4693090647.771..  Test Loss: 3712058624.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4662088539.429..  Test Loss: 3871785472.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4770036992.000..  Test Loss: 3684683776.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4689675849.143..  Test Loss: 3771279104.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4676691229.257..  Test Loss: 3726907136.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4667119433.143..  Test Loss: 3755520512.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4722919336.229..  Test Loss: 3730663424.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4702340169.143..  Test Loss: 3708585984.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4788263409.371..  Test Loss: 3757796608.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4645810494.171..  Test Loss: 3781792256.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4708297354.971..  Test Loss: 3722394368.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4685121631.086..  Test Loss: 3759229696.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4681140889.600..  Test Loss: 3734422016.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4593120841.143..  Test Loss: 3801849088.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4764507194.514..  Test Loss: 3745990400.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4691644730.514..  Test Loss: 3790419712.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4686615427.657..  Test Loss: 3785431808.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4727535879.314..  Test Loss: 3691029248.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4665905225.143..  Test Loss: 3854460160.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4738286752.914..  Test Loss: 3721485056.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4681020796.343..  Test Loss: 3724359680.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4757157339.429..  Test Loss: 3790922496.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4786770366.171..  Test Loss: 3728839424.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4703449834.057..  Test Loss: 3790341376.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4706778371.657..  Test Loss: 3698275584.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4665313250.743..  Test Loss: 3734394624.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4666655005.257..  Test Loss: 3689738752.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4722721265.371..  Test Loss: 3750036224.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4670058656.914..  Test Loss: 3716732160.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4705582343.314..  Test Loss: 3680244480.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4701712405.943..  Test Loss: 3818531328.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4597672265.143..  Test Loss: 3780798208.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4738516458.057..  Test Loss: 3816030208.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4765743879.314..  Test Loss: 3699913472.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4635177903.543..  Test Loss: 3822830080.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4616511246.629..  Test Loss: 3722239744.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4703460798.171..  Test Loss: 3719352064.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4666033685.943..  Test Loss: 3784516864.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 1\n",
      "Epoch: 1/1000..  Training Loss: 13600880412.444..  Test Loss: 12165493760.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13605958030.222..  Test Loss: 12080370688.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13632243256.889..  Test Loss: 12133880832.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13585665251.556..  Test Loss: 12143233024.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13603674538.667..  Test Loss: 12064379904.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13627998862.222..  Test Loss: 12220929024.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13537611136.000..  Test Loss: 12042486784.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13822302293.333..  Test Loss: 12149075968.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13568410737.778..  Test Loss: 12197011456.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13620502400.000..  Test Loss: 12218357760.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13601096846.222..  Test Loss: 12326677504.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13634538780.444..  Test Loss: 12196365312.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13724295196.444..  Test Loss: 12264408064.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13748301468.444..  Test Loss: 12403028992.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13588649671.111..  Test Loss: 12127373312.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13551775104.000..  Test Loss: 12095722496.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13613148416.000..  Test Loss: 12099799040.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13693868714.667..  Test Loss: 12004853760.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13584593550.222..  Test Loss: 12129128448.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13597398840.889..  Test Loss: 12100361216.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13688591559.111..  Test Loss: 12223159296.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13537923896.889..  Test Loss: 12296875008.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13768818488.889..  Test Loss: 12021217280.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13562046378.667..  Test Loss: 12300621824.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13553168938.667..  Test Loss: 11913900032.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13572009272.889..  Test Loss: 11991664640.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13520596736.000..  Test Loss: 12076449792.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13523871175.111..  Test Loss: 12038852608.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13606058865.778..  Test Loss: 12233095168.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13550906311.111..  Test Loss: 11923244032.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13563358606.222..  Test Loss: 12087832576.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13529459740.444..  Test Loss: 12073006080.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13626221368.889..  Test Loss: 12126548992.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13584055025.778..  Test Loss: 12124522496.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13585682090.667..  Test Loss: 12209436672.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13497479139.556..  Test Loss: 12052506624.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13508789390.222..  Test Loss: 12218219520.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13517080888.889..  Test Loss: 12222753792.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13503180600.889..  Test Loss: 11934035968.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13596575317.333..  Test Loss: 11945112576.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13517679445.333..  Test Loss: 12215406592.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13523422037.333..  Test Loss: 12096873472.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13466281699.556..  Test Loss: 11958709248.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13466192810.667..  Test Loss: 12141594624.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13562913820.444..  Test Loss: 12058611712.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13465313621.333..  Test Loss: 11950436352.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13443383722.667..  Test Loss: 12157528064.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13510645802.667..  Test Loss: 12436016128.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13383765660.444..  Test Loss: 11970136064.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13495406378.667..  Test Loss: 12103840768.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13403274766.222..  Test Loss: 12052907008.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13455033173.333..  Test Loss: 12110083072.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13444845454.222..  Test Loss: 12189070336.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13480298097.778..  Test Loss: 12095736832.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13486691825.778..  Test Loss: 12196619264.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13383811712.000..  Test Loss: 11916139520.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13494472021.333..  Test Loss: 11920032768.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13443849187.556..  Test Loss: 12044033024.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13482555192.889..  Test Loss: 11978199040.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13466592142.222..  Test Loss: 12089601024.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13387374222.222..  Test Loss: 11851084800.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13400849024.000..  Test Loss: 12053368832.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13325484686.222..  Test Loss: 11989208064.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13326269838.222..  Test Loss: 11827083264.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13324515584.000..  Test Loss: 11969398784.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13366671189.333..  Test Loss: 11817145344.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13292229148.444..  Test Loss: 11819841536.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13301724330.667..  Test Loss: 11807634432.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13313378944.000..  Test Loss: 12008506368.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13289307392.000..  Test Loss: 11986492416.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13323065116.444..  Test Loss: 11765498880.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13326123178.667..  Test Loss: 11789212672.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13391595889.778..  Test Loss: 11842581504.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13403229667.556..  Test Loss: 11878795264.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13283185507.556..  Test Loss: 11760401408.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13248097422.222..  Test Loss: 12169458688.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13272501546.667..  Test Loss: 11795607552.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13352721152.000..  Test Loss: 11911570432.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13322334208.000..  Test Loss: 11678980096.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13244625464.889..  Test Loss: 11814257664.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13274293888.000..  Test Loss: 11682975744.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13167343317.333..  Test Loss: 11713582080.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13252183424.000..  Test Loss: 11789864960.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13202905429.333..  Test Loss: 11830110208.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13169088384.000..  Test Loss: 11711185920.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13195660088.889..  Test Loss: 11928396800.000.. \n",
      "Epoch: 87/1000..  Training Loss: 13118693646.222..  Test Loss: 11778607104.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13233765219.556..  Test Loss: 11793602560.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13156482275.556..  Test Loss: 11689347072.000.. \n",
      "Epoch: 90/1000..  Training Loss: 13143818638.222..  Test Loss: 11849620480.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13251652323.556..  Test Loss: 11665494016.000.. \n",
      "Epoch: 92/1000..  Training Loss: 13110703217.778..  Test Loss: 11653412864.000.. \n",
      "Epoch: 93/1000..  Training Loss: 13158934044.444..  Test Loss: 11560367104.000.. \n",
      "Epoch: 94/1000..  Training Loss: 13089616184.889..  Test Loss: 11772346368.000.. \n",
      "Epoch: 95/1000..  Training Loss: 13090646328.889..  Test Loss: 11576146944.000.. \n",
      "Epoch: 96/1000..  Training Loss: 13071796963.556..  Test Loss: 11773214720.000.. \n",
      "Epoch: 97/1000..  Training Loss: 13233503943.111..  Test Loss: 11568376832.000.. \n",
      "Epoch: 98/1000..  Training Loss: 13057094300.444..  Test Loss: 11709718528.000.. \n",
      "Epoch: 99/1000..  Training Loss: 13107823928.889..  Test Loss: 11677463552.000.. \n",
      "Epoch: 100/1000..  Training Loss: 13057731370.667..  Test Loss: 11578599424.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000..  Training Loss: 13023824839.111..  Test Loss: 11711730688.000.. \n",
      "Epoch: 102/1000..  Training Loss: 13110788408.889..  Test Loss: 11560692736.000.. \n",
      "Epoch: 103/1000..  Training Loss: 13062427306.667..  Test Loss: 11462097920.000.. \n",
      "Epoch: 104/1000..  Training Loss: 13076913351.111..  Test Loss: 11831738368.000.. \n",
      "Epoch: 105/1000..  Training Loss: 13040217685.333..  Test Loss: 11697682432.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12977673329.778..  Test Loss: 11707332608.000.. \n",
      "Epoch: 107/1000..  Training Loss: 13113672618.667..  Test Loss: 11737842688.000.. \n",
      "Epoch: 108/1000..  Training Loss: 13097815651.556..  Test Loss: 11606021120.000.. \n",
      "Epoch: 109/1000..  Training Loss: 13008136590.222..  Test Loss: 11883378688.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12990857713.778..  Test Loss: 11660499968.000.. \n",
      "Epoch: 111/1000..  Training Loss: 13002595143.111..  Test Loss: 11580322816.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12950963114.667..  Test Loss: 11690224640.000.. \n",
      "Epoch: 113/1000..  Training Loss: 13017533966.222..  Test Loss: 11570814976.000.. \n",
      "Epoch: 114/1000..  Training Loss: 13012124131.556..  Test Loss: 11394365440.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12929465201.778..  Test Loss: 11624133632.000.. \n",
      "Epoch: 116/1000..  Training Loss: 13045775985.778..  Test Loss: 11486671872.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12927423288.889..  Test Loss: 11799723008.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12891033372.444..  Test Loss: 11571833856.000.. \n",
      "Epoch: 119/1000..  Training Loss: 12946286250.667..  Test Loss: 11511139328.000.. \n",
      "Epoch: 120/1000..  Training Loss: 12816958264.889..  Test Loss: 11423289344.000.. \n",
      "Epoch: 121/1000..  Training Loss: 12996414122.667..  Test Loss: 11445583872.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12803097088.000..  Test Loss: 11491137536.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12855614848.000..  Test Loss: 11427096576.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12794971448.889..  Test Loss: 11396833280.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12794298225.778..  Test Loss: 11580535808.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12842198016.000..  Test Loss: 11268214784.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12795475242.667..  Test Loss: 11516253184.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12785481927.111..  Test Loss: 11745934336.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12747895907.556..  Test Loss: 11373109248.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12936701994.667..  Test Loss: 11272614912.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12761699185.778..  Test Loss: 11351655424.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12791716394.667..  Test Loss: 11352295424.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12770654321.778..  Test Loss: 11329243136.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12741734812.444..  Test Loss: 11553211392.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12703407274.667..  Test Loss: 11566773248.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12722031473.778..  Test Loss: 11260865536.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12651378872.889..  Test Loss: 11279556608.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12644609592.889..  Test Loss: 11604744192.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12612796231.111..  Test Loss: 11160975360.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12751310051.556..  Test Loss: 11294657536.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12670548181.333..  Test Loss: 11262470144.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12579763939.556..  Test Loss: 11082404864.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12703022506.667..  Test Loss: 11288619008.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12532750080.000..  Test Loss: 11359547392.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12669647118.222..  Test Loss: 11189908480.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12590444373.333..  Test Loss: 11326121984.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12582406983.111..  Test Loss: 11330663424.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12503851320.889..  Test Loss: 11186703360.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12518589994.667..  Test Loss: 11053061120.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12531936682.667..  Test Loss: 11160508416.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12646473429.333..  Test Loss: 11009628160.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12538160981.333..  Test Loss: 11255252992.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12563987143.111..  Test Loss: 11228013568.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12500460970.667..  Test Loss: 11263128576.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12491983288.889..  Test Loss: 11078405120.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12501655438.222..  Test Loss: 10947718144.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12483452330.667..  Test Loss: 11143205888.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12424570595.556..  Test Loss: 10970244096.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12510855793.778..  Test Loss: 11023947776.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12414593024.000..  Test Loss: 11049262080.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12419113557.333..  Test Loss: 11071493120.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12509693013.333..  Test Loss: 11091390464.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12413226865.778..  Test Loss: 10892348416.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12427874915.556..  Test Loss: 11184446464.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12314359537.778..  Test Loss: 10921310208.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12597600938.667..  Test Loss: 11011215360.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12333867548.444..  Test Loss: 10969588736.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12351994240.000..  Test Loss: 10980407296.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12280008746.667..  Test Loss: 11104305152.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12296345671.111..  Test Loss: 10898857984.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12333757184.000..  Test Loss: 10794459136.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12323538702.222..  Test Loss: 10884966400.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12297548032.000..  Test Loss: 10826825728.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12222843932.444..  Test Loss: 10946179072.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12258653411.556..  Test Loss: 11054356480.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12195341155.556..  Test Loss: 10854005760.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12173656419.556..  Test Loss: 10778785792.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12239464135.111..  Test Loss: 10886215680.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12148736426.667..  Test Loss: 10883335168.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12196395306.667..  Test Loss: 10934724608.000.. \n",
      "Epoch: 181/1000..  Training Loss: 12166406712.889..  Test Loss: 10906767360.000.. \n",
      "Epoch: 182/1000..  Training Loss: 12155112988.444..  Test Loss: 11019016192.000.. \n",
      "Epoch: 183/1000..  Training Loss: 12116697543.111..  Test Loss: 10753433600.000.. \n",
      "Epoch: 184/1000..  Training Loss: 12093160320.000..  Test Loss: 10794121216.000.. \n",
      "Epoch: 185/1000..  Training Loss: 12231349347.556..  Test Loss: 10750700544.000.. \n",
      "Epoch: 186/1000..  Training Loss: 12087017500.444..  Test Loss: 10876106752.000.. \n",
      "Epoch: 187/1000..  Training Loss: 12114388238.222..  Test Loss: 10904761344.000.. \n",
      "Epoch: 188/1000..  Training Loss: 12092158563.556..  Test Loss: 10727314432.000.. \n",
      "Epoch: 189/1000..  Training Loss: 12082287118.222..  Test Loss: 10623919104.000.. \n",
      "Epoch: 190/1000..  Training Loss: 12170518101.333..  Test Loss: 10929234944.000.. \n",
      "Epoch: 191/1000..  Training Loss: 12100284928.000..  Test Loss: 10733010944.000.. \n",
      "Epoch: 192/1000..  Training Loss: 12090726314.667..  Test Loss: 10991646720.000.. \n",
      "Epoch: 193/1000..  Training Loss: 12024513422.222..  Test Loss: 10554022912.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11963958343.111..  Test Loss: 10595326976.000.. \n",
      "Epoch: 195/1000..  Training Loss: 12012756010.667..  Test Loss: 10598132736.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11910017692.444..  Test Loss: 10684414976.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11912595043.556..  Test Loss: 10403728384.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11949894499.556..  Test Loss: 10623720448.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11970463459.556..  Test Loss: 10703109120.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200/1000..  Training Loss: 12009304007.111..  Test Loss: 10601061376.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11849976888.889..  Test Loss: 10725348352.000.. \n",
      "Epoch: 202/1000..  Training Loss: 12039452117.333..  Test Loss: 10553996288.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11823470094.222..  Test Loss: 10601222144.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11874536334.222..  Test Loss: 10428650496.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11864881208.889..  Test Loss: 10511533056.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11783902776.889..  Test Loss: 10728938496.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11759823018.667..  Test Loss: 10487275520.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11819719665.778..  Test Loss: 10402174976.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11741138773.333..  Test Loss: 10264163328.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11785053482.667..  Test Loss: 10378334208.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11746766620.444..  Test Loss: 10427358208.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11717412224.000..  Test Loss: 10578876416.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11870326826.667..  Test Loss: 10469962752.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11708422755.556..  Test Loss: 10326815744.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11741125290.667..  Test Loss: 10466808832.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11729970872.889..  Test Loss: 10496525312.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11726634154.667..  Test Loss: 10250847232.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11640956501.333..  Test Loss: 10274518016.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11659844536.889..  Test Loss: 10171241472.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11645635000.889..  Test Loss: 10205330432.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11568511061.333..  Test Loss: 10234268672.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11766403697.778..  Test Loss: 10180523008.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11526925724.444..  Test Loss: 10425710592.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11658842979.556..  Test Loss: 10262393856.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11546496270.222..  Test Loss: 10240314368.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11633395285.333..  Test Loss: 10210633728.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11536254634.667..  Test Loss: 10310964224.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11526101105.778..  Test Loss: 10213326848.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11452270990.222..  Test Loss: 10288637952.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11479648896.000..  Test Loss: 10158356480.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11546052067.556..  Test Loss: 10115227648.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11586159687.111..  Test Loss: 10411013120.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11560067882.667..  Test Loss: 10206876672.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11485191338.667..  Test Loss: 10142528512.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11440383729.778..  Test Loss: 10018237440.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11434031872.000..  Test Loss: 10247429120.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11395295729.778..  Test Loss: 10039371776.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11419673742.222..  Test Loss: 9904886784.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11320143516.444..  Test Loss: 9991541760.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11330771313.778..  Test Loss: 10139469824.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11330045482.667..  Test Loss: 10206225408.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11344798776.889..  Test Loss: 9953767424.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11342523889.778..  Test Loss: 9915063296.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11339037525.333..  Test Loss: 10080077824.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11434488775.111..  Test Loss: 9889286144.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11317079566.222..  Test Loss: 10012770304.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11267736917.333..  Test Loss: 9993100288.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11211313351.111..  Test Loss: 9879982080.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11208956216.889..  Test Loss: 9763732480.000.. \n",
      "Epoch: 250/1000..  Training Loss: 11176425856.000..  Test Loss: 9879132160.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11162752256.000..  Test Loss: 9880276992.000.. \n",
      "Epoch: 252/1000..  Training Loss: 11113950592.000..  Test Loss: 10078258176.000.. \n",
      "Epoch: 253/1000..  Training Loss: 11079516999.111..  Test Loss: 9978744832.000.. \n",
      "Epoch: 254/1000..  Training Loss: 11270848213.333..  Test Loss: 9719357440.000.. \n",
      "Epoch: 255/1000..  Training Loss: 11155008312.889..  Test Loss: 9809779712.000.. \n",
      "Epoch: 256/1000..  Training Loss: 11077896149.333..  Test Loss: 9858083840.000.. \n",
      "Epoch: 257/1000..  Training Loss: 11077226396.444..  Test Loss: 9595780096.000.. \n",
      "Epoch: 258/1000..  Training Loss: 11078638222.222..  Test Loss: 9871246336.000.. \n",
      "Epoch: 259/1000..  Training Loss: 11050485489.778..  Test Loss: 9946981376.000.. \n",
      "Epoch: 260/1000..  Training Loss: 11031299598.222..  Test Loss: 9737201664.000.. \n",
      "Epoch: 261/1000..  Training Loss: 11136442083.556..  Test Loss: 9519455232.000.. \n",
      "Epoch: 262/1000..  Training Loss: 11032408988.444..  Test Loss: 9723545600.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10934450872.889..  Test Loss: 9710263296.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10964095957.333..  Test Loss: 9662475264.000.. \n",
      "Epoch: 265/1000..  Training Loss: 11086843392.000..  Test Loss: 9734107136.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10871890844.444..  Test Loss: 9622411264.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10898598513.778..  Test Loss: 9997289472.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10931904327.111..  Test Loss: 9558612992.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10977290638.222..  Test Loss: 9409181696.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10889345991.111..  Test Loss: 9718594560.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10930319900.444..  Test Loss: 9550791680.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10841446698.667..  Test Loss: 9528961024.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10769668451.556..  Test Loss: 9591330816.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10882647523.556..  Test Loss: 9542924288.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10726785920.000..  Test Loss: 9400017920.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10769172224.000..  Test Loss: 9524967424.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10809001358.222..  Test Loss: 9434312704.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10776940956.444..  Test Loss: 9550999552.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10940649585.778..  Test Loss: 9508964352.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10711167374.222..  Test Loss: 9353060352.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10701096704.000..  Test Loss: 9357387776.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10626235975.111..  Test Loss: 9359725568.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10616426311.111..  Test Loss: 9321583616.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10654710741.333..  Test Loss: 9219753984.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10581130240.000..  Test Loss: 9221935104.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10638573198.222..  Test Loss: 9278755840.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10657116814.222..  Test Loss: 9339182080.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10542989852.444..  Test Loss: 9453317120.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10581511879.111..  Test Loss: 9252644864.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10611100401.778..  Test Loss: 9149154304.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10563930197.333..  Test Loss: 9252082688.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10515593799.111..  Test Loss: 9179286528.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10452380814.222..  Test Loss: 9192017920.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10491660970.667..  Test Loss: 9132592128.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10478288995.556..  Test Loss: 9275008000.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10415946424.889..  Test Loss: 9214102528.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10460972913.778..  Test Loss: 9333313536.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10414902542.222..  Test Loss: 9282167808.000.. \n",
      "Epoch: 299/1000..  Training Loss: 10363218872.889..  Test Loss: 9248297984.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300/1000..  Training Loss: 10381097685.333..  Test Loss: 9131769856.000.. \n",
      "Epoch: 301/1000..  Training Loss: 10374792561.778..  Test Loss: 9029889024.000.. \n",
      "Epoch: 302/1000..  Training Loss: 10377482382.222..  Test Loss: 9022635008.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10249483861.333..  Test Loss: 9049913344.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10387804515.556..  Test Loss: 9138359296.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10252184988.444..  Test Loss: 8877074432.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10331666645.333..  Test Loss: 9134741504.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10244563697.778..  Test Loss: 8926314496.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10256357361.778..  Test Loss: 9314504704.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10303175751.111..  Test Loss: 8833281024.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10293051790.222..  Test Loss: 8969296896.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10193309724.444..  Test Loss: 8888432640.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10195742080.000..  Test Loss: 9044386816.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10106677760.000..  Test Loss: 8854292480.000.. \n",
      "Epoch: 314/1000..  Training Loss: 10168563527.111..  Test Loss: 8934822912.000.. \n",
      "Epoch: 315/1000..  Training Loss: 10252201870.222..  Test Loss: 9031648256.000.. \n",
      "Epoch: 316/1000..  Training Loss: 10096665976.889..  Test Loss: 9011574784.000.. \n",
      "Epoch: 317/1000..  Training Loss: 10010222236.444..  Test Loss: 8875785216.000.. \n",
      "Epoch: 318/1000..  Training Loss: 10112690773.333..  Test Loss: 8818709504.000.. \n",
      "Epoch: 319/1000..  Training Loss: 10060447729.778..  Test Loss: 8953866240.000.. \n",
      "Epoch: 320/1000..  Training Loss: 10120170481.778..  Test Loss: 8857210880.000.. \n",
      "Epoch: 321/1000..  Training Loss: 10032782876.444..  Test Loss: 8685114368.000.. \n",
      "Epoch: 322/1000..  Training Loss: 10079065315.556..  Test Loss: 8830145536.000.. \n",
      "Epoch: 323/1000..  Training Loss: 10104763178.667..  Test Loss: 8792889344.000.. \n",
      "Epoch: 324/1000..  Training Loss: 10071761536.000..  Test Loss: 8867372032.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9945742136.889..  Test Loss: 8797609984.000.. \n",
      "Epoch: 326/1000..  Training Loss: 10078709134.222..  Test Loss: 8739171328.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9892322424.889..  Test Loss: 8794956800.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9897606414.222..  Test Loss: 8499297280.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9895776711.111..  Test Loss: 8706941952.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9949999530.667..  Test Loss: 8675358720.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9929415480.889..  Test Loss: 8642108416.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9892129095.111..  Test Loss: 8597472256.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9809640206.222..  Test Loss: 8606919680.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9790269639.111..  Test Loss: 8522557952.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9807121393.778..  Test Loss: 8521087488.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9803597425.778..  Test Loss: 8673955840.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9776581831.111..  Test Loss: 8525268992.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9698858026.667..  Test Loss: 8508004864.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9656216789.333..  Test Loss: 8589810688.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9665822805.333..  Test Loss: 8434471424.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9836423424.000..  Test Loss: 8600708096.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9660708949.333..  Test Loss: 8385133568.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9757835434.667..  Test Loss: 8314373120.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9704989212.444..  Test Loss: 8532504064.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9680396672.000..  Test Loss: 8311516672.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9640293788.444..  Test Loss: 8303067136.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9552134968.889..  Test Loss: 8378400768.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9593461134.222..  Test Loss: 8314448384.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9597319765.333..  Test Loss: 8192990208.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9564374229.333..  Test Loss: 8211012608.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9634147825.778..  Test Loss: 8584638976.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9604263651.556..  Test Loss: 8284697088.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9489465827.556..  Test Loss: 8161233408.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9491120568.889..  Test Loss: 8271684608.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9485979847.111..  Test Loss: 8066574848.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9627136042.667..  Test Loss: 7964211712.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9379461290.667..  Test Loss: 8221468672.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9415154560.000..  Test Loss: 8392163328.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9447330858.667..  Test Loss: 8065939968.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9543842830.222..  Test Loss: 8168072192.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9324807722.667..  Test Loss: 8087368192.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9347517141.333..  Test Loss: 8185817088.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9417780636.444..  Test Loss: 8027064832.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9350062136.889..  Test Loss: 7965526528.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9332991488.000..  Test Loss: 8156768768.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9332218040.889..  Test Loss: 8091575296.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9286017450.667..  Test Loss: 7918572032.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9309463011.556..  Test Loss: 7962542080.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9163917966.222..  Test Loss: 8085191680.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9204970360.889..  Test Loss: 8073255424.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9185878328.889..  Test Loss: 7934844928.000.. \n",
      "Epoch: 372/1000..  Training Loss: 9247411157.333..  Test Loss: 8096633344.000.. \n",
      "Epoch: 373/1000..  Training Loss: 9215364963.556..  Test Loss: 8009866240.000.. \n",
      "Epoch: 374/1000..  Training Loss: 9169144206.222..  Test Loss: 7949302784.000.. \n",
      "Epoch: 375/1000..  Training Loss: 9171252480.000..  Test Loss: 7891651072.000.. \n",
      "Epoch: 376/1000..  Training Loss: 9140659313.778..  Test Loss: 7848806912.000.. \n",
      "Epoch: 377/1000..  Training Loss: 9139721827.556..  Test Loss: 8092636672.000.. \n",
      "Epoch: 378/1000..  Training Loss: 9190932195.556..  Test Loss: 7916850688.000.. \n",
      "Epoch: 379/1000..  Training Loss: 9088685632.000..  Test Loss: 7916510208.000.. \n",
      "Epoch: 380/1000..  Training Loss: 9119825358.222..  Test Loss: 8015324160.000.. \n",
      "Epoch: 381/1000..  Training Loss: 9081453511.111..  Test Loss: 7814192128.000.. \n",
      "Epoch: 382/1000..  Training Loss: 9094877169.778..  Test Loss: 7793002496.000.. \n",
      "Epoch: 383/1000..  Training Loss: 9041967175.111..  Test Loss: 7840138240.000.. \n",
      "Epoch: 384/1000..  Training Loss: 9043472426.667..  Test Loss: 7716157952.000.. \n",
      "Epoch: 385/1000..  Training Loss: 9072530887.111..  Test Loss: 7972273152.000.. \n",
      "Epoch: 386/1000..  Training Loss: 9021416632.889..  Test Loss: 7775201792.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8931104896.000..  Test Loss: 7789476864.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8874291840.000..  Test Loss: 7798558208.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8848524977.778..  Test Loss: 7718057472.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8909066296.889..  Test Loss: 7645065728.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8861619285.333..  Test Loss: 7657047040.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8880758385.778..  Test Loss: 7631654400.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8962205169.778..  Test Loss: 7491418112.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8860724053.333..  Test Loss: 7597138944.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8790957539.556..  Test Loss: 7760291840.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8820371128.889..  Test Loss: 7396339712.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8867277283.556..  Test Loss: 7566678528.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8773090944.000..  Test Loss: 7452161024.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8861899847.111..  Test Loss: 7606263808.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8689971612.444..  Test Loss: 7527475712.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 401/1000..  Training Loss: 8752931911.111..  Test Loss: 7471928832.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8730509112.889..  Test Loss: 7634611712.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8584945550.222..  Test Loss: 7494944256.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8627670812.444..  Test Loss: 7272616960.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8611667854.222..  Test Loss: 7474271744.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8630898218.667..  Test Loss: 7587138560.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8695039559.111..  Test Loss: 7329415168.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8589191552.000..  Test Loss: 7484285952.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8705562837.333..  Test Loss: 7623101952.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8502031822.222..  Test Loss: 7543689216.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8549693553.778..  Test Loss: 7374986752.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8531677930.667..  Test Loss: 7267517440.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8555598961.778..  Test Loss: 7295587840.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8550011320.889..  Test Loss: 7358741504.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8428460835.556..  Test Loss: 7345667072.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8542281230.222..  Test Loss: 7459989504.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8453799623.111..  Test Loss: 7417741824.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8417387527.111..  Test Loss: 7516068864.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8347300010.667..  Test Loss: 7114792448.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8383831516.444..  Test Loss: 7270296064.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8497832483.556..  Test Loss: 7268696576.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8388776007.111..  Test Loss: 7176930304.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8253082972.444..  Test Loss: 7230850560.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8362513806.222..  Test Loss: 7326255616.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8455825066.667..  Test Loss: 7333721088.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8352796935.111..  Test Loss: 7018386432.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8296089457.778..  Test Loss: 7012443136.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8281010033.778..  Test Loss: 7033482240.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8232379975.111..  Test Loss: 6972894720.000.. \n",
      "Epoch: 430/1000..  Training Loss: 8318298055.111..  Test Loss: 7101315584.000.. \n",
      "Epoch: 431/1000..  Training Loss: 8290581966.222..  Test Loss: 7161526784.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8279519772.444..  Test Loss: 7097044480.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8104222620.444..  Test Loss: 7052028416.000.. \n",
      "Epoch: 434/1000..  Training Loss: 8114320042.667..  Test Loss: 6982716416.000.. \n",
      "Epoch: 435/1000..  Training Loss: 8183947264.000..  Test Loss: 6916918784.000.. \n",
      "Epoch: 436/1000..  Training Loss: 8219406890.667..  Test Loss: 6850454016.000.. \n",
      "Epoch: 437/1000..  Training Loss: 8109793507.556..  Test Loss: 7037464064.000.. \n",
      "Epoch: 438/1000..  Training Loss: 8202223928.889..  Test Loss: 6949222912.000.. \n",
      "Epoch: 439/1000..  Training Loss: 8120406769.778..  Test Loss: 6814480384.000.. \n",
      "Epoch: 440/1000..  Training Loss: 7998265059.556..  Test Loss: 6856812032.000.. \n",
      "Epoch: 441/1000..  Training Loss: 8144632903.111..  Test Loss: 6814291456.000.. \n",
      "Epoch: 442/1000..  Training Loss: 8099164643.556..  Test Loss: 7013003776.000.. \n",
      "Epoch: 443/1000..  Training Loss: 8004596423.111..  Test Loss: 6884108800.000.. \n",
      "Epoch: 444/1000..  Training Loss: 8016637269.333..  Test Loss: 6872569344.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7958804423.111..  Test Loss: 6908103680.000.. \n",
      "Epoch: 446/1000..  Training Loss: 8022584817.778..  Test Loss: 6817545728.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7973395612.444..  Test Loss: 7108532736.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7880781824.000..  Test Loss: 6782335488.000.. \n",
      "Epoch: 449/1000..  Training Loss: 8037353479.111..  Test Loss: 6795133440.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7881811313.778..  Test Loss: 6750692352.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7868719459.556..  Test Loss: 6857201152.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7904546638.222..  Test Loss: 6736861696.000.. \n",
      "Epoch: 453/1000..  Training Loss: 7853787441.778..  Test Loss: 6702579712.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7893854968.889..  Test Loss: 6568188416.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7839872135.111..  Test Loss: 6678337024.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7986266382.222..  Test Loss: 6800233472.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7877632312.889..  Test Loss: 6546822144.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7857186026.667..  Test Loss: 6733072384.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7763333824.000..  Test Loss: 6586311168.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7739613240.889..  Test Loss: 6458391552.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7687726065.778..  Test Loss: 6568889344.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7704539271.111..  Test Loss: 6532930048.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7730715875.556..  Test Loss: 6674205696.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7686470976.000..  Test Loss: 6647074304.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7629440042.667..  Test Loss: 6618886656.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7639757959.111..  Test Loss: 6413137408.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7627545742.222..  Test Loss: 6580063744.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7755186040.889..  Test Loss: 6547876352.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7671484707.556..  Test Loss: 6650225152.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7642470919.111..  Test Loss: 6341429248.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7676295495.111..  Test Loss: 6356022784.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7517181717.333..  Test Loss: 6435128320.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7575041024.000..  Test Loss: 6451808256.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7551968967.111..  Test Loss: 6459670528.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7491764252.444..  Test Loss: 6344802304.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7593185550.222..  Test Loss: 6419445248.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7480717845.333..  Test Loss: 6380762112.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7459595477.333..  Test Loss: 6284798464.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7551699242.667..  Test Loss: 6523614720.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7457905393.778..  Test Loss: 6188115968.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7503152248.889..  Test Loss: 6346279424.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7443100593.778..  Test Loss: 6307886080.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7477887338.667..  Test Loss: 6477838848.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7502331050.667..  Test Loss: 6224777216.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7394200874.667..  Test Loss: 6266743296.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7318192455.111..  Test Loss: 6521601536.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7339270101.333..  Test Loss: 6142267392.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7270996963.556..  Test Loss: 6047377408.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7318580352.000..  Test Loss: 6415798784.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7311101340.444..  Test Loss: 6169860608.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7235427392.000..  Test Loss: 6180706304.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7253821127.111..  Test Loss: 6114501632.000.. \n",
      "Epoch: 493/1000..  Training Loss: 7233332181.333..  Test Loss: 6129668096.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7264500501.333..  Test Loss: 6094815744.000.. \n",
      "Epoch: 495/1000..  Training Loss: 7247694392.889..  Test Loss: 6278275072.000.. \n",
      "Epoch: 496/1000..  Training Loss: 7219654784.000..  Test Loss: 6172614656.000.. \n",
      "Epoch: 497/1000..  Training Loss: 7121150072.889..  Test Loss: 6015603200.000.. \n",
      "Epoch: 498/1000..  Training Loss: 7190874474.667..  Test Loss: 6009812480.000.. \n",
      "Epoch: 499/1000..  Training Loss: 7233076664.889..  Test Loss: 6165809152.000.. \n",
      "Epoch: 500/1000..  Training Loss: 7068001763.556..  Test Loss: 5966587392.000.. \n",
      "Epoch: 501/1000..  Training Loss: 7162472440.889..  Test Loss: 6076332544.000.. \n",
      "Epoch: 502/1000..  Training Loss: 7162293105.778..  Test Loss: 6065191424.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 503/1000..  Training Loss: 7093000718.222..  Test Loss: 6193806848.000.. \n",
      "Epoch: 504/1000..  Training Loss: 7054320120.889..  Test Loss: 6017048576.000.. \n",
      "Epoch: 505/1000..  Training Loss: 7076282232.889..  Test Loss: 5910601216.000.. \n",
      "Epoch: 506/1000..  Training Loss: 7083029646.222..  Test Loss: 5861331968.000.. \n",
      "Epoch: 507/1000..  Training Loss: 7162598954.667..  Test Loss: 5940743168.000.. \n",
      "Epoch: 508/1000..  Training Loss: 7034333063.111..  Test Loss: 5795236864.000.. \n",
      "Epoch: 509/1000..  Training Loss: 6984744192.000..  Test Loss: 6149834240.000.. \n",
      "Epoch: 510/1000..  Training Loss: 7020909048.889..  Test Loss: 5839221248.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6971650304.000..  Test Loss: 5863308800.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6883930837.333..  Test Loss: 5992151552.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6987270741.333..  Test Loss: 5942361600.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6926853098.667..  Test Loss: 5835471360.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6923827356.444..  Test Loss: 5689497088.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6962707114.667..  Test Loss: 5849168384.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6833875669.333..  Test Loss: 5884230144.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6863299598.222..  Test Loss: 5784756736.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6926568284.444..  Test Loss: 5756424704.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6890219626.667..  Test Loss: 5947864064.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6762226545.778..  Test Loss: 5897043456.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6814839630.222..  Test Loss: 5772388352.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6730218275.556..  Test Loss: 5847434240.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6664235470.222..  Test Loss: 5870018048.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6739297642.667..  Test Loss: 5726454272.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6746594737.778..  Test Loss: 5825865216.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6670635292.444..  Test Loss: 5599838208.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6637055224.889..  Test Loss: 5838616576.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6751044721.778..  Test Loss: 5652182016.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6742468515.556..  Test Loss: 5716102144.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6576377792.000..  Test Loss: 5710944768.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6673948401.778..  Test Loss: 6006739968.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6569189546.667..  Test Loss: 5597536256.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6607013212.444..  Test Loss: 5655673344.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6826587278.222..  Test Loss: 5629867520.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6655067626.667..  Test Loss: 5574476800.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6544884608.000..  Test Loss: 5572596736.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6505011100.444..  Test Loss: 5547580928.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6491681692.444..  Test Loss: 5780894720.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6544969642.667..  Test Loss: 5426212864.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6453865557.333..  Test Loss: 5592461312.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6424543822.222..  Test Loss: 5547507712.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6471244586.667..  Test Loss: 5429185024.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6542819292.444..  Test Loss: 5476858368.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6471140316.444..  Test Loss: 5505020928.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6461792597.333..  Test Loss: 5464867328.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6428093696.000..  Test Loss: 5499893248.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6430847516.444..  Test Loss: 5365122048.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6489208618.667..  Test Loss: 5471019008.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6404734791.111..  Test Loss: 5462387200.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6518034531.556..  Test Loss: 5354015744.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6311656938.667..  Test Loss: 5243065856.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6348561898.667..  Test Loss: 5363607040.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6296999502.222..  Test Loss: 5568626176.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6300356309.333..  Test Loss: 5374097408.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6231271452.444..  Test Loss: 5243342848.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6291515441.778..  Test Loss: 5236574208.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6283845703.111..  Test Loss: 5229808128.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6257979925.333..  Test Loss: 5270589440.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6415276067.556..  Test Loss: 5233128960.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6260067854.222..  Test Loss: 5236954624.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6216529962.667..  Test Loss: 5359282176.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6212918890.667..  Test Loss: 5419806208.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6193492440.889..  Test Loss: 5140929024.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6087337866.667..  Test Loss: 5146773504.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6179708416.000..  Test Loss: 5217913856.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6201381802.667..  Test Loss: 5110281728.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6223190464.000..  Test Loss: 5189658112.000.. \n",
      "Epoch: 569/1000..  Training Loss: 6113491889.778..  Test Loss: 5061102592.000.. \n",
      "Epoch: 570/1000..  Training Loss: 6231433592.889..  Test Loss: 5101661184.000.. \n",
      "Epoch: 571/1000..  Training Loss: 6170877724.444..  Test Loss: 5114475520.000.. \n",
      "Epoch: 572/1000..  Training Loss: 6130181788.444..  Test Loss: 5026966016.000.. \n",
      "Epoch: 573/1000..  Training Loss: 6211344085.333..  Test Loss: 5129670144.000.. \n",
      "Epoch: 574/1000..  Training Loss: 6070888000.000..  Test Loss: 5012049920.000.. \n",
      "Epoch: 575/1000..  Training Loss: 6125288085.333..  Test Loss: 5007210496.000.. \n",
      "Epoch: 576/1000..  Training Loss: 6130158272.000..  Test Loss: 5167270400.000.. \n",
      "Epoch: 577/1000..  Training Loss: 6069157880.889..  Test Loss: 5189766656.000.. \n",
      "Epoch: 578/1000..  Training Loss: 6017574577.778..  Test Loss: 4998976512.000.. \n",
      "Epoch: 579/1000..  Training Loss: 6185890481.778..  Test Loss: 5058923520.000.. \n",
      "Epoch: 580/1000..  Training Loss: 6094472192.000..  Test Loss: 4985460224.000.. \n",
      "Epoch: 581/1000..  Training Loss: 6069125148.444..  Test Loss: 5002637824.000.. \n",
      "Epoch: 582/1000..  Training Loss: 5994554659.556..  Test Loss: 4988174336.000.. \n",
      "Epoch: 583/1000..  Training Loss: 6025105777.778..  Test Loss: 4878949376.000.. \n",
      "Epoch: 584/1000..  Training Loss: 5958196216.889..  Test Loss: 4838242816.000.. \n",
      "Epoch: 585/1000..  Training Loss: 5920615004.444..  Test Loss: 5051528704.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5998471160.889..  Test Loss: 4984005632.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5985103260.444..  Test Loss: 4834805248.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5996912085.333..  Test Loss: 4836762112.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5995848369.778..  Test Loss: 4838545920.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5949390862.222..  Test Loss: 4861459968.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5929829233.778..  Test Loss: 4795634176.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5952574087.111..  Test Loss: 4989905408.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5895882851.556..  Test Loss: 4738790400.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5891013845.333..  Test Loss: 4875372544.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5874998855.111..  Test Loss: 4856274944.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5956877681.778..  Test Loss: 4940446208.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5875039004.444..  Test Loss: 4791364608.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5829570595.556..  Test Loss: 4672136704.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5848788664.889..  Test Loss: 4691635200.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5774259541.333..  Test Loss: 4865968128.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5899773873.778..  Test Loss: 4987161088.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5788313841.778..  Test Loss: 4740504064.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5892921568.000..  Test Loss: 5042986496.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5795977358.222..  Test Loss: 4730388480.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 605/1000..  Training Loss: 5799093390.222..  Test Loss: 4777553408.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5762128760.889..  Test Loss: 4609311232.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5796281432.889..  Test Loss: 4583754752.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5723232497.778..  Test Loss: 4655171584.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5723256711.111..  Test Loss: 4685200896.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5820347512.889..  Test Loss: 4720925184.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5711110549.333..  Test Loss: 4743760896.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5721498197.333..  Test Loss: 4559378432.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5662066496.000..  Test Loss: 4580357632.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5722304853.333..  Test Loss: 4579153408.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5740782741.333..  Test Loss: 4583505408.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5726214016.000..  Test Loss: 4459987968.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5661139349.333..  Test Loss: 4465489920.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5559825557.333..  Test Loss: 4434962432.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5555809760.000..  Test Loss: 4501370368.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5595745251.556..  Test Loss: 4706593280.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5641251665.778..  Test Loss: 4405800960.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5537342897.778..  Test Loss: 4684283904.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5656943416.889..  Test Loss: 4517289472.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5649070314.667..  Test Loss: 4711650816.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5604174286.222..  Test Loss: 4434732032.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5540077539.556..  Test Loss: 4424525824.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5590727360.000..  Test Loss: 4390014976.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5580263409.778..  Test Loss: 4449104384.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5593852615.111..  Test Loss: 4440666624.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5566340757.333..  Test Loss: 4383980032.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5469756056.889..  Test Loss: 4479365120.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5510792640.000..  Test Loss: 4505700352.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5597408362.667..  Test Loss: 4363651584.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5520184661.333..  Test Loss: 4468967424.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5467670272.000..  Test Loss: 4393318912.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5556113834.667..  Test Loss: 4248059136.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5509482517.333..  Test Loss: 4451052032.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5461289464.889..  Test Loss: 4418417664.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5410006826.667..  Test Loss: 4321252352.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5426792903.111..  Test Loss: 4327682048.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5419601642.667..  Test Loss: 4420479488.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5415701134.222..  Test Loss: 4301966848.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5489112839.111..  Test Loss: 4300351488.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5463617952.000..  Test Loss: 4280289024.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5412256270.222..  Test Loss: 4228861952.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5447092821.333..  Test Loss: 4203311104.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5423125077.333..  Test Loss: 4154535424.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5362482357.333..  Test Loss: 4331078144.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5420467968.000..  Test Loss: 4276930816.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5359837123.556..  Test Loss: 4234871808.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5315989304.889..  Test Loss: 4176315392.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5377940942.222..  Test Loss: 4075373568.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5420577148.444..  Test Loss: 4139865856.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5430686997.333..  Test Loss: 4136120320.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5279982293.333..  Test Loss: 4046089472.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5342343843.556..  Test Loss: 4171373824.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5325197482.667..  Test Loss: 4171870720.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5334131790.222..  Test Loss: 4194064640.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5218606307.556..  Test Loss: 4269088768.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5297912661.333..  Test Loss: 4092501504.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5211282780.444..  Test Loss: 4079445760.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5344329230.222..  Test Loss: 4057489920.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5238286769.778..  Test Loss: 4338952704.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5276907345.778..  Test Loss: 4248857344.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5229384760.889..  Test Loss: 4050731008.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5360265692.444..  Test Loss: 4146050304.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5201606734.222..  Test Loss: 4027813120.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5177148408.889..  Test Loss: 4116091392.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5226151431.111..  Test Loss: 4133201152.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5251795512.889..  Test Loss: 4040219904.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5279556970.667..  Test Loss: 4039827968.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5249567495.111..  Test Loss: 4091353856.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5394980049.778..  Test Loss: 4027946240.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5203984782.222..  Test Loss: 3895117568.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5298641891.556..  Test Loss: 4141830144.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5231387420.444..  Test Loss: 4095409408.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5226211370.667..  Test Loss: 4047468288.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5182119175.111..  Test Loss: 3981362432.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5209946645.333..  Test Loss: 3981661440.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5248041457.778..  Test Loss: 4027620864.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5099920924.444..  Test Loss: 3861923584.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5150706268.444..  Test Loss: 4074347776.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5198614023.111..  Test Loss: 4015070720.000.. \n",
      "Epoch: 684/1000..  Training Loss: 5158748920.889..  Test Loss: 3885174784.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5110018136.889..  Test Loss: 3820732416.000.. \n",
      "Epoch: 686/1000..  Training Loss: 5115763363.556..  Test Loss: 3810354432.000.. \n",
      "Epoch: 687/1000..  Training Loss: 5143774933.333..  Test Loss: 3869969920.000.. \n",
      "Epoch: 688/1000..  Training Loss: 5163057984.000..  Test Loss: 4020228608.000.. \n",
      "Epoch: 689/1000..  Training Loss: 5189243804.444..  Test Loss: 3907418880.000.. \n",
      "Epoch: 690/1000..  Training Loss: 5110883427.556..  Test Loss: 3828693248.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5146535352.889..  Test Loss: 3772631808.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5120922101.333..  Test Loss: 3949028608.000.. \n",
      "Epoch: 693/1000..  Training Loss: 5092876835.556..  Test Loss: 3830703360.000.. \n",
      "Epoch: 694/1000..  Training Loss: 5040457518.222..  Test Loss: 4031564032.000.. \n",
      "Epoch: 695/1000..  Training Loss: 5110647936.000..  Test Loss: 3741953280.000.. \n",
      "Epoch: 696/1000..  Training Loss: 5132995470.222..  Test Loss: 3820903680.000.. \n",
      "Epoch: 697/1000..  Training Loss: 5132490211.556..  Test Loss: 3805743104.000.. \n",
      "Epoch: 698/1000..  Training Loss: 5046333703.111..  Test Loss: 3769568512.000.. \n",
      "Epoch: 699/1000..  Training Loss: 5079422499.556..  Test Loss: 3797782016.000.. \n",
      "Epoch: 700/1000..  Training Loss: 5108828636.444..  Test Loss: 3857378816.000.. \n",
      "Epoch: 701/1000..  Training Loss: 5021077148.444..  Test Loss: 3943072768.000.. \n",
      "Epoch: 702/1000..  Training Loss: 5033991978.667..  Test Loss: 3693526272.000.. \n",
      "Epoch: 703/1000..  Training Loss: 5045768419.556..  Test Loss: 3714159872.000.. \n",
      "Epoch: 704/1000..  Training Loss: 5019273891.556..  Test Loss: 3735445248.000.. \n",
      "Epoch: 705/1000..  Training Loss: 5077731676.444..  Test Loss: 3851278080.000.. \n",
      "Epoch: 706/1000..  Training Loss: 5004433500.444..  Test Loss: 3740512256.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 707/1000..  Training Loss: 5008908689.778..  Test Loss: 3679616768.000.. \n",
      "Epoch: 708/1000..  Training Loss: 5052232234.667..  Test Loss: 3696185856.000.. \n",
      "Epoch: 709/1000..  Training Loss: 5002550449.778..  Test Loss: 3723211264.000.. \n",
      "Epoch: 710/1000..  Training Loss: 5098270364.444..  Test Loss: 3737652992.000.. \n",
      "Epoch: 711/1000..  Training Loss: 5061874616.889..  Test Loss: 3846009856.000.. \n",
      "Epoch: 712/1000..  Training Loss: 5117047928.889..  Test Loss: 3861284096.000.. \n",
      "Epoch: 713/1000..  Training Loss: 5032835434.667..  Test Loss: 3600974336.000.. \n",
      "Epoch: 714/1000..  Training Loss: 5048839736.889..  Test Loss: 3675136256.000.. \n",
      "Epoch: 715/1000..  Training Loss: 4964975832.889..  Test Loss: 3806789376.000.. \n",
      "Epoch: 716/1000..  Training Loss: 5043296437.333..  Test Loss: 3640641024.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4986208419.556..  Test Loss: 3695558656.000.. \n",
      "Epoch: 718/1000..  Training Loss: 5045471296.000..  Test Loss: 3641033216.000.. \n",
      "Epoch: 719/1000..  Training Loss: 5002284209.778..  Test Loss: 3714656256.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4935823370.667..  Test Loss: 3623783680.000.. \n",
      "Epoch: 721/1000..  Training Loss: 5011137763.556..  Test Loss: 3608354816.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4977361941.333..  Test Loss: 3655750912.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4992189312.000..  Test Loss: 3561779712.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4955699434.667..  Test Loss: 3617743872.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4958575153.778..  Test Loss: 3639753728.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4945534076.444..  Test Loss: 3645602560.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4922149720.889..  Test Loss: 3616839168.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4947466282.667..  Test Loss: 3590716160.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4930407185.778..  Test Loss: 3550558976.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4920662577.778..  Test Loss: 3709004800.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4894847210.667..  Test Loss: 3614450944.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4953731491.556..  Test Loss: 3593484544.000.. \n",
      "Epoch: 733/1000..  Training Loss: 5024421425.778..  Test Loss: 3604245248.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4952107054.222..  Test Loss: 3519321088.000.. \n",
      "Epoch: 735/1000..  Training Loss: 5002003719.111..  Test Loss: 3645056000.000.. \n",
      "Epoch: 736/1000..  Training Loss: 5018132917.333..  Test Loss: 3609260800.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4934043932.444..  Test Loss: 3650075136.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4953617386.667..  Test Loss: 3576414720.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4970376952.889..  Test Loss: 3544243456.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4927815530.667..  Test Loss: 3497942016.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4985878535.111..  Test Loss: 3484899584.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4903569308.444..  Test Loss: 3478713600.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4929967459.556..  Test Loss: 3438711808.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4929083505.778..  Test Loss: 3498146560.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4944947768.889..  Test Loss: 3584961280.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4933492920.889..  Test Loss: 3575058944.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4924247783.111..  Test Loss: 3502949376.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4885012117.333..  Test Loss: 3596825088.000.. \n",
      "Epoch: 749/1000..  Training Loss: 5033961884.444..  Test Loss: 3525886720.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4930382122.667..  Test Loss: 3478127872.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4884121287.111..  Test Loss: 3547859200.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4935866517.333..  Test Loss: 3511127296.000.. \n",
      "Epoch: 753/1000..  Training Loss: 5003151950.222..  Test Loss: 3543788800.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4991024785.778..  Test Loss: 3492332288.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4875902364.444..  Test Loss: 3445609728.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4969417024.000..  Test Loss: 3480864512.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4894949219.556..  Test Loss: 3595333632.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4901907960.889..  Test Loss: 3423604224.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4905401536.000..  Test Loss: 3402359040.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4828198826.667..  Test Loss: 3430852864.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4906438133.333..  Test Loss: 3428889856.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4819198055.111..  Test Loss: 3410167296.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4901303160.889..  Test Loss: 3405534208.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4872108522.667..  Test Loss: 3445230336.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4900353820.444..  Test Loss: 3442672640.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4910985294.222..  Test Loss: 3395088384.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4851164046.222..  Test Loss: 3494123264.000.. \n",
      "Epoch: 768/1000..  Training Loss: 5022588515.556..  Test Loss: 3518631168.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4992042876.444..  Test Loss: 3589294848.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4802634360.889..  Test Loss: 3486641408.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4885556416.000..  Test Loss: 3483548416.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4877182250.667..  Test Loss: 3525094656.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4877151488.000..  Test Loss: 3350882560.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4851572480.000..  Test Loss: 3337441280.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4845134442.667..  Test Loss: 3299980544.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4838528608.000..  Test Loss: 3432466176.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4835611722.667..  Test Loss: 3490272512.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4862747000.889..  Test Loss: 3542604288.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4786954510.222..  Test Loss: 3379600384.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4835316771.556..  Test Loss: 3338279680.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4743267562.667..  Test Loss: 3529732864.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4805938766.222..  Test Loss: 3409004032.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4882552277.333..  Test Loss: 3426050560.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4830769400.889..  Test Loss: 3363378432.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4879875868.444..  Test Loss: 3410015232.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4906335018.667..  Test Loss: 3391410432.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4821902179.556..  Test Loss: 3366892032.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4906370656.000..  Test Loss: 3457282816.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4989692551.111..  Test Loss: 3365008384.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4793087253.333..  Test Loss: 3373084672.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4836240640.000..  Test Loss: 3302663680.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4795322968.889..  Test Loss: 3343688960.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4811226439.111..  Test Loss: 3295980800.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4824187473.778..  Test Loss: 3557708800.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4846856071.111..  Test Loss: 3403930112.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4930205013.333..  Test Loss: 3365529600.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4826190986.667..  Test Loss: 3419252480.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4955835441.778..  Test Loss: 3380287232.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4873781411.556..  Test Loss: 3302276352.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4878018901.333..  Test Loss: 3294194944.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4920532551.111..  Test Loss: 3315543040.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4816678990.222..  Test Loss: 3282939648.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4815418474.667..  Test Loss: 3336895488.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4890777685.333..  Test Loss: 3329778944.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4809294449.778..  Test Loss: 3351480576.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4845064604.444..  Test Loss: 3361310208.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4794381184.000..  Test Loss: 3351440384.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4802167850.667..  Test Loss: 3329583104.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 809/1000..  Training Loss: 4761933319.111..  Test Loss: 3329954560.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4757521649.778..  Test Loss: 3301285888.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4812470826.667..  Test Loss: 3437466880.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4797501304.889..  Test Loss: 3352818176.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4841606869.333..  Test Loss: 3265905408.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4889537500.444..  Test Loss: 3356723200.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4748241489.778..  Test Loss: 3373190912.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4803209112.889..  Test Loss: 3371912448.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4838944213.333..  Test Loss: 3346400512.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4875761820.444..  Test Loss: 3284825600.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4806692007.111..  Test Loss: 3352162816.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4794163783.111..  Test Loss: 3293349120.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4811469546.667..  Test Loss: 3438274560.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4772094456.889..  Test Loss: 3276083712.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4823903758.222..  Test Loss: 3290354176.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4716607118.222..  Test Loss: 3309790464.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4911853290.667..  Test Loss: 3336560384.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4814447623.111..  Test Loss: 3440777984.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4767081251.556..  Test Loss: 3241093632.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4821462179.556..  Test Loss: 3303229184.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4827237603.556..  Test Loss: 3265888768.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4833058432.000..  Test Loss: 3306832640.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4760992000.000..  Test Loss: 3305584128.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4821251534.222..  Test Loss: 3366488576.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4774229162.667..  Test Loss: 3304453632.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4783378154.667..  Test Loss: 3394311168.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4771764024.889..  Test Loss: 3339840256.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4798989006.222..  Test Loss: 3281183744.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4776163911.111..  Test Loss: 3307349248.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4808308423.111..  Test Loss: 3230395648.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4783565027.556..  Test Loss: 3252960256.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4747439381.333..  Test Loss: 3268919552.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4801443672.889..  Test Loss: 3352735232.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4796055082.667..  Test Loss: 3332811520.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4763907477.333..  Test Loss: 3282762240.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4835596622.222..  Test Loss: 3290484992.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4826335303.111..  Test Loss: 3322925312.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4777696092.444..  Test Loss: 3311144704.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4808417649.778..  Test Loss: 3273647616.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4772076352.000..  Test Loss: 3337890560.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4825598023.111..  Test Loss: 3307778304.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4776729486.222..  Test Loss: 3204418304.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4739415587.556..  Test Loss: 3373154560.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4806932963.556..  Test Loss: 3203459840.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4765679388.444..  Test Loss: 3359055360.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4830449859.556..  Test Loss: 3291027456.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4830039473.778..  Test Loss: 3266854912.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4751966343.111..  Test Loss: 3293750784.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4756485340.444..  Test Loss: 3224272640.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4789538382.222..  Test Loss: 3391408384.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4828799616.000..  Test Loss: 3295370240.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4785025173.333..  Test Loss: 3366927872.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4830123072.000..  Test Loss: 3331597568.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4777131157.333..  Test Loss: 3256289792.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4733220195.556..  Test Loss: 3199679744.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4700791729.778..  Test Loss: 3311888384.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4773318478.222..  Test Loss: 3331372800.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4880633763.556..  Test Loss: 3261311488.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4777867491.556..  Test Loss: 3255119872.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4824093155.556..  Test Loss: 3284131584.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4814630076.444..  Test Loss: 3190396928.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4750033820.444..  Test Loss: 3218663680.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4838760497.778..  Test Loss: 3300375808.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4745178428.444..  Test Loss: 3316325120.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4759977898.667..  Test Loss: 3232438784.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4764304049.778..  Test Loss: 3340996608.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4796725678.222..  Test Loss: 3420142080.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4798062634.667..  Test Loss: 3310236416.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4753514012.444..  Test Loss: 3265404672.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4756115029.333..  Test Loss: 3223984640.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4799457294.222..  Test Loss: 3356120576.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4715840888.889..  Test Loss: 3283657728.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4763297536.000..  Test Loss: 3348141312.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4712154058.667..  Test Loss: 3238171392.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4904801521.778..  Test Loss: 3253989376.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4824440917.333..  Test Loss: 3264004096.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4729146360.889..  Test Loss: 3296135680.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4727617379.556..  Test Loss: 3347636736.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4848460138.667..  Test Loss: 3337320192.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4732370453.333..  Test Loss: 3272121088.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4733002880.000..  Test Loss: 3189039616.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4827077386.667..  Test Loss: 3204615680.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4725496913.778..  Test Loss: 3216883456.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4841564103.111..  Test Loss: 3333244672.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4727714801.778..  Test Loss: 3229416448.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4850526556.444..  Test Loss: 3273661184.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4806542968.889..  Test Loss: 3247728896.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4748695751.111..  Test Loss: 3175496448.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4771592060.444..  Test Loss: 3326498048.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4774406755.556..  Test Loss: 3191250432.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4756623018.667..  Test Loss: 3286267136.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4902232746.667..  Test Loss: 3349779456.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4808757710.222..  Test Loss: 3200831232.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4767592675.556..  Test Loss: 3255390976.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4744017187.556..  Test Loss: 3254817536.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4749557802.667..  Test Loss: 3208484096.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4704876519.111..  Test Loss: 3211052800.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4772100679.111..  Test Loss: 3301000960.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4719580352.000..  Test Loss: 3187843328.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4841907441.778..  Test Loss: 3211940096.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4803527779.556..  Test Loss: 3283861760.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4890378268.444..  Test Loss: 3201533440.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 911/1000..  Training Loss: 4682991395.556..  Test Loss: 3269492224.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4853291370.667..  Test Loss: 3292158976.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4729490986.667..  Test Loss: 3172694016.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4722390481.778..  Test Loss: 3189059584.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4737333880.889..  Test Loss: 3270188544.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4702634723.556..  Test Loss: 3237345024.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4744189347.556..  Test Loss: 3312386304.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4743399573.333..  Test Loss: 3234922752.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4743109155.556..  Test Loss: 3222578432.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4767893724.444..  Test Loss: 3216533760.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4762551278.222..  Test Loss: 3285374720.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4770999829.333..  Test Loss: 3228764928.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4742961301.333..  Test Loss: 3238690816.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4697657358.222..  Test Loss: 3314397696.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4752047338.667..  Test Loss: 3218629376.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4714815537.778..  Test Loss: 3250294016.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4822984113.778..  Test Loss: 3219928320.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4836117681.778..  Test Loss: 3200941056.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4717752846.222..  Test Loss: 3240635904.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4805114368.000..  Test Loss: 3351384832.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4713506673.778..  Test Loss: 3316961536.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4744241546.667..  Test Loss: 3191730176.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4702398677.333..  Test Loss: 3295823872.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4728378951.111..  Test Loss: 3241454592.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4798996508.444..  Test Loss: 3227811840.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4705002844.444..  Test Loss: 3238694144.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4709258410.667..  Test Loss: 3299488000.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4689632348.444..  Test Loss: 3168699648.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4913223303.111..  Test Loss: 3376990208.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4719499697.778..  Test Loss: 3185285632.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4781437639.111..  Test Loss: 3176410624.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4778786805.333..  Test Loss: 3236102400.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4770355370.667..  Test Loss: 3269240064.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4806601258.667..  Test Loss: 3372051712.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4784060864.000..  Test Loss: 3221806336.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4761726336.000..  Test Loss: 3196327936.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4741366570.667..  Test Loss: 3204672768.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4796842538.667..  Test Loss: 3187887104.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4794591601.778..  Test Loss: 3196961024.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4828719509.333..  Test Loss: 3249862912.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4693227477.333..  Test Loss: 3313888512.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4776429877.333..  Test Loss: 3340148992.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4814639480.889..  Test Loss: 3205836032.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4814603882.667..  Test Loss: 3199136512.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4750268359.111..  Test Loss: 3248326144.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4805819335.111..  Test Loss: 3252907264.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4723960860.444..  Test Loss: 3302606592.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4808127125.333..  Test Loss: 3179991296.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4717224526.222..  Test Loss: 3291444480.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4735135189.333..  Test Loss: 3283610880.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4736202112.000..  Test Loss: 3182491136.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4741893141.333..  Test Loss: 3218111232.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4846440640.000..  Test Loss: 3220382208.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4770845760.000..  Test Loss: 3234321664.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4686428732.444..  Test Loss: 3185021952.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4656211626.667..  Test Loss: 3203406080.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4724810289.778..  Test Loss: 3230026496.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4723008348.444..  Test Loss: 3203508480.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4790946524.444..  Test Loss: 3375025920.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4816206311.111..  Test Loss: 3223646976.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4750422264.889..  Test Loss: 3264452096.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4785105891.556..  Test Loss: 3215370496.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4771740088.889..  Test Loss: 3158939392.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4704729564.444..  Test Loss: 3391058944.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4687890520.889..  Test Loss: 3237979392.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4714411505.778..  Test Loss: 3227457280.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4759649258.667..  Test Loss: 3242350336.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4696472327.111..  Test Loss: 3216830976.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4785381262.222..  Test Loss: 3303620096.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4799465571.556..  Test Loss: 3228699136.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4745874688.000..  Test Loss: 3219636480.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4747403434.667..  Test Loss: 3198620672.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4704749568.000..  Test Loss: 3203655680.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4725773148.444..  Test Loss: 3221370112.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4740224291.556..  Test Loss: 3174166016.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4752307939.556..  Test Loss: 3390567936.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4646604942.222..  Test Loss: 3272728576.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4737121841.778..  Test Loss: 3238055168.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4747613134.222..  Test Loss: 3295512320.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4672805792.000..  Test Loss: 3239149568.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4818380312.889..  Test Loss: 3377176576.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4734709127.111..  Test Loss: 3179322624.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4768781816.889..  Test Loss: 3175653120.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4777049642.667..  Test Loss: 3354259712.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4767526254.222..  Test Loss: 3304839168.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4715427200.000..  Test Loss: 3191856384.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4694199068.444..  Test Loss: 3189134848.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4720216519.111..  Test Loss: 3210898432.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4751800561.778..  Test Loss: 3302448640.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4735234773.333..  Test Loss: 3219761664.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 2\n",
      "Epoch: 1/1000..  Training Loss: 12669026889.143..  Test Loss: 15737418752.000.. \n",
      "Epoch: 2/1000..  Training Loss: 12656311764.114..  Test Loss: 16009387008.000.. \n",
      "Epoch: 3/1000..  Training Loss: 12652435017.143..  Test Loss: 15796071424.000.. \n",
      "Epoch: 4/1000..  Training Loss: 12663856640.000..  Test Loss: 15266553856.000.. \n",
      "Epoch: 5/1000..  Training Loss: 12660785034.971..  Test Loss: 15910632448.000.. \n",
      "Epoch: 6/1000..  Training Loss: 12657456230.400..  Test Loss: 16376496128.000.. \n",
      "Epoch: 7/1000..  Training Loss: 12662578673.371..  Test Loss: 15444235264.000.. \n",
      "Epoch: 8/1000..  Training Loss: 12662917939.200..  Test Loss: 15742260224.000.. \n",
      "Epoch: 9/1000..  Training Loss: 12652243733.943..  Test Loss: 16394520576.000.. \n",
      "Epoch: 10/1000..  Training Loss: 12657618329.600..  Test Loss: 16373794816.000.. \n",
      "Epoch: 11/1000..  Training Loss: 12639624864.914..  Test Loss: 18157115392.000.. \n",
      "Epoch: 12/1000..  Training Loss: 12657481962.057..  Test Loss: 15692963840.000.. \n",
      "Epoch: 13/1000..  Training Loss: 12642297344.000..  Test Loss: 15454447616.000.. \n",
      "Epoch: 14/1000..  Training Loss: 12640951442.286..  Test Loss: 15271603200.000.. \n",
      "Epoch: 15/1000..  Training Loss: 12636692845.714..  Test Loss: 15346744320.000.. \n",
      "Epoch: 16/1000..  Training Loss: 12640596275.200..  Test Loss: 15489403904.000.. \n",
      "Epoch: 17/1000..  Training Loss: 12651330940.343..  Test Loss: 15788072960.000.. \n",
      "Epoch: 18/1000..  Training Loss: 12636973992.229..  Test Loss: 15703495680.000.. \n",
      "Epoch: 19/1000..  Training Loss: 12653551440.457..  Test Loss: 16036994048.000.. \n",
      "Epoch: 20/1000..  Training Loss: 12626956127.086..  Test Loss: 16453245952.000.. \n",
      "Epoch: 21/1000..  Training Loss: 12634723679.086..  Test Loss: 16474793984.000.. \n",
      "Epoch: 22/1000..  Training Loss: 12650803682.743..  Test Loss: 16795540480.000.. \n",
      "Epoch: 23/1000..  Training Loss: 12625247202.743..  Test Loss: 16800685056.000.. \n",
      "Epoch: 24/1000..  Training Loss: 12646880285.257..  Test Loss: 17002326016.000.. \n",
      "Epoch: 25/1000..  Training Loss: 12630378656.914..  Test Loss: 15277735936.000.. \n",
      "Epoch: 26/1000..  Training Loss: 12627067611.429..  Test Loss: 16207393792.000.. \n",
      "Epoch: 27/1000..  Training Loss: 12629842563.657..  Test Loss: 16271927296.000.. \n",
      "Epoch: 28/1000..  Training Loss: 12620132293.486..  Test Loss: 15759113216.000.. \n",
      "Epoch: 29/1000..  Training Loss: 12600702332.343..  Test Loss: 15839849472.000.. \n",
      "Epoch: 30/1000..  Training Loss: 12604849590.857..  Test Loss: 15740220416.000.. \n",
      "Epoch: 31/1000..  Training Loss: 12588057424.457..  Test Loss: 17139968000.000.. \n",
      "Epoch: 32/1000..  Training Loss: 12581595326.171..  Test Loss: 16061936640.000.. \n",
      "Epoch: 33/1000..  Training Loss: 12608911564.800..  Test Loss: 15689714688.000.. \n",
      "Epoch: 34/1000..  Training Loss: 12585506362.514..  Test Loss: 15127742464.000.. \n",
      "Epoch: 35/1000..  Training Loss: 12583923317.029..  Test Loss: 15424449536.000.. \n",
      "Epoch: 36/1000..  Training Loss: 12578126730.971..  Test Loss: 16214701056.000.. \n",
      "Epoch: 37/1000..  Training Loss: 12582748993.829..  Test Loss: 15441312768.000.. \n",
      "Epoch: 38/1000..  Training Loss: 12582022421.943..  Test Loss: 15269421056.000.. \n",
      "Epoch: 39/1000..  Training Loss: 12572665826.743..  Test Loss: 16023767040.000.. \n",
      "Epoch: 40/1000..  Training Loss: 12571091090.286..  Test Loss: 15918424064.000.. \n",
      "Epoch: 41/1000..  Training Loss: 12563395189.029..  Test Loss: 16354536448.000.. \n",
      "Epoch: 42/1000..  Training Loss: 12552433839.543..  Test Loss: 15486273536.000.. \n",
      "Epoch: 43/1000..  Training Loss: 12555418814.171..  Test Loss: 15162403840.000.. \n",
      "Epoch: 44/1000..  Training Loss: 12539260971.886..  Test Loss: 15496609792.000.. \n",
      "Epoch: 45/1000..  Training Loss: 12550884556.800..  Test Loss: 16383592448.000.. \n",
      "Epoch: 46/1000..  Training Loss: 12531102208.000..  Test Loss: 16954350592.000.. \n",
      "Epoch: 47/1000..  Training Loss: 12517042614.857..  Test Loss: 15170147328.000.. \n",
      "Epoch: 48/1000..  Training Loss: 12532027157.943..  Test Loss: 15445614592.000.. \n",
      "Epoch: 49/1000..  Training Loss: 12536150513.371..  Test Loss: 15327507456.000.. \n",
      "Epoch: 50/1000..  Training Loss: 12516875732.114..  Test Loss: 17888389120.000.. \n",
      "Epoch: 51/1000..  Training Loss: 12495328548.571..  Test Loss: 16261758976.000.. \n",
      "Epoch: 52/1000..  Training Loss: 12492647277.714..  Test Loss: 15676738560.000.. \n",
      "Epoch: 53/1000..  Training Loss: 12495631813.486..  Test Loss: 15802405888.000.. \n",
      "Epoch: 54/1000..  Training Loss: 12495274218.057..  Test Loss: 16052027392.000.. \n",
      "Epoch: 55/1000..  Training Loss: 12496201069.714..  Test Loss: 15271533568.000.. \n",
      "Epoch: 56/1000..  Training Loss: 12470298624.000..  Test Loss: 16408046592.000.. \n",
      "Epoch: 57/1000..  Training Loss: 12461455550.171..  Test Loss: 16699165696.000.. \n",
      "Epoch: 58/1000..  Training Loss: 12454684320.914..  Test Loss: 16139238400.000.. \n",
      "Epoch: 59/1000..  Training Loss: 12461578371.657..  Test Loss: 15181867008.000.. \n",
      "Epoch: 60/1000..  Training Loss: 12473228083.200..  Test Loss: 15727287296.000.. \n",
      "Epoch: 61/1000..  Training Loss: 12445116035.657..  Test Loss: 15470177280.000.. \n",
      "Epoch: 62/1000..  Training Loss: 12439578975.086..  Test Loss: 15972747264.000.. \n",
      "Epoch: 63/1000..  Training Loss: 12445734736.457..  Test Loss: 17391566848.000.. \n",
      "Epoch: 64/1000..  Training Loss: 12423139532.800..  Test Loss: 15802452992.000.. \n",
      "Epoch: 65/1000..  Training Loss: 12424416914.286..  Test Loss: 16180477952.000.. \n",
      "Epoch: 66/1000..  Training Loss: 12432131744.914..  Test Loss: 15219894272.000.. \n",
      "Epoch: 67/1000..  Training Loss: 12398673334.857..  Test Loss: 16127057920.000.. \n",
      "Epoch: 68/1000..  Training Loss: 12389410347.886..  Test Loss: 16222974976.000.. \n",
      "Epoch: 69/1000..  Training Loss: 12404332573.257..  Test Loss: 15691885568.000.. \n",
      "Epoch: 70/1000..  Training Loss: 12405924688.457..  Test Loss: 15868099584.000.. \n",
      "Epoch: 71/1000..  Training Loss: 12370199522.743..  Test Loss: 15516324864.000.. \n",
      "Epoch: 72/1000..  Training Loss: 12374685681.371..  Test Loss: 15501125632.000.. \n",
      "Epoch: 73/1000..  Training Loss: 12369070518.857..  Test Loss: 16853131264.000.. \n",
      "Epoch: 74/1000..  Training Loss: 12355704042.057..  Test Loss: 16089541632.000.. \n",
      "Epoch: 75/1000..  Training Loss: 12362916761.600..  Test Loss: 15734794240.000.. \n",
      "Epoch: 76/1000..  Training Loss: 12352864607.086..  Test Loss: 15366462464.000.. \n",
      "Epoch: 77/1000..  Training Loss: 12338014515.200..  Test Loss: 16486304768.000.. \n",
      "Epoch: 78/1000..  Training Loss: 12326103361.829..  Test Loss: 15203955712.000.. \n",
      "Epoch: 79/1000..  Training Loss: 12320595295.086..  Test Loss: 15483611136.000.. \n",
      "Epoch: 80/1000..  Training Loss: 12318769532.343..  Test Loss: 15965010944.000.. \n",
      "Epoch: 81/1000..  Training Loss: 12302882801.371..  Test Loss: 15447164928.000.. \n",
      "Epoch: 82/1000..  Training Loss: 12296932293.486..  Test Loss: 15458515968.000.. \n",
      "Epoch: 83/1000..  Training Loss: 12302792001.829..  Test Loss: 14962706432.000.. \n",
      "Epoch: 84/1000..  Training Loss: 12276449265.371..  Test Loss: 15657633792.000.. \n",
      "Epoch: 85/1000..  Training Loss: 12273469088.914..  Test Loss: 14957963264.000.. \n",
      "Epoch: 86/1000..  Training Loss: 12265704828.343..  Test Loss: 15369928704.000.. \n",
      "Epoch: 87/1000..  Training Loss: 12245652757.943..  Test Loss: 15245196288.000.. \n",
      "Epoch: 88/1000..  Training Loss: 12249623771.429..  Test Loss: 16516600832.000.. \n",
      "Epoch: 89/1000..  Training Loss: 12263475755.886..  Test Loss: 16529285120.000.. \n",
      "Epoch: 90/1000..  Training Loss: 12243527855.543..  Test Loss: 15382723584.000.. \n",
      "Epoch: 91/1000..  Training Loss: 12229729397.029..  Test Loss: 16452705280.000.. \n",
      "Epoch: 92/1000..  Training Loss: 12215044213.029..  Test Loss: 16339987456.000.. \n",
      "Epoch: 93/1000..  Training Loss: 12220302833.371..  Test Loss: 14969711616.000.. \n",
      "Epoch: 94/1000..  Training Loss: 12221652992.000..  Test Loss: 15354503168.000.. \n",
      "Epoch: 95/1000..  Training Loss: 12216155838.171..  Test Loss: 14860001280.000.. \n",
      "Epoch: 96/1000..  Training Loss: 12179267232.914..  Test Loss: 14934509568.000.. \n",
      "Epoch: 97/1000..  Training Loss: 12171238253.714..  Test Loss: 15321078784.000.. \n",
      "Epoch: 98/1000..  Training Loss: 12167870961.371..  Test Loss: 15419014144.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12163825561.600..  Test Loss: 14634724352.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12156974123.886..  Test Loss: 15766547456.000.. \n",
      "Epoch: 101/1000..  Training Loss: 12154262996.114..  Test Loss: 15718747136.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102/1000..  Training Loss: 12138294389.029..  Test Loss: 15642055680.000.. \n",
      "Epoch: 103/1000..  Training Loss: 12129518796.800..  Test Loss: 14786933760.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12118047978.057..  Test Loss: 15958801408.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12098757163.886..  Test Loss: 15010547712.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12109785980.343..  Test Loss: 14807302144.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12097912334.629..  Test Loss: 15434263552.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12077606122.057..  Test Loss: 14509665280.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12069134833.371..  Test Loss: 15200474112.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12067877800.229..  Test Loss: 14896106496.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12052425157.486..  Test Loss: 14925490176.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12041872647.314..  Test Loss: 14898341888.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12015228986.514..  Test Loss: 14929574912.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12019766213.486..  Test Loss: 15187948544.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12009512491.886..  Test Loss: 15309930496.000.. \n",
      "Epoch: 116/1000..  Training Loss: 11996388659.200..  Test Loss: 14909027328.000.. \n",
      "Epoch: 117/1000..  Training Loss: 11994675580.343..  Test Loss: 14676554752.000.. \n",
      "Epoch: 118/1000..  Training Loss: 11985847925.029..  Test Loss: 15341084672.000.. \n",
      "Epoch: 119/1000..  Training Loss: 11967332600.686..  Test Loss: 15297534976.000.. \n",
      "Epoch: 120/1000..  Training Loss: 11957879500.800..  Test Loss: 16084044800.000.. \n",
      "Epoch: 121/1000..  Training Loss: 11936106598.400..  Test Loss: 14888233984.000.. \n",
      "Epoch: 122/1000..  Training Loss: 11952199899.429..  Test Loss: 15989432320.000.. \n",
      "Epoch: 123/1000..  Training Loss: 11936572255.086..  Test Loss: 15515358208.000.. \n",
      "Epoch: 124/1000..  Training Loss: 11927842260.114..  Test Loss: 15300732928.000.. \n",
      "Epoch: 125/1000..  Training Loss: 11896675737.600..  Test Loss: 15845722112.000.. \n",
      "Epoch: 126/1000..  Training Loss: 11902878193.371..  Test Loss: 14738196480.000.. \n",
      "Epoch: 127/1000..  Training Loss: 11906499788.800..  Test Loss: 15621116928.000.. \n",
      "Epoch: 128/1000..  Training Loss: 11889680501.029..  Test Loss: 14867799040.000.. \n",
      "Epoch: 129/1000..  Training Loss: 11878487054.629..  Test Loss: 14937467904.000.. \n",
      "Epoch: 130/1000..  Training Loss: 11861107989.943..  Test Loss: 15143523328.000.. \n",
      "Epoch: 131/1000..  Training Loss: 11842010229.029..  Test Loss: 14846700544.000.. \n",
      "Epoch: 132/1000..  Training Loss: 11848638127.543..  Test Loss: 14649029632.000.. \n",
      "Epoch: 133/1000..  Training Loss: 11838176036.571..  Test Loss: 15494309888.000.. \n",
      "Epoch: 134/1000..  Training Loss: 11814225583.543..  Test Loss: 15071697920.000.. \n",
      "Epoch: 135/1000..  Training Loss: 11796723082.971..  Test Loss: 14811565056.000.. \n",
      "Epoch: 136/1000..  Training Loss: 11798108525.714..  Test Loss: 14796862464.000.. \n",
      "Epoch: 137/1000..  Training Loss: 11788890682.514..  Test Loss: 15232327680.000.. \n",
      "Epoch: 138/1000..  Training Loss: 11776224885.029..  Test Loss: 14872648704.000.. \n",
      "Epoch: 139/1000..  Training Loss: 11773328310.857..  Test Loss: 14714454016.000.. \n",
      "Epoch: 140/1000..  Training Loss: 11769295798.857..  Test Loss: 15277574144.000.. \n",
      "Epoch: 141/1000..  Training Loss: 11746199449.600..  Test Loss: 14823704576.000.. \n",
      "Epoch: 142/1000..  Training Loss: 11730477933.714..  Test Loss: 14572445696.000.. \n",
      "Epoch: 143/1000..  Training Loss: 11723918818.743..  Test Loss: 16125385728.000.. \n",
      "Epoch: 144/1000..  Training Loss: 11717708917.029..  Test Loss: 15443150848.000.. \n",
      "Epoch: 145/1000..  Training Loss: 11720664151.771..  Test Loss: 14544253952.000.. \n",
      "Epoch: 146/1000..  Training Loss: 11680878197.029..  Test Loss: 14455414784.000.. \n",
      "Epoch: 147/1000..  Training Loss: 11676644790.857..  Test Loss: 14544209920.000.. \n",
      "Epoch: 148/1000..  Training Loss: 11672292088.686..  Test Loss: 15259972608.000.. \n",
      "Epoch: 149/1000..  Training Loss: 11669546920.229..  Test Loss: 14626422784.000.. \n",
      "Epoch: 150/1000..  Training Loss: 11635938026.057..  Test Loss: 15013704704.000.. \n",
      "Epoch: 151/1000..  Training Loss: 11641252293.486..  Test Loss: 14542337024.000.. \n",
      "Epoch: 152/1000..  Training Loss: 11628596341.029..  Test Loss: 14417492992.000.. \n",
      "Epoch: 153/1000..  Training Loss: 11625571766.857..  Test Loss: 14453415936.000.. \n",
      "Epoch: 154/1000..  Training Loss: 11595329828.571..  Test Loss: 14967372800.000.. \n",
      "Epoch: 155/1000..  Training Loss: 11576746847.086..  Test Loss: 14696482816.000.. \n",
      "Epoch: 156/1000..  Training Loss: 11590012298.971..  Test Loss: 15347902464.000.. \n",
      "Epoch: 157/1000..  Training Loss: 11573911347.200..  Test Loss: 14495352832.000.. \n",
      "Epoch: 158/1000..  Training Loss: 11541818499.657..  Test Loss: 15614446592.000.. \n",
      "Epoch: 159/1000..  Training Loss: 11541646101.943..  Test Loss: 14835501056.000.. \n",
      "Epoch: 160/1000..  Training Loss: 11518427355.429..  Test Loss: 14338768896.000.. \n",
      "Epoch: 161/1000..  Training Loss: 11516585852.343..  Test Loss: 14615194624.000.. \n",
      "Epoch: 162/1000..  Training Loss: 11485500225.829..  Test Loss: 14467347456.000.. \n",
      "Epoch: 163/1000..  Training Loss: 11502684130.743..  Test Loss: 14797949952.000.. \n",
      "Epoch: 164/1000..  Training Loss: 11494014420.114..  Test Loss: 14679692288.000.. \n",
      "Epoch: 165/1000..  Training Loss: 11478741942.857..  Test Loss: 14695876608.000.. \n",
      "Epoch: 166/1000..  Training Loss: 11459399460.571..  Test Loss: 15827475456.000.. \n",
      "Epoch: 167/1000..  Training Loss: 11447380231.314..  Test Loss: 14263047168.000.. \n",
      "Epoch: 168/1000..  Training Loss: 11423571456.000..  Test Loss: 14232427520.000.. \n",
      "Epoch: 169/1000..  Training Loss: 11423272755.200..  Test Loss: 15133932544.000.. \n",
      "Epoch: 170/1000..  Training Loss: 11402779677.257..  Test Loss: 14134049792.000.. \n",
      "Epoch: 171/1000..  Training Loss: 11422424736.914..  Test Loss: 15274275840.000.. \n",
      "Epoch: 172/1000..  Training Loss: 11386638306.743..  Test Loss: 14928218112.000.. \n",
      "Epoch: 173/1000..  Training Loss: 11376449301.943..  Test Loss: 14871688192.000.. \n",
      "Epoch: 174/1000..  Training Loss: 11365475328.000..  Test Loss: 13942191104.000.. \n",
      "Epoch: 175/1000..  Training Loss: 11336178015.086..  Test Loss: 14816435200.000.. \n",
      "Epoch: 176/1000..  Training Loss: 11330409940.114..  Test Loss: 15128916992.000.. \n",
      "Epoch: 177/1000..  Training Loss: 11331747722.971..  Test Loss: 14186391552.000.. \n",
      "Epoch: 178/1000..  Training Loss: 11312915280.457..  Test Loss: 15691447296.000.. \n",
      "Epoch: 179/1000..  Training Loss: 11319660280.686..  Test Loss: 15052919808.000.. \n",
      "Epoch: 180/1000..  Training Loss: 11289284110.629..  Test Loss: 14436409344.000.. \n",
      "Epoch: 181/1000..  Training Loss: 11284264418.743..  Test Loss: 14355360768.000.. \n",
      "Epoch: 182/1000..  Training Loss: 11278113045.943..  Test Loss: 14449084416.000.. \n",
      "Epoch: 183/1000..  Training Loss: 11282046112.914..  Test Loss: 13991053312.000.. \n",
      "Epoch: 184/1000..  Training Loss: 11250017806.629..  Test Loss: 16084868096.000.. \n",
      "Epoch: 185/1000..  Training Loss: 11237105225.143..  Test Loss: 14012730368.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11198094628.571..  Test Loss: 15210086400.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11197161325.714..  Test Loss: 14830411776.000.. \n",
      "Epoch: 188/1000..  Training Loss: 11200281600.000..  Test Loss: 14056111104.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11210077813.029..  Test Loss: 14647464960.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11171497091.657..  Test Loss: 15105580032.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11145576974.629..  Test Loss: 13812803584.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11142502019.657..  Test Loss: 13715315712.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11146459662.629..  Test Loss: 14345350144.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11127653171.200..  Test Loss: 15432083456.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11091246650.514..  Test Loss: 15503438848.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11091589280.914..  Test Loss: 14658780160.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11082451192.686..  Test Loss: 13813951488.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11094789719.771..  Test Loss: 14372418560.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11039340280.686..  Test Loss: 14694817792.000.. \n",
      "Epoch: 200/1000..  Training Loss: 11045645516.800..  Test Loss: 13637292032.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11059552007.314..  Test Loss: 13962507264.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202/1000..  Training Loss: 11046546358.857..  Test Loss: 13757769728.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11014784394.971..  Test Loss: 13756173312.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11011577797.486..  Test Loss: 14338408448.000.. \n",
      "Epoch: 205/1000..  Training Loss: 10980645054.171..  Test Loss: 14114700288.000.. \n",
      "Epoch: 206/1000..  Training Loss: 10967151221.029..  Test Loss: 14303009792.000.. \n",
      "Epoch: 207/1000..  Training Loss: 10934554053.486..  Test Loss: 15092599808.000.. \n",
      "Epoch: 208/1000..  Training Loss: 10957992799.086..  Test Loss: 14266561536.000.. \n",
      "Epoch: 209/1000..  Training Loss: 10921156768.914..  Test Loss: 14496882688.000.. \n",
      "Epoch: 210/1000..  Training Loss: 10897231886.629..  Test Loss: 14020558848.000.. \n",
      "Epoch: 211/1000..  Training Loss: 10912909897.143..  Test Loss: 14707211264.000.. \n",
      "Epoch: 212/1000..  Training Loss: 10883370057.143..  Test Loss: 14340013056.000.. \n",
      "Epoch: 213/1000..  Training Loss: 10880849451.886..  Test Loss: 14835337216.000.. \n",
      "Epoch: 214/1000..  Training Loss: 10857559478.857..  Test Loss: 13838442496.000.. \n",
      "Epoch: 215/1000..  Training Loss: 10850383389.257..  Test Loss: 13609535488.000.. \n",
      "Epoch: 216/1000..  Training Loss: 10842512676.571..  Test Loss: 14097759232.000.. \n",
      "Epoch: 217/1000..  Training Loss: 10809552398.629..  Test Loss: 14259922944.000.. \n",
      "Epoch: 218/1000..  Training Loss: 10809541778.286..  Test Loss: 14998285312.000.. \n",
      "Epoch: 219/1000..  Training Loss: 10786269388.800..  Test Loss: 13869547520.000.. \n",
      "Epoch: 220/1000..  Training Loss: 10803568976.457..  Test Loss: 15093939200.000.. \n",
      "Epoch: 221/1000..  Training Loss: 10745048970.971..  Test Loss: 13763361792.000.. \n",
      "Epoch: 222/1000..  Training Loss: 10738107962.514..  Test Loss: 14204687360.000.. \n",
      "Epoch: 223/1000..  Training Loss: 10740196571.429..  Test Loss: 14067296256.000.. \n",
      "Epoch: 224/1000..  Training Loss: 10719804533.029..  Test Loss: 14612378624.000.. \n",
      "Epoch: 225/1000..  Training Loss: 10687680833.829..  Test Loss: 14072774656.000.. \n",
      "Epoch: 226/1000..  Training Loss: 10692533174.857..  Test Loss: 13383273472.000.. \n",
      "Epoch: 227/1000..  Training Loss: 10676461129.143..  Test Loss: 13885477888.000.. \n",
      "Epoch: 228/1000..  Training Loss: 10672597255.314..  Test Loss: 13304858624.000.. \n",
      "Epoch: 229/1000..  Training Loss: 10656068154.514..  Test Loss: 14199769088.000.. \n",
      "Epoch: 230/1000..  Training Loss: 10626011940.571..  Test Loss: 13365108736.000.. \n",
      "Epoch: 231/1000..  Training Loss: 10622137007.543..  Test Loss: 14495571968.000.. \n",
      "Epoch: 232/1000..  Training Loss: 10609200098.743..  Test Loss: 14284163072.000.. \n",
      "Epoch: 233/1000..  Training Loss: 10618332701.257..  Test Loss: 14831852544.000.. \n",
      "Epoch: 234/1000..  Training Loss: 10571408003.657..  Test Loss: 13233157120.000.. \n",
      "Epoch: 235/1000..  Training Loss: 10564303199.086..  Test Loss: 13183692800.000.. \n",
      "Epoch: 236/1000..  Training Loss: 10550606687.086..  Test Loss: 13778911232.000.. \n",
      "Epoch: 237/1000..  Training Loss: 10550188968.229..  Test Loss: 13657144320.000.. \n",
      "Epoch: 238/1000..  Training Loss: 10531276668.343..  Test Loss: 14195108864.000.. \n",
      "Epoch: 239/1000..  Training Loss: 10513906205.257..  Test Loss: 13425310720.000.. \n",
      "Epoch: 240/1000..  Training Loss: 10504338739.200..  Test Loss: 14032491520.000.. \n",
      "Epoch: 241/1000..  Training Loss: 10484858880.000..  Test Loss: 13895526400.000.. \n",
      "Epoch: 242/1000..  Training Loss: 10453003278.629..  Test Loss: 13474847744.000.. \n",
      "Epoch: 243/1000..  Training Loss: 10473988037.486..  Test Loss: 13844229120.000.. \n",
      "Epoch: 244/1000..  Training Loss: 10453140319.086..  Test Loss: 13915809792.000.. \n",
      "Epoch: 245/1000..  Training Loss: 10450869028.571..  Test Loss: 13066219520.000.. \n",
      "Epoch: 246/1000..  Training Loss: 10403797855.086..  Test Loss: 13563280384.000.. \n",
      "Epoch: 247/1000..  Training Loss: 10408697461.029..  Test Loss: 13391438848.000.. \n",
      "Epoch: 248/1000..  Training Loss: 10406236642.743..  Test Loss: 13672432640.000.. \n",
      "Epoch: 249/1000..  Training Loss: 10397766977.829..  Test Loss: 13425130496.000.. \n",
      "Epoch: 250/1000..  Training Loss: 10353689482.971..  Test Loss: 14084024320.000.. \n",
      "Epoch: 251/1000..  Training Loss: 10341633111.771..  Test Loss: 13795316736.000.. \n",
      "Epoch: 252/1000..  Training Loss: 10347831398.400..  Test Loss: 13198194688.000.. \n",
      "Epoch: 253/1000..  Training Loss: 10338622039.771..  Test Loss: 13417551872.000.. \n",
      "Epoch: 254/1000..  Training Loss: 10296126990.629..  Test Loss: 13035705344.000.. \n",
      "Epoch: 255/1000..  Training Loss: 10303679707.429..  Test Loss: 13302373376.000.. \n",
      "Epoch: 256/1000..  Training Loss: 10271285291.886..  Test Loss: 12985149440.000.. \n",
      "Epoch: 257/1000..  Training Loss: 10244456067.657..  Test Loss: 12842584064.000.. \n",
      "Epoch: 258/1000..  Training Loss: 10240417294.629..  Test Loss: 13600689152.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10218611448.686..  Test Loss: 13096510464.000.. \n",
      "Epoch: 260/1000..  Training Loss: 10208105823.086..  Test Loss: 12821076992.000.. \n",
      "Epoch: 261/1000..  Training Loss: 10214100275.200..  Test Loss: 13175974912.000.. \n",
      "Epoch: 262/1000..  Training Loss: 10144459015.314..  Test Loss: 14128845824.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10192241005.714..  Test Loss: 13304394752.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10159764275.200..  Test Loss: 13821750272.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10136855639.771..  Test Loss: 13169601536.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10115673936.457..  Test Loss: 12991294464.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10089136757.029..  Test Loss: 12956332032.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10078196282.514..  Test Loss: 12967313408.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10074350738.286..  Test Loss: 13975382016.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10056176610.743..  Test Loss: 13823098880.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10033925368.686..  Test Loss: 12985469952.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10031883951.543..  Test Loss: 12949548032.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10005195278.629..  Test Loss: 13367613440.000.. \n",
      "Epoch: 274/1000..  Training Loss: 9991287544.686..  Test Loss: 12627450880.000.. \n",
      "Epoch: 275/1000..  Training Loss: 9974948761.600..  Test Loss: 12898579456.000.. \n",
      "Epoch: 276/1000..  Training Loss: 9942240446.171..  Test Loss: 12493614080.000.. \n",
      "Epoch: 277/1000..  Training Loss: 9945508600.686..  Test Loss: 13832486912.000.. \n",
      "Epoch: 278/1000..  Training Loss: 9942140957.257..  Test Loss: 12801374208.000.. \n",
      "Epoch: 279/1000..  Training Loss: 9902698174.171..  Test Loss: 13210289152.000.. \n",
      "Epoch: 280/1000..  Training Loss: 9887601561.600..  Test Loss: 13055560704.000.. \n",
      "Epoch: 281/1000..  Training Loss: 9908411040.914..  Test Loss: 13778400256.000.. \n",
      "Epoch: 282/1000..  Training Loss: 9888449565.257..  Test Loss: 13537938432.000.. \n",
      "Epoch: 283/1000..  Training Loss: 9873814016.000..  Test Loss: 13425677312.000.. \n",
      "Epoch: 284/1000..  Training Loss: 9863051322.514..  Test Loss: 12501788672.000.. \n",
      "Epoch: 285/1000..  Training Loss: 9874029538.743..  Test Loss: 12606982144.000.. \n",
      "Epoch: 286/1000..  Training Loss: 9856482801.371..  Test Loss: 14181877760.000.. \n",
      "Epoch: 287/1000..  Training Loss: 9800427607.771..  Test Loss: 13071612928.000.. \n",
      "Epoch: 288/1000..  Training Loss: 9794408184.686..  Test Loss: 12362358784.000.. \n",
      "Epoch: 289/1000..  Training Loss: 9771024076.800..  Test Loss: 13003990016.000.. \n",
      "Epoch: 290/1000..  Training Loss: 9793330775.771..  Test Loss: 13861188608.000.. \n",
      "Epoch: 291/1000..  Training Loss: 9736144457.143..  Test Loss: 13416360960.000.. \n",
      "Epoch: 292/1000..  Training Loss: 9736713625.600..  Test Loss: 12691175424.000.. \n",
      "Epoch: 293/1000..  Training Loss: 9733842446.629..  Test Loss: 12734332928.000.. \n",
      "Epoch: 294/1000..  Training Loss: 9697563004.343..  Test Loss: 13176548352.000.. \n",
      "Epoch: 295/1000..  Training Loss: 9690650433.829..  Test Loss: 13288459264.000.. \n",
      "Epoch: 296/1000..  Training Loss: 9690309120.000..  Test Loss: 12995446784.000.. \n",
      "Epoch: 297/1000..  Training Loss: 9632419986.286..  Test Loss: 13086338048.000.. \n",
      "Epoch: 298/1000..  Training Loss: 9616994830.629..  Test Loss: 12269007872.000.. \n",
      "Epoch: 299/1000..  Training Loss: 9673996609.829..  Test Loss: 14229007360.000.. \n",
      "Epoch: 300/1000..  Training Loss: 9608945854.171..  Test Loss: 13271526400.000.. \n",
      "Epoch: 301/1000..  Training Loss: 9598249164.800..  Test Loss: 12889558016.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 302/1000..  Training Loss: 9597654206.171..  Test Loss: 12800060416.000.. \n",
      "Epoch: 303/1000..  Training Loss: 9590282137.600..  Test Loss: 12119351296.000.. \n",
      "Epoch: 304/1000..  Training Loss: 9593086420.114..  Test Loss: 12162673664.000.. \n",
      "Epoch: 305/1000..  Training Loss: 9532464069.486..  Test Loss: 12436225024.000.. \n",
      "Epoch: 306/1000..  Training Loss: 9510805006.629..  Test Loss: 12502927360.000.. \n",
      "Epoch: 307/1000..  Training Loss: 9482427772.343..  Test Loss: 12238064640.000.. \n",
      "Epoch: 308/1000..  Training Loss: 9521716560.457..  Test Loss: 12631284736.000.. \n",
      "Epoch: 309/1000..  Training Loss: 9490815963.429..  Test Loss: 12377606144.000.. \n",
      "Epoch: 310/1000..  Training Loss: 9472328777.143..  Test Loss: 12561781760.000.. \n",
      "Epoch: 311/1000..  Training Loss: 9425634157.714..  Test Loss: 12050363392.000.. \n",
      "Epoch: 312/1000..  Training Loss: 9477270103.771..  Test Loss: 11918107648.000.. \n",
      "Epoch: 313/1000..  Training Loss: 9397048905.143..  Test Loss: 12687497216.000.. \n",
      "Epoch: 314/1000..  Training Loss: 9393923598.629..  Test Loss: 13575786496.000.. \n",
      "Epoch: 315/1000..  Training Loss: 9381695795.200..  Test Loss: 12555517952.000.. \n",
      "Epoch: 316/1000..  Training Loss: 9375061109.029..  Test Loss: 12313957376.000.. \n",
      "Epoch: 317/1000..  Training Loss: 9342384098.743..  Test Loss: 13343943680.000.. \n",
      "Epoch: 318/1000..  Training Loss: 9345003461.486..  Test Loss: 12437594112.000.. \n",
      "Epoch: 319/1000..  Training Loss: 9283229359.543..  Test Loss: 12576065536.000.. \n",
      "Epoch: 320/1000..  Training Loss: 9348119581.257..  Test Loss: 12185309184.000.. \n",
      "Epoch: 321/1000..  Training Loss: 9287276602.514..  Test Loss: 13396724736.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9263346922.057..  Test Loss: 12424742912.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9242868706.743..  Test Loss: 12248554496.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9261184351.086..  Test Loss: 12472437760.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9243602651.429..  Test Loss: 11788692480.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9236995803.429..  Test Loss: 11778574336.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9212453931.886..  Test Loss: 12619199488.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9179447530.057..  Test Loss: 12463333376.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9183648636.343..  Test Loss: 11838065664.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9143461493.029..  Test Loss: 11963567104.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9136108426.971..  Test Loss: 12656534528.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9108925337.600..  Test Loss: 12357527552.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9143482558.171..  Test Loss: 12003510272.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9109383138.743..  Test Loss: 12261288960.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9076175140.571..  Test Loss: 12841695232.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9066962651.429..  Test Loss: 12022045696.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9088969098.971..  Test Loss: 12408363008.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9047934303.086..  Test Loss: 12102758400.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9032768453.486..  Test Loss: 12961004544.000.. \n",
      "Epoch: 340/1000..  Training Loss: 8981389670.400..  Test Loss: 11493645312.000.. \n",
      "Epoch: 341/1000..  Training Loss: 8972972236.800..  Test Loss: 12764515328.000.. \n",
      "Epoch: 342/1000..  Training Loss: 8956777779.200..  Test Loss: 11440035840.000.. \n",
      "Epoch: 343/1000..  Training Loss: 8939140695.771..  Test Loss: 11905965056.000.. \n",
      "Epoch: 344/1000..  Training Loss: 8947116734.171..  Test Loss: 11521851392.000.. \n",
      "Epoch: 345/1000..  Training Loss: 8879844161.829..  Test Loss: 13215849472.000.. \n",
      "Epoch: 346/1000..  Training Loss: 8929410223.543..  Test Loss: 11879929856.000.. \n",
      "Epoch: 347/1000..  Training Loss: 8916902005.029..  Test Loss: 11620503552.000.. \n",
      "Epoch: 348/1000..  Training Loss: 8860696049.371..  Test Loss: 11509775360.000.. \n",
      "Epoch: 349/1000..  Training Loss: 8903029116.343..  Test Loss: 12233458688.000.. \n",
      "Epoch: 350/1000..  Training Loss: 8866482439.314..  Test Loss: 12802203648.000.. \n",
      "Epoch: 351/1000..  Training Loss: 8841553598.171..  Test Loss: 11379950592.000.. \n",
      "Epoch: 352/1000..  Training Loss: 8808977466.514..  Test Loss: 12618366976.000.. \n",
      "Epoch: 353/1000..  Training Loss: 8795614485.943..  Test Loss: 11549785088.000.. \n",
      "Epoch: 354/1000..  Training Loss: 8836514406.400..  Test Loss: 12134317056.000.. \n",
      "Epoch: 355/1000..  Training Loss: 8779456585.143..  Test Loss: 11521055744.000.. \n",
      "Epoch: 356/1000..  Training Loss: 8815127464.229..  Test Loss: 12262054912.000.. \n",
      "Epoch: 357/1000..  Training Loss: 8704914373.486..  Test Loss: 11577288704.000.. \n",
      "Epoch: 358/1000..  Training Loss: 8721566529.829..  Test Loss: 13059812352.000.. \n",
      "Epoch: 359/1000..  Training Loss: 8658484721.371..  Test Loss: 11276680192.000.. \n",
      "Epoch: 360/1000..  Training Loss: 8709053440.000..  Test Loss: 12044244992.000.. \n",
      "Epoch: 361/1000..  Training Loss: 8616807365.486..  Test Loss: 11746873344.000.. \n",
      "Epoch: 362/1000..  Training Loss: 8660570331.429..  Test Loss: 11428028416.000.. \n",
      "Epoch: 363/1000..  Training Loss: 8663682779.429..  Test Loss: 11482742784.000.. \n",
      "Epoch: 364/1000..  Training Loss: 8633338221.714..  Test Loss: 11103856640.000.. \n",
      "Epoch: 365/1000..  Training Loss: 8616735071.086..  Test Loss: 11665637376.000.. \n",
      "Epoch: 366/1000..  Training Loss: 8606065751.771..  Test Loss: 11723308032.000.. \n",
      "Epoch: 367/1000..  Training Loss: 8559751709.257..  Test Loss: 11545395200.000.. \n",
      "Epoch: 368/1000..  Training Loss: 8513523346.286..  Test Loss: 11516832768.000.. \n",
      "Epoch: 369/1000..  Training Loss: 8588759946.971..  Test Loss: 13102763008.000.. \n",
      "Epoch: 370/1000..  Training Loss: 8533897201.371..  Test Loss: 11258483712.000.. \n",
      "Epoch: 371/1000..  Training Loss: 8478938419.200..  Test Loss: 11352475648.000.. \n",
      "Epoch: 372/1000..  Training Loss: 8499442044.343..  Test Loss: 11536701440.000.. \n",
      "Epoch: 373/1000..  Training Loss: 8512014058.057..  Test Loss: 11079130112.000.. \n",
      "Epoch: 374/1000..  Training Loss: 8473511789.714..  Test Loss: 11928211456.000.. \n",
      "Epoch: 375/1000..  Training Loss: 8457391967.086..  Test Loss: 11399972864.000.. \n",
      "Epoch: 376/1000..  Training Loss: 8438433645.714..  Test Loss: 11169631232.000.. \n",
      "Epoch: 377/1000..  Training Loss: 8486956778.057..  Test Loss: 11315073024.000.. \n",
      "Epoch: 378/1000..  Training Loss: 8449153828.571..  Test Loss: 12413370368.000.. \n",
      "Epoch: 379/1000..  Training Loss: 8434132260.571..  Test Loss: 11319298048.000.. \n",
      "Epoch: 380/1000..  Training Loss: 8383062688.914..  Test Loss: 11471662080.000.. \n",
      "Epoch: 381/1000..  Training Loss: 8362690633.143..  Test Loss: 11185776640.000.. \n",
      "Epoch: 382/1000..  Training Loss: 8348096029.257..  Test Loss: 11570540544.000.. \n",
      "Epoch: 383/1000..  Training Loss: 8344713479.314..  Test Loss: 11106228224.000.. \n",
      "Epoch: 384/1000..  Training Loss: 8284979872.914..  Test Loss: 11157531648.000.. \n",
      "Epoch: 385/1000..  Training Loss: 8294502517.029..  Test Loss: 10994677760.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8316695903.086..  Test Loss: 11175964672.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8255695030.857..  Test Loss: 10763444224.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8240273627.429..  Test Loss: 11234885632.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8275253730.743..  Test Loss: 10608262144.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8245366023.314..  Test Loss: 10739574784.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8185091993.600..  Test Loss: 11077515264.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8219085736.229..  Test Loss: 11425388544.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8199996284.343..  Test Loss: 12595764224.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8128880683.886..  Test Loss: 11710326784.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8137228273.371..  Test Loss: 10959014912.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8141293641.143..  Test Loss: 10779397120.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8132847228.343..  Test Loss: 11325956096.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8098539066.514..  Test Loss: 10698350592.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8134727680.000..  Test Loss: 10925193216.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8080125381.486..  Test Loss: 10672999424.000.. \n",
      "Epoch: 401/1000..  Training Loss: 8077476044.800..  Test Loss: 11665996800.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 402/1000..  Training Loss: 8041882989.714..  Test Loss: 11000938496.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8025878235.429..  Test Loss: 10628896768.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8002421379.657..  Test Loss: 10992062464.000.. \n",
      "Epoch: 405/1000..  Training Loss: 7980728583.314..  Test Loss: 10935503872.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8002743244.800..  Test Loss: 10409346048.000.. \n",
      "Epoch: 407/1000..  Training Loss: 7979947710.171..  Test Loss: 10396314624.000.. \n",
      "Epoch: 408/1000..  Training Loss: 7995043781.486..  Test Loss: 10639760384.000.. \n",
      "Epoch: 409/1000..  Training Loss: 7938088872.229..  Test Loss: 10775516160.000.. \n",
      "Epoch: 410/1000..  Training Loss: 7936780375.771..  Test Loss: 11048728576.000.. \n",
      "Epoch: 411/1000..  Training Loss: 7893963666.286..  Test Loss: 11471983616.000.. \n",
      "Epoch: 412/1000..  Training Loss: 7876150272.000..  Test Loss: 10793402368.000.. \n",
      "Epoch: 413/1000..  Training Loss: 7914033898.057..  Test Loss: 11193231360.000.. \n",
      "Epoch: 414/1000..  Training Loss: 7820598674.286..  Test Loss: 10735444992.000.. \n",
      "Epoch: 415/1000..  Training Loss: 7889374076.343..  Test Loss: 11622935552.000.. \n",
      "Epoch: 416/1000..  Training Loss: 7803926001.371..  Test Loss: 11223288832.000.. \n",
      "Epoch: 417/1000..  Training Loss: 7829199711.086..  Test Loss: 10132743168.000.. \n",
      "Epoch: 418/1000..  Training Loss: 7766975495.314..  Test Loss: 10445745152.000.. \n",
      "Epoch: 419/1000..  Training Loss: 7795920808.229..  Test Loss: 10549156864.000.. \n",
      "Epoch: 420/1000..  Training Loss: 7818594377.143..  Test Loss: 10449266688.000.. \n",
      "Epoch: 421/1000..  Training Loss: 7775113333.029..  Test Loss: 10223356928.000.. \n",
      "Epoch: 422/1000..  Training Loss: 7770896983.771..  Test Loss: 10418094080.000.. \n",
      "Epoch: 423/1000..  Training Loss: 7708600817.371..  Test Loss: 10718925824.000.. \n",
      "Epoch: 424/1000..  Training Loss: 7698069211.429..  Test Loss: 10746957824.000.. \n",
      "Epoch: 425/1000..  Training Loss: 7695250900.114..  Test Loss: 10374898688.000.. \n",
      "Epoch: 426/1000..  Training Loss: 7704289214.171..  Test Loss: 10071514112.000.. \n",
      "Epoch: 427/1000..  Training Loss: 7643876761.600..  Test Loss: 10396490752.000.. \n",
      "Epoch: 428/1000..  Training Loss: 7686409625.600..  Test Loss: 10463480832.000.. \n",
      "Epoch: 429/1000..  Training Loss: 7660111754.971..  Test Loss: 10233596928.000.. \n",
      "Epoch: 430/1000..  Training Loss: 7659061752.686..  Test Loss: 10591484928.000.. \n",
      "Epoch: 431/1000..  Training Loss: 7621701200.457..  Test Loss: 10199741440.000.. \n",
      "Epoch: 432/1000..  Training Loss: 7567239226.514..  Test Loss: 10586570752.000.. \n",
      "Epoch: 433/1000..  Training Loss: 7594043962.514..  Test Loss: 10746023936.000.. \n",
      "Epoch: 434/1000..  Training Loss: 7591272638.171..  Test Loss: 10922463232.000.. \n",
      "Epoch: 435/1000..  Training Loss: 7506302464.000..  Test Loss: 9997505536.000.. \n",
      "Epoch: 436/1000..  Training Loss: 7575460030.171..  Test Loss: 11093548032.000.. \n",
      "Epoch: 437/1000..  Training Loss: 7490653666.743..  Test Loss: 10070678528.000.. \n",
      "Epoch: 438/1000..  Training Loss: 7472933683.200..  Test Loss: 9950516224.000.. \n",
      "Epoch: 439/1000..  Training Loss: 7490074229.029..  Test Loss: 9833935872.000.. \n",
      "Epoch: 440/1000..  Training Loss: 7497530631.314..  Test Loss: 10171168768.000.. \n",
      "Epoch: 441/1000..  Training Loss: 7452199570.286..  Test Loss: 9950092288.000.. \n",
      "Epoch: 442/1000..  Training Loss: 7424912903.314..  Test Loss: 10256259072.000.. \n",
      "Epoch: 443/1000..  Training Loss: 7403789794.743..  Test Loss: 10583628800.000.. \n",
      "Epoch: 444/1000..  Training Loss: 7464691039.086..  Test Loss: 10309950464.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7422963126.857..  Test Loss: 10342907904.000.. \n",
      "Epoch: 446/1000..  Training Loss: 7359563717.486..  Test Loss: 10684016640.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7357036960.914..  Test Loss: 11367454720.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7362010389.943..  Test Loss: 10229662720.000.. \n",
      "Epoch: 449/1000..  Training Loss: 7353638268.343..  Test Loss: 10595930112.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7290665413.486..  Test Loss: 9680016384.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7308985519.543..  Test Loss: 9712819200.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7338346795.886..  Test Loss: 10068674560.000.. \n",
      "Epoch: 453/1000..  Training Loss: 7293442691.657..  Test Loss: 10135226368.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7281981381.486..  Test Loss: 10219555840.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7239916990.171..  Test Loss: 10345912320.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7243121649.371..  Test Loss: 10480697344.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7175438306.743..  Test Loss: 9841424384.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7212307675.429..  Test Loss: 10580825088.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7216068534.857..  Test Loss: 10331412480.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7168928409.600..  Test Loss: 10396564480.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7160218053.486..  Test Loss: 9578324992.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7100073925.486..  Test Loss: 10209771520.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7124353514.057..  Test Loss: 10503756800.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7152516030.171..  Test Loss: 10619811840.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7082373822.171..  Test Loss: 9932581888.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7084127670.857..  Test Loss: 9687701504.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7054480640.000..  Test Loss: 9789767680.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7022140496.457..  Test Loss: 9402841088.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7018180842.057..  Test Loss: 9887536128.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7067517973.943..  Test Loss: 9637651456.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7044005376.000..  Test Loss: 10147014656.000.. \n",
      "Epoch: 472/1000..  Training Loss: 6960211558.400..  Test Loss: 9702197248.000.. \n",
      "Epoch: 473/1000..  Training Loss: 6917864989.257..  Test Loss: 9473648640.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7035191171.657..  Test Loss: 9810649088.000.. \n",
      "Epoch: 475/1000..  Training Loss: 6914651121.371..  Test Loss: 9773639680.000.. \n",
      "Epoch: 476/1000..  Training Loss: 6929782374.400..  Test Loss: 9514519552.000.. \n",
      "Epoch: 477/1000..  Training Loss: 6928499946.057..  Test Loss: 9792963584.000.. \n",
      "Epoch: 478/1000..  Training Loss: 6964667626.057..  Test Loss: 9865837568.000.. \n",
      "Epoch: 479/1000..  Training Loss: 6909593753.600..  Test Loss: 9846555648.000.. \n",
      "Epoch: 480/1000..  Training Loss: 6823440888.686..  Test Loss: 9430367232.000.. \n",
      "Epoch: 481/1000..  Training Loss: 6863685705.143..  Test Loss: 9272112128.000.. \n",
      "Epoch: 482/1000..  Training Loss: 6850141388.800..  Test Loss: 9431236608.000.. \n",
      "Epoch: 483/1000..  Training Loss: 6850434706.286..  Test Loss: 9350985728.000.. \n",
      "Epoch: 484/1000..  Training Loss: 6776886125.714..  Test Loss: 10197803008.000.. \n",
      "Epoch: 485/1000..  Training Loss: 6828692480.000..  Test Loss: 9220652032.000.. \n",
      "Epoch: 486/1000..  Training Loss: 6769328179.200..  Test Loss: 9732677632.000.. \n",
      "Epoch: 487/1000..  Training Loss: 6778965035.886..  Test Loss: 9257382912.000.. \n",
      "Epoch: 488/1000..  Training Loss: 6715024047.543..  Test Loss: 9510885376.000.. \n",
      "Epoch: 489/1000..  Training Loss: 6633004273.371..  Test Loss: 9228171264.000.. \n",
      "Epoch: 490/1000..  Training Loss: 6707156904.229..  Test Loss: 10049379328.000.. \n",
      "Epoch: 491/1000..  Training Loss: 6681728636.343..  Test Loss: 9440492544.000.. \n",
      "Epoch: 492/1000..  Training Loss: 6701327023.543..  Test Loss: 9307188224.000.. \n",
      "Epoch: 493/1000..  Training Loss: 6652816135.314..  Test Loss: 10024953856.000.. \n",
      "Epoch: 494/1000..  Training Loss: 6688519204.571..  Test Loss: 9591917568.000.. \n",
      "Epoch: 495/1000..  Training Loss: 6593875836.343..  Test Loss: 8834146304.000.. \n",
      "Epoch: 496/1000..  Training Loss: 6558283227.429..  Test Loss: 8828566528.000.. \n",
      "Epoch: 497/1000..  Training Loss: 6596560683.886..  Test Loss: 9321191424.000.. \n",
      "Epoch: 498/1000..  Training Loss: 6551031778.743..  Test Loss: 9413535744.000.. \n",
      "Epoch: 499/1000..  Training Loss: 6547266764.800..  Test Loss: 9410577408.000.. \n",
      "Epoch: 500/1000..  Training Loss: 6581718805.943..  Test Loss: 9344264192.000.. \n",
      "Epoch: 501/1000..  Training Loss: 6530497323.886..  Test Loss: 10035549184.000.. \n",
      "Epoch: 502/1000..  Training Loss: 6507452313.600..  Test Loss: 8919204864.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 503/1000..  Training Loss: 6429039455.086..  Test Loss: 9418103808.000.. \n",
      "Epoch: 504/1000..  Training Loss: 6517950061.714..  Test Loss: 9158310912.000.. \n",
      "Epoch: 505/1000..  Training Loss: 6441916562.286..  Test Loss: 10595212288.000.. \n",
      "Epoch: 506/1000..  Training Loss: 6455664676.571..  Test Loss: 9048393728.000.. \n",
      "Epoch: 507/1000..  Training Loss: 6475858885.486..  Test Loss: 8947080192.000.. \n",
      "Epoch: 508/1000..  Training Loss: 6417376256.000..  Test Loss: 8894618624.000.. \n",
      "Epoch: 509/1000..  Training Loss: 6391852653.714..  Test Loss: 9565035520.000.. \n",
      "Epoch: 510/1000..  Training Loss: 6444616469.943..  Test Loss: 8794999808.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6390027081.143..  Test Loss: 8938780672.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6367032429.714..  Test Loss: 8681574400.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6361038679.771..  Test Loss: 8856160256.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6321306499.657..  Test Loss: 8864295936.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6313131242.057..  Test Loss: 8755484672.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6236681845.029..  Test Loss: 9175861248.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6311079833.600..  Test Loss: 9931820032.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6249263140.571..  Test Loss: 9343167488.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6299713843.200..  Test Loss: 9421009920.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6251466459.429..  Test Loss: 8978786304.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6227290880.000..  Test Loss: 9649620992.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6209778000.457..  Test Loss: 8731825152.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6174053200.457..  Test Loss: 9159961600.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6185690653.257..  Test Loss: 8715676672.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6155549066.971..  Test Loss: 8626121728.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6105936032.914..  Test Loss: 8738683904.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6172952422.400..  Test Loss: 8614908928.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6151468288.000..  Test Loss: 8588614144.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6231260328.229..  Test Loss: 8991467520.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6089383650.743..  Test Loss: 9719293952.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6073896579.657..  Test Loss: 8799339520.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6120462453.029..  Test Loss: 8656741376.000.. \n",
      "Epoch: 533/1000..  Training Loss: 5999685215.086..  Test Loss: 8573507072.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6068798756.571..  Test Loss: 8204743680.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6028017912.686..  Test Loss: 8390856192.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6061003541.943..  Test Loss: 9688000512.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6033636959.086..  Test Loss: 9772924928.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6025011280.457..  Test Loss: 8699652096.000.. \n",
      "Epoch: 539/1000..  Training Loss: 5963309546.057..  Test Loss: 8152454656.000.. \n",
      "Epoch: 540/1000..  Training Loss: 5959425930.971..  Test Loss: 8176031232.000.. \n",
      "Epoch: 541/1000..  Training Loss: 5911259669.943..  Test Loss: 8426374656.000.. \n",
      "Epoch: 542/1000..  Training Loss: 5955524278.857..  Test Loss: 9221508096.000.. \n",
      "Epoch: 543/1000..  Training Loss: 5959704641.829..  Test Loss: 8272434688.000.. \n",
      "Epoch: 544/1000..  Training Loss: 5955577856.000..  Test Loss: 8755051520.000.. \n",
      "Epoch: 545/1000..  Training Loss: 5922770519.771..  Test Loss: 9108329472.000.. \n",
      "Epoch: 546/1000..  Training Loss: 5890317290.057..  Test Loss: 8689200128.000.. \n",
      "Epoch: 547/1000..  Training Loss: 5858031850.057..  Test Loss: 8335264256.000.. \n",
      "Epoch: 548/1000..  Training Loss: 5942359654.400..  Test Loss: 8358064128.000.. \n",
      "Epoch: 549/1000..  Training Loss: 5886210362.514..  Test Loss: 8613897216.000.. \n",
      "Epoch: 550/1000..  Training Loss: 5853629652.114..  Test Loss: 8545000960.000.. \n",
      "Epoch: 551/1000..  Training Loss: 5810203662.629..  Test Loss: 8702730240.000.. \n",
      "Epoch: 552/1000..  Training Loss: 5858583314.286..  Test Loss: 8564718080.000.. \n",
      "Epoch: 553/1000..  Training Loss: 5863670915.657..  Test Loss: 8370971648.000.. \n",
      "Epoch: 554/1000..  Training Loss: 5766407965.257..  Test Loss: 8908434432.000.. \n",
      "Epoch: 555/1000..  Training Loss: 5917994108.343..  Test Loss: 8928427008.000.. \n",
      "Epoch: 556/1000..  Training Loss: 5838187264.000..  Test Loss: 7787747840.000.. \n",
      "Epoch: 557/1000..  Training Loss: 5778336599.771..  Test Loss: 8170323968.000.. \n",
      "Epoch: 558/1000..  Training Loss: 5753347551.086..  Test Loss: 8325575680.000.. \n",
      "Epoch: 559/1000..  Training Loss: 5775585609.143..  Test Loss: 9240800256.000.. \n",
      "Epoch: 560/1000..  Training Loss: 5707677703.314..  Test Loss: 7801047552.000.. \n",
      "Epoch: 561/1000..  Training Loss: 5767580123.429..  Test Loss: 8417932800.000.. \n",
      "Epoch: 562/1000..  Training Loss: 5735015877.486..  Test Loss: 8121449984.000.. \n",
      "Epoch: 563/1000..  Training Loss: 5764828174.629..  Test Loss: 7904834560.000.. \n",
      "Epoch: 564/1000..  Training Loss: 5702243627.886..  Test Loss: 7861904384.000.. \n",
      "Epoch: 565/1000..  Training Loss: 5657061741.714..  Test Loss: 8228818944.000.. \n",
      "Epoch: 566/1000..  Training Loss: 5658624841.143..  Test Loss: 8106528256.000.. \n",
      "Epoch: 567/1000..  Training Loss: 5703772357.486..  Test Loss: 7816161792.000.. \n",
      "Epoch: 568/1000..  Training Loss: 5647598657.829..  Test Loss: 8027915776.000.. \n",
      "Epoch: 569/1000..  Training Loss: 5642687692.800..  Test Loss: 7870819840.000.. \n",
      "Epoch: 570/1000..  Training Loss: 5597827064.686..  Test Loss: 8152177152.000.. \n",
      "Epoch: 571/1000..  Training Loss: 5604726805.943..  Test Loss: 8427482624.000.. \n",
      "Epoch: 572/1000..  Training Loss: 5671595637.029..  Test Loss: 8491236864.000.. \n",
      "Epoch: 573/1000..  Training Loss: 5591001073.371..  Test Loss: 8051677696.000.. \n",
      "Epoch: 574/1000..  Training Loss: 5567341568.000..  Test Loss: 7901989376.000.. \n",
      "Epoch: 575/1000..  Training Loss: 5631352268.800..  Test Loss: 7583749120.000.. \n",
      "Epoch: 576/1000..  Training Loss: 5577486167.771..  Test Loss: 7826562560.000.. \n",
      "Epoch: 577/1000..  Training Loss: 5542111327.086..  Test Loss: 7598391296.000.. \n",
      "Epoch: 578/1000..  Training Loss: 5570665918.171..  Test Loss: 7701998080.000.. \n",
      "Epoch: 579/1000..  Training Loss: 5528491373.714..  Test Loss: 7736000000.000.. \n",
      "Epoch: 580/1000..  Training Loss: 5545099000.686..  Test Loss: 7554436608.000.. \n",
      "Epoch: 581/1000..  Training Loss: 5472421193.143..  Test Loss: 7902086656.000.. \n",
      "Epoch: 582/1000..  Training Loss: 5503409525.029..  Test Loss: 7986380288.000.. \n",
      "Epoch: 583/1000..  Training Loss: 5490782515.200..  Test Loss: 8317016576.000.. \n",
      "Epoch: 584/1000..  Training Loss: 5452765944.686..  Test Loss: 7622665216.000.. \n",
      "Epoch: 585/1000..  Training Loss: 5500017649.371..  Test Loss: 8267516416.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5435700271.543..  Test Loss: 7641483776.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5446421613.714..  Test Loss: 7514753536.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5441752758.857..  Test Loss: 8493473280.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5445018624.000..  Test Loss: 7447147520.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5430780072.229..  Test Loss: 7725995520.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5355590202.514..  Test Loss: 7865910272.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5322860617.143..  Test Loss: 8609317888.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5374330368.000..  Test Loss: 7550997504.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5362727299.657..  Test Loss: 7539990528.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5382031557.486..  Test Loss: 7867862528.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5308888502.857..  Test Loss: 7234985984.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5328235110.400..  Test Loss: 8595628032.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5308605213.257..  Test Loss: 7428523008.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5324994282.057..  Test Loss: 7473841152.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5309587434.057..  Test Loss: 7268077568.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5329961589.029..  Test Loss: 7753396224.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5258518008.686..  Test Loss: 8379746816.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5278806308.571..  Test Loss: 7967118848.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5214247541.029..  Test Loss: 7524961792.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 605/1000..  Training Loss: 5259858907.429..  Test Loss: 7871129088.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5213382414.629..  Test Loss: 7296440832.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5249274744.686..  Test Loss: 7480967168.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5150644794.514..  Test Loss: 7847667200.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5251508114.286..  Test Loss: 7315163648.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5231954161.371..  Test Loss: 7453594624.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5196398877.257..  Test Loss: 8217703424.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5238325101.714..  Test Loss: 7396624896.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5122337448.229..  Test Loss: 7003514368.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5173334842.514..  Test Loss: 8601771008.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5159837432.686..  Test Loss: 7072259584.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5117183729.371..  Test Loss: 8105735680.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5120281102.629..  Test Loss: 7011958784.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5126276864.000..  Test Loss: 7805190144.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5204920195.657..  Test Loss: 7961425408.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5122079363.657..  Test Loss: 7465660416.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5084932030.171..  Test Loss: 7564392960.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5079560652.800..  Test Loss: 7883400192.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5118429001.143..  Test Loss: 7305195520.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5072017561.600..  Test Loss: 6975605248.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5061591314.286..  Test Loss: 7225612800.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5047191142.400..  Test Loss: 7312862720.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5016580480.000..  Test Loss: 7054255104.000.. \n",
      "Epoch: 628/1000..  Training Loss: 4977375868.343..  Test Loss: 7433220096.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5004104016.457..  Test Loss: 7100751360.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5064532575.086..  Test Loss: 6859032064.000.. \n",
      "Epoch: 631/1000..  Training Loss: 4938065890.743..  Test Loss: 6992963072.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5002073925.486..  Test Loss: 7748064256.000.. \n",
      "Epoch: 633/1000..  Training Loss: 4950816043.886..  Test Loss: 7050415616.000.. \n",
      "Epoch: 634/1000..  Training Loss: 4986443095.771..  Test Loss: 7391966720.000.. \n",
      "Epoch: 635/1000..  Training Loss: 4957807835.429..  Test Loss: 7543574528.000.. \n",
      "Epoch: 636/1000..  Training Loss: 4930348858.514..  Test Loss: 7358387712.000.. \n",
      "Epoch: 637/1000..  Training Loss: 4937910835.200..  Test Loss: 7177043968.000.. \n",
      "Epoch: 638/1000..  Training Loss: 4951536800.914..  Test Loss: 7534845440.000.. \n",
      "Epoch: 639/1000..  Training Loss: 4916302745.600..  Test Loss: 7892853760.000.. \n",
      "Epoch: 640/1000..  Training Loss: 4948472517.486..  Test Loss: 7394905600.000.. \n",
      "Epoch: 641/1000..  Training Loss: 4946504484.571..  Test Loss: 7115542528.000.. \n",
      "Epoch: 642/1000..  Training Loss: 4922550996.114..  Test Loss: 6707271168.000.. \n",
      "Epoch: 643/1000..  Training Loss: 4939594064.457..  Test Loss: 6965607936.000.. \n",
      "Epoch: 644/1000..  Training Loss: 4914993510.400..  Test Loss: 6760863744.000.. \n",
      "Epoch: 645/1000..  Training Loss: 4957096974.629..  Test Loss: 6695759360.000.. \n",
      "Epoch: 646/1000..  Training Loss: 4893435977.143..  Test Loss: 7245669888.000.. \n",
      "Epoch: 647/1000..  Training Loss: 4838378122.971..  Test Loss: 7767824896.000.. \n",
      "Epoch: 648/1000..  Training Loss: 4886286116.571..  Test Loss: 6568477696.000.. \n",
      "Epoch: 649/1000..  Training Loss: 4876798529.829..  Test Loss: 6814014976.000.. \n",
      "Epoch: 650/1000..  Training Loss: 4941575818.971..  Test Loss: 7147549696.000.. \n",
      "Epoch: 651/1000..  Training Loss: 4861725849.600..  Test Loss: 7664784384.000.. \n",
      "Epoch: 652/1000..  Training Loss: 4845355523.657..  Test Loss: 6835088384.000.. \n",
      "Epoch: 653/1000..  Training Loss: 4795978049.829..  Test Loss: 6757972480.000.. \n",
      "Epoch: 654/1000..  Training Loss: 4893712903.314..  Test Loss: 6769900032.000.. \n",
      "Epoch: 655/1000..  Training Loss: 4863073162.971..  Test Loss: 8096550400.000.. \n",
      "Epoch: 656/1000..  Training Loss: 4772081408.000..  Test Loss: 6625846784.000.. \n",
      "Epoch: 657/1000..  Training Loss: 4814108277.029..  Test Loss: 6871897088.000.. \n",
      "Epoch: 658/1000..  Training Loss: 4829753600.000..  Test Loss: 6827171328.000.. \n",
      "Epoch: 659/1000..  Training Loss: 4774898241.829..  Test Loss: 7041332224.000.. \n",
      "Epoch: 660/1000..  Training Loss: 4800078050.743..  Test Loss: 6774690816.000.. \n",
      "Epoch: 661/1000..  Training Loss: 4795531680.914..  Test Loss: 6386901504.000.. \n",
      "Epoch: 662/1000..  Training Loss: 4769662833.371..  Test Loss: 6783874048.000.. \n",
      "Epoch: 663/1000..  Training Loss: 4807730490.514..  Test Loss: 6493372928.000.. \n",
      "Epoch: 664/1000..  Training Loss: 4813063555.657..  Test Loss: 7102848512.000.. \n",
      "Epoch: 665/1000..  Training Loss: 4772740527.543..  Test Loss: 7376786432.000.. \n",
      "Epoch: 666/1000..  Training Loss: 4787399186.286..  Test Loss: 6477101056.000.. \n",
      "Epoch: 667/1000..  Training Loss: 4741030736.457..  Test Loss: 6697208832.000.. \n",
      "Epoch: 668/1000..  Training Loss: 4760820516.571..  Test Loss: 7335107072.000.. \n",
      "Epoch: 669/1000..  Training Loss: 4759286776.686..  Test Loss: 6317101056.000.. \n",
      "Epoch: 670/1000..  Training Loss: 4716005134.629..  Test Loss: 6690770432.000.. \n",
      "Epoch: 671/1000..  Training Loss: 4711289870.629..  Test Loss: 6690684416.000.. \n",
      "Epoch: 672/1000..  Training Loss: 4638912226.743..  Test Loss: 6618251264.000.. \n",
      "Epoch: 673/1000..  Training Loss: 4734973699.657..  Test Loss: 6423114240.000.. \n",
      "Epoch: 674/1000..  Training Loss: 4706659353.600..  Test Loss: 6489874432.000.. \n",
      "Epoch: 675/1000..  Training Loss: 4717642649.600..  Test Loss: 6617384448.000.. \n",
      "Epoch: 676/1000..  Training Loss: 4682316587.886..  Test Loss: 7252839936.000.. \n",
      "Epoch: 677/1000..  Training Loss: 4646655959.771..  Test Loss: 6984687616.000.. \n",
      "Epoch: 678/1000..  Training Loss: 4702432438.857..  Test Loss: 6418677248.000.. \n",
      "Epoch: 679/1000..  Training Loss: 4675450609.371..  Test Loss: 7144062976.000.. \n",
      "Epoch: 680/1000..  Training Loss: 4693158239.086..  Test Loss: 6660672512.000.. \n",
      "Epoch: 681/1000..  Training Loss: 4696155523.657..  Test Loss: 6383535616.000.. \n",
      "Epoch: 682/1000..  Training Loss: 4677263206.400..  Test Loss: 6222700032.000.. \n",
      "Epoch: 683/1000..  Training Loss: 4678050252.800..  Test Loss: 6515422208.000.. \n",
      "Epoch: 684/1000..  Training Loss: 4648279844.571..  Test Loss: 6497659392.000.. \n",
      "Epoch: 685/1000..  Training Loss: 4676317845.943..  Test Loss: 6658186752.000.. \n",
      "Epoch: 686/1000..  Training Loss: 4599303197.257..  Test Loss: 6198107648.000.. \n",
      "Epoch: 687/1000..  Training Loss: 4698969782.857..  Test Loss: 6234576384.000.. \n",
      "Epoch: 688/1000..  Training Loss: 4688073241.600..  Test Loss: 6941396992.000.. \n",
      "Epoch: 689/1000..  Training Loss: 4589593044.114..  Test Loss: 6666783232.000.. \n",
      "Epoch: 690/1000..  Training Loss: 4573485743.543..  Test Loss: 6264686592.000.. \n",
      "Epoch: 691/1000..  Training Loss: 4604314207.086..  Test Loss: 6774175232.000.. \n",
      "Epoch: 692/1000..  Training Loss: 4634698229.029..  Test Loss: 6581921792.000.. \n",
      "Epoch: 693/1000..  Training Loss: 4658176837.486..  Test Loss: 6453769728.000.. \n",
      "Epoch: 694/1000..  Training Loss: 4588164271.543..  Test Loss: 6251310592.000.. \n",
      "Epoch: 695/1000..  Training Loss: 4611820712.229..  Test Loss: 6517518336.000.. \n",
      "Epoch: 696/1000..  Training Loss: 4711384188.343..  Test Loss: 6066841600.000.. \n",
      "Epoch: 697/1000..  Training Loss: 4580642421.029..  Test Loss: 6223736832.000.. \n",
      "Epoch: 698/1000..  Training Loss: 4559220501.943..  Test Loss: 6316695552.000.. \n",
      "Epoch: 699/1000..  Training Loss: 4566847978.057..  Test Loss: 6379648000.000.. \n",
      "Epoch: 700/1000..  Training Loss: 4600817788.343..  Test Loss: 6268949504.000.. \n",
      "Epoch: 701/1000..  Training Loss: 4552335930.514..  Test Loss: 6420069888.000.. \n",
      "Epoch: 702/1000..  Training Loss: 4506474393.600..  Test Loss: 6860926464.000.. \n",
      "Epoch: 703/1000..  Training Loss: 4629395002.514..  Test Loss: 6254474240.000.. \n",
      "Epoch: 704/1000..  Training Loss: 4549244522.057..  Test Loss: 6738480128.000.. \n",
      "Epoch: 705/1000..  Training Loss: 4519987521.829..  Test Loss: 6015235072.000.. \n",
      "Epoch: 706/1000..  Training Loss: 4544720252.343..  Test Loss: 6340684800.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 707/1000..  Training Loss: 4582533544.229..  Test Loss: 5973289984.000.. \n",
      "Epoch: 708/1000..  Training Loss: 4485167488.000..  Test Loss: 6740759552.000.. \n",
      "Epoch: 709/1000..  Training Loss: 4552051090.286..  Test Loss: 6027549184.000.. \n",
      "Epoch: 710/1000..  Training Loss: 4510674110.171..  Test Loss: 6273014272.000.. \n",
      "Epoch: 711/1000..  Training Loss: 4488514208.914..  Test Loss: 5928653312.000.. \n",
      "Epoch: 712/1000..  Training Loss: 4542912329.143..  Test Loss: 5911382016.000.. \n",
      "Epoch: 713/1000..  Training Loss: 4519859931.429..  Test Loss: 5936897024.000.. \n",
      "Epoch: 714/1000..  Training Loss: 4462409172.114..  Test Loss: 6020154880.000.. \n",
      "Epoch: 715/1000..  Training Loss: 4550862310.400..  Test Loss: 5985801216.000.. \n",
      "Epoch: 716/1000..  Training Loss: 4510479074.743..  Test Loss: 6982106624.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4473304261.486..  Test Loss: 6520206336.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4503150752.914..  Test Loss: 5935517184.000.. \n",
      "Epoch: 719/1000..  Training Loss: 4456384987.429..  Test Loss: 7878610432.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4495661941.029..  Test Loss: 6365775872.000.. \n",
      "Epoch: 721/1000..  Training Loss: 4461211936.914..  Test Loss: 5947225088.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4512595104.914..  Test Loss: 6207176704.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4466525279.086..  Test Loss: 6697818624.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4442956214.857..  Test Loss: 5876678656.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4493519930.514..  Test Loss: 6070530560.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4466926138.514..  Test Loss: 6354112000.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4434995013.486..  Test Loss: 6185637376.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4494091893.029..  Test Loss: 6046482432.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4475998822.400..  Test Loss: 5813925376.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4405890757.486..  Test Loss: 6109217792.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4435125986.743..  Test Loss: 6425259008.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4430581525.943..  Test Loss: 5761889280.000.. \n",
      "Epoch: 733/1000..  Training Loss: 4459996657.371..  Test Loss: 5719097344.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4475439850.057..  Test Loss: 5745008128.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4430998765.714..  Test Loss: 6477431296.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4463593537.829..  Test Loss: 6133809152.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4435314541.714..  Test Loss: 5785068544.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4435372485.486..  Test Loss: 6179923456.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4445425188.571..  Test Loss: 5801955328.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4418385290.971..  Test Loss: 5943095808.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4364088663.771..  Test Loss: 5943353856.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4392197434.514..  Test Loss: 6377786880.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4469320674.743..  Test Loss: 5768669184.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4494503047.314..  Test Loss: 5983294464.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4443066258.286..  Test Loss: 6027483136.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4422663570.286..  Test Loss: 6701258240.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4355786869.029..  Test Loss: 6144483328.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4465805824.000..  Test Loss: 5884241408.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4392853269.943..  Test Loss: 6008894464.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4421800023.771..  Test Loss: 6097495552.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4366460035.657..  Test Loss: 5870631936.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4407468785.371..  Test Loss: 5705256960.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4394700631.771..  Test Loss: 5825249792.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4406679844.571..  Test Loss: 6306395648.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4413555635.200..  Test Loss: 5853193216.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4342629397.943..  Test Loss: 5854767616.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4430475351.771..  Test Loss: 6420851200.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4405112864.914..  Test Loss: 6261882368.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4372388103.314..  Test Loss: 5669090304.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4411300809.143..  Test Loss: 5907098112.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4436629467.429..  Test Loss: 5744887296.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4366761998.629..  Test Loss: 6347033600.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4351629750.857..  Test Loss: 6673196544.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4358170631.314..  Test Loss: 5538583040.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4405592970.971..  Test Loss: 5632745472.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4335856398.629..  Test Loss: 6108814848.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4344777654.857..  Test Loss: 5536002560.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4453605653.943..  Test Loss: 6582005760.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4341105546.971..  Test Loss: 5915643392.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4377993428.114..  Test Loss: 5845720576.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4383369281.829..  Test Loss: 6775075840.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4366116355.657..  Test Loss: 5473573376.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4318210984.229..  Test Loss: 6111288832.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4361341125.486..  Test Loss: 6780651008.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4310690260.114..  Test Loss: 6209146880.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4387917414.400..  Test Loss: 5476519936.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4314104056.686..  Test Loss: 5830179840.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4355823915.886..  Test Loss: 5600634368.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4329131560.229..  Test Loss: 5494410240.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4406549774.629..  Test Loss: 5670701056.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4316552674.743..  Test Loss: 5596718592.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4405966701.714..  Test Loss: 5850702336.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4360228099.657..  Test Loss: 5485751808.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4346043293.257..  Test Loss: 5849373184.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4350434165.029..  Test Loss: 5458003456.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4330635838.171..  Test Loss: 6003193344.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4335240689.371..  Test Loss: 5405319680.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4352810686.171..  Test Loss: 5553740800.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4336672537.600..  Test Loss: 5862464000.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4278255140.571..  Test Loss: 5425388032.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4374674194.286..  Test Loss: 6336190976.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4338549840.457..  Test Loss: 5562154496.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4324100315.429..  Test Loss: 5602127872.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4297821893.486..  Test Loss: 5448051712.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4308630312.229..  Test Loss: 5498583552.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4307208287.086..  Test Loss: 6061430272.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4351827807.086..  Test Loss: 6089340416.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4334855058.286..  Test Loss: 5551937024.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4320072352.914..  Test Loss: 5576837120.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4306068977.371..  Test Loss: 6197067776.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4321425239.771..  Test Loss: 5941815808.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4307890293.029..  Test Loss: 5409033728.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4332649621.943..  Test Loss: 5793517568.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4327281568.914..  Test Loss: 5522353664.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4282965452.800..  Test Loss: 5478534656.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4280804659.200..  Test Loss: 6896537088.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4306602404.571..  Test Loss: 5706818560.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4331763770.514..  Test Loss: 5770925568.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 809/1000..  Training Loss: 4338781096.229..  Test Loss: 5596061696.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4313038500.571..  Test Loss: 5613283328.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4365875006.171..  Test Loss: 5367595520.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4280495725.714..  Test Loss: 5498762752.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4274877805.714..  Test Loss: 5786848768.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4297410311.314..  Test Loss: 5367453696.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4358283307.886..  Test Loss: 6074136064.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4280719758.629..  Test Loss: 5687689216.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4288400512.000..  Test Loss: 6109568512.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4335200643.657..  Test Loss: 5707776512.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4293550343.314..  Test Loss: 6013563392.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4353635733.943..  Test Loss: 5296778752.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4314435463.314..  Test Loss: 5635390464.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4270949332.114..  Test Loss: 6062529024.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4294514761.143..  Test Loss: 5376416768.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4364973568.000..  Test Loss: 6409657856.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4315281455.543..  Test Loss: 5609170432.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4330403349.943..  Test Loss: 5999609344.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4345315430.400..  Test Loss: 5804143616.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4308753473.829..  Test Loss: 5285283328.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4333066645.943..  Test Loss: 5668250624.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4292010912.914..  Test Loss: 5815549952.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4269160802.743..  Test Loss: 5406095872.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4284286727.314..  Test Loss: 5442685440.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4186077871.543..  Test Loss: 5710538240.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4268156576.914..  Test Loss: 5969903104.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4275487049.143..  Test Loss: 5401972224.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4308482172.343..  Test Loss: 5845423616.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4289408976.457..  Test Loss: 5254350848.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4271535937.829..  Test Loss: 6351425536.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4269663824.457..  Test Loss: 5462434816.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4305090720.914..  Test Loss: 5442568704.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4279327802.514..  Test Loss: 5326630912.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4311069396.114..  Test Loss: 5348697600.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4255729890.743..  Test Loss: 5602444800.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4308920407.771..  Test Loss: 6133824000.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4288014895.543..  Test Loss: 5927800832.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4280858071.771..  Test Loss: 5242115072.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4287490241.829..  Test Loss: 5310977536.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4329163161.600..  Test Loss: 6124436992.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4310431056.457..  Test Loss: 5479679488.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4258295767.771..  Test Loss: 5839529472.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4273537784.686..  Test Loss: 5573612544.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4325345034.971..  Test Loss: 6068125696.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4328359116.800..  Test Loss: 5219311104.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4290149390.629..  Test Loss: 5184750592.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4330772187.429..  Test Loss: 5730599424.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4305886763.886..  Test Loss: 5252523520.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4286044891.429..  Test Loss: 5560159744.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4302903712.914..  Test Loss: 6122996736.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4273412205.714..  Test Loss: 6285569536.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4317162627.657..  Test Loss: 5906278912.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4358719275.886..  Test Loss: 5451938304.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4315847047.314..  Test Loss: 5879846400.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4350004480.000..  Test Loss: 5866146816.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4232245430.857..  Test Loss: 5308116480.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4267791989.029..  Test Loss: 6263903744.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4260510727.314..  Test Loss: 5511353344.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4232208270.629..  Test Loss: 5351955968.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4324195342.629..  Test Loss: 5220918784.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4289401687.771..  Test Loss: 5167609856.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4322157297.371..  Test Loss: 6084597248.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4254116743.314..  Test Loss: 5252195840.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4269011353.600..  Test Loss: 5391987200.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4271739801.600..  Test Loss: 5340462080.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4247077686.857..  Test Loss: 6050445824.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4306718175.086..  Test Loss: 5272110592.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4311055323.429..  Test Loss: 5476228096.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4303879372.800..  Test Loss: 5556467712.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4254644926.171..  Test Loss: 5450039808.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4241234673.371..  Test Loss: 6326458880.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4305281009.371..  Test Loss: 5178124800.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4282373844.114..  Test Loss: 5223814144.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4297351453.257..  Test Loss: 5640065024.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4285276843.886..  Test Loss: 5617025024.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4249496239.543..  Test Loss: 5544601088.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4251479372.800..  Test Loss: 5495059968.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4295694270.171..  Test Loss: 5475054592.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4330990306.743..  Test Loss: 5706973184.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4223627402.971..  Test Loss: 5769936384.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4282633183.086..  Test Loss: 5143636480.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4321510012.343..  Test Loss: 5497867776.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4237065603.657..  Test Loss: 5257998848.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4291280958.171..  Test Loss: 5286422016.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4274806440.229..  Test Loss: 6156482560.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4220107600.457..  Test Loss: 5258735104.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4292896292.571..  Test Loss: 5687523840.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4200866194.286..  Test Loss: 5400239616.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4277750213.486..  Test Loss: 5735955968.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4263134116.571..  Test Loss: 6077723648.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4248849444.571..  Test Loss: 5277096448.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4289211677.257..  Test Loss: 5422238720.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4268247829.943..  Test Loss: 5326202880.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4286678491.429..  Test Loss: 5237851136.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4240223019.886..  Test Loss: 5427213312.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4298842609.371..  Test Loss: 5435404800.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4238943714.743..  Test Loss: 5269239296.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4317577486.629..  Test Loss: 5264590336.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4233315145.143..  Test Loss: 5418383872.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4292702537.143..  Test Loss: 5158772224.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4324172653.714..  Test Loss: 5197955072.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4310647105.829..  Test Loss: 5193375744.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 911/1000..  Training Loss: 4240629705.143..  Test Loss: 5200855040.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4287711941.486..  Test Loss: 6336897536.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4276978768.457..  Test Loss: 5471086080.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4261664512.000..  Test Loss: 5203554304.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4285126736.457..  Test Loss: 5288817152.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4233980558.629..  Test Loss: 5152904704.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4246422008.686..  Test Loss: 5309124608.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4315710003.200..  Test Loss: 5418955776.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4278514797.714..  Test Loss: 6252338688.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4314565602.743..  Test Loss: 5270299648.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4259667434.057..  Test Loss: 5247622656.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4249065055.086..  Test Loss: 5503545344.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4299563026.286..  Test Loss: 5356163072.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4247909332.114..  Test Loss: 5629068800.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4271071626.971..  Test Loss: 5404455424.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4214139040.914..  Test Loss: 5364226048.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4250364401.371..  Test Loss: 5275106816.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4285209406.171..  Test Loss: 5152521728.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4262987991.771..  Test Loss: 5610399232.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4220559539.200..  Test Loss: 5263357440.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4274391946.971..  Test Loss: 5339634688.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4300563426.743..  Test Loss: 6106451456.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4275671208.229..  Test Loss: 5381583872.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4255077909.943..  Test Loss: 6071094272.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4246509187.657..  Test Loss: 6075415552.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4267398835.200..  Test Loss: 5488787456.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4233711279.543..  Test Loss: 5233036800.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4278783729.371..  Test Loss: 5428559360.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4259826600.229..  Test Loss: 5571019264.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4272423972.571..  Test Loss: 5508741120.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4231970713.600..  Test Loss: 6190907904.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4253071890.286..  Test Loss: 5373635584.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4213875770.514..  Test Loss: 5123086848.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4264178753.829..  Test Loss: 5128779264.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4233364842.057..  Test Loss: 5186126848.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4218737415.314..  Test Loss: 5285735936.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4215866126.629..  Test Loss: 5650791936.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4279031669.029..  Test Loss: 5148154368.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4180823808.000..  Test Loss: 5566874112.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4260235198.171..  Test Loss: 5716489216.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4263129534.171..  Test Loss: 5277817856.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4246406107.429..  Test Loss: 5092513280.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4270540412.343..  Test Loss: 5287350784.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4266167610.514..  Test Loss: 5867183616.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4240343895.771..  Test Loss: 5509781504.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4255905700.571..  Test Loss: 5832216576.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4258861341.257..  Test Loss: 5282091520.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4240595002.514..  Test Loss: 5230004736.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4243985075.200..  Test Loss: 5699986944.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4227765972.114..  Test Loss: 5521861120.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4293411876.571..  Test Loss: 5152524288.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4241542443.886..  Test Loss: 5293290496.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4232297055.086..  Test Loss: 5438459392.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4212517141.943..  Test Loss: 5367042048.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4214998608.457..  Test Loss: 5139902464.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4198231018.057..  Test Loss: 5939414016.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4249305387.886..  Test Loss: 5184544256.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4242318427.429..  Test Loss: 5477741568.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4282869350.400..  Test Loss: 5767382528.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4246964260.571..  Test Loss: 6154385920.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4249371611.429..  Test Loss: 5233762304.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4250355551.086..  Test Loss: 5149417472.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4236558123.886..  Test Loss: 5385263104.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4264854169.600..  Test Loss: 5572173312.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4235212580.571..  Test Loss: 5241317376.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4243858622.171..  Test Loss: 5099314176.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4237445405.257..  Test Loss: 5274146304.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4265738510.629..  Test Loss: 5254371328.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4251197432.686..  Test Loss: 5230278656.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4250059973.486..  Test Loss: 5231451136.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4240951274.057..  Test Loss: 5092106240.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4273152080.457..  Test Loss: 5089347584.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4226559700.114..  Test Loss: 6094807040.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4206309394.286..  Test Loss: 5244716544.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4251072416.914..  Test Loss: 5410322944.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4292908946.286..  Test Loss: 5254075904.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4195419253.029..  Test Loss: 5880151040.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4244924723.200..  Test Loss: 5548127232.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4243419267.657..  Test Loss: 5306967040.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4248420505.600..  Test Loss: 5740764672.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4284444057.600..  Test Loss: 5125897728.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4271448766.171..  Test Loss: 5388193280.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4218913755.429..  Test Loss: 5071349248.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4210777369.600..  Test Loss: 5359779328.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4219204600.686..  Test Loss: 5567125504.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4227720352.914..  Test Loss: 5384556032.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4218824557.714..  Test Loss: 5284915712.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4213999162.514..  Test Loss: 5260499456.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4226253867.886..  Test Loss: 5151161344.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4213357626.514..  Test Loss: 5079583232.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 3\n",
      "Epoch: 1/1000..  Training Loss: 13536281486.222..  Test Loss: 12812148736.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13525072170.667..  Test Loss: 12515994624.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13491487459.556..  Test Loss: 12672442368.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13472110520.889..  Test Loss: 12559864832.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13448138595.556..  Test Loss: 12700618752.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13523776028.444..  Test Loss: 12631339008.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13518634666.667..  Test Loss: 12642081792.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13529272604.444..  Test Loss: 12994646016.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13517327701.333..  Test Loss: 12683692032.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13587248625.778..  Test Loss: 12677635072.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13507817713.778..  Test Loss: 12836400128.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13473678904.889..  Test Loss: 12749394944.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13465182862.222..  Test Loss: 12644883456.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13480502101.333..  Test Loss: 12625516544.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13431594965.333..  Test Loss: 12420748288.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13541129912.889..  Test Loss: 12693916672.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13483388444.444..  Test Loss: 12510840832.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13499421610.667..  Test Loss: 12728125440.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13457600995.556..  Test Loss: 12853531648.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13438799189.333..  Test Loss: 12899341312.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13527995875.556..  Test Loss: 12873956352.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13447136341.333..  Test Loss: 12507179008.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13434199381.333..  Test Loss: 12584667136.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13539098481.778..  Test Loss: 13005001728.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13450469091.556..  Test Loss: 12489261056.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13472734890.667..  Test Loss: 12834026496.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13447954545.778..  Test Loss: 13024892928.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13437359360.000..  Test Loss: 12485785600.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13393688789.333..  Test Loss: 12437839872.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13409854264.889..  Test Loss: 12681096192.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13457269973.333..  Test Loss: 12653382656.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13394161180.444..  Test Loss: 12863894528.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13404961536.000..  Test Loss: 12419408896.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13414196664.889..  Test Loss: 12592591872.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13450328689.778..  Test Loss: 12864260096.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13440353095.111..  Test Loss: 12823541760.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13439463168.000..  Test Loss: 12521483264.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13400182556.444..  Test Loss: 12550889472.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13388476373.333..  Test Loss: 13008419840.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13460475932.444..  Test Loss: 12413137920.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13435194680.889..  Test Loss: 12499374080.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13409718300.444..  Test Loss: 12729586688.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13417582620.444..  Test Loss: 12660922368.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13389204195.556..  Test Loss: 12826433536.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13391484643.556..  Test Loss: 12460581888.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13367047466.667..  Test Loss: 12866757632.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13355570972.444..  Test Loss: 12784617472.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13359535587.556..  Test Loss: 12304749568.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13337349404.444..  Test Loss: 12638704640.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13361855872.000..  Test Loss: 12581860352.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13288420209.778..  Test Loss: 12579312640.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13346250567.111..  Test Loss: 12371659776.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13385721216.000..  Test Loss: 12501130240.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13363840256.000..  Test Loss: 13013568512.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13298669539.556..  Test Loss: 12128178176.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13349534350.222..  Test Loss: 12273459200.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13275849059.556..  Test Loss: 13129313280.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13299116088.889..  Test Loss: 12376141824.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13288465806.222..  Test Loss: 12254889984.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13276522908.444..  Test Loss: 12501480448.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13229746133.333..  Test Loss: 12536165376.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13267766954.667..  Test Loss: 12751884288.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13274204558.222..  Test Loss: 12402548736.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13213708785.778..  Test Loss: 12226437120.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13217696640.000..  Test Loss: 12163118080.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13277643605.333..  Test Loss: 12291969024.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13253251726.222..  Test Loss: 12422551552.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13219971271.111..  Test Loss: 12309446656.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13244719644.444..  Test Loss: 12917633024.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13209754168.889..  Test Loss: 12032516096.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13170256924.444..  Test Loss: 12556673024.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13166807424.000..  Test Loss: 12594574336.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13184598755.556..  Test Loss: 12092834816.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13191343018.667..  Test Loss: 12435811328.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13220837831.111..  Test Loss: 12208291840.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13180674901.333..  Test Loss: 12335484928.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13251339235.556..  Test Loss: 12228342784.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13113911950.222..  Test Loss: 12224100352.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13188778424.889..  Test Loss: 12651626496.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13155115747.556..  Test Loss: 12139879424.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13203265934.222..  Test Loss: 12255181824.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13112747960.889..  Test Loss: 12204982272.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13125009464.889..  Test Loss: 12558850048.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13070114161.778..  Test Loss: 12681850880.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13097956024.889..  Test Loss: 12275279872.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13122852437.333..  Test Loss: 12119942144.000.. \n",
      "Epoch: 87/1000..  Training Loss: 13050467356.444..  Test Loss: 12932928512.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13097237191.111..  Test Loss: 12457448448.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13052825315.556..  Test Loss: 12277442560.000.. \n",
      "Epoch: 90/1000..  Training Loss: 13101564984.889..  Test Loss: 12570926080.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13049854378.667..  Test Loss: 12389377024.000.. \n",
      "Epoch: 92/1000..  Training Loss: 13016980280.889..  Test Loss: 12050776064.000.. \n",
      "Epoch: 93/1000..  Training Loss: 13018810552.889..  Test Loss: 12471030784.000.. \n",
      "Epoch: 94/1000..  Training Loss: 13030503310.222..  Test Loss: 12003617792.000.. \n",
      "Epoch: 95/1000..  Training Loss: 13000808931.556..  Test Loss: 12466396160.000.. \n",
      "Epoch: 96/1000..  Training Loss: 12959744284.444..  Test Loss: 12523591680.000.. \n",
      "Epoch: 97/1000..  Training Loss: 12993136640.000..  Test Loss: 12339562496.000.. \n",
      "Epoch: 98/1000..  Training Loss: 12977308999.111..  Test Loss: 11906595840.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12993352305.778..  Test Loss: 11996620800.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12943768832.000..  Test Loss: 12376712192.000.. \n",
      "Epoch: 101/1000..  Training Loss: 12967816049.778..  Test Loss: 11965253632.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102/1000..  Training Loss: 13008177052.444..  Test Loss: 12295663616.000.. \n",
      "Epoch: 103/1000..  Training Loss: 12898697415.111..  Test Loss: 12129484800.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12952499640.889..  Test Loss: 12150447104.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12894134855.111..  Test Loss: 11985804288.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12906342855.111..  Test Loss: 12110648320.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12916679964.444..  Test Loss: 12128334848.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12902495786.667..  Test Loss: 12170287104.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12908786844.444..  Test Loss: 12132979712.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12864619477.333..  Test Loss: 12056118272.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12875359772.444..  Test Loss: 11933497344.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12842326528.000..  Test Loss: 12137662464.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12854300757.333..  Test Loss: 12221969408.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12832582656.000..  Test Loss: 12150456320.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12817360455.111..  Test Loss: 12478567424.000.. \n",
      "Epoch: 116/1000..  Training Loss: 12775801244.444..  Test Loss: 11994765312.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12808711537.778..  Test Loss: 12009927680.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12759632526.222..  Test Loss: 12351454208.000.. \n",
      "Epoch: 119/1000..  Training Loss: 12764001322.667..  Test Loss: 11741665280.000.. \n",
      "Epoch: 120/1000..  Training Loss: 12724099000.889..  Test Loss: 12033838080.000.. \n",
      "Epoch: 121/1000..  Training Loss: 12745111466.667..  Test Loss: 12400839680.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12778017564.444..  Test Loss: 12102652928.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12705667754.667..  Test Loss: 11726972928.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12768165461.333..  Test Loss: 11841408000.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12695004529.778..  Test Loss: 12277270528.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12751164074.667..  Test Loss: 11987018752.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12699864064.000..  Test Loss: 11765146624.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12669355392.000..  Test Loss: 11978309632.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12647420160.000..  Test Loss: 11762100224.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12695511751.111..  Test Loss: 11885943808.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12656542037.333..  Test Loss: 12048642048.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12613880604.444..  Test Loss: 12143384576.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12629966222.222..  Test Loss: 12038608896.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12630606791.111..  Test Loss: 11922142208.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12596202012.444..  Test Loss: 11900608512.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12643626609.778..  Test Loss: 12042040320.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12566178716.444..  Test Loss: 11509851136.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12602561934.222..  Test Loss: 11641910272.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12614972871.111..  Test Loss: 11652772864.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12617088910.222..  Test Loss: 12029134848.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12506075818.667..  Test Loss: 11511051264.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12509356074.667..  Test Loss: 11573268480.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12508719886.222..  Test Loss: 12079592448.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12499693226.667..  Test Loss: 11889876992.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12447703281.778..  Test Loss: 11563973632.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12468890325.333..  Test Loss: 11375097856.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12482205795.556..  Test Loss: 12263622656.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12468961948.444..  Test Loss: 11687180288.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12414722432.000..  Test Loss: 11868115968.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12426307825.778..  Test Loss: 11710863360.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12402730595.556..  Test Loss: 11358388224.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12374231651.556..  Test Loss: 11561677824.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12398303658.667..  Test Loss: 11783103488.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12351451776.000..  Test Loss: 11821730816.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12389748593.778..  Test Loss: 11957646336.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12381511011.556..  Test Loss: 11669550080.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12360613148.444..  Test Loss: 11426338816.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12319973134.222..  Test Loss: 11289498624.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12331538688.000..  Test Loss: 11542834176.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12280835441.778..  Test Loss: 11574670336.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12264147811.556..  Test Loss: 11699621888.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12289297379.556..  Test Loss: 11295499264.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12286471921.778..  Test Loss: 11667707904.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12269017016.889..  Test Loss: 11443737600.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12224930858.667..  Test Loss: 11466771456.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12222027392.000..  Test Loss: 11352590336.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12252210318.222..  Test Loss: 11470286848.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12193671992.889..  Test Loss: 11807584256.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12216297045.333..  Test Loss: 11544200192.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12195329834.667..  Test Loss: 11592669184.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12159237859.556..  Test Loss: 11738085376.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12149916131.556..  Test Loss: 11598918656.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12163370410.667..  Test Loss: 11641654272.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12186778439.111..  Test Loss: 11961716736.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12098115157.333..  Test Loss: 11101515776.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12120251477.333..  Test Loss: 11483238400.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12047339790.222..  Test Loss: 11405403136.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12035618560.000..  Test Loss: 11752295424.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12059228288.000..  Test Loss: 11107846144.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12037760028.444..  Test Loss: 11297805312.000.. \n",
      "Epoch: 181/1000..  Training Loss: 11998308167.111..  Test Loss: 11313389568.000.. \n",
      "Epoch: 182/1000..  Training Loss: 12045810929.778..  Test Loss: 11512836096.000.. \n",
      "Epoch: 183/1000..  Training Loss: 12010302734.222..  Test Loss: 11674389504.000.. \n",
      "Epoch: 184/1000..  Training Loss: 12033052344.889..  Test Loss: 11282473984.000.. \n",
      "Epoch: 185/1000..  Training Loss: 11986314752.000..  Test Loss: 11069633536.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11968985016.889..  Test Loss: 11671100416.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11984082360.889..  Test Loss: 11111731200.000.. \n",
      "Epoch: 188/1000..  Training Loss: 11981015736.889..  Test Loss: 11294182400.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11959358805.333..  Test Loss: 10996443136.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11919683157.333..  Test Loss: 11174191104.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11975958357.333..  Test Loss: 11203847168.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11896214556.444..  Test Loss: 11049188352.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11869824042.667..  Test Loss: 10928769024.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11859636949.333..  Test Loss: 11148711936.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11844986254.222..  Test Loss: 11457466368.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11891757013.333..  Test Loss: 11897766912.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11816649031.111..  Test Loss: 11051492352.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11831427925.333..  Test Loss: 11283578880.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11850430151.111..  Test Loss: 11458405376.000.. \n",
      "Epoch: 200/1000..  Training Loss: 11847000220.444..  Test Loss: 11440563200.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11729091214.222..  Test Loss: 11018093568.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202/1000..  Training Loss: 11771556224.000..  Test Loss: 11021860864.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11744330666.667..  Test Loss: 11016042496.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11709540352.000..  Test Loss: 10875217920.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11710211484.444..  Test Loss: 11164878848.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11707068472.889..  Test Loss: 10868649984.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11715562766.222..  Test Loss: 10894639104.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11674420593.778..  Test Loss: 10774798336.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11626897493.333..  Test Loss: 10863174656.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11697884771.556..  Test Loss: 10848261120.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11599469269.333..  Test Loss: 11287930880.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11645240462.222..  Test Loss: 11039905792.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11606158065.778..  Test Loss: 11015096320.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11588103153.778..  Test Loss: 10714854400.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11650936561.778..  Test Loss: 10885153792.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11573285319.111..  Test Loss: 10851349504.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11535535175.111..  Test Loss: 10830150656.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11566507648.000..  Test Loss: 10814344192.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11549180273.778..  Test Loss: 10740375552.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11559131434.667..  Test Loss: 11052819456.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11485157447.111..  Test Loss: 10476796928.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11480581418.667..  Test Loss: 10829883392.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11454064213.333..  Test Loss: 10716260352.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11505209628.444..  Test Loss: 10599281664.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11424376433.778..  Test Loss: 10950530048.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11405606072.889..  Test Loss: 10603213824.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11434807224.889..  Test Loss: 10496397312.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11406012558.222..  Test Loss: 11063952384.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11341531136.000..  Test Loss: 10648566784.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11366927118.222..  Test Loss: 10457494528.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11328910136.889..  Test Loss: 10363731968.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11324341304.889..  Test Loss: 10949185536.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11367201806.222..  Test Loss: 10373556224.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11335090119.111..  Test Loss: 10650848256.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11285038094.222..  Test Loss: 10321381376.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11273978183.111..  Test Loss: 10636365824.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11285558897.778..  Test Loss: 11032765440.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11249498268.444..  Test Loss: 10469901312.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11178320625.778..  Test Loss: 10528508928.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11205446912.000..  Test Loss: 10489156608.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11220604714.667..  Test Loss: 10876556288.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11213294691.556..  Test Loss: 10359840768.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11169946837.333..  Test Loss: 10613864448.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11218353720.889..  Test Loss: 10434754560.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11168851015.111..  Test Loss: 10191081472.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11103488625.778..  Test Loss: 10754708480.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11062536078.222..  Test Loss: 10248837120.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11099484842.667..  Test Loss: 10210412544.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11076349411.556..  Test Loss: 10096123904.000.. \n",
      "Epoch: 250/1000..  Training Loss: 11058014179.556..  Test Loss: 10127209472.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11109585464.889..  Test Loss: 10243736576.000.. \n",
      "Epoch: 252/1000..  Training Loss: 11046518570.667..  Test Loss: 10383412224.000.. \n",
      "Epoch: 253/1000..  Training Loss: 10961649450.667..  Test Loss: 10074547200.000.. \n",
      "Epoch: 254/1000..  Training Loss: 11047624746.667..  Test Loss: 10609284096.000.. \n",
      "Epoch: 255/1000..  Training Loss: 10987037098.667..  Test Loss: 10423600128.000.. \n",
      "Epoch: 256/1000..  Training Loss: 10985302997.333..  Test Loss: 10084152320.000.. \n",
      "Epoch: 257/1000..  Training Loss: 10959057408.000..  Test Loss: 10308370432.000.. \n",
      "Epoch: 258/1000..  Training Loss: 10884874979.556..  Test Loss: 10505311232.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10942773546.667..  Test Loss: 10138632192.000.. \n",
      "Epoch: 260/1000..  Training Loss: 10919375303.111..  Test Loss: 10668721152.000.. \n",
      "Epoch: 261/1000..  Training Loss: 10879626453.333..  Test Loss: 10080078848.000.. \n",
      "Epoch: 262/1000..  Training Loss: 10883850097.778..  Test Loss: 10720599040.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10828637155.556..  Test Loss: 10132591616.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10866255687.111..  Test Loss: 10212316160.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10866391637.333..  Test Loss: 10147428352.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10819015111.111..  Test Loss: 9926259712.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10775870634.667..  Test Loss: 10106935296.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10770688824.889..  Test Loss: 9977569280.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10832481834.667..  Test Loss: 9836624896.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10740635591.111..  Test Loss: 9830529024.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10754594858.667..  Test Loss: 10370680832.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10697529230.222..  Test Loss: 10050491392.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10689669603.556..  Test Loss: 9826412544.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10675305656.889..  Test Loss: 10039298048.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10658687601.778..  Test Loss: 10273697792.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10662229262.222..  Test Loss: 10078277632.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10589599616.000..  Test Loss: 9959400448.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10569124024.889..  Test Loss: 9614401536.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10623167544.889..  Test Loss: 10044481536.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10524971264.000..  Test Loss: 9643912192.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10518531086.222..  Test Loss: 9735521280.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10532349070.222..  Test Loss: 10136050688.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10547896504.889..  Test Loss: 9799539712.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10501440398.222..  Test Loss: 9732081664.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10479566976.000..  Test Loss: 9823160320.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10421092679.111..  Test Loss: 9794151424.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10475224718.222..  Test Loss: 9819723776.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10428762353.778..  Test Loss: 9565849600.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10396685980.444..  Test Loss: 9839995904.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10481662648.889..  Test Loss: 9800318976.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10394928796.444..  Test Loss: 9512779776.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10347394602.667..  Test Loss: 9819171840.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10387233649.778..  Test Loss: 9934255104.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10309107185.778..  Test Loss: 9537458176.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10372137272.889..  Test Loss: 9666099200.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10367442844.444..  Test Loss: 9492792320.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10333081685.333..  Test Loss: 10124214272.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10286048170.667..  Test Loss: 9692712960.000.. \n",
      "Epoch: 299/1000..  Training Loss: 10268696618.667..  Test Loss: 10089869312.000.. \n",
      "Epoch: 300/1000..  Training Loss: 10217265735.111..  Test Loss: 9712628736.000.. \n",
      "Epoch: 301/1000..  Training Loss: 10221240576.000..  Test Loss: 9366992896.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 302/1000..  Training Loss: 10190201528.889..  Test Loss: 9498443776.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10195762488.889..  Test Loss: 9812255744.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10169870165.333..  Test Loss: 9159165952.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10128059335.111..  Test Loss: 9931873280.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10095677895.111..  Test Loss: 9287589888.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10109972792.889..  Test Loss: 9758571520.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10120830691.556..  Test Loss: 9840208896.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10092755271.111..  Test Loss: 9732025344.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10108491520.000..  Test Loss: 9376404480.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10078587633.778..  Test Loss: 9648377856.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10014482872.889..  Test Loss: 9394804736.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10044330453.333..  Test Loss: 9299280896.000.. \n",
      "Epoch: 314/1000..  Training Loss: 10025490503.111..  Test Loss: 10286400512.000.. \n",
      "Epoch: 315/1000..  Training Loss: 10074010040.889..  Test Loss: 9157156864.000.. \n",
      "Epoch: 316/1000..  Training Loss: 9938411548.444..  Test Loss: 9192097792.000.. \n",
      "Epoch: 317/1000..  Training Loss: 9987762417.778..  Test Loss: 9602922496.000.. \n",
      "Epoch: 318/1000..  Training Loss: 9980278200.889..  Test Loss: 9485370368.000.. \n",
      "Epoch: 319/1000..  Training Loss: 9882459107.556..  Test Loss: 9128978432.000.. \n",
      "Epoch: 320/1000..  Training Loss: 9915638229.333..  Test Loss: 9536781312.000.. \n",
      "Epoch: 321/1000..  Training Loss: 9924444245.333..  Test Loss: 9607047168.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9876304369.778..  Test Loss: 9267756032.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9874280860.444..  Test Loss: 9273909248.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9836929934.222..  Test Loss: 9121346560.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9804271566.222..  Test Loss: 9353620480.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9856379420.444..  Test Loss: 9724494848.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9776027363.556..  Test Loss: 9009630208.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9738951907.556..  Test Loss: 9128928256.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9841271523.556..  Test Loss: 9122957312.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9720621738.667..  Test Loss: 9268840448.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9694254961.778..  Test Loss: 9625452544.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9699037866.667..  Test Loss: 9314164736.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9708411776.000..  Test Loss: 9285769216.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9633528661.333..  Test Loss: 8945802240.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9778826439.111..  Test Loss: 9461707776.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9590362880.000..  Test Loss: 9169790976.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9595940309.333..  Test Loss: 9098322944.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9633964800.000..  Test Loss: 8733463552.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9580547228.444..  Test Loss: 8598999040.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9523940536.889..  Test Loss: 8936830976.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9585667484.444..  Test Loss: 9127205888.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9546086471.111..  Test Loss: 9110534144.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9537175665.778..  Test Loss: 9516693504.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9508056206.222..  Test Loss: 9303528448.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9540619548.444..  Test Loss: 9375656960.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9478377600.000..  Test Loss: 8866004992.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9489996259.556..  Test Loss: 9087587328.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9447883107.556..  Test Loss: 8818863104.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9420611114.667..  Test Loss: 9155105792.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9369993984.000..  Test Loss: 8771528704.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9358938936.889..  Test Loss: 8457563648.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9321886990.222..  Test Loss: 8805915648.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9293861077.333..  Test Loss: 8692443136.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9294953116.444..  Test Loss: 8699532288.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9300265429.333..  Test Loss: 8861323264.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9279347470.222..  Test Loss: 8837492736.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9300967893.333..  Test Loss: 9197787136.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9267667171.556..  Test Loss: 8575698944.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9233053397.333..  Test Loss: 8861706240.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9143990670.222..  Test Loss: 8664491008.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9242536988.444..  Test Loss: 8745188352.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9177488981.333..  Test Loss: 8436016128.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9153590371.556..  Test Loss: 9000968192.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9139088583.111..  Test Loss: 8764321792.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9193051904.000..  Test Loss: 8743598080.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9141820088.889..  Test Loss: 8759969792.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9070412074.667..  Test Loss: 8385485312.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9063190471.111..  Test Loss: 8465812992.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9069841550.222..  Test Loss: 8191412736.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9080945848.889..  Test Loss: 8276798976.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9123306894.222..  Test Loss: 8614119424.000.. \n",
      "Epoch: 372/1000..  Training Loss: 9026688952.889..  Test Loss: 8390583296.000.. \n",
      "Epoch: 373/1000..  Training Loss: 9025621646.222..  Test Loss: 8807977984.000.. \n",
      "Epoch: 374/1000..  Training Loss: 8981899306.667..  Test Loss: 8589144576.000.. \n",
      "Epoch: 375/1000..  Training Loss: 8941207068.444..  Test Loss: 8728867840.000.. \n",
      "Epoch: 376/1000..  Training Loss: 8954647651.556..  Test Loss: 8483822592.000.. \n",
      "Epoch: 377/1000..  Training Loss: 9002648995.556..  Test Loss: 8384048640.000.. \n",
      "Epoch: 378/1000..  Training Loss: 8963160206.222..  Test Loss: 8758778880.000.. \n",
      "Epoch: 379/1000..  Training Loss: 8899739022.222..  Test Loss: 8686798848.000.. \n",
      "Epoch: 380/1000..  Training Loss: 8884672312.889..  Test Loss: 8334469120.000.. \n",
      "Epoch: 381/1000..  Training Loss: 8935899136.000..  Test Loss: 8591855616.000.. \n",
      "Epoch: 382/1000..  Training Loss: 8858129792.000..  Test Loss: 8200356864.000.. \n",
      "Epoch: 383/1000..  Training Loss: 8880205368.889..  Test Loss: 8160662016.000.. \n",
      "Epoch: 384/1000..  Training Loss: 8806442609.778..  Test Loss: 8480946688.000.. \n",
      "Epoch: 385/1000..  Training Loss: 8755054734.222..  Test Loss: 8378791424.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8763411484.444..  Test Loss: 8081842176.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8772922702.222..  Test Loss: 8271931904.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8760241735.111..  Test Loss: 8615570432.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8757976533.333..  Test Loss: 8066281984.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8749063694.222..  Test Loss: 8246397440.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8726002972.444..  Test Loss: 8138308096.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8704699434.667..  Test Loss: 8226592256.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8700494001.778..  Test Loss: 8535523328.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8667705272.889..  Test Loss: 8126754304.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8677710748.444..  Test Loss: 8825047040.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8689520220.444..  Test Loss: 8416274432.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8614486229.333..  Test Loss: 8005517312.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8662305948.444..  Test Loss: 8406856192.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8585489806.222..  Test Loss: 7998050816.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8537817827.556..  Test Loss: 8284653568.000.. \n",
      "Epoch: 401/1000..  Training Loss: 8547368576.000..  Test Loss: 8063067136.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8502055061.333..  Test Loss: 8295263744.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8524486627.556..  Test Loss: 8192282112.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 404/1000..  Training Loss: 8501007217.778..  Test Loss: 8150478336.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8527216327.111..  Test Loss: 8125884928.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8458553301.333..  Test Loss: 8263526400.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8399985088.000..  Test Loss: 7720908288.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8408374115.556..  Test Loss: 7912299520.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8424944426.667..  Test Loss: 7829346816.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8402031701.333..  Test Loss: 7973418496.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8381066695.111..  Test Loss: 7679772672.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8359747712.000..  Test Loss: 7728572928.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8298044657.778..  Test Loss: 8071801344.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8337753194.667..  Test Loss: 8151972352.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8224480085.333..  Test Loss: 7724077568.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8323783552.000..  Test Loss: 8099476992.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8284534023.111..  Test Loss: 7925005312.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8342540316.444..  Test Loss: 7888957952.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8190847936.000..  Test Loss: 7929156096.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8219243050.667..  Test Loss: 8598094848.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8203887502.222..  Test Loss: 7704235520.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8215778218.667..  Test Loss: 7885635584.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8154202147.556..  Test Loss: 7878706176.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8136419214.222..  Test Loss: 7937775104.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8180317098.667..  Test Loss: 7922381312.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8202621027.556..  Test Loss: 7697716736.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8048510264.889..  Test Loss: 7662194176.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8051730375.111..  Test Loss: 7486590464.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8053516330.667..  Test Loss: 7768188928.000.. \n",
      "Epoch: 430/1000..  Training Loss: 8024667484.444..  Test Loss: 8192457216.000.. \n",
      "Epoch: 431/1000..  Training Loss: 8000540992.000..  Test Loss: 7614238720.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8053005368.889..  Test Loss: 7886019584.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8014571299.556..  Test Loss: 7569757696.000.. \n",
      "Epoch: 434/1000..  Training Loss: 7918469745.778..  Test Loss: 7116682752.000.. \n",
      "Epoch: 435/1000..  Training Loss: 7932448654.222..  Test Loss: 7435438080.000.. \n",
      "Epoch: 436/1000..  Training Loss: 8017999281.778..  Test Loss: 7426998272.000.. \n",
      "Epoch: 437/1000..  Training Loss: 7992817521.778..  Test Loss: 7202368000.000.. \n",
      "Epoch: 438/1000..  Training Loss: 7910470840.889..  Test Loss: 7421258240.000.. \n",
      "Epoch: 439/1000..  Training Loss: 7952030478.222..  Test Loss: 7412593664.000.. \n",
      "Epoch: 440/1000..  Training Loss: 7877315100.444..  Test Loss: 7715826176.000.. \n",
      "Epoch: 441/1000..  Training Loss: 7850375480.889..  Test Loss: 7558800384.000.. \n",
      "Epoch: 442/1000..  Training Loss: 7922849329.778..  Test Loss: 7368523264.000.. \n",
      "Epoch: 443/1000..  Training Loss: 7885878072.889..  Test Loss: 7485029376.000.. \n",
      "Epoch: 444/1000..  Training Loss: 7832866254.222..  Test Loss: 7408616448.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7846341162.667..  Test Loss: 8060316160.000.. \n",
      "Epoch: 446/1000..  Training Loss: 7743752640.000..  Test Loss: 7388890624.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7806782983.111..  Test Loss: 7287164928.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7753283399.111..  Test Loss: 7488271872.000.. \n",
      "Epoch: 449/1000..  Training Loss: 7788985813.333..  Test Loss: 7078073856.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7747763754.667..  Test Loss: 7957304832.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7735850560.000..  Test Loss: 7340386304.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7681103758.222..  Test Loss: 7034165760.000.. \n",
      "Epoch: 453/1000..  Training Loss: 7654442858.667..  Test Loss: 7033367552.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7758876010.667..  Test Loss: 6966347264.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7668815587.556..  Test Loss: 7213497856.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7582771356.444..  Test Loss: 7307129856.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7602776448.000..  Test Loss: 6943870464.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7570826972.444..  Test Loss: 7189103104.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7505915029.333..  Test Loss: 7275836928.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7581647203.556..  Test Loss: 7018064384.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7519526720.000..  Test Loss: 7203529216.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7516396657.778..  Test Loss: 7246307840.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7530259235.556..  Test Loss: 7121555968.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7530431374.222..  Test Loss: 7538796544.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7428454279.111..  Test Loss: 7336582144.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7448208981.333..  Test Loss: 6819904512.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7417403079.111..  Test Loss: 7088923136.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7356910087.111..  Test Loss: 6690482176.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7364599964.444..  Test Loss: 7122774528.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7447685105.778..  Test Loss: 7310290944.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7302984142.222..  Test Loss: 6928760320.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7423518940.444..  Test Loss: 6928052736.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7338907505.778..  Test Loss: 6789682688.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7355360810.667..  Test Loss: 6989165568.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7320408469.333..  Test Loss: 7064505856.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7337321080.889..  Test Loss: 7409334272.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7265980088.889..  Test Loss: 6815232000.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7280164579.556..  Test Loss: 6802768896.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7270016426.667..  Test Loss: 7122332672.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7185540864.000..  Test Loss: 7122148352.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7205981511.111..  Test Loss: 6690407424.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7260732160.000..  Test Loss: 6883722240.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7226496647.111..  Test Loss: 6705511936.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7182685020.444..  Test Loss: 6520839168.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7210951971.556..  Test Loss: 6794506240.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7161665976.889..  Test Loss: 6478103040.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7099750008.889..  Test Loss: 6397169664.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7226345031.111..  Test Loss: 6583296000.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7168035057.778..  Test Loss: 6764182016.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7085346780.444..  Test Loss: 6680209920.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7090227911.111..  Test Loss: 6404076032.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7039358200.889..  Test Loss: 6477996032.000.. \n",
      "Epoch: 493/1000..  Training Loss: 7119945329.778..  Test Loss: 6523689984.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7031288248.889..  Test Loss: 6835776000.000.. \n",
      "Epoch: 495/1000..  Training Loss: 6992660138.667..  Test Loss: 6683044864.000.. \n",
      "Epoch: 496/1000..  Training Loss: 7059357248.000..  Test Loss: 6528432640.000.. \n",
      "Epoch: 497/1000..  Training Loss: 7035574620.444..  Test Loss: 6588887552.000.. \n",
      "Epoch: 498/1000..  Training Loss: 7046694513.778..  Test Loss: 6387096064.000.. \n",
      "Epoch: 499/1000..  Training Loss: 6949174684.444..  Test Loss: 6250322944.000.. \n",
      "Epoch: 500/1000..  Training Loss: 6906130887.111..  Test Loss: 6826434048.000.. \n",
      "Epoch: 501/1000..  Training Loss: 6976424263.111..  Test Loss: 6603064320.000.. \n",
      "Epoch: 502/1000..  Training Loss: 6959999651.556..  Test Loss: 6880539648.000.. \n",
      "Epoch: 503/1000..  Training Loss: 6895109994.667..  Test Loss: 6524123648.000.. \n",
      "Epoch: 504/1000..  Training Loss: 6838809038.222..  Test Loss: 6384572928.000.. \n",
      "Epoch: 505/1000..  Training Loss: 6856703644.444..  Test Loss: 6621499904.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 506/1000..  Training Loss: 6895689024.000..  Test Loss: 6737260544.000.. \n",
      "Epoch: 507/1000..  Training Loss: 6815867050.667..  Test Loss: 6457538048.000.. \n",
      "Epoch: 508/1000..  Training Loss: 6823071011.556..  Test Loss: 6159113216.000.. \n",
      "Epoch: 509/1000..  Training Loss: 6765406407.111..  Test Loss: 6407475712.000.. \n",
      "Epoch: 510/1000..  Training Loss: 6786608426.667..  Test Loss: 6353097216.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6797058474.667..  Test Loss: 6568049664.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6750999644.444..  Test Loss: 6185045504.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6781419349.333..  Test Loss: 6093906432.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6814831914.667..  Test Loss: 6386309120.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6712443612.444..  Test Loss: 6197099008.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6755359274.667..  Test Loss: 6280966656.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6731366236.444..  Test Loss: 5984226304.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6693945415.111..  Test Loss: 6091181056.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6632386929.778..  Test Loss: 6396243456.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6661015367.111..  Test Loss: 6269399552.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6570685532.444..  Test Loss: 5910388224.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6590917148.444..  Test Loss: 5983916544.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6683209856.000..  Test Loss: 5968686080.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6567717105.778..  Test Loss: 6198464512.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6529696576.000..  Test Loss: 6027472384.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6532572721.778..  Test Loss: 5804290048.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6606059406.222..  Test Loss: 6184300544.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6581366791.111..  Test Loss: 5764652544.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6643809600.000..  Test Loss: 5840674304.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6532373098.667..  Test Loss: 5496695808.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6415860672.000..  Test Loss: 5862169600.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6435024931.556..  Test Loss: 6002116096.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6463215587.556..  Test Loss: 5587507712.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6480128668.444..  Test Loss: 6068380672.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6453149639.111..  Test Loss: 5874082304.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6401945016.889..  Test Loss: 5817452032.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6396291441.778..  Test Loss: 6275427840.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6454944099.556..  Test Loss: 5862068224.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6459074624.000..  Test Loss: 5907139584.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6404065728.000..  Test Loss: 6303910400.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6364223651.556..  Test Loss: 5829507584.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6418284529.778..  Test Loss: 6227750912.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6344696960.000..  Test Loss: 5530237952.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6347552462.222..  Test Loss: 5738179072.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6316699456.000..  Test Loss: 5459230208.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6249416817.778..  Test Loss: 5489786880.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6337044295.111..  Test Loss: 5712023040.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6241665578.667..  Test Loss: 5662684672.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6219875249.778..  Test Loss: 5296700416.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6240698332.444..  Test Loss: 6254734848.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6224550414.222..  Test Loss: 5811575296.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6253432263.111..  Test Loss: 5654800384.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6301701546.667..  Test Loss: 5935999488.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6195277802.667..  Test Loss: 5786212864.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6172650375.111..  Test Loss: 5253303808.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6188788928.000..  Test Loss: 5483423232.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6156465628.444..  Test Loss: 5679176704.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6144451612.444..  Test Loss: 5754985472.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6224253738.667..  Test Loss: 5756890624.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6164721692.444..  Test Loss: 5611271168.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6109486243.556..  Test Loss: 5408351232.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6151244039.111..  Test Loss: 5856710656.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6052639559.111..  Test Loss: 5561637376.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6074702094.222..  Test Loss: 5500699136.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6043122382.222..  Test Loss: 5431086080.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6033713294.222..  Test Loss: 5244634112.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6025310364.444..  Test Loss: 5377467904.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6041128071.111..  Test Loss: 5569510400.000.. \n",
      "Epoch: 569/1000..  Training Loss: 5957424753.778..  Test Loss: 5217143808.000.. \n",
      "Epoch: 570/1000..  Training Loss: 6084336803.556..  Test Loss: 5092370944.000.. \n",
      "Epoch: 571/1000..  Training Loss: 5998810503.111..  Test Loss: 5583354368.000.. \n",
      "Epoch: 572/1000..  Training Loss: 6036160035.556..  Test Loss: 5396882432.000.. \n",
      "Epoch: 573/1000..  Training Loss: 5917320938.667..  Test Loss: 5433181184.000.. \n",
      "Epoch: 574/1000..  Training Loss: 5927662634.667..  Test Loss: 5706639872.000.. \n",
      "Epoch: 575/1000..  Training Loss: 5952435761.778..  Test Loss: 5412537856.000.. \n",
      "Epoch: 576/1000..  Training Loss: 5918174229.333..  Test Loss: 5551292416.000.. \n",
      "Epoch: 577/1000..  Training Loss: 5902385287.111..  Test Loss: 5247826432.000.. \n",
      "Epoch: 578/1000..  Training Loss: 5917600288.000..  Test Loss: 5505865216.000.. \n",
      "Epoch: 579/1000..  Training Loss: 5946490097.778..  Test Loss: 5338908672.000.. \n",
      "Epoch: 580/1000..  Training Loss: 5872784714.667..  Test Loss: 5630818304.000.. \n",
      "Epoch: 581/1000..  Training Loss: 5911159246.222..  Test Loss: 5089913856.000.. \n",
      "Epoch: 582/1000..  Training Loss: 5971497479.111..  Test Loss: 5277200896.000.. \n",
      "Epoch: 583/1000..  Training Loss: 5848804387.556..  Test Loss: 5215853568.000.. \n",
      "Epoch: 584/1000..  Training Loss: 5823569351.111..  Test Loss: 4866493440.000.. \n",
      "Epoch: 585/1000..  Training Loss: 5871333312.000..  Test Loss: 5398610944.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5833146574.222..  Test Loss: 5491792384.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5845169955.556..  Test Loss: 5344849920.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5870385372.444..  Test Loss: 5185417728.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5771478748.444..  Test Loss: 4981540864.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5828588138.667..  Test Loss: 4969482752.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5816578432.000..  Test Loss: 4861113344.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5719005703.111..  Test Loss: 4868490752.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5772180828.444..  Test Loss: 5213366784.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5728595057.778..  Test Loss: 5056545280.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5846390506.667..  Test Loss: 5463615488.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5712054229.333..  Test Loss: 5213209088.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5654610915.556..  Test Loss: 5252561408.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5772149553.778..  Test Loss: 5025913344.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5676691648.000..  Test Loss: 5157678592.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5731722119.111..  Test Loss: 5058989568.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5744471267.556..  Test Loss: 4911618560.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5735807495.111..  Test Loss: 5622627840.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5597568796.444..  Test Loss: 4853261824.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5659220956.444..  Test Loss: 5074554880.000.. \n",
      "Epoch: 605/1000..  Training Loss: 5683614826.667..  Test Loss: 4715529216.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5667989781.333..  Test Loss: 4809877504.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5669385166.222..  Test Loss: 5071970304.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 608/1000..  Training Loss: 5575881592.889..  Test Loss: 4650885632.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5584128412.444..  Test Loss: 5157371392.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5638693852.444..  Test Loss: 4907681280.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5517798855.111..  Test Loss: 4708140032.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5592462208.000..  Test Loss: 4755401216.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5511762076.444..  Test Loss: 4694604800.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5519040355.556..  Test Loss: 5084887552.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5597265806.222..  Test Loss: 5278124544.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5512586410.667..  Test Loss: 4663622144.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5519449692.444..  Test Loss: 4776563712.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5477509468.444..  Test Loss: 5191395328.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5449455580.444..  Test Loss: 4873057792.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5461060679.111..  Test Loss: 4820150272.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5426702670.222..  Test Loss: 4976458240.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5520818140.444..  Test Loss: 4628734464.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5401961258.667..  Test Loss: 4811574784.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5480307484.444..  Test Loss: 4563317760.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5439060892.444..  Test Loss: 4650505216.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5457710321.778..  Test Loss: 4942375936.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5471406890.667..  Test Loss: 4471527936.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5403721884.444..  Test Loss: 4630715904.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5435400597.333..  Test Loss: 4710083584.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5439282801.778..  Test Loss: 4513385472.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5332916487.111..  Test Loss: 4600861184.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5410269596.444..  Test Loss: 4409491456.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5350816529.778..  Test Loss: 4755620864.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5407147399.111..  Test Loss: 4468850688.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5407538979.556..  Test Loss: 4891236864.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5343618197.333..  Test Loss: 4495547904.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5418856106.667..  Test Loss: 4816723456.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5354386112.000..  Test Loss: 4519343616.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5312629045.333..  Test Loss: 4317535744.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5337733895.111..  Test Loss: 4746136576.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5270684672.000..  Test Loss: 4252534016.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5313044017.778..  Test Loss: 4752151552.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5307605952.000..  Test Loss: 4712462336.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5342961116.444..  Test Loss: 4643736576.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5323053681.778..  Test Loss: 4385493504.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5222896263.111..  Test Loss: 4505511424.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5261833500.444..  Test Loss: 4338223104.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5372067285.333..  Test Loss: 4433604096.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5294092344.889..  Test Loss: 4270297088.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5272127911.111..  Test Loss: 4287684608.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5280382279.111..  Test Loss: 4565976576.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5192264583.111..  Test Loss: 4308963328.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5205778645.333..  Test Loss: 4541250048.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5306024696.889..  Test Loss: 4421740544.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5245140330.667..  Test Loss: 4367229952.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5238128526.222..  Test Loss: 4455899136.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5212610247.111..  Test Loss: 4203080448.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5194819192.889..  Test Loss: 4505392128.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5179529450.667..  Test Loss: 4351002624.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5173114357.333..  Test Loss: 3939812352.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5098425770.667..  Test Loss: 4441389568.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5174193856.000..  Test Loss: 4834018816.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5074968903.111..  Test Loss: 4338321920.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5224236480.000..  Test Loss: 4261082880.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5155128576.000..  Test Loss: 4388871680.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5121681550.222..  Test Loss: 4460910080.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5132865159.111..  Test Loss: 4528118272.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5198964871.111..  Test Loss: 4677951488.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5084624622.222..  Test Loss: 4460060160.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5185239018.667..  Test Loss: 4515606016.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5202254186.667..  Test Loss: 4370529792.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5129738510.222..  Test Loss: 4195506432.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5146013443.556..  Test Loss: 4454771200.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5149436984.889..  Test Loss: 4460538368.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5058459370.667..  Test Loss: 4193616896.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5081223004.444..  Test Loss: 3914599168.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5115602062.222..  Test Loss: 4518275584.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5086415032.889..  Test Loss: 4212860672.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5114470890.667..  Test Loss: 4120825344.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5140412387.556..  Test Loss: 4228050944.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5134281699.556..  Test Loss: 4181782016.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5042447616.000..  Test Loss: 4599717376.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5091626823.111..  Test Loss: 4118330880.000.. \n",
      "Epoch: 684/1000..  Training Loss: 5080741582.222..  Test Loss: 3998748672.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5071347086.222..  Test Loss: 4352247296.000.. \n",
      "Epoch: 686/1000..  Training Loss: 5043235143.111..  Test Loss: 4256310272.000.. \n",
      "Epoch: 687/1000..  Training Loss: 5068472256.000..  Test Loss: 4104744192.000.. \n",
      "Epoch: 688/1000..  Training Loss: 5089506154.667..  Test Loss: 4089350400.000.. \n",
      "Epoch: 689/1000..  Training Loss: 5035198581.333..  Test Loss: 4095968512.000.. \n",
      "Epoch: 690/1000..  Training Loss: 4997123441.778..  Test Loss: 4204568064.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5046965105.778..  Test Loss: 3974160896.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5024016576.000..  Test Loss: 3956724992.000.. \n",
      "Epoch: 693/1000..  Training Loss: 5067744007.111..  Test Loss: 3916489728.000.. \n",
      "Epoch: 694/1000..  Training Loss: 4938153486.222..  Test Loss: 4158096384.000.. \n",
      "Epoch: 695/1000..  Training Loss: 4995569393.778..  Test Loss: 4006823168.000.. \n",
      "Epoch: 696/1000..  Training Loss: 4991945429.333..  Test Loss: 4198855168.000.. \n",
      "Epoch: 697/1000..  Training Loss: 5026911139.556..  Test Loss: 4120131328.000.. \n",
      "Epoch: 698/1000..  Training Loss: 5054737564.444..  Test Loss: 4104086784.000.. \n",
      "Epoch: 699/1000..  Training Loss: 5040903139.556..  Test Loss: 4012155904.000.. \n",
      "Epoch: 700/1000..  Training Loss: 4993266691.556..  Test Loss: 4096483840.000.. \n",
      "Epoch: 701/1000..  Training Loss: 4986817294.222..  Test Loss: 4318021632.000.. \n",
      "Epoch: 702/1000..  Training Loss: 4949352935.111..  Test Loss: 3896035584.000.. \n",
      "Epoch: 703/1000..  Training Loss: 5026254314.667..  Test Loss: 4048774144.000.. \n",
      "Epoch: 704/1000..  Training Loss: 4954339655.111..  Test Loss: 3799052288.000.. \n",
      "Epoch: 705/1000..  Training Loss: 4972684266.667..  Test Loss: 3800405760.000.. \n",
      "Epoch: 706/1000..  Training Loss: 4970389461.333..  Test Loss: 3952737024.000.. \n",
      "Epoch: 707/1000..  Training Loss: 4971482368.000..  Test Loss: 4102434816.000.. \n",
      "Epoch: 708/1000..  Training Loss: 4968580380.444..  Test Loss: 3853247744.000.. \n",
      "Epoch: 709/1000..  Training Loss: 5013181486.222..  Test Loss: 4102488064.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 710/1000..  Training Loss: 4861754026.667..  Test Loss: 4073857536.000.. \n",
      "Epoch: 711/1000..  Training Loss: 4939917440.000..  Test Loss: 4057767168.000.. \n",
      "Epoch: 712/1000..  Training Loss: 5006923242.667..  Test Loss: 4170094848.000.. \n",
      "Epoch: 713/1000..  Training Loss: 4890100352.000..  Test Loss: 4190633472.000.. \n",
      "Epoch: 714/1000..  Training Loss: 4915649443.556..  Test Loss: 4184980992.000.. \n",
      "Epoch: 715/1000..  Training Loss: 4923380750.222..  Test Loss: 4222227712.000.. \n",
      "Epoch: 716/1000..  Training Loss: 4933375495.111..  Test Loss: 3997136640.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4932415452.444..  Test Loss: 4004873216.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4914725098.667..  Test Loss: 3895785216.000.. \n",
      "Epoch: 719/1000..  Training Loss: 4965385976.889..  Test Loss: 3716915968.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4867100024.889..  Test Loss: 4174452992.000.. \n",
      "Epoch: 721/1000..  Training Loss: 4946134641.778..  Test Loss: 4111801088.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4951870065.778..  Test Loss: 3714791424.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4877607459.556..  Test Loss: 3958979840.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4926860003.556..  Test Loss: 3943920128.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4875463733.333..  Test Loss: 4010954752.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4839087096.889..  Test Loss: 3768626432.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4878771040.000..  Test Loss: 4082847232.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4931961848.889..  Test Loss: 4028017408.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4907217536.000..  Test Loss: 4172557824.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4902660273.778..  Test Loss: 3730635264.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4834376362.667..  Test Loss: 3936058624.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4865740672.000..  Test Loss: 3755997696.000.. \n",
      "Epoch: 733/1000..  Training Loss: 4851500615.111..  Test Loss: 3729380096.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4928299868.444..  Test Loss: 4254504192.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4815527658.667..  Test Loss: 4020638976.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4889349696.000..  Test Loss: 4145240320.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4866545479.111..  Test Loss: 3970831360.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4830188995.556..  Test Loss: 3597143552.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4868327779.556..  Test Loss: 3748468480.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4868304967.111..  Test Loss: 3702549504.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4882604572.444..  Test Loss: 4207514112.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4828961162.667..  Test Loss: 3818242560.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4900333699.556..  Test Loss: 3882396928.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4844923950.222..  Test Loss: 3688420608.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4884888860.444..  Test Loss: 3798520320.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4868541596.444..  Test Loss: 3653682944.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4855800334.222..  Test Loss: 3623185920.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4871776142.222..  Test Loss: 3676641280.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4829140252.444..  Test Loss: 4083782912.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4846833927.111..  Test Loss: 3752340992.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4860369415.111..  Test Loss: 3769949696.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4938986040.889..  Test Loss: 4047638016.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4819631018.667..  Test Loss: 3698315264.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4754768910.222..  Test Loss: 3751801856.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4806440455.111..  Test Loss: 3659162880.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4790042823.111..  Test Loss: 3681649920.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4906147249.778..  Test Loss: 3620825600.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4859662183.111..  Test Loss: 3907617792.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4867275057.778..  Test Loss: 3553770752.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4847472995.556..  Test Loss: 3683888128.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4824380067.556..  Test Loss: 3934390016.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4828893724.444..  Test Loss: 3836056064.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4844854677.333..  Test Loss: 3777135872.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4844926897.778..  Test Loss: 3701342976.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4811057848.889..  Test Loss: 3723013632.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4912540323.556..  Test Loss: 3721347072.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4823749041.778..  Test Loss: 3712679168.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4826833550.222..  Test Loss: 3900716800.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4846358741.333..  Test Loss: 3663503616.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4844718826.667..  Test Loss: 3571139840.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4812334577.778..  Test Loss: 3608023296.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4748093479.111..  Test Loss: 3673373952.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4818176704.000..  Test Loss: 3723778304.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4797523576.889..  Test Loss: 3644554496.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4786627548.444..  Test Loss: 3865271808.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4795616924.444..  Test Loss: 3516210688.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4853387370.667..  Test Loss: 3612891136.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4800003768.889..  Test Loss: 3916136960.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4785150577.778..  Test Loss: 3693210368.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4793499363.556..  Test Loss: 3947856896.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4772790990.222..  Test Loss: 3534739968.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4783864739.556..  Test Loss: 3480547072.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4771536881.778..  Test Loss: 3622481920.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4818399530.667..  Test Loss: 3746575616.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4846979235.556..  Test Loss: 3639460352.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4798440149.333..  Test Loss: 3583522816.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4815946176.000..  Test Loss: 3555940864.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4810817777.778..  Test Loss: 3560269824.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4854137628.444..  Test Loss: 3832274176.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4845158833.778..  Test Loss: 3601346560.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4789686108.444..  Test Loss: 3743483648.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4804102720.000..  Test Loss: 3571145984.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4837366240.000..  Test Loss: 4034934528.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4778828842.667..  Test Loss: 3483055360.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4772000476.444..  Test Loss: 3517202688.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4773010154.667..  Test Loss: 3685695232.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4883862001.778..  Test Loss: 3769589504.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4779337077.333..  Test Loss: 3547872256.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4808960512.000..  Test Loss: 3536467968.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4779784305.778..  Test Loss: 3532935680.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4748993994.667..  Test Loss: 3777279232.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4821306776.889..  Test Loss: 3502413312.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4783277006.222..  Test Loss: 3991305472.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4761734926.222..  Test Loss: 3813172224.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4786037749.333..  Test Loss: 3441286144.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4775997738.667..  Test Loss: 3833454080.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4786727736.889..  Test Loss: 3584750592.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4762314503.111..  Test Loss: 3545409280.000.. \n",
      "Epoch: 809/1000..  Training Loss: 4757766414.222..  Test Loss: 3601739008.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4841334193.778..  Test Loss: 3555356160.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4768796643.556..  Test Loss: 3518628352.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 812/1000..  Training Loss: 4735162673.778..  Test Loss: 3468200448.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4730663921.778..  Test Loss: 3575203328.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4758595072.000..  Test Loss: 3705097984.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4759765447.111..  Test Loss: 3484908800.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4719009080.889..  Test Loss: 3496084736.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4748142080.000..  Test Loss: 3582889216.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4783912071.111..  Test Loss: 3724666112.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4714235086.222..  Test Loss: 3930396928.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4745577920.000..  Test Loss: 3574641920.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4786297678.222..  Test Loss: 3424856832.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4776323072.000..  Test Loss: 3975125760.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4743271872.000..  Test Loss: 3596131840.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4791322958.222..  Test Loss: 3580506880.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4751401066.667..  Test Loss: 3550848512.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4767570410.667..  Test Loss: 3707190528.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4789221660.444..  Test Loss: 3546255104.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4742128448.000..  Test Loss: 3507036160.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4768571968.000..  Test Loss: 3535268864.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4831896199.111..  Test Loss: 3611082752.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4797056327.111..  Test Loss: 3469246976.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4776434133.333..  Test Loss: 3485900032.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4756434744.889..  Test Loss: 3388409088.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4762663424.000..  Test Loss: 3436977408.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4755949489.778..  Test Loss: 3603984896.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4712003626.667..  Test Loss: 3655889920.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4753551374.222..  Test Loss: 3519130880.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4721041784.889..  Test Loss: 3869528064.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4813932081.778..  Test Loss: 3444094976.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4825221304.889..  Test Loss: 3551532032.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4717595754.667..  Test Loss: 3648823552.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4775739000.889..  Test Loss: 3412538368.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4780942940.444..  Test Loss: 3784678912.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4727708238.222..  Test Loss: 3453442304.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4731934016.000..  Test Loss: 3565974272.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4761416359.111..  Test Loss: 3523689472.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4803884878.222..  Test Loss: 3445306624.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4779911057.778..  Test Loss: 3672527872.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4758743822.222..  Test Loss: 3524504832.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4720626147.556..  Test Loss: 3733273856.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4718144526.222..  Test Loss: 3439675904.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4686496846.222..  Test Loss: 3471670528.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4721323655.111..  Test Loss: 3497574912.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4750583274.667..  Test Loss: 3690904832.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4757278264.889..  Test Loss: 3618183424.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4738154318.222..  Test Loss: 3454762752.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4753853824.000..  Test Loss: 3599737088.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4772878222.222..  Test Loss: 3604259328.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4755085735.111..  Test Loss: 3648119808.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4714187427.556..  Test Loss: 3487988992.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4823182247.111..  Test Loss: 3425908736.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4752521905.778..  Test Loss: 3434808320.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4710760433.778..  Test Loss: 3526876672.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4751267918.222..  Test Loss: 3536185088.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4753597511.111..  Test Loss: 3607843584.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4754336078.222..  Test Loss: 3449229312.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4795740519.111..  Test Loss: 3642953728.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4730843648.000..  Test Loss: 3565504000.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4714975395.556..  Test Loss: 3487263488.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4684244366.222..  Test Loss: 3506964224.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4722786908.444..  Test Loss: 3692441344.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4777278784.000..  Test Loss: 3620755200.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4797573184.000..  Test Loss: 3592129792.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4748619303.111..  Test Loss: 3431617792.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4740850353.778..  Test Loss: 3685959936.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4713951395.556..  Test Loss: 3776510976.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4813991040.000..  Test Loss: 3414764288.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4801188757.333..  Test Loss: 3492878080.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4726587093.333..  Test Loss: 3365159936.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4713612003.556..  Test Loss: 3733953280.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4705083605.333..  Test Loss: 3383493376.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4678201329.778..  Test Loss: 3528965120.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4690249973.333..  Test Loss: 3464705024.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4793245297.778..  Test Loss: 3429495296.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4801322524.444..  Test Loss: 3436036864.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4750851192.889..  Test Loss: 3410484480.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4761265358.222..  Test Loss: 3460333312.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4808221888.000..  Test Loss: 3670284032.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4698759708.444..  Test Loss: 3627855360.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4737210520.889..  Test Loss: 3640413952.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4705224853.333..  Test Loss: 3440456960.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4775166030.222..  Test Loss: 3561903360.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4732425166.222..  Test Loss: 3642453248.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4716253546.667..  Test Loss: 3598440960.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4769008832.000..  Test Loss: 3571049472.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4722962410.667..  Test Loss: 3708825600.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4730873564.444..  Test Loss: 3377704192.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4748589767.111..  Test Loss: 3459483392.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4690821866.667..  Test Loss: 3548177152.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4744590499.556..  Test Loss: 3540995072.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4731002190.222..  Test Loss: 3586565376.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4770872896.000..  Test Loss: 3420120576.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4736708472.889..  Test Loss: 3584440576.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4709817073.778..  Test Loss: 3678918912.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4718692611.556..  Test Loss: 3560783872.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4728600192.000..  Test Loss: 3475742720.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4772080092.444..  Test Loss: 3385323264.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4771957326.222..  Test Loss: 3589084416.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4729059719.111..  Test Loss: 3563738624.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4774521713.778..  Test Loss: 3466904832.000.. \n",
      "Epoch: 911/1000..  Training Loss: 4698271132.444..  Test Loss: 3438186496.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4776617603.556..  Test Loss: 3480918784.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4719762307.556..  Test Loss: 3500801280.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 914/1000..  Training Loss: 4774623096.889..  Test Loss: 3560711168.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4720835840.000..  Test Loss: 3474413568.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4753025600.000..  Test Loss: 3563407104.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4681187413.333..  Test Loss: 3651666176.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4673553841.778..  Test Loss: 3491347456.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4736479637.333..  Test Loss: 3477864192.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4676701624.889..  Test Loss: 3705793536.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4735533717.333..  Test Loss: 3499648256.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4817816348.444..  Test Loss: 3800012032.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4750814940.444..  Test Loss: 3419432192.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4746243456.000..  Test Loss: 3397370880.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4712583324.444..  Test Loss: 3413023232.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4673500615.111..  Test Loss: 3371910400.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4712143459.556..  Test Loss: 3320653568.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4752388899.556..  Test Loss: 3423662592.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4756122513.778..  Test Loss: 3455567104.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4775283495.111..  Test Loss: 3529973760.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4719471751.111..  Test Loss: 3438514432.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4777729457.778..  Test Loss: 3813891840.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4768383054.222..  Test Loss: 3433782016.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4771623420.444..  Test Loss: 3436037632.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4697234979.556..  Test Loss: 3500579840.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4643884682.667..  Test Loss: 3582517504.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4673326254.222..  Test Loss: 3513746176.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4750299861.333..  Test Loss: 3542315264.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4765195690.667..  Test Loss: 3465235968.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4706466247.111..  Test Loss: 3468070144.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4772375296.000..  Test Loss: 3585097472.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4709810990.222..  Test Loss: 3566711808.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4689276949.333..  Test Loss: 3424109824.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4691037955.556..  Test Loss: 3381584128.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4723404700.444..  Test Loss: 3523486208.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4711930944.000..  Test Loss: 3564147712.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4682790478.222..  Test Loss: 3593237504.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4734132010.667..  Test Loss: 3621758208.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4694373276.444..  Test Loss: 3383792896.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4705867029.333..  Test Loss: 3493789696.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4749952277.333..  Test Loss: 3440808704.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4708244330.667..  Test Loss: 3401451008.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4721301397.333..  Test Loss: 3371712000.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4699182037.333..  Test Loss: 3534619136.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4720986481.778..  Test Loss: 3587812864.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4746923790.222..  Test Loss: 3577084672.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4689190400.000..  Test Loss: 3569860096.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4696633777.778..  Test Loss: 3509675264.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4741367594.667..  Test Loss: 3547211008.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4747464654.222..  Test Loss: 3452079872.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4722204714.667..  Test Loss: 3433086208.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4719713500.444..  Test Loss: 3579662336.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4757798741.333..  Test Loss: 3678968576.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4715338872.889..  Test Loss: 3592927232.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4705791861.333..  Test Loss: 3614999808.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4712332565.333..  Test Loss: 3430868224.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4718991445.333..  Test Loss: 3585243392.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4745406908.444..  Test Loss: 3432937984.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4779216533.333..  Test Loss: 3482839040.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4750782400.000..  Test Loss: 3417558272.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4763417678.222..  Test Loss: 3416982784.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4729723505.778..  Test Loss: 3341922048.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4661249934.222..  Test Loss: 3351051776.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4699576120.889..  Test Loss: 3416777472.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4696182883.556..  Test Loss: 3419228416.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4681116128.000..  Test Loss: 3600115968.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4713351971.556..  Test Loss: 3418670848.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4705930357.333..  Test Loss: 3367468032.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4718146645.333..  Test Loss: 3521824000.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4741856241.778..  Test Loss: 3368849152.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4709270961.778..  Test Loss: 3571574016.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4677736611.556..  Test Loss: 3426738944.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4725136220.444..  Test Loss: 3346507008.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4683187256.889..  Test Loss: 3322438912.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4713979968.000..  Test Loss: 3380966656.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4668608312.889..  Test Loss: 3710207744.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4610079591.111..  Test Loss: 3399324160.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4716683818.667..  Test Loss: 3418992384.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4689278972.444..  Test Loss: 3390033152.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4709298154.667..  Test Loss: 3582032128.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4722542563.556..  Test Loss: 3749057792.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4667904483.556..  Test Loss: 3609957632.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4729656085.333..  Test Loss: 3561715456.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4679839054.222..  Test Loss: 3477395456.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4759934776.889..  Test Loss: 3565200384.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4717068814.222..  Test Loss: 3390482432.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4691407466.667..  Test Loss: 3548530176.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4661232483.556..  Test Loss: 3498222336.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4682787744.000..  Test Loss: 3355240192.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4731730730.667..  Test Loss: 3362120960.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 4\n",
      "Epoch: 1/1000..  Training Loss: 13471076750.222..  Test Loss: 13435499520.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13476426808.889..  Test Loss: 12462203904.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13467530695.111..  Test Loss: 12237198336.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13466457031.111..  Test Loss: 12356546560.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13463654940.444..  Test Loss: 12188789760.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13463910286.222..  Test Loss: 12905364480.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13466768270.222..  Test Loss: 13349967872.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13464846449.778..  Test Loss: 12611162112.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13463840654.222..  Test Loss: 12277977088.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13461132472.889..  Test Loss: 14652962816.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13462310428.444..  Test Loss: 12608861184.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13460345543.111..  Test Loss: 12344215552.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13453689002.667..  Test Loss: 13857291264.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13458101760.000..  Test Loss: 13681857536.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13452892984.889..  Test Loss: 12132545536.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13449528035.556..  Test Loss: 12952252416.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13446775936.000..  Test Loss: 12706117632.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13442708280.889..  Test Loss: 12192988160.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13446428273.778..  Test Loss: 12027403264.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13443153962.667..  Test Loss: 12286983168.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13438607274.667..  Test Loss: 12287880192.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13442592398.222..  Test Loss: 12025544704.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13426398364.444..  Test Loss: 12444614656.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13427188366.222..  Test Loss: 12300625920.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13425947292.444..  Test Loss: 12889571328.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13420313685.333..  Test Loss: 12517184512.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13414896099.556..  Test Loss: 12998740992.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13410967808.000..  Test Loss: 12233933824.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13414801976.889..  Test Loss: 12422403072.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13406032241.778..  Test Loss: 12303348736.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13401343800.889..  Test Loss: 12209315840.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13397861489.778..  Test Loss: 12664846336.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13394468551.111..  Test Loss: 12464096256.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13393526784.000..  Test Loss: 13274412032.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13383528960.000..  Test Loss: 13240932352.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13380708892.444..  Test Loss: 12168818688.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13376438542.222..  Test Loss: 12374351872.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13367111793.778..  Test Loss: 12669684736.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13363801671.111..  Test Loss: 12474385408.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13364154880.000..  Test Loss: 12160603136.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13360201443.556..  Test Loss: 13104850944.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13352036721.778..  Test Loss: 12585961472.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13345493134.222..  Test Loss: 13354986496.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13341882766.222..  Test Loss: 12304332800.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13335756999.111..  Test Loss: 12361348096.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13337341297.778..  Test Loss: 13217360896.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13332323441.778..  Test Loss: 13614951424.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13317483776.000..  Test Loss: 12509360128.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13311618360.889..  Test Loss: 15177175040.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13306978901.333..  Test Loss: 12871136256.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13297839644.444..  Test Loss: 12264136704.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13297790890.667..  Test Loss: 12318730240.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13289455644.444..  Test Loss: 14697537536.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13283101240.889..  Test Loss: 12679789568.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13274731832.889..  Test Loss: 12228243456.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13268433123.556..  Test Loss: 12065542144.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13264200391.111..  Test Loss: 12281006080.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13254144412.444..  Test Loss: 12296557568.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13258436935.111..  Test Loss: 13818166272.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13245137664.000..  Test Loss: 14370065408.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13241374592.000..  Test Loss: 12075168768.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13236362467.556..  Test Loss: 12217032704.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13231927651.556..  Test Loss: 12629706752.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13217723704.889..  Test Loss: 12144394240.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13212050716.444..  Test Loss: 12477355008.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13200946986.667..  Test Loss: 12990755840.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13197882225.778..  Test Loss: 12577887232.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13191035733.333..  Test Loss: 12090771456.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13181374833.778..  Test Loss: 12407031808.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13176922112.000..  Test Loss: 12632591360.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13170036138.667..  Test Loss: 12577920000.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13163299740.444..  Test Loss: 11801731072.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13155377322.667..  Test Loss: 12236542976.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13148013752.889..  Test Loss: 11971965952.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13136513308.444..  Test Loss: 12550714368.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13129093034.667..  Test Loss: 14967548928.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13124573297.778..  Test Loss: 12374654976.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13117970261.333..  Test Loss: 12268483584.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13113973816.889..  Test Loss: 11883586560.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13111858375.111..  Test Loss: 12366521344.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13088803896.889..  Test Loss: 11908301824.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13086966016.000..  Test Loss: 13950109696.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13078991616.000..  Test Loss: 12585308160.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13069402097.778..  Test Loss: 12543705088.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13062453816.889..  Test Loss: 14166307840.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13052833948.444..  Test Loss: 12498515968.000.. \n",
      "Epoch: 87/1000..  Training Loss: 13039354311.111..  Test Loss: 12194904064.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13031822862.222..  Test Loss: 11955879936.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13026811335.111..  Test Loss: 12680548352.000.. \n",
      "Epoch: 90/1000..  Training Loss: 13005374321.778..  Test Loss: 12318041088.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13012218083.556..  Test Loss: 13320668160.000.. \n",
      "Epoch: 92/1000..  Training Loss: 12994663182.222..  Test Loss: 12104165376.000.. \n",
      "Epoch: 93/1000..  Training Loss: 12986754190.222..  Test Loss: 13025076224.000.. \n",
      "Epoch: 94/1000..  Training Loss: 12978991075.556..  Test Loss: 12031725568.000.. \n",
      "Epoch: 95/1000..  Training Loss: 12969750414.222..  Test Loss: 12207215616.000.. \n",
      "Epoch: 96/1000..  Training Loss: 12959244529.778..  Test Loss: 13842876416.000.. \n",
      "Epoch: 97/1000..  Training Loss: 12955373340.444..  Test Loss: 12383919104.000.. \n",
      "Epoch: 98/1000..  Training Loss: 12952690147.556..  Test Loss: 11898713088.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12930801436.444..  Test Loss: 12096687104.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12919896874.667..  Test Loss: 12724840448.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000..  Training Loss: 12913528348.444..  Test Loss: 12054746112.000.. \n",
      "Epoch: 102/1000..  Training Loss: 12904037432.889..  Test Loss: 11907888128.000.. \n",
      "Epoch: 103/1000..  Training Loss: 12898434232.889..  Test Loss: 12705444864.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12890815488.000..  Test Loss: 12196974592.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12876643783.111..  Test Loss: 12351934464.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12867912135.111..  Test Loss: 13803936768.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12858821831.111..  Test Loss: 14318442496.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12850708736.000..  Test Loss: 12746627072.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12840960896.000..  Test Loss: 12054762496.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12840085560.889..  Test Loss: 11894002688.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12814545991.111..  Test Loss: 13583438848.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12806446677.333..  Test Loss: 11983449088.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12801034211.556..  Test Loss: 12954749952.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12787815680.000..  Test Loss: 11853908992.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12789001187.556..  Test Loss: 11812126720.000.. \n",
      "Epoch: 116/1000..  Training Loss: 12775991452.444..  Test Loss: 13831030784.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12760885404.444..  Test Loss: 11947458560.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12749313365.333..  Test Loss: 11750738944.000.. \n",
      "Epoch: 119/1000..  Training Loss: 12736863516.444..  Test Loss: 12688801792.000.. \n",
      "Epoch: 120/1000..  Training Loss: 12723254414.222..  Test Loss: 12572627968.000.. \n",
      "Epoch: 121/1000..  Training Loss: 12733985251.556..  Test Loss: 12686807040.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12718047061.333..  Test Loss: 11964478464.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12700200248.889..  Test Loss: 13085256704.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12679528192.000..  Test Loss: 12167296000.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12674028771.556..  Test Loss: 12085742592.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12674887623.111..  Test Loss: 13343784960.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12654572316.444..  Test Loss: 12371571712.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12648491690.667..  Test Loss: 12549068800.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12633635527.111..  Test Loss: 13501060096.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12628744334.222..  Test Loss: 12473229312.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12612857955.556..  Test Loss: 13392710656.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12605773184.000..  Test Loss: 13800903680.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12596855680.000..  Test Loss: 11797129216.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12579543452.444..  Test Loss: 12541939712.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12564317482.667..  Test Loss: 15215132672.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12548828743.111..  Test Loss: 12463882240.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12542364472.889..  Test Loss: 11884073984.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12533356174.222..  Test Loss: 12143022080.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12519471630.222..  Test Loss: 12616935424.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12513367978.667..  Test Loss: 12064890880.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12502013184.000..  Test Loss: 12721455104.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12492944952.889..  Test Loss: 12152080384.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12486195384.889..  Test Loss: 12324667392.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12476803669.333..  Test Loss: 11813184512.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12449341895.111..  Test Loss: 11992890368.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12444189070.222..  Test Loss: 12394537984.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12424813667.556..  Test Loss: 11710535680.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12418099527.111..  Test Loss: 13068567552.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12406307569.778..  Test Loss: 12710140928.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12388398919.111..  Test Loss: 12892438528.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12396351459.556..  Test Loss: 12538119168.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12366728391.111..  Test Loss: 13113814016.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12356610688.000..  Test Loss: 12578370560.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12350202055.111..  Test Loss: 12482807808.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12341176007.111..  Test Loss: 11494871040.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12330961464.889..  Test Loss: 13551024128.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12317522574.222..  Test Loss: 12331594752.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12290051512.889..  Test Loss: 12034700288.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12296577706.667..  Test Loss: 11954408448.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12274462051.556..  Test Loss: 14009186304.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12260774016.000..  Test Loss: 11756737536.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12237659790.222..  Test Loss: 11511302144.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12230744234.667..  Test Loss: 12840134656.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12224695182.222..  Test Loss: 12176247808.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12196320426.667..  Test Loss: 13061158912.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12196776092.444..  Test Loss: 11506832384.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12188998456.889..  Test Loss: 12252052480.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12174290816.000..  Test Loss: 12582946816.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12155969934.222..  Test Loss: 11952307200.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12159571456.000..  Test Loss: 11780068352.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12138208099.556..  Test Loss: 11460179968.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12142687544.889..  Test Loss: 12435911680.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12111302385.778..  Test Loss: 13258507264.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12084819953.778..  Test Loss: 11409447936.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12087192035.556..  Test Loss: 11342893056.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12089478840.889..  Test Loss: 11648088064.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12078582712.889..  Test Loss: 11624944640.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12042144853.333..  Test Loss: 11809945600.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12046690759.111..  Test Loss: 12430014464.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12022557667.556..  Test Loss: 12214480896.000.. \n",
      "Epoch: 181/1000..  Training Loss: 12010742556.444..  Test Loss: 11385863168.000.. \n",
      "Epoch: 182/1000..  Training Loss: 12002624483.556..  Test Loss: 11574430720.000.. \n",
      "Epoch: 183/1000..  Training Loss: 11989558343.111..  Test Loss: 12070813696.000.. \n",
      "Epoch: 184/1000..  Training Loss: 11968217628.444..  Test Loss: 12904067072.000.. \n",
      "Epoch: 185/1000..  Training Loss: 11964381383.111..  Test Loss: 11632382976.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11931490076.444..  Test Loss: 11799322624.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11931097614.222..  Test Loss: 12134011904.000.. \n",
      "Epoch: 188/1000..  Training Loss: 11948317852.444..  Test Loss: 11558130688.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11912269795.556..  Test Loss: 11682591744.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11890969671.111..  Test Loss: 12208018432.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11873000675.556..  Test Loss: 12335971328.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11865248398.222..  Test Loss: 12076329984.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11857066865.778..  Test Loss: 12582408192.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11841319352.889..  Test Loss: 13955897344.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11849223950.222..  Test Loss: 12137835520.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11809310008.889..  Test Loss: 11554034688.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11796431886.222..  Test Loss: 11456470016.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11788360732.444..  Test Loss: 11636416512.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11778160554.667..  Test Loss: 11658679296.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200/1000..  Training Loss: 11749514538.667..  Test Loss: 12110118912.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11755615189.333..  Test Loss: 11948893184.000.. \n",
      "Epoch: 202/1000..  Training Loss: 11709516074.667..  Test Loss: 11460212736.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11717237632.000..  Test Loss: 13099853824.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11715677084.444..  Test Loss: 11446629376.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11689839047.111..  Test Loss: 12340354048.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11659448391.111..  Test Loss: 11828199424.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11647068529.778..  Test Loss: 11739993088.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11640826979.556..  Test Loss: 11679000576.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11620109454.222..  Test Loss: 11523571712.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11608312533.333..  Test Loss: 12477698048.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11603529386.667..  Test Loss: 11313900544.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11581677824.000..  Test Loss: 11985894400.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11575492636.444..  Test Loss: 12314178560.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11566519623.111..  Test Loss: 14121273344.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11532461852.444..  Test Loss: 11654094848.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11562596835.556..  Test Loss: 12072653824.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11507627207.111..  Test Loss: 12243198976.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11493212074.667..  Test Loss: 13931401216.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11497192078.222..  Test Loss: 11808451584.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11457472440.889..  Test Loss: 11194023936.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11434678243.556..  Test Loss: 11291603968.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11441565710.222..  Test Loss: 11131454464.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11434150343.111..  Test Loss: 11601636352.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11406187164.444..  Test Loss: 12582183936.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11379591594.667..  Test Loss: 11327607808.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11405727715.556..  Test Loss: 11312907264.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11356026993.778..  Test Loss: 11410327552.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11345977059.556..  Test Loss: 11630558208.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11334437959.111..  Test Loss: 10985059328.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11297154019.556..  Test Loss: 11007395840.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11315573603.556..  Test Loss: 12415955968.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11309520398.222..  Test Loss: 11287560192.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11288492814.222..  Test Loss: 11816589312.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11295855345.778..  Test Loss: 11558760448.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11257982108.444..  Test Loss: 13541100544.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11238262058.667..  Test Loss: 11253404672.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11219742065.778..  Test Loss: 11435168768.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11207214080.000..  Test Loss: 11830306816.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11185839985.778..  Test Loss: 11946006528.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11159354936.889..  Test Loss: 11955055616.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11150216007.111..  Test Loss: 12399420416.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11146356252.444..  Test Loss: 10862901248.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11153686613.333..  Test Loss: 11816435712.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11105275562.667..  Test Loss: 11014583296.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11143598051.556..  Test Loss: 11158260736.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11087302456.889..  Test Loss: 12450681856.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11095314474.667..  Test Loss: 11892907008.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11063415608.889..  Test Loss: 11067167744.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11039257799.111..  Test Loss: 10866349056.000.. \n",
      "Epoch: 250/1000..  Training Loss: 11028462279.111..  Test Loss: 11173303296.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11010081877.333..  Test Loss: 11573408768.000.. \n",
      "Epoch: 252/1000..  Training Loss: 10995250645.333..  Test Loss: 11393669120.000.. \n",
      "Epoch: 253/1000..  Training Loss: 10992084280.889..  Test Loss: 12599397376.000.. \n",
      "Epoch: 254/1000..  Training Loss: 10971209912.889..  Test Loss: 11372211200.000.. \n",
      "Epoch: 255/1000..  Training Loss: 10966648960.000..  Test Loss: 11129369600.000.. \n",
      "Epoch: 256/1000..  Training Loss: 10936581731.556..  Test Loss: 11050243072.000.. \n",
      "Epoch: 257/1000..  Training Loss: 10922730609.778..  Test Loss: 13006350336.000.. \n",
      "Epoch: 258/1000..  Training Loss: 10919907996.444..  Test Loss: 12292310016.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10922457201.778..  Test Loss: 10969450496.000.. \n",
      "Epoch: 260/1000..  Training Loss: 10867876864.000..  Test Loss: 12188490752.000.. \n",
      "Epoch: 261/1000..  Training Loss: 10856177848.889..  Test Loss: 11182842880.000.. \n",
      "Epoch: 262/1000..  Training Loss: 10857285148.444..  Test Loss: 11584012288.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10848010467.556..  Test Loss: 11112444928.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10816056419.556..  Test Loss: 11073809408.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10815173902.222..  Test Loss: 11086863360.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10789876366.222..  Test Loss: 11351129088.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10754850631.111..  Test Loss: 11794838528.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10773531719.111..  Test Loss: 13745000448.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10750493795.556..  Test Loss: 11100506112.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10723582606.222..  Test Loss: 11671645184.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10721858275.556..  Test Loss: 11745999872.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10685891256.889..  Test Loss: 11168368640.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10660862464.000..  Test Loss: 11010185216.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10695865784.889..  Test Loss: 10787747840.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10636150997.333..  Test Loss: 11221666816.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10681241742.222..  Test Loss: 10711054336.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10608453432.889..  Test Loss: 10604490752.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10583820487.111..  Test Loss: 11470534656.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10587807473.778..  Test Loss: 10835996672.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10563092295.111..  Test Loss: 11285181440.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10587549041.778..  Test Loss: 11044087808.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10509096035.556..  Test Loss: 11750563840.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10487658467.556..  Test Loss: 11331015680.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10511634261.333..  Test Loss: 10612928512.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10516944369.778..  Test Loss: 10593968128.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10480184035.556..  Test Loss: 10809235456.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10461486734.222..  Test Loss: 11113332736.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10441555185.778..  Test Loss: 10443877376.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10400720384.000..  Test Loss: 10682360832.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10434780316.444..  Test Loss: 12145017856.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10421587768.889..  Test Loss: 11243978752.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10385528860.444..  Test Loss: 11009666048.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10363119203.556..  Test Loss: 10654514176.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10346370090.667..  Test Loss: 10570035200.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10322065393.778..  Test Loss: 12351542272.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10311742037.333..  Test Loss: 13240308736.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10285562638.222..  Test Loss: 12210484224.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10282540615.111..  Test Loss: 10629495808.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/1000..  Training Loss: 10278814919.111..  Test Loss: 10778076160.000.. \n",
      "Epoch: 300/1000..  Training Loss: 10261093120.000..  Test Loss: 13051680768.000.. \n",
      "Epoch: 301/1000..  Training Loss: 10198301511.111..  Test Loss: 11149669376.000.. \n",
      "Epoch: 302/1000..  Training Loss: 10189226112.000..  Test Loss: 10342784000.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10198332416.000..  Test Loss: 10544779264.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10198629105.778..  Test Loss: 10552042496.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10167975637.333..  Test Loss: 12367246336.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10113480334.222..  Test Loss: 11040489472.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10121272106.667..  Test Loss: 10242970624.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10115467847.111..  Test Loss: 10924565504.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10083429120.000..  Test Loss: 10472354816.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10084080938.667..  Test Loss: 10322123776.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10092919779.556..  Test Loss: 10263057408.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10028780856.889..  Test Loss: 10886018048.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10037767125.333..  Test Loss: 10394003456.000.. \n",
      "Epoch: 314/1000..  Training Loss: 10007567473.778..  Test Loss: 10244068352.000.. \n",
      "Epoch: 315/1000..  Training Loss: 10026233358.222..  Test Loss: 10048789504.000.. \n",
      "Epoch: 316/1000..  Training Loss: 9978052906.667..  Test Loss: 10376606720.000.. \n",
      "Epoch: 317/1000..  Training Loss: 9981308956.444..  Test Loss: 11824014336.000.. \n",
      "Epoch: 318/1000..  Training Loss: 9962691683.556..  Test Loss: 10340774912.000.. \n",
      "Epoch: 319/1000..  Training Loss: 9952851399.111..  Test Loss: 10887644160.000.. \n",
      "Epoch: 320/1000..  Training Loss: 9941580984.889..  Test Loss: 10605155328.000.. \n",
      "Epoch: 321/1000..  Training Loss: 9876911189.333..  Test Loss: 11146590208.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9905868060.444..  Test Loss: 10725920768.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9900213020.444..  Test Loss: 10482868224.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9847382542.222..  Test Loss: 10124177408.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9811984853.333..  Test Loss: 10434292736.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9817806193.778..  Test Loss: 10139977728.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9818150385.778..  Test Loss: 10762736640.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9776728419.556..  Test Loss: 12741253120.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9770126208.000..  Test Loss: 10277039104.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9757215815.111..  Test Loss: 10115561472.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9732979939.556..  Test Loss: 10165137408.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9703991025.778..  Test Loss: 9931581440.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9720497578.667..  Test Loss: 10964833280.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9762409927.111..  Test Loss: 10523585536.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9699173603.556..  Test Loss: 10370357248.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9712792007.111..  Test Loss: 10822459392.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9629655111.111..  Test Loss: 10488290304.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9604898033.778..  Test Loss: 11468722176.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9651168455.111..  Test Loss: 10264638464.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9607729678.222..  Test Loss: 10213579776.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9586719203.556..  Test Loss: 10960142336.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9584185685.333..  Test Loss: 10028790784.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9583572821.333..  Test Loss: 10239180800.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9516981347.556..  Test Loss: 10378033152.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9520996366.222..  Test Loss: 10894630912.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9520877724.444..  Test Loss: 10926969856.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9515682588.444..  Test Loss: 12235027456.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9438600519.111..  Test Loss: 10042970112.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9474936192.000..  Test Loss: 10295294976.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9466309162.667..  Test Loss: 11004926976.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9442645091.556..  Test Loss: 13261304832.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9412285809.778..  Test Loss: 10327155712.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9404245504.000..  Test Loss: 9994320896.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9363158684.444..  Test Loss: 10022071296.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9367116003.556..  Test Loss: 10218443776.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9324213077.333..  Test Loss: 10161941504.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9359921123.556..  Test Loss: 10099307520.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9303624576.000..  Test Loss: 10511145984.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9275265607.111..  Test Loss: 9911064576.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9284707726.222..  Test Loss: 11099400192.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9258792974.222..  Test Loss: 10684879872.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9259289329.778..  Test Loss: 11287499776.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9220821816.889..  Test Loss: 10518457344.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9270516337.778..  Test Loss: 9725350912.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9219182236.444..  Test Loss: 9810514944.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9203800504.889..  Test Loss: 9820605440.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9139814172.444..  Test Loss: 9760755712.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9135729834.667..  Test Loss: 9657753600.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9144087502.222..  Test Loss: 10183621632.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9080212195.556..  Test Loss: 8949780480.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9089706424.889..  Test Loss: 9868315648.000.. \n",
      "Epoch: 372/1000..  Training Loss: 9097836487.111..  Test Loss: 9448237056.000.. \n",
      "Epoch: 373/1000..  Training Loss: 9052451584.000..  Test Loss: 10611526656.000.. \n",
      "Epoch: 374/1000..  Training Loss: 9043519473.778..  Test Loss: 10236007424.000.. \n",
      "Epoch: 375/1000..  Training Loss: 9058319502.222..  Test Loss: 9360196608.000.. \n",
      "Epoch: 376/1000..  Training Loss: 9028915498.667..  Test Loss: 9213587456.000.. \n",
      "Epoch: 377/1000..  Training Loss: 9017617678.222..  Test Loss: 9768145920.000.. \n",
      "Epoch: 378/1000..  Training Loss: 8986183153.778..  Test Loss: 9113105408.000.. \n",
      "Epoch: 379/1000..  Training Loss: 8940473329.778..  Test Loss: 8840320000.000.. \n",
      "Epoch: 380/1000..  Training Loss: 8956974321.778..  Test Loss: 8789000192.000.. \n",
      "Epoch: 381/1000..  Training Loss: 8935464547.556..  Test Loss: 8766067712.000.. \n",
      "Epoch: 382/1000..  Training Loss: 8923337543.111..  Test Loss: 9103157248.000.. \n",
      "Epoch: 383/1000..  Training Loss: 8884725191.111..  Test Loss: 10337129472.000.. \n",
      "Epoch: 384/1000..  Training Loss: 8811676117.333..  Test Loss: 8222902272.000.. \n",
      "Epoch: 385/1000..  Training Loss: 8849680810.667..  Test Loss: 8756168704.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8803168725.333..  Test Loss: 8077647872.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8776337521.778..  Test Loss: 9323214848.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8791193272.889..  Test Loss: 8424487936.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8758952704.000..  Test Loss: 9180049408.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8745256192.000..  Test Loss: 9470694400.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8735496163.556..  Test Loss: 7914588160.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8734022755.556..  Test Loss: 8061196800.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8709131306.667..  Test Loss: 8034397696.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8726940216.889..  Test Loss: 7782678528.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8681845916.444..  Test Loss: 8609835008.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8628795804.444..  Test Loss: 8527813632.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8598013240.889..  Test Loss: 7781586432.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8627406208.000..  Test Loss: 8179879424.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8567544718.222..  Test Loss: 7541304832.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400/1000..  Training Loss: 8546221425.778..  Test Loss: 7784238592.000.. \n",
      "Epoch: 401/1000..  Training Loss: 8522571050.667..  Test Loss: 8634315776.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8506766592.000..  Test Loss: 8999371776.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8540714410.667..  Test Loss: 8282191360.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8532033031.111..  Test Loss: 7520655872.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8519841692.444..  Test Loss: 8053330432.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8490849848.889..  Test Loss: 7864961024.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8414402446.222..  Test Loss: 7943981568.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8413693816.889..  Test Loss: 7462932992.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8422625336.889..  Test Loss: 7740873216.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8431589809.778..  Test Loss: 7813585920.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8418630535.111..  Test Loss: 7552566784.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8384714282.667..  Test Loss: 7714652160.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8343394496.000..  Test Loss: 8389264384.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8388126897.778..  Test Loss: 8377851904.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8281921450.667..  Test Loss: 7490861568.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8359616312.889..  Test Loss: 7656622080.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8315585436.444..  Test Loss: 7718730240.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8245489528.889..  Test Loss: 8175924736.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8266111843.556..  Test Loss: 7628652544.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8217810944.000..  Test Loss: 8295224832.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8178740878.222..  Test Loss: 7951628800.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8230117475.556..  Test Loss: 7483707904.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8230503672.889..  Test Loss: 8162959360.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8215721187.556..  Test Loss: 7226088960.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8146953287.111..  Test Loss: 7484013056.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8192330752.000..  Test Loss: 7387208704.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8117679075.556..  Test Loss: 7587003392.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8092161934.222..  Test Loss: 8224076288.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8074129920.000..  Test Loss: 7212341248.000.. \n",
      "Epoch: 430/1000..  Training Loss: 8105256199.111..  Test Loss: 9381906432.000.. \n",
      "Epoch: 431/1000..  Training Loss: 8061558471.111..  Test Loss: 8882161664.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8046035783.111..  Test Loss: 7579637248.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8000367189.333..  Test Loss: 7666250240.000.. \n",
      "Epoch: 434/1000..  Training Loss: 8043424199.111..  Test Loss: 7108210688.000.. \n",
      "Epoch: 435/1000..  Training Loss: 7903408967.111..  Test Loss: 8452099584.000.. \n",
      "Epoch: 436/1000..  Training Loss: 7976878023.111..  Test Loss: 7641298432.000.. \n",
      "Epoch: 437/1000..  Training Loss: 7990648305.778..  Test Loss: 7086937088.000.. \n",
      "Epoch: 438/1000..  Training Loss: 7939787178.667..  Test Loss: 7095698432.000.. \n",
      "Epoch: 439/1000..  Training Loss: 7935988430.222..  Test Loss: 9497455616.000.. \n",
      "Epoch: 440/1000..  Training Loss: 7880462364.444..  Test Loss: 7298368512.000.. \n",
      "Epoch: 441/1000..  Training Loss: 7917814172.444..  Test Loss: 8571297792.000.. \n",
      "Epoch: 442/1000..  Training Loss: 7871047694.222..  Test Loss: 7158508032.000.. \n",
      "Epoch: 443/1000..  Training Loss: 7830467477.333..  Test Loss: 6981599232.000.. \n",
      "Epoch: 444/1000..  Training Loss: 7826935495.111..  Test Loss: 7673948160.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7833813397.333..  Test Loss: 6917155328.000.. \n",
      "Epoch: 446/1000..  Training Loss: 7811072803.556..  Test Loss: 7215121408.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7765535630.222..  Test Loss: 7565999104.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7771795904.000..  Test Loss: 8588724224.000.. \n",
      "Epoch: 449/1000..  Training Loss: 7679674922.667..  Test Loss: 7315207680.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7779279068.444..  Test Loss: 7052889088.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7702643370.667..  Test Loss: 7694879232.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7652255232.000..  Test Loss: 6956010496.000.. \n",
      "Epoch: 453/1000..  Training Loss: 7668077070.222..  Test Loss: 7269538304.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7708737379.556..  Test Loss: 6872457216.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7658054968.889..  Test Loss: 7192066560.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7638273280.000..  Test Loss: 7340751872.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7522565056.000..  Test Loss: 6651281408.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7612416497.778..  Test Loss: 9114843136.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7541171896.889..  Test Loss: 7064631808.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7585554112.000..  Test Loss: 7548682240.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7551300565.333..  Test Loss: 6853402624.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7564309873.778..  Test Loss: 6669164032.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7540853468.444..  Test Loss: 7251843584.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7503068074.667..  Test Loss: 8007105536.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7514757319.111..  Test Loss: 6924443648.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7457947676.444..  Test Loss: 6820305408.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7523245539.556..  Test Loss: 7359729664.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7539512732.444..  Test Loss: 7029102080.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7443021632.000..  Test Loss: 6950753792.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7384058197.333..  Test Loss: 7569900032.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7403870663.111..  Test Loss: 8881884160.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7416238535.111..  Test Loss: 6694403584.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7399367352.889..  Test Loss: 6735064576.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7317222940.444..  Test Loss: 7339511296.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7303010126.222..  Test Loss: 6717400576.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7350046257.778..  Test Loss: 7270813184.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7310098645.333..  Test Loss: 6855569408.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7293703736.889..  Test Loss: 6738164224.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7299847047.111..  Test Loss: 6981106176.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7279062158.222..  Test Loss: 6963639296.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7255519445.333..  Test Loss: 8553705984.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7237035384.889..  Test Loss: 7995359232.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7291289009.778..  Test Loss: 7823795200.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7187379164.444..  Test Loss: 6358443008.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7172705464.889..  Test Loss: 6679675904.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7190757760.000..  Test Loss: 6542561280.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7162035079.111..  Test Loss: 6511625728.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7169039047.111..  Test Loss: 7414085632.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7171800590.222..  Test Loss: 6399321600.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7156329920.000..  Test Loss: 6991396352.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7080436821.333..  Test Loss: 6280327168.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7106101184.000..  Test Loss: 6756052992.000.. \n",
      "Epoch: 493/1000..  Training Loss: 7141203790.222..  Test Loss: 6457262592.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7131380088.889..  Test Loss: 6971142656.000.. \n",
      "Epoch: 495/1000..  Training Loss: 7049795541.333..  Test Loss: 6900852736.000.. \n",
      "Epoch: 496/1000..  Training Loss: 7005343516.444..  Test Loss: 6662326272.000.. \n",
      "Epoch: 497/1000..  Training Loss: 7009398343.111..  Test Loss: 7173857280.000.. \n",
      "Epoch: 498/1000..  Training Loss: 6989676174.222..  Test Loss: 6688910848.000.. \n",
      "Epoch: 499/1000..  Training Loss: 7012909326.222..  Test Loss: 6268281344.000.. \n",
      "Epoch: 500/1000..  Training Loss: 6985816220.444..  Test Loss: 6807442944.000.. \n",
      "Epoch: 501/1000..  Training Loss: 6945853760.000..  Test Loss: 7850530304.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 502/1000..  Training Loss: 6959205980.444..  Test Loss: 6821950976.000.. \n",
      "Epoch: 503/1000..  Training Loss: 6959450808.889..  Test Loss: 6802512384.000.. \n",
      "Epoch: 504/1000..  Training Loss: 6949134613.333..  Test Loss: 6773033472.000.. \n",
      "Epoch: 505/1000..  Training Loss: 6885339000.889..  Test Loss: 6190819328.000.. \n",
      "Epoch: 506/1000..  Training Loss: 6860501845.333..  Test Loss: 6940169728.000.. \n",
      "Epoch: 507/1000..  Training Loss: 6858970894.222..  Test Loss: 6142492672.000.. \n",
      "Epoch: 508/1000..  Training Loss: 6906698360.889..  Test Loss: 6554550784.000.. \n",
      "Epoch: 509/1000..  Training Loss: 6845895544.889..  Test Loss: 5937568256.000.. \n",
      "Epoch: 510/1000..  Training Loss: 6887856028.444..  Test Loss: 6185187328.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6883099875.556..  Test Loss: 7553776128.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6832943416.889..  Test Loss: 7622383104.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6827383139.556..  Test Loss: 6476098048.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6779463018.667..  Test Loss: 6102153728.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6774608903.111..  Test Loss: 6317961728.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6734064490.667..  Test Loss: 6056226304.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6704410389.333..  Test Loss: 6089055232.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6677246890.667..  Test Loss: 6241944576.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6708894499.556..  Test Loss: 6867220992.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6660952867.556..  Test Loss: 7044317184.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6710577436.444..  Test Loss: 7251035136.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6704024099.556..  Test Loss: 7161285120.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6675221070.222..  Test Loss: 6476880384.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6649319708.444..  Test Loss: 6055675392.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6606548956.444..  Test Loss: 5834754560.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6560401073.778..  Test Loss: 6185118208.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6546752021.333..  Test Loss: 6966739968.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6551956088.889..  Test Loss: 5843446272.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6581586730.667..  Test Loss: 5916764672.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6608447228.444..  Test Loss: 5739582976.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6554864661.333..  Test Loss: 5759778304.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6533339363.556..  Test Loss: 5756112896.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6475028323.556..  Test Loss: 5784590848.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6522367004.444..  Test Loss: 5727332352.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6482761280.000..  Test Loss: 5731118592.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6454116593.778..  Test Loss: 5624384000.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6474050062.222..  Test Loss: 6198738944.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6406926620.444..  Test Loss: 6133360128.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6429129706.667..  Test Loss: 6700166656.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6510740771.556..  Test Loss: 5748062208.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6398218673.778..  Test Loss: 5685558272.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6410119516.444..  Test Loss: 5606161920.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6448903160.889..  Test Loss: 5723462656.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6344206592.000..  Test Loss: 5838979072.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6371940174.222..  Test Loss: 5525883392.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6370936078.222..  Test Loss: 5531504640.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6302937443.556..  Test Loss: 5894240768.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6349802339.556..  Test Loss: 6077086208.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6261904142.222..  Test Loss: 5668557824.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6324722218.667..  Test Loss: 5611193344.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6288260280.889..  Test Loss: 5570363392.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6300508920.889..  Test Loss: 5709741056.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6233448640.000..  Test Loss: 6277163520.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6255172131.556..  Test Loss: 5767195136.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6213044423.111..  Test Loss: 5647268352.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6240815665.778..  Test Loss: 5787885568.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6198126762.667..  Test Loss: 5639107072.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6213142456.889..  Test Loss: 6216083456.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6190903808.000..  Test Loss: 5604501504.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6176036039.111..  Test Loss: 5402033152.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6183967850.667..  Test Loss: 6437636096.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6162673052.444..  Test Loss: 5482462720.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6080764117.333..  Test Loss: 7266281984.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6068899605.333..  Test Loss: 5481306624.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6137524494.222..  Test Loss: 5625232896.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6089041365.333..  Test Loss: 5449796096.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6102916231.111..  Test Loss: 5660538368.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6013259818.667..  Test Loss: 5632444416.000.. \n",
      "Epoch: 569/1000..  Training Loss: 6054885909.333..  Test Loss: 6404369920.000.. \n",
      "Epoch: 570/1000..  Training Loss: 6015365219.556..  Test Loss: 5343795712.000.. \n",
      "Epoch: 571/1000..  Training Loss: 6029508231.111..  Test Loss: 5684274176.000.. \n",
      "Epoch: 572/1000..  Training Loss: 5966500707.556..  Test Loss: 5319741440.000.. \n",
      "Epoch: 573/1000..  Training Loss: 5991927096.889..  Test Loss: 5400371200.000.. \n",
      "Epoch: 574/1000..  Training Loss: 5953515484.444..  Test Loss: 5282489856.000.. \n",
      "Epoch: 575/1000..  Training Loss: 5950455985.778..  Test Loss: 5296297984.000.. \n",
      "Epoch: 576/1000..  Training Loss: 6093920305.778..  Test Loss: 5605541376.000.. \n",
      "Epoch: 577/1000..  Training Loss: 6021812074.667..  Test Loss: 6210598912.000.. \n",
      "Epoch: 578/1000..  Training Loss: 5977174584.889..  Test Loss: 5306426880.000.. \n",
      "Epoch: 579/1000..  Training Loss: 5931831829.333..  Test Loss: 5168927232.000.. \n",
      "Epoch: 580/1000..  Training Loss: 5921436650.667..  Test Loss: 5165994496.000.. \n",
      "Epoch: 581/1000..  Training Loss: 5874671345.778..  Test Loss: 5355968000.000.. \n",
      "Epoch: 582/1000..  Training Loss: 5862360199.111..  Test Loss: 5839496704.000.. \n",
      "Epoch: 583/1000..  Training Loss: 5885163214.222..  Test Loss: 5248281088.000.. \n",
      "Epoch: 584/1000..  Training Loss: 5863286648.889..  Test Loss: 5175387136.000.. \n",
      "Epoch: 585/1000..  Training Loss: 5891818104.889..  Test Loss: 5129884672.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5819927118.222..  Test Loss: 5777830912.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5897277653.333..  Test Loss: 6249505280.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5803634332.444..  Test Loss: 6172084224.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5856581283.556..  Test Loss: 5020600832.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5818570510.222..  Test Loss: 4891755520.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5857142833.778..  Test Loss: 5286785536.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5775138197.333..  Test Loss: 4986391040.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5810857088.000..  Test Loss: 5837710336.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5775293752.889..  Test Loss: 4966677504.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5785618453.333..  Test Loss: 5557504512.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5780533233.778..  Test Loss: 5446517248.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5741311608.889..  Test Loss: 4907581440.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5744111672.889..  Test Loss: 4942232576.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5761852636.444..  Test Loss: 5331334144.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5720379328.000..  Test Loss: 5672578048.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5741740113.778..  Test Loss: 4961058304.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5732266552.889..  Test Loss: 4994379264.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5639492252.444..  Test Loss: 5419214848.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 604/1000..  Training Loss: 5614643768.889..  Test Loss: 6334964736.000.. \n",
      "Epoch: 605/1000..  Training Loss: 5619832256.000..  Test Loss: 5400825856.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5648502741.333..  Test Loss: 5706499584.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5651540088.889..  Test Loss: 4793698304.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5627158627.556..  Test Loss: 5012319744.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5667629312.000..  Test Loss: 4735452160.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5625395409.778..  Test Loss: 5136206336.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5649383360.000..  Test Loss: 4924094464.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5552951811.556..  Test Loss: 5937672192.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5551246855.111..  Test Loss: 4939296768.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5565873315.556..  Test Loss: 4951530496.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5576059662.222..  Test Loss: 4954773504.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5538235626.667..  Test Loss: 4740750336.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5485839544.889..  Test Loss: 6962860032.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5551061688.889..  Test Loss: 4953126912.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5569387936.000..  Test Loss: 5623026688.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5559215246.222..  Test Loss: 5760807424.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5473324252.444..  Test Loss: 4839663104.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5499984241.778..  Test Loss: 4917532672.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5461281457.778..  Test Loss: 5078628864.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5455566997.333..  Test Loss: 6091910656.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5519978204.444..  Test Loss: 4638550528.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5517874730.667..  Test Loss: 5581316096.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5438371512.889..  Test Loss: 4654963712.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5457717383.111..  Test Loss: 4776540160.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5486707861.333..  Test Loss: 5152422400.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5495154968.889..  Test Loss: 4910666240.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5465307989.333..  Test Loss: 5197236736.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5450333703.111..  Test Loss: 5212308480.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5412856967.111..  Test Loss: 4772016640.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5437846467.556..  Test Loss: 4471721472.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5446769578.667..  Test Loss: 4450428416.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5404335608.889..  Test Loss: 4754925568.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5365377927.111..  Test Loss: 4934901248.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5432229617.778..  Test Loss: 5379656704.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5319152590.222..  Test Loss: 5521226240.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5417299164.444..  Test Loss: 4672089600.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5357257902.222..  Test Loss: 4431690752.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5315710741.333..  Test Loss: 4435974656.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5334224149.333..  Test Loss: 4440721408.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5363446684.444..  Test Loss: 4451751936.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5322157326.222..  Test Loss: 4346184192.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5291180949.333..  Test Loss: 4863496192.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5308158122.667..  Test Loss: 4874761728.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5380596615.111..  Test Loss: 4372071424.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5274147505.778..  Test Loss: 4416262144.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5311974727.111..  Test Loss: 4550336512.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5279055907.556..  Test Loss: 4474986496.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5185512092.444..  Test Loss: 4262084608.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5289012128.000..  Test Loss: 4296218112.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5345596608.000..  Test Loss: 4470316032.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5265981980.444..  Test Loss: 4351896576.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5234067818.667..  Test Loss: 5858573312.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5301261820.444..  Test Loss: 4253800192.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5255473909.333..  Test Loss: 4654522368.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5241488302.222..  Test Loss: 4322981376.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5227736149.333..  Test Loss: 4955347456.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5261533333.333..  Test Loss: 4924336128.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5181220295.111..  Test Loss: 4399332864.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5145437802.667..  Test Loss: 4341043200.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5152000554.667..  Test Loss: 4530384384.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5118324480.000..  Test Loss: 4398757888.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5171040391.111..  Test Loss: 4282115072.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5168446357.333..  Test Loss: 6236262912.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5145274396.444..  Test Loss: 4327224320.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5185846944.000..  Test Loss: 4594412032.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5143179484.444..  Test Loss: 6260918784.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5165586723.556..  Test Loss: 4294282752.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5137579626.667..  Test Loss: 4672000512.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5107685006.222..  Test Loss: 4144158464.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5093446656.000..  Test Loss: 4526797312.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5051202456.889..  Test Loss: 4096963072.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5096863395.556..  Test Loss: 4163276288.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5132104270.222..  Test Loss: 4568043520.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5132921532.444..  Test Loss: 4290716672.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5114024824.889..  Test Loss: 4147640064.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5047689322.667..  Test Loss: 4074586112.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5072789553.778..  Test Loss: 4100806400.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5074547100.444..  Test Loss: 4321347584.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5119806613.333..  Test Loss: 4297308672.000.. \n",
      "Epoch: 684/1000..  Training Loss: 5132585937.778..  Test Loss: 4117298432.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5131477312.000..  Test Loss: 4116842752.000.. \n",
      "Epoch: 686/1000..  Training Loss: 5065031786.667..  Test Loss: 4150103552.000.. \n",
      "Epoch: 687/1000..  Training Loss: 5019597162.667..  Test Loss: 4384665088.000.. \n",
      "Epoch: 688/1000..  Training Loss: 4974573404.444..  Test Loss: 4164449536.000.. \n",
      "Epoch: 689/1000..  Training Loss: 5006460174.222..  Test Loss: 4633378304.000.. \n",
      "Epoch: 690/1000..  Training Loss: 5048421255.111..  Test Loss: 4028390912.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5027932529.778..  Test Loss: 4105500928.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5010657376.000..  Test Loss: 4408880128.000.. \n",
      "Epoch: 693/1000..  Training Loss: 4974640156.444..  Test Loss: 4325646848.000.. \n",
      "Epoch: 694/1000..  Training Loss: 4956339726.222..  Test Loss: 4129126656.000.. \n",
      "Epoch: 695/1000..  Training Loss: 5009679448.889..  Test Loss: 4867049472.000.. \n",
      "Epoch: 696/1000..  Training Loss: 4996944952.889..  Test Loss: 4331484160.000.. \n",
      "Epoch: 697/1000..  Training Loss: 4972116451.556..  Test Loss: 4139070720.000.. \n",
      "Epoch: 698/1000..  Training Loss: 5001519459.556..  Test Loss: 4580258304.000.. \n",
      "Epoch: 699/1000..  Training Loss: 4991430350.222..  Test Loss: 4105961984.000.. \n",
      "Epoch: 700/1000..  Training Loss: 5003886698.667..  Test Loss: 4236012288.000.. \n",
      "Epoch: 701/1000..  Training Loss: 4981724508.444..  Test Loss: 4016122112.000.. \n",
      "Epoch: 702/1000..  Training Loss: 5013865162.667..  Test Loss: 4062537472.000.. \n",
      "Epoch: 703/1000..  Training Loss: 4924963669.333..  Test Loss: 4440985088.000.. \n",
      "Epoch: 704/1000..  Training Loss: 4878480455.111..  Test Loss: 3990318336.000.. \n",
      "Epoch: 705/1000..  Training Loss: 4945727488.000..  Test Loss: 3893273600.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 706/1000..  Training Loss: 4901526080.000..  Test Loss: 3910355712.000.. \n",
      "Epoch: 707/1000..  Training Loss: 4953860984.889..  Test Loss: 4113566464.000.. \n",
      "Epoch: 708/1000..  Training Loss: 4957514958.222..  Test Loss: 3937068288.000.. \n",
      "Epoch: 709/1000..  Training Loss: 4920156693.333..  Test Loss: 4229350656.000.. \n",
      "Epoch: 710/1000..  Training Loss: 4902276849.778..  Test Loss: 6259718656.000.. \n",
      "Epoch: 711/1000..  Training Loss: 4960160760.889..  Test Loss: 4537330176.000.. \n",
      "Epoch: 712/1000..  Training Loss: 4890220640.000..  Test Loss: 3908473344.000.. \n",
      "Epoch: 713/1000..  Training Loss: 4924565048.889..  Test Loss: 3978261504.000.. \n",
      "Epoch: 714/1000..  Training Loss: 4911570033.778..  Test Loss: 3876835840.000.. \n",
      "Epoch: 715/1000..  Training Loss: 4950502421.333..  Test Loss: 4591577600.000.. \n",
      "Epoch: 716/1000..  Training Loss: 4893241148.444..  Test Loss: 4008896768.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4948030371.556..  Test Loss: 4060466432.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4875687601.778..  Test Loss: 4017772288.000.. \n",
      "Epoch: 719/1000..  Training Loss: 4842804743.111..  Test Loss: 3948707328.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4898595772.444..  Test Loss: 3884349184.000.. \n",
      "Epoch: 721/1000..  Training Loss: 4912806855.111..  Test Loss: 4953370624.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4887012956.444..  Test Loss: 4891977216.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4878162133.333..  Test Loss: 4249875712.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4885827463.111..  Test Loss: 4298103296.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4901091072.000..  Test Loss: 4037172736.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4891338179.556..  Test Loss: 4064052224.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4884605873.778..  Test Loss: 4328854016.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4844051491.556..  Test Loss: 4735833600.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4895446997.333..  Test Loss: 3824480256.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4803186588.444..  Test Loss: 4468054528.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4900539811.556..  Test Loss: 4207201024.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4818891918.222..  Test Loss: 4189437440.000.. \n",
      "Epoch: 733/1000..  Training Loss: 4821999950.222..  Test Loss: 3909969152.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4850996821.333..  Test Loss: 3866307328.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4846432725.333..  Test Loss: 4388311040.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4824207360.000..  Test Loss: 3741347328.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4844603562.667..  Test Loss: 5580265984.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4821013063.111..  Test Loss: 4204026112.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4772014776.889..  Test Loss: 3756919296.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4794413688.889..  Test Loss: 4154218240.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4833566869.333..  Test Loss: 3757591808.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4810308995.556..  Test Loss: 3808773376.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4823828910.222..  Test Loss: 3770294784.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4813365027.556..  Test Loss: 4178784256.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4874224746.667..  Test Loss: 3822652928.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4761264974.222..  Test Loss: 4243610368.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4729618958.222..  Test Loss: 4864219136.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4815062464.000..  Test Loss: 5552190976.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4814757248.000..  Test Loss: 3799139584.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4776184483.556..  Test Loss: 3663030784.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4847425450.667..  Test Loss: 3667148800.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4750784128.000..  Test Loss: 4483313152.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4753092721.778..  Test Loss: 5132724736.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4805053888.000..  Test Loss: 3657691648.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4743906069.333..  Test Loss: 4399942144.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4824612672.000..  Test Loss: 4057536256.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4796168807.111..  Test Loss: 3920625152.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4767602488.889..  Test Loss: 3770467584.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4784154410.667..  Test Loss: 3928441344.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4743428195.556..  Test Loss: 4314324992.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4748391971.556..  Test Loss: 3684512000.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4852760565.333..  Test Loss: 3896738816.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4814913678.222..  Test Loss: 3783405056.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4762056768.000..  Test Loss: 3689436928.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4816415338.667..  Test Loss: 4147598592.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4677578908.444..  Test Loss: 3896339712.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4736739285.333..  Test Loss: 3831095808.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4785655488.000..  Test Loss: 3627719168.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4755892209.778..  Test Loss: 3606330112.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4777734592.000..  Test Loss: 4265708288.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4756471431.111..  Test Loss: 3705679360.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4751101838.222..  Test Loss: 4118154752.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4736894286.222..  Test Loss: 3759293440.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4747398044.444..  Test Loss: 3867159808.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4752699740.444..  Test Loss: 4007539968.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4718352014.222..  Test Loss: 3614343424.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4749438400.000..  Test Loss: 3704609280.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4686383971.556..  Test Loss: 3939521792.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4737403847.111..  Test Loss: 6668338176.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4694673031.111..  Test Loss: 3762956544.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4746151168.000..  Test Loss: 4174582272.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4712414272.000..  Test Loss: 3659687424.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4727987975.111..  Test Loss: 3762394368.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4762286136.889..  Test Loss: 3733577984.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4718262979.556..  Test Loss: 4223497216.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4729290275.556..  Test Loss: 3888195840.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4687957269.333..  Test Loss: 3969402112.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4714509553.778..  Test Loss: 3624385792.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4712969834.667..  Test Loss: 3646290688.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4709087644.444..  Test Loss: 3864623360.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4700633418.667..  Test Loss: 3693760000.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4759561457.778..  Test Loss: 3635107584.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4771770211.556..  Test Loss: 3571451136.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4725091072.000..  Test Loss: 3604842752.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4668000675.556..  Test Loss: 3517924352.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4760079104.000..  Test Loss: 3568880896.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4759991971.556..  Test Loss: 3929990912.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4729947768.889..  Test Loss: 3580024064.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4719738140.444..  Test Loss: 3629714688.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4744906197.333..  Test Loss: 3735892992.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4670685838.222..  Test Loss: 3673398016.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4692455320.889..  Test Loss: 4091651328.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4708166848.000..  Test Loss: 3718069504.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4634777440.000..  Test Loss: 3719665152.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4737010837.333..  Test Loss: 3779867392.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4708512590.222..  Test Loss: 3587760128.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4740216938.667..  Test Loss: 3529897728.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 808/1000..  Training Loss: 4670038300.444..  Test Loss: 4236674816.000.. \n",
      "Epoch: 809/1000..  Training Loss: 4710149927.111..  Test Loss: 3656441600.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4700840142.222..  Test Loss: 3958075904.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4745115722.667..  Test Loss: 4190693120.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4706294279.111..  Test Loss: 4820404224.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4693978254.222..  Test Loss: 3659415040.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4688570161.778..  Test Loss: 3920780032.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4689206321.778..  Test Loss: 3690910208.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4704836579.556..  Test Loss: 4111322624.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4703037664.000..  Test Loss: 3485083648.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4696095964.444..  Test Loss: 3609104896.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4745673272.889..  Test Loss: 3486473984.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4667317184.000..  Test Loss: 3890661120.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4705674062.222..  Test Loss: 5520804864.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4753447125.333..  Test Loss: 3917431296.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4718627086.222..  Test Loss: 3521259776.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4664102784.000..  Test Loss: 3749015040.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4620006357.333..  Test Loss: 3721787648.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4735812259.556..  Test Loss: 3786025984.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4671379512.889..  Test Loss: 3531973120.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4702814670.222..  Test Loss: 4459900928.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4708729208.889..  Test Loss: 4160453376.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4680519431.111..  Test Loss: 3583002880.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4673640746.667..  Test Loss: 3494313472.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4635113198.222..  Test Loss: 3633616896.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4642411029.333..  Test Loss: 3712808960.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4686006520.889..  Test Loss: 3531998720.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4655294421.333..  Test Loss: 3708278528.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4725499384.889..  Test Loss: 3572586496.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4670260551.111..  Test Loss: 3673484032.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4671234446.222..  Test Loss: 3586163712.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4676378979.556..  Test Loss: 3653740288.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4711342126.222..  Test Loss: 3744685824.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4696237688.889..  Test Loss: 5107415552.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4679074830.222..  Test Loss: 3536920064.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4695081386.667..  Test Loss: 3591711232.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4695278577.778..  Test Loss: 4760165376.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4619423601.778..  Test Loss: 3553170432.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4713604423.111..  Test Loss: 3870810112.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4696763982.222..  Test Loss: 3554552832.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4622931840.000..  Test Loss: 3624172800.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4627911018.667..  Test Loss: 3480642816.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4666837596.444..  Test Loss: 3497008128.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4648623651.556..  Test Loss: 4944150528.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4716193166.222..  Test Loss: 3465706240.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4656319473.778..  Test Loss: 3676077312.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4670768504.889..  Test Loss: 3665152256.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4622575445.333..  Test Loss: 3585926400.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4654138090.667..  Test Loss: 3652931328.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4644490510.222..  Test Loss: 3520635392.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4697988067.556..  Test Loss: 3528042240.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4649738552.889..  Test Loss: 3551223040.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4653416071.111..  Test Loss: 3614425856.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4647377422.222..  Test Loss: 4008226816.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4699737806.222..  Test Loss: 3682114816.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4698970048.000..  Test Loss: 3980765440.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4651877802.667..  Test Loss: 3937094400.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4652523445.333..  Test Loss: 4320637440.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4602966208.000..  Test Loss: 3506947328.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4679717294.222..  Test Loss: 3718955520.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4669135047.111..  Test Loss: 4781919744.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4652762403.556..  Test Loss: 3566729216.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4641049827.556..  Test Loss: 3461936896.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4652568099.556..  Test Loss: 3472235264.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4667191566.222..  Test Loss: 3635590400.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4701638833.778..  Test Loss: 3473485056.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4638533440.000..  Test Loss: 3704159744.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4671061191.111..  Test Loss: 3951620608.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4646039082.667..  Test Loss: 3513556992.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4625051463.111..  Test Loss: 3898047232.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4654096348.444..  Test Loss: 3523515904.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4635134627.556..  Test Loss: 3460447488.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4657738560.000..  Test Loss: 4611707392.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4655710883.556..  Test Loss: 3882508288.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4635560113.778..  Test Loss: 3961037824.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4641259456.000..  Test Loss: 3467242752.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4672677518.222..  Test Loss: 3449318400.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4621531448.889..  Test Loss: 4478415872.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4602561187.556..  Test Loss: 4171504384.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4641499996.444..  Test Loss: 3853437696.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4676395249.778..  Test Loss: 3689141248.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4639852192.000..  Test Loss: 3607814144.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4613468640.000..  Test Loss: 3459534336.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4656225137.778..  Test Loss: 3556234496.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4652623047.111..  Test Loss: 3478385152.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4604150200.889..  Test Loss: 4727745024.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4631321361.778..  Test Loss: 3692143872.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4668116800.000..  Test Loss: 3995209216.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4658955100.444..  Test Loss: 3553645824.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4683106112.000..  Test Loss: 3791325952.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4675706702.222..  Test Loss: 3502698240.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4656742983.111..  Test Loss: 3516451328.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4609937002.667..  Test Loss: 3570613760.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4625187576.889..  Test Loss: 3439391744.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4654538823.111..  Test Loss: 3638173696.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4607327416.889..  Test Loss: 3579575552.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4648940992.000..  Test Loss: 3431416320.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4610111160.889..  Test Loss: 3548242432.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4589835996.444..  Test Loss: 3416504576.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4632331470.222..  Test Loss: 3443340800.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4646499392.000..  Test Loss: 3433961216.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4630137088.000..  Test Loss: 5606160896.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 910/1000..  Training Loss: 4630244128.000..  Test Loss: 3746338560.000.. \n",
      "Epoch: 911/1000..  Training Loss: 4611018019.556..  Test Loss: 3547347968.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4617177027.556..  Test Loss: 3474145792.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4616129223.111..  Test Loss: 3444121088.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4614573504.000..  Test Loss: 3571574528.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4655932522.667..  Test Loss: 3599067136.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4629615182.222..  Test Loss: 4070333184.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4629483107.556..  Test Loss: 4403598848.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4638239936.000..  Test Loss: 3447362816.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4651921976.889..  Test Loss: 3461298944.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4669775068.444..  Test Loss: 3775744768.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4696946311.111..  Test Loss: 3867496448.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4609888099.556..  Test Loss: 3400148224.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4674825678.222..  Test Loss: 3682177792.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4617568696.889..  Test Loss: 3631570688.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4631047203.556..  Test Loss: 3751260416.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4631063296.000..  Test Loss: 3783390720.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4597058311.111..  Test Loss: 4378806784.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4664262805.333..  Test Loss: 3959931904.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4641895360.000..  Test Loss: 3531917056.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4626357141.333..  Test Loss: 3554375168.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4664358698.667..  Test Loss: 3446407424.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4673882058.667..  Test Loss: 5325923328.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4618726371.556..  Test Loss: 3605508096.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4617301717.333..  Test Loss: 3483328512.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4617347996.444..  Test Loss: 3783314688.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4610907825.778..  Test Loss: 3438513408.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4611549653.333..  Test Loss: 4182680576.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4614339064.889..  Test Loss: 3636937984.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4619466325.333..  Test Loss: 3449006592.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4642322496.000..  Test Loss: 3506796288.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4624248341.333..  Test Loss: 4058914816.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4567813112.889..  Test Loss: 3630004480.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4616119516.444..  Test Loss: 3711194368.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4623895644.444..  Test Loss: 3480222464.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4667650616.889..  Test Loss: 3463849216.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4640234183.111..  Test Loss: 3737104128.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4610940160.000..  Test Loss: 3810022400.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4585554922.667..  Test Loss: 3563145472.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4600852202.667..  Test Loss: 3454473984.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4644880163.556..  Test Loss: 3657320192.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4630821688.889..  Test Loss: 3544585216.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4683418432.000..  Test Loss: 4489470976.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4610712583.111..  Test Loss: 3748282624.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4645553528.889..  Test Loss: 3426359040.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4666793248.000..  Test Loss: 3471233280.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4639039836.444..  Test Loss: 3920789504.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4632040817.778..  Test Loss: 3429892864.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4610491527.111..  Test Loss: 4299760128.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4616919864.889..  Test Loss: 3474434560.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4611764160.000..  Test Loss: 4836619776.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4674462343.111..  Test Loss: 3441615104.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4625492970.667..  Test Loss: 4332127232.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4602839224.889..  Test Loss: 3539563008.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4584351580.444..  Test Loss: 3580953600.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4662584128.000..  Test Loss: 3838587392.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4637244387.556..  Test Loss: 4312331264.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4588028920.889..  Test Loss: 3436919552.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4613297667.556..  Test Loss: 4380254208.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4618098304.000..  Test Loss: 3521744384.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4582485489.778..  Test Loss: 3899652864.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4570027377.778..  Test Loss: 4772850176.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4616621610.667..  Test Loss: 3547432960.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4605133880.889..  Test Loss: 3569547520.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4608187463.111..  Test Loss: 3618316800.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4606697379.556..  Test Loss: 3502397696.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4605332572.444..  Test Loss: 3817209088.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4666911452.444..  Test Loss: 3437432320.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4653196924.444..  Test Loss: 5150830592.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4665764024.889..  Test Loss: 3412987392.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4621202712.889..  Test Loss: 3426307328.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4677717269.333..  Test Loss: 3433166592.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4609315484.444..  Test Loss: 3790802688.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4616413930.667..  Test Loss: 3473849088.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4628082261.333..  Test Loss: 3575485696.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4610658268.444..  Test Loss: 3645239808.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4570596565.333..  Test Loss: 3529825280.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4577671701.333..  Test Loss: 3452171520.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4616205639.111..  Test Loss: 3976947456.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4604738211.556..  Test Loss: 3586714624.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4653915292.444..  Test Loss: 3519718912.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4581664760.889..  Test Loss: 3538726400.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4568745400.889..  Test Loss: 3407273984.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4600839548.444..  Test Loss: 3449870592.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4631603776.000..  Test Loss: 5180468736.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4659408721.778..  Test Loss: 3460992256.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4605135367.111..  Test Loss: 3553345536.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4610234190.222..  Test Loss: 4279729664.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4597808419.556..  Test Loss: 3479263232.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4597202503.111..  Test Loss: 3745911552.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4636188807.111..  Test Loss: 5721723392.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv = cv.split(X_train_scaled, y_train)\n",
    "\n",
    "m_hidden_layers = 10\n",
    "\n",
    "n_input = 6\n",
    "n_hidden = 4\n",
    "n_output = 1\n",
    "\n",
    "bs = 64\n",
    "device = \"cuda:0\"\n",
    "epochs = 1000\n",
    "\n",
    "network_type = \"regression\"\n",
    "\n",
    "regressors = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "    print(\"Model for Fold: \" + str(fold))\n",
    "\n",
    "    train_set, train_labels = X_train_scaled[train_idx], y_train[train_idx]\n",
    "    valid_set, valid_labels = X_train_scaled[val_idx], y_train[val_idx]\n",
    "    \n",
    "    trainset = HousePriceDataset(train_set, train_labels)\n",
    "    trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    validset = HousePriceDataset(valid_set, valid_labels)\n",
    "    validloader = DataLoader(validset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    regressor = NeuralNetwork(m_hidden_layers, n_input, n_hidden, n_output, network_type).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion_2 = RMSLELoss\n",
    "    optimizer = optim.Adam(regressor.parameters(), lr = 0.005)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        for features, labels in trainloader:\n",
    "\n",
    "            regressor.train()\n",
    "\n",
    "            features = features.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = regressor(features.float())\n",
    "\n",
    "            loss = criterion(output, labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for features, labels in validloader:\n",
    "                    regressor.eval()\n",
    "\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    output = regressor(features.float())\n",
    "\n",
    "                    test_loss += criterion(output, labels)\n",
    "\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(validloader)))\n",
    "            \n",
    "        \n",
    "        \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations with other metrics\n",
    "- RMSLE Loss and R2 Score\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on Testing Data: 4416205312.0\n",
      "Lets see predictions\n",
      "[88557.24  88556.914 88557.19  88557.22  88557.234 88557.12  88557.25\n",
      " 88557.23  88557.24  88557.24  88557.24  88557.805 88557.17  88557.47\n",
      " 88557.24  88556.98  88557.99  88557.89  88557.875 88557.234 88557.13\n",
      " 88557.25  88557.15  88557.3   88557.15  88557.234 88557.24  88557.12\n",
      " 88557.19  88557.25  88557.24  88557.24  88556.99  88555.586 88557.15\n",
      " 88556.875 88557.06  88557.24  88557.23  88557.21  88556.68  88557.086\n",
      " 88557.25  88557.22  88557.29  88556.89  88557.23  88557.164 88557.195\n",
      " 88557.336 88556.914 88557.29  88557.16  88557.234 88557.29  88557.19\n",
      " 88557.234 88557.23  88557.24  88557.164 88556.98  88557.23  88557.26\n",
      " 88557.24  88557.18  88556.65  88557.27  88557.7   88557.23  88557.73\n",
      " 88556.68  88557.19  88557.24  88557.266 88557.33  88557.21  88557.25\n",
      " 88557.234 88557.12  88557.15  88556.75  88557.24  88557.414 88557.195\n",
      " 88557.07  88557.17  88557.08  88556.9   88557.25  88557.24  88557.21\n",
      " 88556.64  88557.055 88557.086 88557.02  88557.34  88557.04  88557.164\n",
      " 88557.29  88556.805 88557.31  88557.7   88558.5   88557.12  88558.555\n",
      " 88557.62  88556.79  88557.24  88557.09  88557.21  88557.17  88556.75\n",
      " 88557.24  88557.15  88557.21  88557.234 88557.586 88557.87  88557.195\n",
      " 88557.24  88557.234 88557.266 88557.086 88557.25  88555.99  88557.19\n",
      " 88557.16  88557.086 88557.25  88557.24  88557.17  88557.29  88557.22\n",
      " 88556.87  88556.95  88557.336 88557.06  88557.24  88556.68  88556.46\n",
      " 88557.24  88557.24  88556.086 88557.19  88557.18  88557.164 88557.23\n",
      " 88557.305 88557.17  88557.305 88558.12  88557.24  88556.9   88557.24\n",
      " 88556.75  88557.164 88557.23  88557.56  88557.21  88557.305 88557.39\n",
      " 88558.484 88557.24  88557.29  88557.24  88557.234 88557.055 88557.15\n",
      " 88557.234 88557.08  88557.54  88556.93  88557.24  88557.23  88556.64\n",
      " 88557.35  88557.14  88557.22  88557.21  88557.086 88557.24  88556.33\n",
      " 88557.24  88557.24  88557.22  88557.23  88557.234 88557.25  88557.086\n",
      " 88557.4   88558.69  88557.21  88557.06  88557.64  88557.23  88557.24\n",
      " 88557.32  88557.75  88556.44  88557.99  88557.15  88557.24  88557.18\n",
      " 88557.26  88557.234 88556.73  88557.234 88557.    88557.14  88557.16\n",
      " 88557.24  88557.305 88558.05  88557.24  88557.25  88557.33  88557.266\n",
      " 88557.24  88557.23  88557.25  88557.2   88557.12  88557.24  88557.266\n",
      " 88557.445 88556.54  88557.31  88557.24  88556.9   88557.58  88557.234\n",
      " 88557.39  88557.24  88556.82  88557.27  88556.44  88556.75  88556.96\n",
      " 88556.94  88556.25  88557.555 88556.46  88557.77  88556.836 88557.21\n",
      " 88557.34  88557.24  88557.24  88557.336 88557.16  88557.24  88557.17\n",
      " 88557.29  88557.305 88557.06  88557.19  88557.086 88556.45  88556.56\n",
      " 88557.24  88557.18  88557.31  88557.24  88557.18  88557.17  88557.24\n",
      " 88557.445 88557.24  88557.19  88556.95  88557.16  88557.2   88557.305\n",
      " 88557.2   88556.54  88557.234 88557.234 88557.23  88557.05  88557.27\n",
      " 88556.766 88557.29  88557.27  88557.336 88557.12  88557.31  88557.2\n",
      " 88557.24  88556.336 88556.87  88557.24  88557.24  88557.25  88557.27\n",
      " 88557.49  88557.23  88557.305 88557.18  88557.14  88557.19  88557.23\n",
      " 88557.31  88557.24  88557.24  88557.24  88557.24  88556.71  88557.234\n",
      " 88557.3   88557.016 88556.27  88557.23  88557.016 88557.17  88557.27\n",
      " 88557.54  88557.23  88557.12  88557.234 88557.1   88557.24  88557.36\n",
      " 88557.234 88557.23  88557.15  88557.27  88556.83  88557.336 88557.95\n",
      " 88557.19  88557.08  88557.31  88557.266 88557.3   88557.27  88557.12\n",
      " 88557.79  88557.24  88557.19  88557.24  88557.01  88557.164 88557.23\n",
      " 88557.24  88557.24  88557.18  88557.24  88557.24  88557.24  88557.234\n",
      " 88557.24  88558.62  88557.19  88557.24  88557.29  88556.75  88557.24\n",
      " 88557.234 88557.21  88557.31  88557.28  88557.23  88556.6   88557.15\n",
      " 88557.086 88557.34  88556.95  88557.32  88557.25  88556.98  88557.234\n",
      " 88557.19  88557.234 88556.71  88557.22  88557.21  88557.36  88556.54\n",
      " 88557.33  88556.95  88557.    88557.21  88557.12  88557.086 88556.93\n",
      " 88557.04  88557.24  88557.27  88557.37  88556.65  88557.24  88556.99\n",
      " 88557.09  88557.21  88557.27  88556.87  88556.9   88557.125 88556.83\n",
      " 88557.21  88557.25  88557.24  88557.24  88557.234 88557.31  88557.14\n",
      " 88557.766 88556.69  88555.91  88556.56  88556.336 88557.016 88557.27\n",
      " 88557.26  88557.39  88557.19  88557.2   88557.19  88557.65  88556.96\n",
      " 88557.234 88557.22  88556.695 88557.24  88556.27  88556.83  88557.18\n",
      " 88557.02  88557.1   88557.234 88557.1   88557.51  88557.266 88557.\n",
      " 88557.17  88557.234 88557.21  88556.88  88557.21  88557.195 88557.24\n",
      " 88558.44  88557.27  88556.87  88557.31  88557.24  88557.414 88556.76\n",
      " 88556.625 88557.305 88557.05  88557.2   88557.09  88557.23  88557.12\n",
      " 88556.02  88557.305 88557.95  88557.234 88557.2   88556.87  88557.3\n",
      " 88557.24  88557.31  88557.24  88557.16  88555.37  88557.24  88557.33\n",
      " 88557.94  88557.234 88557.234 88556.95  88557.445 88557.14  88557.08\n",
      " 88557.36  88557.25  88556.6   88557.33  88557.35  88557.56  88556.87\n",
      " 88557.195 88557.31  88556.14  88557.23  88557.24  88557.27  88557.18\n",
      " 88557.24  88557.2   88557.266 88557.29  88556.625 88557.26  88557.23\n",
      " 88557.24  88556.85  88557.18  88557.04  88556.9   88557.14  88557.24\n",
      " 88557.336 88557.24  88557.234 88557.195 88557.27  88557.305 88557.27\n",
      " 88557.19  88556.57  88557.086 88557.375 88557.555 88556.58  88557.18\n",
      " 88557.29  88557.23  88557.7   88557.26  88557.95  88557.66  88557.234\n",
      " 88558.01  88557.85  88557.32  88557.266 88557.555 88557.15  88557.24\n",
      " 88557.52  88557.586 88556.77  88557.164 88557.055 88557.21  88556.81\n",
      " 88557.27  88557.14  88557.24  88557.555 88557.15  88556.38  88556.96\n",
      " 88557.33  88557.81  88557.27  88557.336 88557.3   88557.234 88557.24\n",
      " 88557.18  88556.96  88556.39  88556.81  88557.2   88557.15  88557.56\n",
      " 88557.125 88557.305 88557.24  88557.24  88558.086 88557.234 88557.06\n",
      " 88557.164 88557.23  88557.33  88556.45  88557.055 88557.24  88557.18\n",
      " 88557.98  88557.125 88557.25  88557.234 88557.24  88557.164 88557.32\n",
      " 88557.055 88557.305 88557.234 88556.86  88556.625 88557.17  88557.31\n",
      " 88557.234 88557.02  88557.24  88558.    88557.19  88557.29  88557.11\n",
      " 88556.875 88557.24  88557.21  88557.305 88556.93  88557.4   88557.08\n",
      " 88557.23  88556.96  88557.28  88557.3   88556.24  88557.23  88557.14\n",
      " 88557.15  88557.21  88556.93  88557.21  88557.12  88557.18  88555.87\n",
      " 88556.54  88557.164 88557.516 88557.23  88557.25  88557.234 88557.27\n",
      " 88557.24  88557.2   88557.195 88556.75  88556.875 88557.24  88557.336\n",
      " 88557.24  88557.445 88557.24  88557.086 88557.5   88557.24  88556.766\n",
      " 88557.234 88557.984 88557.016 88557.24  88557.305 88557.234 88557.19\n",
      " 88557.234 88557.305 88557.24  88557.234 88557.15  88557.25  88557.22\n",
      " 88557.125 88557.02  88556.77  88556.93  88555.92  88557.23  88557.22\n",
      " 88557.24  88556.75  88556.06  88556.96  88557.33  88557.305 88557.02\n",
      " 88557.5   88558.14  88557.31  88556.86  88557.19  88557.305 88557.23\n",
      " 88557.13  88556.5   88557.31  88557.32  88557.16  88557.18  88557.44\n",
      " 88557.37  88557.02  88557.29  88557.31  88557.34  88557.125 88560.14\n",
      " 88557.21  88557.24  88556.336 88557.75  88557.24  88557.    88557.24\n",
      " 88557.266 88556.75  88556.516 88557.23  88557.31  88557.23  88557.3\n",
      " 88557.25  88556.74  88557.99  88557.266 88557.09  88556.53 ]\n",
      "[ 50500  94666 103500  34500  45505  74000  43650 185000  35500 113900\n",
      "  75500 445000  65000  90000  55000 145000 325000 305000 144000  57500\n",
      " 105574 127500  33860 124000  47000  45000  52000  85483  79500  53610\n",
      "  60500  40000 160000  64457  80000  82900 105000  72000  80000  73000\n",
      "  73500 160000  54000  40000  79000  80950  69850  69000  76934 289000\n",
      "  76500  85000 149000  46650 170000  74000  57500  62000  37764  84990\n",
      "  56300 120086  46750  74000  55800 126000  83000  85619  57700 280000\n",
      " 119000  94000  49000 179000 125000  79000 147000  32850  66300 124000\n",
      "  52900  34900  95000  55075  65700  56900 255000 150000  35000  89000\n",
      "  50500  54000 125000  55000  55000 139900 180000  83500 110000  75000\n",
      "  78600 300000 329000 118000 299000 180000  61500  64300  66999  54900\n",
      "  63000  54900  82000  60999  78599  50500  94500 240000  56953  49900\n",
      "  68240  81383  62900 218000  46500  53010  75000  95000  73715  80688\n",
      " 125000 145000  40272 130000 112000 130252 142000 100700 119000  71850\n",
      "  93000  32000 138000  91900  29900 123043  44000  73715 120000  65500\n",
      " 181500 209000  82375  49400  53900 113000  75900 270000  66414  68500\n",
      " 114750 275000  38500 139000  48999  39600  73000  59500  48900  77900\n",
      "  86000  52500 105000  75000  82000 135000 115000  89953 119000  45400\n",
      "  78500  53500  61020  76100  85000  83000  59950  45700  69000 100000\n",
      " 375000 152285 199000  83000  38000  45000 120000 390000  76000 435000\n",
      " 109440  33700  63900 169000  41000  57900  58000 152976 129508  53010\n",
      "  63000 123500 190000  56000 133820  64600 149000  51040  48500 157510\n",
      "  56953  81257  46900  61000 250000  48000 101500  34900  59800 229900\n",
      "  58999  82000  36190  86227 117000 110000 103000  78900  70500  78900\n",
      " 125000 101000 149000  45000 112000 128000  95000  61000 125500 179000\n",
      "  68500 136000  73000  79500 199000  74000  59900  49600  79900  55100\n",
      "  67500 125000  76500  90600  61000  44010 169000 196970  57000  59800\n",
      "  83800 125000  74500  69900  89000  48100  59000  59500  65000 219000\n",
      " 144000  73900  65000 189000 123219  73715 129000  42500  54900  50990\n",
      "  52600  23500  39000 101900 230000 132000  72760  77500 205000  75000\n",
      "  64000  63900  95000  56000  56953  57500  92200  52000  72000  79080\n",
      "  69900  87000  80000  90000 113900 174839  61500 126000  56500  68500\n",
      "  59000 108000  94000  51133  43000 143000  50400  97000 385000  60900\n",
      " 195000  77000  88000  58700  99000  74998  79900  86500 106257  47000\n",
      "  76930 127000 145000  89900  80687  91800  78500  62600  89953  44000\n",
      "  47500 320000 104500  78900  54900  59900  62500  35000  73000  74500\n",
      "  83500  52000  71000  80000  59900 330000 167000 245000  83000  92400\n",
      "  82500  57000  39500 100000  38300  53010 153500  89000  47000 178000\n",
      "  78300  68000 110188  60900  99800 185000 173000  87000 100000  54896\n",
      "  68000  51500  78100  78000  99900 199000  88000  66000  59500  19900\n",
      " 149000  56000  36500  62000 175759  55000 112900  64000 110000  36500\n",
      "  48500 116900  63500  58900 146000 125000  79900  87000 290000  58000\n",
      "  54900  35500 189000  49500  58900  71000  60000 135000  65000  59993\n",
      "  81900  83500  84630  68000  97000  25500  81000  57000 102300  97000\n",
      "  80130 400000 123500  71500 147300  41500 160000 100000  61500  75900\n",
      "  54000 125539  92000  52440  99726  75000  86900 239000 133820  75000\n",
      "  73000  65000  52000  97000  41500  83800  66957  96000  84900 400000\n",
      "  43000  53000  67000 225000 142000 142000 139000 137500 165000  64300\n",
      " 130000 280000  57900 125000  95000 115000  68000  39000  73715  78000\n",
      "  58000 125539  89953  78900  79500  79650 122900  30000 173000  65000\n",
      "  59000  60000  71000  57000 218000  62000  46500  63000 156000 139000\n",
      " 170000  71000  65000  93840 117500 115000  47900 100269 173500  53500\n",
      "  83000 138999 289000 160000  75672 329000  80000 125000  66800 125000\n",
      " 109000  45000  77900 110250  67500  79500 144500  63000  60000 130000\n",
      "  40999  57000 125000  57000  85000  59999  91500 255000  89000 128000\n",
      " 195000  47000  79900  67150 100000  73000 137000 102000 120089 165000\n",
      " 109000 115000  63900  68499 380000 124000 118500 197635  37000  67100\n",
      "  53000  64900  41900  74000 249000  67733 170000  49100  49500  42000\n",
      " 199000  65700  57000  52400 130000  67000 120089  64900  60000  85000\n",
      "  44900 367000  55000  79000  80824 162300  42000  67000  86900  99800\n",
      " 230000  60000  56000  70952 119000 175000  59500 174999 120000 171500\n",
      " 114500  44000  86100  92000 108131  63000  73000  62000 115000  48000\n",
      "  73715  50500 135000  75000 116500  59000 103000 105000  38900  88500\n",
      "  64160 139000  58900 148000 112455  84900  65760 139000 360000  32000\n",
      "  94300  76900  44500 116700  42800  60000  79000  55500  58500  84000\n",
      "  94000 199000  72900  95000 170400 167000 103000  64400  66500  55900\n",
      "  53500  51600  89000  83000  74500 112455 380000  68800 111466  71590\n",
      "  68100  65200 104500  65000 144500 134505  67143 119000  58000  96000\n",
      "  92900  59900  86000 115000  34500 450000  73000  30000  71700 137498\n",
      "  47000  69048  19905 110000  62000  45900  82000  96500  33400 125500\n",
      " 157510 130000 149500  89110  56000  69500]\n",
      "R2 Score: -0.027464550874526372\n",
      "Root Mean Squared Log Error: 0.5278021693229675\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evalset = HousePriceDataset(X_test_scaled, y_test)\n",
    "loader  = DataLoader(evalset, batch_size=len(X_test_scaled))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in loader: \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        \n",
    "        outputs = 0\n",
    "        for regressor in regressors:\n",
    "            regressor.eval()\n",
    "            output = regressor(features.float())\n",
    "            outputs += output\n",
    "        \n",
    "        outputs = outputs / len(models)\n",
    "        \n",
    "Ypred = outputs.cpu().numpy().squeeze()\n",
    "Yreal = labels.cpu().numpy()\n",
    "\n",
    "print(\"Loss on Testing Data:\", criterion(output, labels).item())\n",
    "\n",
    "print(\"Lets see predictions\")\n",
    "print(Ypred)\n",
    "print(Yreal)\n",
    "\n",
    "rmsle = RMSLELoss(output, labels)\n",
    "r2 = r2_score(Yreal, Ypred)\n",
    "\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Root Mean Squared Log Error:\", rmsle.item())\n",
    "\n",
    "plt.hist(Ypred)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(Yreal)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And Sklearn Baseline\n",
    "# It seems that the problem is still here \n",
    "- Even in sklearn if you run multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error Neural Network Sklearn:  1.182376865087882\n",
      "R2 Score: -1.1300124612395712\n",
      "[29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032 29571.31628032 29571.31628032\n",
      " 29571.31628032 29571.31628032]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAY1ElEQVR4nO3dfbRddX3n8fdHwkOtYHgICAkYLZHCuAQxKq0dtNJRARXsgilMK5FB05mio6NdQh07Oh1rfergUFssghJciCKKRMUHRNFaBQ2CCKJDpEiuILnIgyA+gd/5Y/+untzcm3uS3Idk5/1a666z92//9t7f37nwuTu/c84+qSokSf3yiLkuQJI0/Qx3Seohw12Seshwl6QeMtwlqYcMd0nqIcNdcyLJ4iSVZF5b/1SSZZtwnP2SPJBku+mvctMleXeSv57rOrTtiu9z12SS3ArsBTwM/AS4DHhFVT0wDcdeDPwbsH1VPbSRNb20qj63uTVsqiTnASNV9fqBtsVspeNRP3nlrqm8oKoeBRwKPBV4/fgO6fjf0hZm7F9F2jb5P6SGUlU/AD4FPBEgyZVJ/jbJvwIPAo9P8ugk5ya5I8kPkrxpbLokyXZJ3pHkriS3AEcPHr8d76UD6y9LclOS+5N8O8mhSd4P7Ad8vE3FvHaC6Z19kqxMcneS1UleNnDMNya5KMn57bg3Jlk6sP20Vvf9Sb6b5IhNfb6SnJfkTW15jySfSHJvq+tfkjxiovG0/i9std3bnpcDB457aJJrW40fTvKhgfM8K8lIG8cPgfcl2bWdezTJPW150bjn/U1JvtJq+HiS3ZNckOTHSb7e/lWirYzhrqEk2Rc4Crh2oPnFwHJgZ+D7wArgIWB/4MnAc4CxwH4Z8PzWvhQ4bgPnOh54I3ASsAvwQuBHVfVi4Dbavyaq6m0T7H4hMALs087x5nEh/ULgg8B8YCXwrnbOA4CXA0+tqp2B5wK3bvhZGdprWk0L6Ka5XgfURONJ8oQ2hle1/pfRhf8OSXYALgHOA3Zr/V407lyPadseS/e7eQTwvra+H/DTsTEPOIHud7kQ+B3gq22f3YCbgDdMy7OgWWW4ayofS3Iv8GXgi8CbB7adV1U3tjnm3YAjgVdV1U+qai1wBl1wAPxH4J1Vtaaq7gb+bgPnfCnwtqr6enVWV9X3pyq0/QH6A+C0qvpZVV0HnEMXXGO+XFWXVdXDwPuBg1v7w8COwEFJtq+qW6vqexs43V+2K+t72/Nz/Qb6/hLYG3hsVf2yqv6lJn+x60+AT1bV5VX1S+AdwG8Bvw8cBswDzmzH+SjwtXH7/wp4Q1X9vKp+WlU/qqqPVNWDVXU/8LfAM8ft876q+l5V3Uf3r7PvVdXn2u/1w3R/kLWVMdw1lWOran5VPbaq/qKqfjqwbc3A8mOB7YE7BgLvn4E92/Z9xvXfUFjvC2woWCezD3B3C7HB8ywcWP/hwPKDwE5J5lXVarqr5TcCa5N8MMk+GzjXO9rzMr+q5gNP2kDftwOrgc8muSXJ6VOM4dfPTVX9iu55W9i2/WDcH4Y16+7OaFX9bGwlySOT/HOS7yf5MfAlYP64dxfdObD80wnWH7WBerWFMty1OcaHzM+BPQZCb5eq+ndt+x10oT1mvw0cdw3d9MBU5xzvdmC3JDuPO88PNrDPbw5c9YGq+gO6P1QFvHWY/YY47v1V9ZqqejzwAuDVA1NF48dzezs/0L1YTfe8/YDuOVzY2sbsu+7u6x3vNcABwNOrahfg8LFDb+p4tHUw3DUtquoO4LPA3yfZpb1g+DtJxqYALgL+W5JFSXYFNnT1eg7dtMdTujfiZP8kY4F3J/D4SWpYA3wF+LskOyV5EnAKcMFU9Sc5IMmzk+wI/IzuivXhqUc+tSTPb2MI8ON23LFjjx/PRcDRSY5Isj1dOP+8jeurbb+XJ5mX5BjgaVOcfuc2lnuT7Ibz59sMw13T6SRgB+DbwD3AxXRzzQDvAT4DfBP4BvDRyQ5SVR+mmxv+AHA/8DG6OX3o5upf36Z+/nKC3U8EFtNdAV9CN/98+RC17wi8BbiLbupmT7oXPqfDEuBzwAN0Af1PVXVl27bOeKrqu8CfAf/QankB3Quuv6iqXwB/TPcH697W7xN04T+Zd9LN2d8FXAV8eprGpC2cH2KStmJJrgbeXVXvm+tatGXxyl3aiiR5ZpLHtGmZZXQv5Ho1rvX4CTZp63IA3bz8o+jeUXRce71DWofTMpLUQ07LSFIPbRHTMnvssUctXrx4rsuQpK3KNddcc1dVLZho2xYR7osXL2bVqlVzXYYkbVWSTPpJb6dlJKmHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12SemjKcG/3ub5u4OfHSV6VZLcklye5uT3u2vonyZnpvpz4+iSHzvwwJEmDpgz3qvpuVR1SVYcAT6H7arJL6L5s4YqqWgJcwW++fOFIuvtXL6H7gt6zZqJwSdLkNvYTqkfQfXnu99u3wDyrta8ArgROA44Bzm/f83hVkvlJ9vbOddoaLT79k3N27lvfcvScnVtbv42dcz8BuLAt7zUW2O1x7IuQF7Lul/aOsO4XFAOQZHmSVUlWjY6ObmQZkqQNGTrck+wAvBD48FRdJ2hb777CVXV2VS2tqqULFkx43xtJ0ibamCv3I4FvVNWdbf3OJHsDtMe1rX2Edb+RfRHd91lKkmbJxoT7ifxmSgZgJbCsLS8DLh1oP6m9a+Yw4D7n2yVpdg31gmqSRwL/Afjzgea3ABclOQW4DTi+tV8GHAWspntnzcnTVq0kaShDhXtVPQjsPq7tR3Tvnhnft4BTp6U6SdIm8ROqktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1ENDhXuS+UkuTvKdJDcl+b0kuyW5PMnN7XHX1jdJzkyyOsn1SQ6d2SFIksYb9sr9/wKfrqrfBQ4GbgJOB66oqiXAFW0d4EhgSftZDpw1rRVLkqY0Zbgn2QU4HDgXoKp+UVX3AscAK1q3FcCxbfkY4PzqXAXMT7L3tFcuSZrUMFfujwdGgfcluTbJOUl+G9irqu4AaI97tv4LgTUD+4+0tnUkWZ5kVZJVo6OjmzUISdK6hgn3ecChwFlV9WTgJ/xmCmYimaCt1muoOruqllbV0gULFgxVrCRpOMOE+wgwUlVXt/WL6cL+zrHplva4dqD/vgP7LwJun55yJUnDmDLcq+qHwJokB7SmI4BvAyuBZa1tGXBpW14JnNTeNXMYcN/Y9I0kaXbMG7LfK4ALkuwA3AKcTPeH4aIkpwC3Ace3vpcBRwGrgQdbX0nSLBoq3KvqOmDpBJuOmKBvAaduZl2SpM3gJ1QlqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seshwl6QeMtwlqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4aKtyT3JrkW0muS7Kqte2W5PIkN7fHXVt7kpyZZHWS65McOpMDkCStb2Ou3P+wqg6pqqVt/XTgiqpaAlzR1gGOBJa0n+XAWdNVrCRpOJszLXMMsKItrwCOHWg/vzpXAfOT7L0Z55EkbaRhw72Azya5Jsny1rZXVd0B0B73bO0LgTUD+460tnUkWZ5kVZJVo6Ojm1a9JGlC84bs94yquj3JnsDlSb6zgb6ZoK3Wa6g6GzgbYOnSpettlyRtuqGu3Kvq9va4FrgEeBpw59h0S3tc27qPAPsO7L4IuH26CpYkTW3KcE/y20l2HlsGngPcAKwElrVuy4BL2/JK4KT2rpnDgPvGpm8kSbNjmGmZvYBLkoz1/0BVfTrJ14GLkpwC3AYc3/pfBhwFrAYeBE6e9qolSRs0ZbhX1S3AwRO0/wg4YoL2Ak6dluokSZvET6hKUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST00dLgn2S7JtUk+0dYfl+TqJDcn+VCSHVr7jm19ddu+eGZKlyRNZmOu3F8J3DSw/lbgjKpaAtwDnNLaTwHuqar9gTNaP0nSLBoq3JMsAo4GzmnrAZ4NXNy6rACObcvHtHXa9iNaf0nSLBn2yv2dwGuBX7X13YF7q+qhtj4CLGzLC4E1AG37fa3/OpIsT7IqyarR0dFNLF+SNJEpwz3J84G1VXXNYPMEXWuIbb9pqDq7qpZW1dIFCxYMVawkaTjzhujzDOCFSY4CdgJ2obuSn59kXrs6XwTc3vqPAPsCI0nmAY8G7p72yiVJk5ryyr2q/qqqFlXVYuAE4PNV9afAF4DjWrdlwKVteWVbp23/fFWtd+UuSZo5m/M+99OAVydZTTenfm5rPxfYvbW/Gjh980qUJG2sYaZlfq2qrgSubMu3AE+boM/PgOOnoTZJ0ibyE6qS1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ1OGe5KdknwtyTeT3Jjkf7X2xyW5OsnNST6UZIfWvmNbX922L57ZIUiSxhvmyv3nwLOr6mDgEOB5SQ4D3gqcUVVLgHuAU1r/U4B7qmp/4IzWT5I0i6YM9+o80Fa3bz8FPBu4uLWvAI5ty8e0ddr2I5Jk2iqWJE1pqDn3JNsluQ5YC1wOfA+4t6oeal1GgIVteSGwBqBtvw/YfYJjLk+yKsmq0dHRzRuFJGkdQ4V7VT1cVYcAi4CnAQdO1K09TnSVXus1VJ1dVUuraumCBQuGrVeSNISNerdMVd0LXAkcBsxPMq9tWgTc3pZHgH0B2vZHA3dPR7GSpOEM826ZBUnmt+XfAv4IuAn4AnBc67YMuLQtr2zrtO2fr6r1rtwlSTNn3tRd2BtYkWQ7uj8GF1XVJ5J8G/hgkjcB1wLntv7nAu9Pspruiv2EGahbkrQBU4Z7VV0PPHmC9lvo5t/Ht/8MOH5aqpMkbRI/oSpJPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9dCU4Z5k3yRfSHJTkhuTvLK175bk8iQ3t8ddW3uSnJlkdZLrkxw604OQJK1rmCv3h4DXVNWBwGHAqUkOAk4HrqiqJcAVbR3gSGBJ+1kOnDXtVUuSNmjKcK+qO6rqG235fuAmYCFwDLCidVsBHNuWjwHOr85VwPwke0975ZKkSW3UnHuSxcCTgauBvarqDuj+AAB7tm4LgTUDu420tvHHWp5kVZJVo6OjG1+5JGlSQ4d7kkcBHwFeVVU/3lDXCdpqvYaqs6tqaVUtXbBgwbBlSJKGMFS4J9meLtgvqKqPtuY7x6Zb2uPa1j4C7Duw+yLg9ukpV5I0jGHeLRPgXOCmqvo/A5tWAsva8jLg0oH2k9q7Zg4D7hubvpEkzY55Q/R5BvBi4FtJrmttrwPeAlyU5BTgNuD4tu0y4ChgNfAgcPK0VixJmtKU4V5VX2bieXSAIyboX8Cpm1mXJGkz+AlVSeohw12Seshwl6QeMtwlqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seshwl6QeMtwlqYcMd0nqIcNdknrIcJekHjLcJamHpgz3JO9NsjbJDQNtuyW5PMnN7XHX1p4kZyZZneT6JIfOZPGSpIkNc+V+HvC8cW2nA1dU1RLgirYOcCSwpP0sB86anjIlSRtjynCvqi8Bd49rPgZY0ZZXAMcOtJ9fnauA+Un2nq5iJUnD2dQ5972q6g6A9rhna18IrBnoN9La1pNkeZJVSVaNjo5uYhmSpIlM9wuqmaCtJupYVWdX1dKqWrpgwYJpLkOStm2bGu53jk23tMe1rX0E2Heg3yLg9k0vT5K0KTY13FcCy9ryMuDSgfaT2rtmDgPuG5u+kSTNnnlTdUhyIfAsYI8kI8AbgLcAFyU5BbgNOL51vww4ClgNPAicPAM1S5KmMGW4V9WJk2w6YoK+BZy6uUVJkjaPn1CVpB4y3CWphwx3Seohw12Seshwl6QeMtwlqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seshwl6QeMtwlqYcMd0nqIcNdknrIcJekHpqRcE/yvCTfTbI6yekzcQ5J0uSmPdyTbAf8I3AkcBBwYpKDpvs8kqTJzcSV+9OA1VV1S1X9AvggcMwMnEeSNIl5M3DMhcCagfUR4OnjOyVZDixvqw8k+e4Qx94DuGuzK9y6OOZtw3pjzlvnqJLZ4+958z12sg0zEe6ZoK3Wa6g6Gzh7ow6crKqqpZta2NbIMW8bHPO2YTbHPBPTMiPAvgPri4DbZ+A8kqRJzES4fx1YkuRxSXYATgBWzsB5JEmTmPZpmap6KMnLgc8A2wHvraobp+nwGzWN0xOOedvgmLcNszbmVK03HS5J2sr5CVVJ6iHDXZJ6aIsM96luX5BkvyRfSHJtkuuTHDUXdU6XJO9NsjbJDZNsT5Iz2/NxfZJDZ7vG6TbEmP+0jfX6JF9JcvBs1zjdphrzQL+nJnk4yXGzVdtMGWbMSZ6V5LokNyb54mzWNxOG+G/70Uk+nuSbbcwnz0ghVbVF/dC9CPs94PHADsA3gYPG9Tkb+K9t+SDg1rmuezPHfDhwKHDDJNuPAj5F9xmCw4Cr57rmWRjz7wO7tuUjt4Uxtz7bAZ8HLgOOm+uaZ+H3PB/4NrBfW99zrmuehTG/DnhrW14A3A3sMN11bIlX7sPcvqCAXdryo9nK30dfVV+i+wVP5hjg/OpcBcxPsvfsVDczphpzVX2lqu5pq1fRfV5iqzbE7xngFcBHgLUzX9HMG2LM/wn4aFXd1vpv9eMeYswF7JwkwKNa34emu44tMdwnun3BwnF93gj8WZIRuiucV8xOaXNmmOekz06h+5dLryVZCLwIePdc1zKLngDsmuTKJNckOWmuC5oF7wIOpLso/Rbwyqr61XSfZEsM92FuX3AicF5VLaKbsnh/ki1xLNNlqFs69FGSP6QL99PmupZZ8E7gtKp6eK4LmUXzgKcARwPPBf46yRPmtqQZ91zgOmAf4BDgXUl22fAuG28m7i2zuYa5fcEpwPMAquqrSXaiuyHPVv9Puklsk7d0SPIk4BzgyKr60VzXMwuWAh/s/rXOHsBRSR6qqo/NbVkzagS4q6p+AvwkyZeAg4H/N7dlzaiTgbdUN+m+Osm/Ab8LfG06T7IlXu0Oc/uC24AjAJIcCOwEjM5qlbNrJXBSe9fMYcB9VXXHXBc1k5LsB3wUeHFV9fl/9F+rqsdV1eKqWgxcDPxFz4Md4FLg3yeZl+SRdHeQvWmOa5ppg/m1F3AAcMt0n2SLu3KvSW5fkORvgFVVtRJ4DfCeJP+dbnriJe2v4FYpyYXAs4A92usIbwC2B6iqd9O9rnAUsBp4kO4v/1ZtiDH/T2B34J/alexDtZXfQXCIMffOVGOuqpuSfBq4HvgVcE5VbfCtolu6IX7P/xs4L8m36KZcT6uqab/1sbcfkKQe2hKnZSRJm8lwl6QeMtwlqYcMd0nqIcNdksZJ8vYk32k3rrskyfxJ+r0yyQ3tBmCvGmh/Y5IftBuiXTd2c8N2Q7zrBn5+leSQIWv6hyQPDDsGw13SNq3dlfK8cc2XA0+sqifRfaDqrybY74nAy+juh3Uw8PwkSwa6nFFVh7SfywCq6oKxNuDFdDc9vG6IGpfS3WRtaIa7JI1TVZ+tqrGbeU1247oDgauq6sHW94t09wYa1onAhWMrSZ6T5KtJvpHkw0ke1dq3A94OvHZjxmC4S9KG/WcmvnHdDcDhSXZvn649inVvE/LyNq3z3iS7TrD/n9DCPckewOuBP6qqQ4FVwKvHjgOs3NhPpW9xn1CVpNmQ5GpgR7rb7u6WZGx65LSq+kzr8z/obsd7wfj926dr30o3hfMA3XdPjF3tn0X3SdRqj39P90di7NxPBx4c+DTuYXTfTfGv7RPZOwBfTbIPcDzdJ143iuEuaZtUVU+Hbs6d7hYmLxncnmQZ8HzgiMlub1JV5wLntv5vprsRGlV158Bx3gN8YtyuJzAwJUN3G4LLq+rEcTUcDexPd4MxgEcmWV1V+081PsNdksZJ8jy620w/s6oe3EC/PatqbbvR3R8Dv9fa9x6YRnkR3RTO2D6PoLsaP3zgUFcB/5hk/6pa3aZ5FlXVJ4HHDOz7wDDBDoa7JE3kXXRTNpe3K+arquq/tGmSc6pq7HubP5Jkd+CXwKkD3x72tvYWxwJuBf584NiHAyNV9es7QVbVaJKXABcm2bE1v57NuPWxNw6TpB7y3TKS1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk99P8BtHNQdeoS48IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATZElEQVR4nO3df7DddX3n8edLQKjFlYQEjCF60aY7xmmLbEpRu11aXVG0xc6oC20lY9lJtwuzOutuJ+hupZ3SoZ2tdRlba7pSEX9Biy4ZwLoUbam7KxgQEQws0UaJSckFK9BqqcT3/nE+iYebc38k997cm899Pma+c77n8/18z/d9PpPzOt987veck6pCktSXpy10AZKkuWe4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHDXopTkL5P828O9b9v/7Un+x6HuLy0GhrvmVZIdSV6x0HXsk+TSJB8a0V5Jfgigqn67qqZ9c5jtm4g0nwx3aRFKcvRC16Ajm+GuBZFkWZIbkown+bu2fsqEbi9IcnuSR5Ncn2T50P5nJvk/Sb6V5ItJzprD2vaf3Sc5LsmHkjzSjvX5JCcnuQz4l8B7kvx9kve0/i9tfR5tty8detxTk9ya5PEkf5HkD4aOM9b+93Bhkq8Dn27tf5rkb9vj3ZrkRUOP94Ekf5jkk62G/53k2Une3cb0viQvnqtx0ZHFcNdCeRrwJ8DzgOcC3wHeM6HPBcAvA88BngSuAEiyGrgR+C1gOfCfgOuSrJyHOjcAzwLWACcC/w74TlW9A/hr4OKqOr6qLm5vPje2Ok8E3gXcmOTE9lgfAW5v2y4F3jTieP8KeCFwdrv/SWAtcBJwJ/DhCf3fCPwXYAXwBPB/W78VwJ+1GrQEGe5aEFX1SFVdV1XfrqrHgcsYBNuwq6vqnqr6B+C/Am9MchTwS8BNVXVTVX2vqm4GtgLnzPDwb2xn4fuXKfp+l0EY/1BV7a2qO6rqsUn6vgZ4oKqurqonq+qjwH3AzyZ5LvDjwK9X1T9V1WeBLSMe49Kq+oeq+g5AVV1ZVY9X1RMM3hB+LMmzhvp/otX0j8AngH+sqg9W1V7gGsAz9yXKcNeCSPKMJO9L8rUkjwG3Aie08N7nwaH1rwHHMDgjfR7whgnh/JPAqhke/tqqOmF4maLv1cCngI8l2ZXkd5McM0nf57Q6h30NWN22fbOqvj3J8zugLclRSS5P8pU2RjvaphVD/R8aWv/OiPvHT1KrOme4a6G8DfjnwE9U1T8Dfqq1Z6jPmqH15zI4i36YQQBePSGgf7CqLp/rIqvqu1X1G1W1Dngp8FoG00UAE79SdReDN55hzwW+AewGlid5xtC2NRxo+DF/ATgXeAWDqaGx1h6kaRjuOhyOaX+Y3LccDTyTwZnlt9pc9TtH7PdLSda1QPxN4M/adMOHGEx1nN3Obo9LctaIP8jOWpKfTvIj7X8UjzF4g9nbNj8EPH+o+03ADyf5hSRHJ/k3wDrghqr6GoOpo0uTPD3JS4Cfnebwz2Qwj/4I8Azgt+fsial7hrsOh5sYBPm+5VLg3cAPMDgT/xzw5yP2uxr4APC3wHHAfwCoqgcZnNG+HRhncCb/n5mff8/PZvCHyceAbcBfMXhzAfjvwOvblSlXVNUjDM7s38YgkH8NeG1VPdz6/yLwkrbttxjMiT8xxbE/yGBa5xvAlxmMkzQj8cc6pIWR5Brgvqoa9b8WaVY8c5cOkyQ/nuQFSZ6W5FUM/vfxPxe6LvXJT8FJh8+zgY8zuLRyJ/CrVfWFhS1JvXJaRpI65LSMJHVoUUzLrFixosbGxha6DEk6otxxxx0PV9XIr91YFOE+NjbG1q1bF7oMSTqiJJn4iej9nJaRpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOLYpPqB6pxjbduCDH3XH5axbkuJKOHJ65S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6NG24J1mT5DNJtiW5N8lbWvulSb6R5K62nDO0zyVJtie5P8nZ8/kEJEkHmskvMT0JvK2q7kzyTOCOJDe3bb9fVf9tuHOSdcB5wIuA5wB/keSHq2rvXBYuSZrctGfuVbW7qu5s648D24DVU+xyLvCxqnqiqv4G2A6cMRfFSpJm5qDm3JOMAS8GbmtNFye5O8mVSZa1ttXAg0O77WTEm0GSjUm2Jtk6Pj5+0IVLkiY343BPcjxwHfDWqnoMeC/wAuA0YDfwe/u6jti9Dmio2lxV66tq/cqVKw+6cEnS5GYU7kmOYRDsH66qjwNU1UNVtbeqvgf8Md+fetkJrBna/RRg19yVLEmazkyulgnwfmBbVb1rqH3VULefB+5p61uA85Icm+RUYC1w+9yVLEmazkyulnkZ8CbgS0nuam1vB85PchqDKZcdwK8AVNW9Sa4FvszgSpuLvFJGkg6vacO9qj7L6Hn0m6bY5zLgslnUJUmaBT+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOnT0QhcwW2ObblzoEiRp0fHMXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ9OGe5I1ST6TZFuSe5O8pbUvT3Jzkgfa7bLWniRXJNme5O4kp8/3k5AkPdVMztyfBN5WVS8EzgQuSrIO2ATcUlVrgVvafYBXA2vbshF475xXLUma0rThXlW7q+rOtv44sA1YDZwLXNW6XQW8rq2fC3ywBj4HnJBk1ZxXLkma1EHNuScZA14M3AacXFW7YfAGAJzUuq0GHhzabWdrm/hYG5NsTbJ1fHz84CuXJE1qxuGe5HjgOuCtVfXYVF1HtNUBDVWbq2p9Va1fuXLlTMuQJM3AjMI9yTEMgv3DVfXx1vzQvumWdrunte8E1gztfgqwa27KlSTNxEyulgnwfmBbVb1raNMWYENb3wBcP9R+Qbtq5kzg0X3TN5Kkw2MmXxz2MuBNwJeS3NXa3g5cDlyb5ELg68Ab2rabgHOA7cC3gTfPacWSpGlNG+5V9VlGz6MDvHxE/wIummVdkqRZ8BOqktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tC04Z7kyiR7ktwz1HZpkm8kuast5wxtuyTJ9iT3Jzl7vgqXJE1uJmfuHwBeNaL996vqtLbcBJBkHXAe8KK2zx8mOWquipUkzcy04V5VtwLfnOHjnQt8rKqeqKq/AbYDZ8yiPknSIZjNnPvFSe5u0zbLWttq4MGhPjtbmyTpMDrUcH8v8ALgNGA38HutPSP61qgHSLIxydYkW8fHxw+xDEnSKIcU7lX1UFXtrarvAX/M96dedgJrhrqeAuya5DE2V9X6qlq/cuXKQylDkjSJQwr3JKuG7v48sO9Kmi3AeUmOTXIqsBa4fXYlSpIO1tHTdUjyUeAsYEWSncA7gbOSnMZgymUH8CsAVXVvkmuBLwNPAhdV1d75KV2SNJlpw72qzh/R/P4p+l8GXDaboiRJs+MnVCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOTfsbqlp8xjbduGDH3nH5axbs2JJmzjN3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0LThnuTKJHuS3DPUtjzJzUkeaLfLWnuSXJFke5K7k5w+n8VLkkabyZn7B4BXTWjbBNxSVWuBW9p9gFcDa9uyEXjv3JQpSToY04Z7Vd0KfHNC87nAVW39KuB1Q+0frIHPASckWTVXxUqSZuZQ59xPrqrdAO32pNa+GnhwqN/O1naAJBuTbE2ydXx8/BDLkCSNMtd/UM2IthrVsao2V9X6qlq/cuXKOS5Dkpa2Qw33h/ZNt7TbPa19J7BmqN8pwK5DL0+SdCgONdy3ABva+gbg+qH2C9pVM2cCj+6bvpEkHT7T/lhHko8CZwErkuwE3glcDlyb5ELg68AbWvebgHOA7cC3gTfPQ82SpGlMG+5Vdf4km14+om8BF822KEnS7PgJVUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXo6NnsnGQH8DiwF3iyqtYnWQ5cA4wBO4A3VtXfza5MSdLBmIsz95+uqtOqan27vwm4parWAre0+5Kkw2g+pmXOBa5q61cBr5uHY0iSpjDbcC/gfyW5I8nG1nZyVe0GaLcnjdoxycYkW5NsHR8fn2UZkqRhs5pzB15WVbuSnATcnOS+me5YVZuBzQDr16+vWdYhSRoyqzP3qtrVbvcAnwDOAB5Ksgqg3e6ZbZGSpINzyGfuSX4QeFpVPd7WXwn8JrAF2ABc3m6vn4tCtTiMbbpxQY674/LXLMhxpSPVbKZlTgY+kWTf43ykqv48yeeBa5NcCHwdeMPsy5QkHYxDDveq+irwYyPaHwFePpuiJEmz4ydUJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1aDa/oSodNgv1w9zgj3PryOSZuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQl0JK01jIyzAXgpd+9sFwl7RoLNQbaY9vaE7LSFKHPHOX9BRLbRqqV/N25p7kVUnuT7I9yab5Oo4k6UDzcuae5CjgD4B/DewEPp9kS1V9eT6OJ0mz0eN3F83XmfsZwPaq+mpV/RPwMeDceTqWJGmC+ZpzXw08OHR/J/ATwx2SbAQ2trt/n+QR4OF5qudItwLHZjKOzeQcm9EW1bjkd2a1+/Mm2zBf4Z4RbfWUO1Wbgc37d0i2VtX6earniObYTM6xmZxjM9pSGZf5mpbZCawZun8KsGuejiVJmmC+wv3zwNokpyZ5OnAesGWejiVJmmBepmWq6skkFwOfAo4Crqyqe6fZbfM025cyx2Zyjs3kHJvRlsS4pKqm7yVJOqL49QOS1CHDXZI6tCjCvdevKkhyZZI9Se4Zalue5OYkD7TbZa09Sa5oY3B3ktOH9tnQ+j+QZMNQ+79I8qW2zxVJMtUxFpMka5J8Jsm2JPcmeUtrX/Ljk+S4JLcn+WIbm99o7acmua3VfU27WIEkx7b729v2saHHuqS135/k7KH2ka+5yY6xmCQ5KskXktzQ7jsuo1TVgi4M/uD6FeD5wNOBLwLrFrquOXpuPwWcDtwz1Pa7wKa2vgn4nbZ+DvBJBp8ROBO4rbUvB77abpe19WVt2+3AS9o+nwRePdUxFtMCrAJOb+vPBP4fsM7xKVq9x7f1Y4Db2nO+Fjivtf8R8Ktt/d8Df9TWzwOuaevr2uvpWODU9jo7aqrX3GTHWEwL8B+BjwA3TFXzUhuXA8ZpwQsYvPg+NXT/EuCSha5rDp/fGE8N9/uBVW19FXB/W38fcP7EfsD5wPuG2t/X2lYB9w217+832TEW8wJcz+C7iByfp47LM4A7GXzC+2Hg6Na+/3XD4Kq0l7T1o1u/THwt7es32Wuu7TPyGItlYfCZmVuAnwFumKrmpTQuo5bFMC0z6qsKVi9QLYfDyVW1G6DdntTaJxuHqdp3jmif6hiLUvvv8osZnKE6PuyfergL2APczOCM8ltV9WTrMvx89o9B2/4ocCIHP2YnTnGMxeLdwK8B32v3p6p5KY3LARZDuE/7VQVLxGTjcLDtR5QkxwPXAW+tqsem6jqirdvxqaq9VXUagzPVM4AXjurWbudqbBb1mCV5LbCnqu4Ybh7RdUmNy2QWQ7gvta8qeCjJKoB2u6e1TzYOU7WfMqJ9qmMsKkmOYRDsH66qj7dmx2dIVX0L+EsGc+4nJNn3wcPh57N/DNr2ZwHf5ODH7OEpjrEYvAz4uSQ7GHzT7M8wOJNf6uMy0mII96X2VQVbgH1XdGxgMNe8r/2CdlXImcCjbcrgU8ArkyxrV3W8ksF8327g8SRntqtALpjwWKOOsWi0mt8PbKuqdw1tWvLjk2RlkhPa+g8ArwC2AZ8BXt+6TRybfc/n9cCnazA5vAU4r101ciqwlsEfmUe+5to+kx1jwVXVJVV1SlWNMaj501X1iyzxcZnUQk/6tz9QnMPgaomvAO9Y6Hrm8Hl9FNgNfJfBWcGFDObvbgEeaLfLW98w+IGTrwBfAtYPPc4vA9vb8uah9vXAPW2f9/D9TxyPPMZiWoCfZPBf27uBu9pyjuNTAD8KfKGNzT3Ar7f25zMIoe3AnwLHtvbj2v3tbfvzhx7rHe3530+7Wqi1j3zNTXaMxbYAZ/H9q2UclxGLXz8gSR1aDNMykqQ5ZrhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDv1/W/khD3zS7NIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes = (4, 4, 4, 4, 4, 4, 4, 4, 4), max_iter = 1000)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Root Mean Squared Log Error Neural Network Sklearn: \", RMSLELoss_for_numpy(y_predict, y_test))\n",
    "\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "\n",
    "print(y_predict)\n",
    "\n",
    "plt.hist(y_predict)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_test)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This solution for this problem would be to scale the labels\n",
    "- This will help with the convergence, because the initial predictions won't be \"to far off\"\n",
    "- And if the targets will be too big, the mean squared error will be huge which means that the gradients will also be huge which can lead to numerical instabiliy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train, (-1, 1))\n",
    "y_test = np.reshape(y_test, (-1, 1))\n",
    "\n",
    "y_train_scaled, y_test_scaled, min_max_scaler = preprocessing(y_train, y_test, preprocessing_type = \"MinMax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try again in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error Neural Network Sklearn:  11.210874164524583\n",
      "R2 Score: 0.7715970780185892\n",
      "Predictions:  [ 62889.02721158 127210.37665811  52859.79832381  57225.46603787\n",
      "  49643.40710598  55375.09417938  63361.49429948 187834.55061007\n",
      "  61136.80522543 140797.26302944  55229.3267905  252392.66938152\n",
      "  92460.52865064 138590.24007593  59523.97453316 142725.40787546\n",
      " 260842.76837099 279362.54744955 172002.3707248   52193.10546542\n",
      "  89299.78297816 113149.81318837  73639.01755216 140013.20813906\n",
      "  79764.68637618  50035.8768822   52852.66714984  98967.32543539\n",
      "  57965.97818425  79953.39751684  58408.89470331  47891.49015006\n",
      " 128314.80355192 115966.47391621 103126.79612956  58606.18499108\n",
      "  87234.12171066  51001.47175674  61739.55834883  59640.7501331\n",
      "  58816.0734532  144172.8487026   66724.25071512  63073.34536027\n",
      "  66379.77745827  88359.71384758  70561.25228717  60642.16200297\n",
      " 107019.46348747 188890.16279643  90288.46268257  90528.66324515\n",
      " 112110.24417104  50252.82306892 115761.6788722  109030.84794284\n",
      "  49167.69712645  59096.35020914  57127.19855988  82899.95592903\n",
      "  62762.96588376 126427.63904513  81621.13179405  56033.78567663\n",
      "  57784.05354815 170325.36238799  92447.22663105 103002.92809006\n",
      "  57643.61800424 254284.88789898 160081.84321414 128707.62833788\n",
      "  60443.02861012 134574.41164045  76219.60024999 123606.23504117\n",
      " 120810.68579467  54398.48101114  62168.88453363  82517.68277974\n",
      "  78880.74662321  57432.11417338  60542.50021244  82877.66807122\n",
      "  95025.70143257  87560.32162048 195628.84815566 152765.86839337\n",
      "  50736.65616799 160507.31687259  61606.3701087   59252.27965433\n",
      " 123840.16518785  74354.8047855   56824.64156843 163873.70987936\n",
      " 187393.72756396  99802.00388291  66800.46181273  66196.77734031\n",
      "  81859.56360554 265500.24446658 369278.13949127  83083.73881946\n",
      " 301745.1082331  158952.24905444  53661.95811331  52594.72640173\n",
      "  89894.54927782  56659.10798384  89635.44924333  61941.83868274\n",
      "  59068.81051843  54137.60860188  93104.48281025  59171.61613545\n",
      " 117116.12471793 274893.3420503   72974.39623468  61439.13443864\n",
      "  84124.14385869 136473.64285302  95489.06801699 138753.4341064\n",
      "  76355.89930315  76497.45448746 104033.35376593 121009.18695982\n",
      "  87605.6200324   50738.26763572  99433.32310824  76486.35063641\n",
      "  63336.08138151  98268.6938104  127353.72016323 143479.27264962\n",
      " 125881.95489754  88088.76743597 159585.72253138  69749.07781191\n",
      "  58596.74900096  61055.2464145  175549.90855541 100468.40731922\n",
      "  74514.7961141  101524.67267637  52758.99462815 123591.44566401\n",
      "  85633.72115117  49107.5221885  291569.95191667 152769.46649727\n",
      " 107840.49972831  51424.74459231 139793.63627891  94348.68997263\n",
      "  51430.20101882 210537.7628726  103727.09745243 105556.41156031\n",
      " 146043.03692944 287394.19636836  50117.16737363 145676.59648477\n",
      "  59419.41165319  54167.44384012  57228.76766352  65320.86395251\n",
      "  49826.38080864  69109.37489433  54517.73266657  60576.48524411\n",
      "  55984.89168883  60323.26390893  74493.3723814   84737.30566658\n",
      " 106313.70836288 124153.56508645  75805.01766401  71986.90872298\n",
      "  54864.00484824  63996.16386022  78296.74905727  78835.968841\n",
      "  74935.98073705  58434.09774551  58271.06338471  62624.7908655\n",
      "  62181.24166536 160769.03057265 280059.97819151 129405.61573955\n",
      " 231016.5696553  110875.10034393  55796.18929377  59932.89559467\n",
      " 133289.30158006 271762.69348264  54611.1236354  267610.36241723\n",
      " 106432.08180779  56678.85154831  74691.92498395 141465.3681669\n",
      "  54743.56841887  68758.88371765  55607.83980547 151760.66046317\n",
      " 124670.17348241  87086.01226772  52730.64018177 104900.76180506\n",
      " 204846.21756123  52749.93571946 134383.66359123  82310.38746686\n",
      " 161114.6463835   62092.02888192  83179.02953749 151483.22341938\n",
      "  76265.73466524  91088.58649868  47715.23263609  83927.41396709\n",
      " 205565.05143665  63331.31989922  81034.09534675  56623.8477719\n",
      "  54227.00302012 185298.73904402  54388.13086752  52451.34724176\n",
      "  52114.26370146  74577.92680593  99552.92611894 116012.03680519\n",
      " 101946.09764603  61431.70566729  69919.31410188 102610.84738433\n",
      " 107307.11252431 115657.7708015  257344.88095193  68739.22295178\n",
      "  84491.35363118 151038.95016534  86415.09008494  53172.6770653\n",
      " 111041.99130183 114646.62945083  53734.49344191 100709.63556786\n",
      "  55872.15686896  52846.21464938 231016.5696553  103382.96407904\n",
      "  58994.29364507  64949.26175454  87434.22487842  51011.1720392\n",
      "  60360.48962635 147120.45724458  61989.51100606  99567.7619813\n",
      "  68401.63879693  47520.10733626 148802.64164858 176168.41660542\n",
      "  90580.56356453  63648.18329528 100632.88337696  56750.47743301\n",
      "  63125.24746708  75965.42142728 112030.97469565  59647.87229203\n",
      "  54630.20828258  72400.4132374   88918.78211259 157199.62973079\n",
      " 124677.71112475  65575.24570465  52745.46324666 121044.88268639\n",
      " 136223.30460198  72499.63235091  99507.743928    55100.13856684\n",
      "  64213.14619129  61438.97665727  50503.40263021  57092.8329385\n",
      "  52218.63637552  66344.06068965 194367.20429248 109162.91352634\n",
      " 121426.42775915  88501.75917929 242994.41774566  92393.26330798\n",
      "  57396.32412636  67115.45966888  86415.09008494  53951.87794417\n",
      "  52148.9646071   63118.52702333  86583.14822731  49646.62122846\n",
      "  50358.13763294 108788.69113525  76247.28268077  77363.49209405\n",
      "  73347.4559731  103472.74149905 159446.12176593 173967.98086015\n",
      "  74564.87474899 113103.10913707  55695.01975862  58671.86174994\n",
      "  54392.83806504 145016.28611022  67201.75206265  59913.71392761\n",
      "  65723.52761755 132762.05520994  53171.35018267  90222.04623404\n",
      " 251471.50466971  85454.97542288 183791.5800208   95087.72639364\n",
      "  82364.3078885   50182.08436738  86991.91081494  87522.41116643\n",
      " 169831.26195141  48441.86671747 128125.73052585  49381.05181038\n",
      "  88306.86830239  54968.66120489 150086.75766389  95148.61084389\n",
      "  91285.77423934 103793.30799743  74043.3956131   62991.81201004\n",
      " 109260.47440704  54630.20828258  49373.7808204  363658.42417255\n",
      " 111400.87792695  51215.39041561  79208.64836315  62682.4587358\n",
      "  55967.13119264  53404.07230885  75805.01766401  54120.69625747\n",
      "  60353.2043687   56279.05318859  96998.56648113  55121.30163116\n",
      "  72818.00033478 237493.06654968 167582.10002752 223834.17074672\n",
      "  54827.73337904 112886.73909685  53462.57014631  90580.56356453\n",
      "  56308.23615849 133403.15040414  61089.06855837  73206.1160569\n",
      " 143200.04189925  93302.04312322 104242.1925234  165839.62444833\n",
      "  59796.47626551  73617.76061905 120679.34192432  65558.94087878\n",
      "  70265.19182384 185844.96889829 163644.51023704  86834.79646454\n",
      " 203789.8515055   67021.44126249  49649.20070183  55862.76258683\n",
      " 120348.33552876  73504.3331575  132161.47332737 192154.90713251\n",
      "  79437.71277674  61650.58416372  85934.89949089  58702.54206959\n",
      " 140491.15012702  51973.31894881  56990.74814957  52193.10546542\n",
      " 106199.8876956   89184.36231574 198965.29664531  60479.19335412\n",
      " 147497.64869044  61552.89816103  64460.94170903 113621.45410148\n",
      "  84619.64497142  59010.68397947 132757.97958348 133140.39643155\n",
      "  61554.78135984 101445.35400352 237616.4455805   65222.32975085\n",
      "  51756.22636521  53107.59087042 151702.63756862  48394.66263835\n",
      "  76247.28268077  91771.41903834  57880.05635787 124442.4712596\n",
      "  54211.13964734  53281.01674919  98363.04399508  80004.41193113\n",
      "  84925.5624163   64528.71431706 103472.74149905  55742.02147983\n",
      "  64930.24396642  56429.90749717 146357.62234169 143386.18373325\n",
      "  77385.67032856 305077.65347977 157952.78924344  61934.56769276\n",
      " 133204.53867693  50127.5619361  176011.29649796 135517.94056102\n",
      "  62085.07132052  52458.07048262  55948.96678953 114702.3326665\n",
      " 103271.30439968  47413.29975425 111490.34001414  77107.05762726\n",
      "  63530.67236756 200387.22995325 152778.08868738  55406.89407937\n",
      "  62306.26096937  68247.86953083  53283.4011813   52673.90294068\n",
      "  51363.17148209 100632.88337696 116535.83835993 137690.34654671\n",
      "  79149.85663891 310113.22171298  55556.96029522  50376.75737606\n",
      "  95801.12337812 197509.24846539 101201.55128897 129866.0299387\n",
      " 101557.97377018 119075.50075788 105170.06155103  62363.55410279\n",
      " 162844.94753463 211959.97305345  59341.73965917 133784.86185658\n",
      "  78862.28443193 143273.12438727  55959.38847841  55109.1323846\n",
      "  80156.07331871  93630.06049915  59779.04104088 114702.3326665\n",
      " 117285.91715302  70776.6553082   98195.49768806  76755.70119626\n",
      " 105303.30622296  56295.38873528 119568.22344206  93742.29513456\n",
      "  57116.93379358  76376.72455681  60631.86377716  52097.21670768\n",
      " 151117.96300447  63012.30268452  50252.82306892  81481.15747865\n",
      " 114241.10891019 112714.66214913 135694.83569199  97373.73341351\n",
      "  99076.65138113 101200.39261956 193350.3429948  188872.9166804\n",
      "  63938.74480466  97437.32325483 144092.81339382  59455.88348536\n",
      " 100717.17058245 125650.48709935 283535.30477251 204444.66212156\n",
      "  75187.48624188 265069.63937435 217203.43008524 108304.1255244\n",
      "  68510.04086773 107307.11252431 108991.10980603  64460.74021504\n",
      "  65918.52037305 140500.08268948  52631.26243978  60546.29291382\n",
      " 130444.05500474  69820.36532286 112975.63865975  96510.94615907\n",
      "  75034.92521343  50615.23650016 107307.11252431  67393.30337024\n",
      "  83647.30530318  66850.7127092   78375.68928694 196797.57022285\n",
      "  96510.94615907  91425.98850523 164673.17414978  48006.13949664\n",
      "  55266.50191106 105458.12346895  74890.36091134  67359.65921221\n",
      " 106379.47192966  60611.13457923 103393.69481512 148774.23598793\n",
      " 112329.85865767  53969.92710069  48739.53705235  62965.39453632\n",
      " 332082.34533803 181139.0509944   99407.6949715  121902.79328872\n",
      "  53439.09884016 104477.03941649  64453.67071905  52289.5238906\n",
      "  54262.8697347   55838.44053483 244737.29177703  79576.38615595\n",
      " 104197.06726386  50277.03081043  61259.3629122   65804.44550227\n",
      " 156344.88889149  86094.06877789  86751.84802861  49039.64318832\n",
      " 157316.91410503  80544.5834926  102647.17804497 106108.76414262\n",
      "  49646.62122846  83434.38479085  59164.34514547 268070.91364811\n",
      "  66500.99075575  70284.99793212  96748.42585733 148094.3502469\n",
      "  48270.76487948  68745.56962365  63508.9303382   70265.19182384\n",
      " 171155.77578406  70167.28634378  58270.45496447  57700.65524927\n",
      " 149459.23708287 168774.22300847  65211.59925225 166695.84494463\n",
      " 121752.51353075 183403.43228334  92974.8127749   57124.20478356\n",
      "  85646.4246851   95200.43527484 130389.25820782  80858.6514419\n",
      "  62903.07388924  65725.92750943  79913.31300739  58010.53571585\n",
      "  87605.6200324   59647.87229203 142619.68790532  47002.4903371\n",
      " 104738.11610074  78492.88218551 109424.60033148  83402.08140721\n",
      "  47629.46311517  93775.52692483  54107.05852538 190525.01968681\n",
      "  48683.54229633 159215.93314198 145932.60319375  50512.96150533\n",
      "  62313.53195935 169387.17596811 384231.43836818  57128.9976825\n",
      "  99271.10836012  56884.11313446  51825.26024043 111120.78429773\n",
      "  52401.57488923  79217.64593167  94719.62235312  48798.71202165\n",
      "  59605.66873312  52646.59712757  77787.41733876 222517.19202233\n",
      "  86421.20170293 130827.67148703 189281.11880521 191850.92562086\n",
      "  60245.66602     60352.03902741  54920.04629912  64952.44092592\n",
      "  84778.90863043  71714.10254079 172599.60935701  57746.46810183\n",
      " 100925.67175497 143779.79890713 285763.07338242  53992.80196709\n",
      " 101762.87211448  97661.76526872  56940.67187071  59739.73835955\n",
      "  79556.10844348  58831.33683727 132118.96685207  98766.68165313\n",
      "  56460.76443406  88501.75917929  68181.32310038 153181.8877656\n",
      "  86834.11994933  82255.71132316  93673.7021343   99009.10641178\n",
      "  76572.88383893 501753.11573632 108531.86359391  60057.06367722\n",
      " 110766.47312768 261725.46452896  49522.45813105  54228.68682836\n",
      "  56412.64505309 109053.21389944  58568.95927366  63162.92543295\n",
      "  72715.61032318  65753.37682918  53431.82785018  61988.45002217\n",
      " 151483.22341938 130940.55095425 210057.30776746 152371.20971359\n",
      "  61156.45836844  85909.05031677]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes = (4, 4, 4, 4, 4, 4, 4, 4), max_iter = 1000)\n",
    "\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "y_predict = np.reshape(y_predict, (-1, 1))\n",
    "\n",
    "print(\"Root Mean Squared Log Error Neural Network Sklearn: \", RMSLELoss_for_numpy(y_predict, y_test))\n",
    "\n",
    "y_predict = min_max_scaler.inverse_transform(y_predict)\n",
    "\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "\n",
    "print(\"Predictions: \", y_predict.reshape(-1))\n",
    "\n",
    "plt.hist(y_predict)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_test)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now back in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 0\n",
      "Epoch: 1/500..  Training Loss: 0.356..  Test Loss: 0.221.. \n",
      "Epoch: 2/500..  Training Loss: 0.259..  Test Loss: 0.168.. \n",
      "Epoch: 3/500..  Training Loss: 0.200..  Test Loss: 0.127.. \n",
      "Epoch: 4/500..  Training Loss: 0.170..  Test Loss: 0.088.. \n",
      "Epoch: 5/500..  Training Loss: 0.147..  Test Loss: 0.083.. \n",
      "Epoch: 6/500..  Training Loss: 0.121..  Test Loss: 0.052.. \n",
      "Epoch: 7/500..  Training Loss: 0.116..  Test Loss: 0.081.. \n",
      "Epoch: 8/500..  Training Loss: 0.095..  Test Loss: 0.052.. \n",
      "Epoch: 9/500..  Training Loss: 0.091..  Test Loss: 0.047.. \n",
      "Epoch: 10/500..  Training Loss: 0.080..  Test Loss: 0.039.. \n",
      "Epoch: 11/500..  Training Loss: 0.073..  Test Loss: 0.039.. \n",
      "Epoch: 12/500..  Training Loss: 0.074..  Test Loss: 0.033.. \n",
      "Epoch: 13/500..  Training Loss: 0.068..  Test Loss: 0.025.. \n",
      "Epoch: 14/500..  Training Loss: 0.064..  Test Loss: 0.027.. \n",
      "Epoch: 15/500..  Training Loss: 0.058..  Test Loss: 0.030.. \n",
      "Epoch: 16/500..  Training Loss: 0.055..  Test Loss: 0.027.. \n",
      "Epoch: 17/500..  Training Loss: 0.051..  Test Loss: 0.027.. \n",
      "Epoch: 18/500..  Training Loss: 0.046..  Test Loss: 0.025.. \n",
      "Epoch: 19/500..  Training Loss: 0.047..  Test Loss: 0.020.. \n",
      "Epoch: 20/500..  Training Loss: 0.044..  Test Loss: 0.025.. \n",
      "Epoch: 21/500..  Training Loss: 0.042..  Test Loss: 0.019.. \n",
      "Epoch: 22/500..  Training Loss: 0.041..  Test Loss: 0.027.. \n",
      "Epoch: 23/500..  Training Loss: 0.038..  Test Loss: 0.018.. \n",
      "Epoch: 24/500..  Training Loss: 0.036..  Test Loss: 0.017.. \n",
      "Epoch: 25/500..  Training Loss: 0.035..  Test Loss: 0.019.. \n",
      "Epoch: 26/500..  Training Loss: 0.034..  Test Loss: 0.020.. \n",
      "Epoch: 27/500..  Training Loss: 0.035..  Test Loss: 0.024.. \n",
      "Epoch: 28/500..  Training Loss: 0.031..  Test Loss: 0.020.. \n",
      "Epoch: 29/500..  Training Loss: 0.031..  Test Loss: 0.019.. \n",
      "Epoch: 30/500..  Training Loss: 0.030..  Test Loss: 0.021.. \n",
      "Epoch: 31/500..  Training Loss: 0.030..  Test Loss: 0.017.. \n",
      "Epoch: 32/500..  Training Loss: 0.030..  Test Loss: 0.018.. \n",
      "Epoch: 33/500..  Training Loss: 0.028..  Test Loss: 0.016.. \n",
      "Epoch: 34/500..  Training Loss: 0.027..  Test Loss: 0.017.. \n",
      "Epoch: 35/500..  Training Loss: 0.028..  Test Loss: 0.019.. \n",
      "Epoch: 36/500..  Training Loss: 0.026..  Test Loss: 0.015.. \n",
      "Epoch: 37/500..  Training Loss: 0.025..  Test Loss: 0.016.. \n",
      "Epoch: 38/500..  Training Loss: 0.025..  Test Loss: 0.019.. \n",
      "Epoch: 39/500..  Training Loss: 0.024..  Test Loss: 0.017.. \n",
      "Epoch: 40/500..  Training Loss: 0.023..  Test Loss: 0.020.. \n",
      "Epoch: 41/500..  Training Loss: 0.023..  Test Loss: 0.016.. \n",
      "Epoch: 42/500..  Training Loss: 0.023..  Test Loss: 0.014.. \n",
      "Epoch: 43/500..  Training Loss: 0.022..  Test Loss: 0.015.. \n",
      "Epoch: 44/500..  Training Loss: 0.022..  Test Loss: 0.016.. \n",
      "Epoch: 45/500..  Training Loss: 0.021..  Test Loss: 0.019.. \n",
      "Epoch: 46/500..  Training Loss: 0.021..  Test Loss: 0.017.. \n",
      "Epoch: 47/500..  Training Loss: 0.020..  Test Loss: 0.017.. \n",
      "Epoch: 48/500..  Training Loss: 0.021..  Test Loss: 0.017.. \n",
      "Epoch: 49/500..  Training Loss: 0.020..  Test Loss: 0.018.. \n",
      "Epoch: 50/500..  Training Loss: 0.020..  Test Loss: 0.015.. \n",
      "Epoch: 51/500..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 52/500..  Training Loss: 0.020..  Test Loss: 0.015.. \n",
      "Epoch: 53/500..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 54/500..  Training Loss: 0.019..  Test Loss: 0.015.. \n",
      "Epoch: 55/500..  Training Loss: 0.019..  Test Loss: 0.016.. \n",
      "Epoch: 56/500..  Training Loss: 0.019..  Test Loss: 0.014.. \n",
      "Epoch: 57/500..  Training Loss: 0.019..  Test Loss: 0.016.. \n",
      "Epoch: 58/500..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 59/500..  Training Loss: 0.019..  Test Loss: 0.016.. \n",
      "Epoch: 60/500..  Training Loss: 0.019..  Test Loss: 0.020.. \n",
      "Epoch: 61/500..  Training Loss: 0.018..  Test Loss: 0.014.. \n",
      "Epoch: 62/500..  Training Loss: 0.018..  Test Loss: 0.021.. \n",
      "Epoch: 63/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 64/500..  Training Loss: 0.018..  Test Loss: 0.015.. \n",
      "Epoch: 65/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 66/500..  Training Loss: 0.018..  Test Loss: 0.022.. \n",
      "Epoch: 67/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 68/500..  Training Loss: 0.018..  Test Loss: 0.015.. \n",
      "Epoch: 69/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 70/500..  Training Loss: 0.018..  Test Loss: 0.019.. \n",
      "Epoch: 71/500..  Training Loss: 0.018..  Test Loss: 0.015.. \n",
      "Epoch: 72/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 73/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 74/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 75/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 76/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 77/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 78/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 79/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 80/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 81/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 82/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 83/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 84/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 85/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 86/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 87/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 88/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 89/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 90/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 91/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 92/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 93/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 94/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 95/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 96/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 97/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 98/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 99/500..  Training Loss: 0.017..  Test Loss: 0.023.. \n",
      "Epoch: 100/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 101/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 102/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 103/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 104/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 105/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 106/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 107/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 108/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 109/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 110/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 111/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 112/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 113/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 114/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 115/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 116/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 117/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 118/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 119/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 120/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 121/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 122/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 123/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 124/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 125/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 126/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 127/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 128/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 129/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 130/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 131/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 132/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 133/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 134/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 135/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 137/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 138/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 139/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 140/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 141/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 142/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 143/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 144/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 145/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 146/500..  Training Loss: 0.017..  Test Loss: 0.013.. \n",
      "Epoch: 147/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 148/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 149/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 150/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 151/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 152/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 153/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 154/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 155/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 156/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 157/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 158/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 159/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 160/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 161/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 162/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 163/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 164/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 165/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 166/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 167/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 168/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 169/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 170/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 171/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 172/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 173/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 174/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 175/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 176/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 177/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 178/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 179/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 180/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 181/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 182/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 183/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 184/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 185/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 186/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 187/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 188/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 189/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 190/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 191/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 192/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 193/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 194/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 195/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 196/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 197/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 198/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 199/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 200/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 201/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 202/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 203/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 204/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 205/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 206/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 207/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 208/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 209/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 210/500..  Training Loss: 0.016..  Test Loss: 0.023.. \n",
      "Epoch: 211/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 212/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 213/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 214/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 215/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 216/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 217/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 218/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 219/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 220/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 221/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 222/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 223/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 224/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 225/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 226/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 227/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 228/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 229/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 230/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 231/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 232/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 233/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 234/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 235/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 236/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 237/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 238/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 239/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 240/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 241/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 242/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 243/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 244/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 245/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 246/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 247/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 248/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 249/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 250/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 251/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 252/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 253/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 254/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 255/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 256/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 257/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 258/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 259/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 260/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 261/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 262/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 263/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 264/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 265/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 266/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 267/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 268/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 269/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 270/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 271/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 272/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 273/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 274/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 275/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 276/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 277/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 278/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 279/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 280/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 281/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 282/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 283/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 284/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 285/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 286/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 287/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 288/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 289/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 290/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 291/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 292/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 293/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 294/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 295/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 296/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 297/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 298/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 299/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 300/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 301/500..  Training Loss: 0.014..  Test Loss: 0.011.. \n",
      "Epoch: 302/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 303/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 304/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 305/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 306/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 307/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 308/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 309/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 310/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 311/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 312/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 313/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 314/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 315/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 316/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 317/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 318/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 319/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 320/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 321/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 322/500..  Training Loss: 0.014..  Test Loss: 0.011.. \n",
      "Epoch: 323/500..  Training Loss: 0.014..  Test Loss: 0.011.. \n",
      "Epoch: 324/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 325/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 326/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 327/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 328/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 329/500..  Training Loss: 0.014..  Test Loss: 0.011.. \n",
      "Epoch: 330/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 331/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 332/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 333/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 334/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 335/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 336/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 337/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 338/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 339/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 340/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 341/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 342/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 343/500..  Training Loss: 0.014..  Test Loss: 0.019.. \n",
      "Epoch: 344/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 345/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 346/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 347/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 348/500..  Training Loss: 0.014..  Test Loss: 0.011.. \n",
      "Epoch: 349/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 350/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 351/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 352/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 353/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 354/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 355/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 356/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 357/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 358/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 359/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 360/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 361/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 362/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 363/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 364/500..  Training Loss: 0.014..  Test Loss: 0.011.. \n",
      "Epoch: 365/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 366/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 367/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 368/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 369/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 370/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 371/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 372/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 373/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 374/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 375/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 376/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 377/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 378/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 379/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 380/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 381/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 382/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 383/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 384/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 385/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 386/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 387/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 388/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 389/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 390/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 391/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 392/500..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 393/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 394/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 395/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 396/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 397/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 398/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 399/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 400/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 401/500..  Training Loss: 0.014..  Test Loss: 0.019.. \n",
      "Epoch: 402/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 403/500..  Training Loss: 0.013..  Test Loss: 0.016.. \n",
      "Epoch: 404/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 405/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 406/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 407/500..  Training Loss: 0.013..  Test Loss: 0.017.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 408/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 409/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 410/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 411/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 412/500..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 413/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 414/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 415/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 416/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 417/500..  Training Loss: 0.014..  Test Loss: 0.011.. \n",
      "Epoch: 418/500..  Training Loss: 0.015..  Test Loss: 0.018.. \n",
      "Epoch: 419/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 420/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 421/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 422/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 423/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 424/500..  Training Loss: 0.014..  Test Loss: 0.019.. \n",
      "Epoch: 425/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 426/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 427/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 428/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 429/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 430/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 431/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 432/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 433/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 434/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 435/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 436/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 437/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 438/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 439/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 440/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 441/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 442/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 443/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 444/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 445/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 446/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 447/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 448/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 449/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 450/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 451/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 452/500..  Training Loss: 0.014..  Test Loss: 0.018.. \n",
      "Epoch: 453/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 454/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 455/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 456/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 457/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 458/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 459/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 460/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 461/500..  Training Loss: 0.014..  Test Loss: 0.018.. \n",
      "Epoch: 462/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 463/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 464/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 465/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 466/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 467/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 468/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 469/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 470/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 471/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 472/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 473/500..  Training Loss: 0.014..  Test Loss: 0.012.. \n",
      "Epoch: 474/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 475/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 476/500..  Training Loss: 0.013..  Test Loss: 0.012.. \n",
      "Epoch: 477/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 478/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 479/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 480/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 481/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 482/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 483/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 484/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 485/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 486/500..  Training Loss: 0.013..  Test Loss: 0.016.. \n",
      "Epoch: 487/500..  Training Loss: 0.014..  Test Loss: 0.019.. \n",
      "Epoch: 488/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 489/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 490/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 491/500..  Training Loss: 0.014..  Test Loss: 0.018.. \n",
      "Epoch: 492/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 493/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 494/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 495/500..  Training Loss: 0.013..  Test Loss: 0.019.. \n",
      "Epoch: 496/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 497/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 498/500..  Training Loss: 0.013..  Test Loss: 0.016.. \n",
      "Epoch: 499/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 500/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 1\n",
      "Epoch: 1/500..  Training Loss: 0.266..  Test Loss: 0.198.. \n",
      "Epoch: 2/500..  Training Loss: 0.191..  Test Loss: 0.146.. \n",
      "Epoch: 3/500..  Training Loss: 0.134..  Test Loss: 0.090.. \n",
      "Epoch: 4/500..  Training Loss: 0.090..  Test Loss: 0.054.. \n",
      "Epoch: 5/500..  Training Loss: 0.064..  Test Loss: 0.041.. \n",
      "Epoch: 6/500..  Training Loss: 0.043..  Test Loss: 0.036.. \n",
      "Epoch: 7/500..  Training Loss: 0.031..  Test Loss: 0.024.. \n",
      "Epoch: 8/500..  Training Loss: 0.027..  Test Loss: 0.020.. \n",
      "Epoch: 9/500..  Training Loss: 0.024..  Test Loss: 0.022.. \n",
      "Epoch: 10/500..  Training Loss: 0.023..  Test Loss: 0.020.. \n",
      "Epoch: 11/500..  Training Loss: 0.023..  Test Loss: 0.018.. \n",
      "Epoch: 12/500..  Training Loss: 0.021..  Test Loss: 0.017.. \n",
      "Epoch: 13/500..  Training Loss: 0.022..  Test Loss: 0.015.. \n",
      "Epoch: 14/500..  Training Loss: 0.022..  Test Loss: 0.016.. \n",
      "Epoch: 15/500..  Training Loss: 0.021..  Test Loss: 0.018.. \n",
      "Epoch: 16/500..  Training Loss: 0.021..  Test Loss: 0.018.. \n",
      "Epoch: 17/500..  Training Loss: 0.020..  Test Loss: 0.017.. \n",
      "Epoch: 18/500..  Training Loss: 0.019..  Test Loss: 0.016.. \n",
      "Epoch: 19/500..  Training Loss: 0.019..  Test Loss: 0.016.. \n",
      "Epoch: 20/500..  Training Loss: 0.020..  Test Loss: 0.020.. \n",
      "Epoch: 21/500..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 22/500..  Training Loss: 0.019..  Test Loss: 0.019.. \n",
      "Epoch: 23/500..  Training Loss: 0.019..  Test Loss: 0.018.. \n",
      "Epoch: 24/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 25/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 26/500..  Training Loss: 0.019..  Test Loss: 0.017.. \n",
      "Epoch: 27/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 28/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 29/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 30/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 31/500..  Training Loss: 0.018..  Test Loss: 0.021.. \n",
      "Epoch: 32/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 33/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 34/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 35/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 36/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 37/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 38/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 39/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 40/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 41/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 42/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 43/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 44/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 45/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 46/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 47/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 48/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 49/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 50/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 51/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 52/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 53/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 54/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 55/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 56/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 57/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 58/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 59/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 60/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 61/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 62/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 63/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 64/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 65/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 66/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 67/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 68/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 69/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 70/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 71/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 72/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 73/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 74/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 75/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 76/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 77/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 78/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 79/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 80/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 81/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 82/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 83/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 84/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 85/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 86/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 87/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 88/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 89/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 90/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 91/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 92/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 93/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 94/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 95/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 96/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 97/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 98/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 99/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 100/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 101/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 102/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 103/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 104/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 105/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 106/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 107/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 108/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 109/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 110/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 111/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 112/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 113/500..  Training Loss: 0.017..  Test Loss: 0.023.. \n",
      "Epoch: 114/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 115/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 116/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 117/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 118/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 119/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 120/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 121/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 122/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 123/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 124/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 125/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 126/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 127/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 128/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 129/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 130/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 131/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 132/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 133/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 134/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 135/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 137/500..  Training Loss: 0.016..  Test Loss: 0.023.. \n",
      "Epoch: 138/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 139/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 140/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 141/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 142/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 143/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 144/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 145/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 146/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 147/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 148/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 149/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 150/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 151/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 152/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 153/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 154/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 155/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 156/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 157/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 158/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 159/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 160/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 161/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 162/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 163/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 164/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 165/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 166/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 167/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 168/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 169/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 170/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 171/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 172/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 173/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 174/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 175/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 176/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 177/500..  Training Loss: 0.017..  Test Loss: 0.023.. \n",
      "Epoch: 178/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 179/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 180/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 181/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 182/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 183/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 184/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 185/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 186/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 187/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 188/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 189/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 190/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 191/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 192/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 193/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 194/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 195/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 196/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 197/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 198/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 199/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 200/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 201/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 202/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 203/500..  Training Loss: 0.015..  Test Loss: 0.018.. \n",
      "Epoch: 204/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 205/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 206/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 207/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 208/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 209/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 210/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 211/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 212/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 213/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 214/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 215/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 216/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 217/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 218/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 219/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 220/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 221/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 222/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 223/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 224/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 225/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 226/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 227/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 228/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 229/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 230/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 231/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 232/500..  Training Loss: 0.015..  Test Loss: 0.021.. \n",
      "Epoch: 233/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 234/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 235/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 236/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 237/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 238/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 239/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 240/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 241/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 242/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 243/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 244/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 245/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 246/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 247/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 248/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 249/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 250/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 251/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 252/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 253/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 254/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 255/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 256/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 257/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 258/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 259/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 260/500..  Training Loss: 0.015..  Test Loss: 0.018.. \n",
      "Epoch: 261/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 262/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 263/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 264/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 265/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 266/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 267/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 268/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 269/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 271/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 272/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 273/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 274/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 275/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 276/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 277/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 278/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 279/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 280/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 281/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 282/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 283/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 284/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 285/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 286/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 287/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 288/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 289/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 290/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 291/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 292/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 293/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 294/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 295/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 296/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 297/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 298/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 299/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 300/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 301/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 302/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 303/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 304/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 305/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 306/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 307/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 308/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 309/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 310/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 311/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 312/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 313/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 314/500..  Training Loss: 0.015..  Test Loss: 0.020.. \n",
      "Epoch: 315/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 316/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 317/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 318/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 319/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 320/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 321/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 322/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 323/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 324/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 325/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 326/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 327/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 328/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 329/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 330/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 331/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 332/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 333/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 334/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 335/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 336/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 337/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 338/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 339/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 340/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 341/500..  Training Loss: 0.016..  Test Loss: 0.011.. \n",
      "Epoch: 342/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 343/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 344/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 345/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 346/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 347/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 348/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 349/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 350/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 351/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 352/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 353/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 354/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 355/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 356/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 357/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 358/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 359/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 360/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 361/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 362/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 363/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 364/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 365/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 366/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 367/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 368/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 369/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 370/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 371/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 372/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 373/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 374/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 375/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 376/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 377/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 378/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 379/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 380/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 381/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 382/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 383/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 384/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 385/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 386/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 387/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 388/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 389/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 390/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 391/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 392/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 393/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 394/500..  Training Loss: 0.016..  Test Loss: 0.012.. \n",
      "Epoch: 395/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 396/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 397/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 398/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 399/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 400/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 401/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 402/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 403/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 404/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 405/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 406/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 407/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 408/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 409/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 410/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 411/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 412/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 413/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 414/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 415/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 416/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 417/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 418/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 419/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 420/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 421/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 422/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 423/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 424/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 425/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 426/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 427/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 428/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 429/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 430/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 431/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 432/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 433/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 434/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 435/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 436/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 437/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 438/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 439/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 440/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 441/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 442/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 443/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 444/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 445/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 446/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 447/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 448/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 449/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 450/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 451/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 452/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 453/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 454/500..  Training Loss: 0.016..  Test Loss: 0.011.. \n",
      "Epoch: 455/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 456/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 457/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 458/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 459/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 460/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 461/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 462/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 463/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 464/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 465/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 466/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 467/500..  Training Loss: 0.014..  Test Loss: 0.013.. \n",
      "Epoch: 468/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 469/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 470/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 471/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 472/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 473/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 474/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 475/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 476/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 477/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 478/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 479/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 480/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 481/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 482/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 483/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 484/500..  Training Loss: 0.015..  Test Loss: 0.011.. \n",
      "Epoch: 485/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 486/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 487/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 488/500..  Training Loss: 0.015..  Test Loss: 0.018.. \n",
      "Epoch: 489/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 490/500..  Training Loss: 0.014..  Test Loss: 0.014.. \n",
      "Epoch: 491/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 492/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 493/500..  Training Loss: 0.015..  Test Loss: 0.014.. \n",
      "Epoch: 494/500..  Training Loss: 0.015..  Test Loss: 0.013.. \n",
      "Epoch: 495/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 496/500..  Training Loss: 0.015..  Test Loss: 0.012.. \n",
      "Epoch: 497/500..  Training Loss: 0.015..  Test Loss: 0.015.. \n",
      "Epoch: 498/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 499/500..  Training Loss: 0.014..  Test Loss: 0.010.. \n",
      "Epoch: 500/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 2\n",
      "Epoch: 1/500..  Training Loss: 1.164..  Test Loss: 0.027.. \n",
      "Epoch: 2/500..  Training Loss: 0.844..  Test Loss: 0.020.. \n",
      "Epoch: 3/500..  Training Loss: 0.555..  Test Loss: 0.020.. \n",
      "Epoch: 4/500..  Training Loss: 0.420..  Test Loss: 0.016.. \n",
      "Epoch: 5/500..  Training Loss: 0.340..  Test Loss: 0.018.. \n",
      "Epoch: 6/500..  Training Loss: 0.205..  Test Loss: 0.018.. \n",
      "Epoch: 7/500..  Training Loss: 0.208..  Test Loss: 0.020.. \n",
      "Epoch: 8/500..  Training Loss: 0.196..  Test Loss: 0.019.. \n",
      "Epoch: 9/500..  Training Loss: 0.159..  Test Loss: 0.019.. \n",
      "Epoch: 10/500..  Training Loss: 0.158..  Test Loss: 0.020.. \n",
      "Epoch: 11/500..  Training Loss: 0.139..  Test Loss: 0.022.. \n",
      "Epoch: 12/500..  Training Loss: 0.109..  Test Loss: 0.019.. \n",
      "Epoch: 13/500..  Training Loss: 0.096..  Test Loss: 0.021.. \n",
      "Epoch: 14/500..  Training Loss: 0.075..  Test Loss: 0.018.. \n",
      "Epoch: 15/500..  Training Loss: 0.079..  Test Loss: 0.019.. \n",
      "Epoch: 16/500..  Training Loss: 0.086..  Test Loss: 0.020.. \n",
      "Epoch: 17/500..  Training Loss: 0.064..  Test Loss: 0.019.. \n",
      "Epoch: 18/500..  Training Loss: 0.061..  Test Loss: 0.018.. \n",
      "Epoch: 19/500..  Training Loss: 0.052..  Test Loss: 0.019.. \n",
      "Epoch: 20/500..  Training Loss: 0.044..  Test Loss: 0.019.. \n",
      "Epoch: 21/500..  Training Loss: 0.046..  Test Loss: 0.018.. \n",
      "Epoch: 22/500..  Training Loss: 0.043..  Test Loss: 0.019.. \n",
      "Epoch: 23/500..  Training Loss: 0.037..  Test Loss: 0.016.. \n",
      "Epoch: 24/500..  Training Loss: 0.037..  Test Loss: 0.020.. \n",
      "Epoch: 25/500..  Training Loss: 0.032..  Test Loss: 0.018.. \n",
      "Epoch: 26/500..  Training Loss: 0.030..  Test Loss: 0.018.. \n",
      "Epoch: 27/500..  Training Loss: 0.030..  Test Loss: 0.016.. \n",
      "Epoch: 28/500..  Training Loss: 0.029..  Test Loss: 0.018.. \n",
      "Epoch: 29/500..  Training Loss: 0.027..  Test Loss: 0.018.. \n",
      "Epoch: 30/500..  Training Loss: 0.027..  Test Loss: 0.017.. \n",
      "Epoch: 31/500..  Training Loss: 0.025..  Test Loss: 0.016.. \n",
      "Epoch: 32/500..  Training Loss: 0.024..  Test Loss: 0.017.. \n",
      "Epoch: 33/500..  Training Loss: 0.024..  Test Loss: 0.016.. \n",
      "Epoch: 34/500..  Training Loss: 0.023..  Test Loss: 0.015.. \n",
      "Epoch: 35/500..  Training Loss: 0.022..  Test Loss: 0.016.. \n",
      "Epoch: 36/500..  Training Loss: 0.022..  Test Loss: 0.015.. \n",
      "Epoch: 37/500..  Training Loss: 0.021..  Test Loss: 0.016.. \n",
      "Epoch: 38/500..  Training Loss: 0.021..  Test Loss: 0.017.. \n",
      "Epoch: 39/500..  Training Loss: 0.020..  Test Loss: 0.015.. \n",
      "Epoch: 40/500..  Training Loss: 0.021..  Test Loss: 0.018.. \n",
      "Epoch: 41/500..  Training Loss: 0.021..  Test Loss: 0.016.. \n",
      "Epoch: 42/500..  Training Loss: 0.020..  Test Loss: 0.018.. \n",
      "Epoch: 43/500..  Training Loss: 0.020..  Test Loss: 0.016.. \n",
      "Epoch: 44/500..  Training Loss: 0.020..  Test Loss: 0.021.. \n",
      "Epoch: 45/500..  Training Loss: 0.020..  Test Loss: 0.015.. \n",
      "Epoch: 46/500..  Training Loss: 0.020..  Test Loss: 0.017.. \n",
      "Epoch: 47/500..  Training Loss: 0.019..  Test Loss: 0.020.. \n",
      "Epoch: 48/500..  Training Loss: 0.019..  Test Loss: 0.014.. \n",
      "Epoch: 49/500..  Training Loss: 0.018..  Test Loss: 0.019.. \n",
      "Epoch: 50/500..  Training Loss: 0.019..  Test Loss: 0.017.. \n",
      "Epoch: 51/500..  Training Loss: 0.019..  Test Loss: 0.017.. \n",
      "Epoch: 52/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 53/500..  Training Loss: 0.018..  Test Loss: 0.015.. \n",
      "Epoch: 54/500..  Training Loss: 0.018..  Test Loss: 0.019.. \n",
      "Epoch: 55/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 56/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 57/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 58/500..  Training Loss: 0.018..  Test Loss: 0.019.. \n",
      "Epoch: 59/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 60/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 61/500..  Training Loss: 0.018..  Test Loss: 0.019.. \n",
      "Epoch: 62/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 63/500..  Training Loss: 0.018..  Test Loss: 0.015.. \n",
      "Epoch: 64/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 65/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 66/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 67/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 68/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 69/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 70/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 71/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 72/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 73/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 74/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 75/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 76/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 77/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 78/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 79/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 80/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 81/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 82/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 83/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 84/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 85/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 86/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 87/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 88/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 89/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 90/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 91/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 92/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 93/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 94/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 95/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 96/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 97/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 98/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 99/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 100/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 101/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 102/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 103/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 104/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 105/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 106/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 107/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 108/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 109/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 110/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 111/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 112/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 113/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 114/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 115/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 116/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 117/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 118/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 119/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 120/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 121/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 122/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 123/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 124/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 125/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 126/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 127/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 128/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 129/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 130/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 131/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 132/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 133/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 134/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 135/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 137/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 138/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 139/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 140/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 141/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 142/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 143/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 144/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 145/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 146/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 147/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 148/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 149/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 150/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 151/500..  Training Loss: 0.017..  Test Loss: 0.022.. \n",
      "Epoch: 152/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 153/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 154/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 155/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 156/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 157/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 158/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 159/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 160/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 161/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 162/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 163/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 164/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 165/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 166/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 167/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 168/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 169/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 170/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 171/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 172/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 173/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 174/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 175/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 176/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 177/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 178/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 179/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 180/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 181/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 182/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 183/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 184/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 185/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 186/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 187/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 188/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 189/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 190/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 191/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 192/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 193/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 194/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 195/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 196/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 197/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 198/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 199/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 200/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 201/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 202/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 203/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 204/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 205/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 206/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 207/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 208/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 209/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 210/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 211/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 212/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 213/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 214/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 215/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 216/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 217/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 218/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 219/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 220/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 221/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 222/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 223/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 224/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 225/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 226/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 227/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 228/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 229/500..  Training Loss: 0.017..  Test Loss: 0.022.. \n",
      "Epoch: 230/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 231/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 232/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 233/500..  Training Loss: 0.017..  Test Loss: 0.022.. \n",
      "Epoch: 234/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 235/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 236/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 237/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 238/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 239/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 240/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 241/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 242/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 243/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 244/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 245/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 246/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 247/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 248/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 249/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 250/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 251/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 252/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 253/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 254/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 255/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 256/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 257/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 258/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 259/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 260/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 261/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 262/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 263/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 264/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 265/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 266/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 267/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 268/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 269/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 271/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 272/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 273/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 274/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 275/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 276/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 277/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 278/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 279/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 280/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 281/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 282/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 283/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 284/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 285/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 286/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 287/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 288/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 289/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 290/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 291/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 292/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 293/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 294/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 295/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 296/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 297/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 298/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 299/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 300/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 301/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 302/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 303/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 304/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 305/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 306/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 307/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 308/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 309/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 310/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 311/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 312/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 313/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 314/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 315/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 316/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 317/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 318/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 319/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 320/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 321/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 322/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 323/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 324/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 325/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 326/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 327/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 328/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 329/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 330/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 331/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 332/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 333/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 334/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 335/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 336/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 337/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 338/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 339/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 340/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 341/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 342/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 343/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 344/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 345/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 346/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 347/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 348/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 349/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 350/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 351/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 352/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 353/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 354/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 355/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 356/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 357/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 358/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 359/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 360/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 361/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 362/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 363/500..  Training Loss: 0.016..  Test Loss: 0.021.. \n",
      "Epoch: 364/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 365/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 366/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 367/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 368/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 369/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 370/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 371/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 372/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 373/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 374/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 375/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 376/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 377/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 378/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 379/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 380/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 381/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 382/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 383/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 384/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 385/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 386/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 387/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 388/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 389/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 390/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 391/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 392/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 393/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 394/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 395/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 396/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 397/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 398/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 399/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 400/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 401/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 402/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 403/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 404/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 405/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 406/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 407/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 408/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 409/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 410/500..  Training Loss: 0.016..  Test Loss: 0.020.. \n",
      "Epoch: 411/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 412/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 413/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 414/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 415/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 416/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 417/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 418/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 419/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 420/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 421/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 422/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 423/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 424/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 425/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 426/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 427/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 428/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 429/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 430/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 431/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 432/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 433/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 434/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 435/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 436/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 437/500..  Training Loss: 0.016..  Test Loss: 0.021.. \n",
      "Epoch: 438/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 439/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 440/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 441/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 442/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 443/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 444/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 445/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 446/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 447/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 448/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 449/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 450/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 451/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 452/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 453/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 454/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 455/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 456/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 457/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 458/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 459/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 460/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 461/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 462/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 463/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 464/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 465/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 466/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 467/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 468/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 469/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 470/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 471/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 472/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 473/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 474/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 475/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 476/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 477/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 478/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 479/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 480/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 481/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 482/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 483/500..  Training Loss: 0.016..  Test Loss: 0.014.. \n",
      "Epoch: 484/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 485/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 486/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 487/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 488/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 489/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 490/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 491/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 492/500..  Training Loss: 0.016..  Test Loss: 0.018.. \n",
      "Epoch: 493/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 494/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 495/500..  Training Loss: 0.016..  Test Loss: 0.019.. \n",
      "Epoch: 496/500..  Training Loss: 0.016..  Test Loss: 0.013.. \n",
      "Epoch: 497/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 498/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 499/500..  Training Loss: 0.016..  Test Loss: 0.015.. \n",
      "Epoch: 500/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 3\n",
      "Epoch: 1/500..  Training Loss: 0.051..  Test Loss: 0.017.. \n",
      "Epoch: 2/500..  Training Loss: 0.033..  Test Loss: 0.015.. \n",
      "Epoch: 3/500..  Training Loss: 0.032..  Test Loss: 0.017.. \n",
      "Epoch: 4/500..  Training Loss: 0.022..  Test Loss: 0.019.. \n",
      "Epoch: 5/500..  Training Loss: 0.022..  Test Loss: 0.019.. \n",
      "Epoch: 6/500..  Training Loss: 0.021..  Test Loss: 0.018.. \n",
      "Epoch: 7/500..  Training Loss: 0.019..  Test Loss: 0.016.. \n",
      "Epoch: 8/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 9/500..  Training Loss: 0.018..  Test Loss: 0.028.. \n",
      "Epoch: 10/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 11/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 12/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 13/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 14/500..  Training Loss: 0.015..  Test Loss: 0.020.. \n",
      "Epoch: 15/500..  Training Loss: 0.016..  Test Loss: 0.016.. \n",
      "Epoch: 16/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 17/500..  Training Loss: 0.016..  Test Loss: 0.017.. \n",
      "Epoch: 18/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 19/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 20/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 21/500..  Training Loss: 0.016..  Test Loss: 0.022.. \n",
      "Epoch: 22/500..  Training Loss: 0.015..  Test Loss: 0.024.. \n",
      "Epoch: 23/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 24/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 25/500..  Training Loss: 0.015..  Test Loss: 0.016.. \n",
      "Epoch: 26/500..  Training Loss: 0.015..  Test Loss: 0.019.. \n",
      "Epoch: 27/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 28/500..  Training Loss: 0.014..  Test Loss: 0.019.. \n",
      "Epoch: 29/500..  Training Loss: 0.015..  Test Loss: 0.019.. \n",
      "Epoch: 30/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 31/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 32/500..  Training Loss: 0.015..  Test Loss: 0.017.. \n",
      "Epoch: 33/500..  Training Loss: 0.014..  Test Loss: 0.018.. \n",
      "Epoch: 34/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 35/500..  Training Loss: 0.014..  Test Loss: 0.015.. \n",
      "Epoch: 36/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 37/500..  Training Loss: 0.014..  Test Loss: 0.016.. \n",
      "Epoch: 38/500..  Training Loss: 0.015..  Test Loss: 0.018.. \n",
      "Epoch: 39/500..  Training Loss: 0.014..  Test Loss: 0.018.. \n",
      "Epoch: 40/500..  Training Loss: 0.013..  Test Loss: 0.019.. \n",
      "Epoch: 41/500..  Training Loss: 0.014..  Test Loss: 0.020.. \n",
      "Epoch: 42/500..  Training Loss: 0.014..  Test Loss: 0.021.. \n",
      "Epoch: 43/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 44/500..  Training Loss: 0.013..  Test Loss: 0.016.. \n",
      "Epoch: 45/500..  Training Loss: 0.014..  Test Loss: 0.021.. \n",
      "Epoch: 46/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 47/500..  Training Loss: 0.013..  Test Loss: 0.018.. \n",
      "Epoch: 48/500..  Training Loss: 0.013..  Test Loss: 0.021.. \n",
      "Epoch: 49/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 50/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 51/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 52/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 53/500..  Training Loss: 0.014..  Test Loss: 0.017.. \n",
      "Epoch: 54/500..  Training Loss: 0.013..  Test Loss: 0.017.. \n",
      "Epoch: 55/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 56/500..  Training Loss: 0.012..  Test Loss: 0.017.. \n",
      "Epoch: 57/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 58/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 59/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 60/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 61/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 62/500..  Training Loss: 0.013..  Test Loss: 0.013.. \n",
      "Epoch: 63/500..  Training Loss: 0.012..  Test Loss: 0.013.. \n",
      "Epoch: 64/500..  Training Loss: 0.012..  Test Loss: 0.022.. \n",
      "Epoch: 65/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 66/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 67/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 68/500..  Training Loss: 0.013..  Test Loss: 0.026.. \n",
      "Epoch: 69/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 70/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 71/500..  Training Loss: 0.013..  Test Loss: 0.020.. \n",
      "Epoch: 72/500..  Training Loss: 0.012..  Test Loss: 0.019.. \n",
      "Epoch: 73/500..  Training Loss: 0.012..  Test Loss: 0.013.. \n",
      "Epoch: 74/500..  Training Loss: 0.012..  Test Loss: 0.017.. \n",
      "Epoch: 75/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 76/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 77/500..  Training Loss: 0.012..  Test Loss: 0.017.. \n",
      "Epoch: 78/500..  Training Loss: 0.013..  Test Loss: 0.014.. \n",
      "Epoch: 79/500..  Training Loss: 0.012..  Test Loss: 0.016.. \n",
      "Epoch: 80/500..  Training Loss: 0.013..  Test Loss: 0.021.. \n",
      "Epoch: 81/500..  Training Loss: 0.012..  Test Loss: 0.013.. \n",
      "Epoch: 82/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 83/500..  Training Loss: 0.013..  Test Loss: 0.018.. \n",
      "Epoch: 84/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 85/500..  Training Loss: 0.012..  Test Loss: 0.012.. \n",
      "Epoch: 86/500..  Training Loss: 0.012..  Test Loss: 0.013.. \n",
      "Epoch: 87/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 88/500..  Training Loss: 0.012..  Test Loss: 0.016.. \n",
      "Epoch: 89/500..  Training Loss: 0.013..  Test Loss: 0.015.. \n",
      "Epoch: 90/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 91/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 92/500..  Training Loss: 0.012..  Test Loss: 0.017.. \n",
      "Epoch: 93/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 94/500..  Training Loss: 0.012..  Test Loss: 0.013.. \n",
      "Epoch: 95/500..  Training Loss: 0.012..  Test Loss: 0.014.. \n",
      "Epoch: 96/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 97/500..  Training Loss: 0.012..  Test Loss: 0.016.. \n",
      "Epoch: 98/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 99/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 100/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 101/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 102/500..  Training Loss: 0.012..  Test Loss: 0.018.. \n",
      "Epoch: 103/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 104/500..  Training Loss: 0.012..  Test Loss: 0.020.. \n",
      "Epoch: 105/500..  Training Loss: 0.011..  Test Loss: 0.020.. \n",
      "Epoch: 106/500..  Training Loss: 0.012..  Test Loss: 0.017.. \n",
      "Epoch: 107/500..  Training Loss: 0.011..  Test Loss: 0.019.. \n",
      "Epoch: 108/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 109/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 110/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 111/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 112/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 113/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 114/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 115/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 116/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 117/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 118/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 119/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 120/500..  Training Loss: 0.011..  Test Loss: 0.019.. \n",
      "Epoch: 121/500..  Training Loss: 0.012..  Test Loss: 0.014.. \n",
      "Epoch: 122/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 123/500..  Training Loss: 0.012..  Test Loss: 0.015.. \n",
      "Epoch: 124/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 125/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 126/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 127/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 128/500..  Training Loss: 0.012..  Test Loss: 0.016.. \n",
      "Epoch: 129/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 130/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 131/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 132/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 133/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 134/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 135/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 137/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 138/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 139/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 140/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 141/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 142/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 143/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 144/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 145/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 146/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 147/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 148/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 149/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 150/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 151/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 152/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 153/500..  Training Loss: 0.011..  Test Loss: 0.019.. \n",
      "Epoch: 154/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 155/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 156/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 157/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 158/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 159/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 160/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 161/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 162/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 163/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 164/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 165/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 166/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 167/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 168/500..  Training Loss: 0.011..  Test Loss: 0.019.. \n",
      "Epoch: 169/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 170/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 171/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 172/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 173/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 174/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 175/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 176/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 177/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 178/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 179/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 180/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 181/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 182/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 183/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 184/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 185/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 186/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 187/500..  Training Loss: 0.011..  Test Loss: 0.019.. \n",
      "Epoch: 188/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 189/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 190/500..  Training Loss: 0.011..  Test Loss: 0.019.. \n",
      "Epoch: 191/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 192/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 193/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 194/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 195/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 196/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 197/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 198/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 199/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 200/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 201/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 202/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 203/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 204/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 205/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 206/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 207/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 208/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 209/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 210/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 211/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 212/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 213/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 214/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 215/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 216/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 217/500..  Training Loss: 0.011..  Test Loss: 0.020.. \n",
      "Epoch: 218/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 219/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 220/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 221/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 222/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 223/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 224/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 225/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 226/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 227/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 228/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 229/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 230/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 231/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 232/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 233/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 234/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 235/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 236/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 237/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 238/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 239/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 240/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 241/500..  Training Loss: 0.010..  Test Loss: 0.024.. \n",
      "Epoch: 242/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 243/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 244/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 245/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 246/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 247/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 248/500..  Training Loss: 0.010..  Test Loss: 0.012.. \n",
      "Epoch: 249/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 250/500..  Training Loss: 0.011..  Test Loss: 0.018.. \n",
      "Epoch: 251/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 252/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 253/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 254/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 255/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 256/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 257/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 258/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 259/500..  Training Loss: 0.011..  Test Loss: 0.019.. \n",
      "Epoch: 260/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 261/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 262/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 263/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 264/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 265/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 266/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 267/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 268/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 269/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 271/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 272/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 273/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 274/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 275/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 276/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n",
      "Epoch: 277/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 278/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 279/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 280/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 281/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 282/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 283/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 284/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 285/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 286/500..  Training Loss: 0.010..  Test Loss: 0.023.. \n",
      "Epoch: 287/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 288/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 289/500..  Training Loss: 0.009..  Test Loss: 0.013.. \n",
      "Epoch: 290/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 291/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 292/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 293/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 294/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 295/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 296/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 297/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 298/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 299/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 300/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 301/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 302/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 303/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 304/500..  Training Loss: 0.009..  Test Loss: 0.017.. \n",
      "Epoch: 305/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 306/500..  Training Loss: 0.009..  Test Loss: 0.017.. \n",
      "Epoch: 307/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 308/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 309/500..  Training Loss: 0.009..  Test Loss: 0.017.. \n",
      "Epoch: 310/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 311/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 312/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 313/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 314/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 315/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 316/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 317/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 318/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 319/500..  Training Loss: 0.010..  Test Loss: 0.022.. \n",
      "Epoch: 320/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 321/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 322/500..  Training Loss: 0.009..  Test Loss: 0.020.. \n",
      "Epoch: 323/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 324/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 325/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 326/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 327/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 328/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 329/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 330/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 331/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 332/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 333/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 334/500..  Training Loss: 0.009..  Test Loss: 0.021.. \n",
      "Epoch: 335/500..  Training Loss: 0.009..  Test Loss: 0.017.. \n",
      "Epoch: 336/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 337/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 338/500..  Training Loss: 0.009..  Test Loss: 0.019.. \n",
      "Epoch: 339/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 340/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n",
      "Epoch: 341/500..  Training Loss: 0.009..  Test Loss: 0.016.. \n",
      "Epoch: 342/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 343/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 344/500..  Training Loss: 0.009..  Test Loss: 0.014.. \n",
      "Epoch: 345/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n",
      "Epoch: 346/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 347/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 348/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 349/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n",
      "Epoch: 350/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 351/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 352/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 353/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 354/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 355/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 356/500..  Training Loss: 0.009..  Test Loss: 0.019.. \n",
      "Epoch: 357/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 358/500..  Training Loss: 0.009..  Test Loss: 0.021.. \n",
      "Epoch: 359/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 360/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 361/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 362/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 363/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 364/500..  Training Loss: 0.010..  Test Loss: 0.023.. \n",
      "Epoch: 365/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 366/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 367/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 368/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 369/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 370/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 371/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 372/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 373/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 374/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 375/500..  Training Loss: 0.010..  Test Loss: 0.022.. \n",
      "Epoch: 376/500..  Training Loss: 0.009..  Test Loss: 0.014.. \n",
      "Epoch: 377/500..  Training Loss: 0.009..  Test Loss: 0.016.. \n",
      "Epoch: 378/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 379/500..  Training Loss: 0.009..  Test Loss: 0.014.. \n",
      "Epoch: 380/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 381/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 382/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 383/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 384/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 385/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 386/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 387/500..  Training Loss: 0.009..  Test Loss: 0.016.. \n",
      "Epoch: 388/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 389/500..  Training Loss: 0.010..  Test Loss: 0.023.. \n",
      "Epoch: 390/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 391/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 392/500..  Training Loss: 0.009..  Test Loss: 0.019.. \n",
      "Epoch: 393/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 394/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 395/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 396/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 397/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 398/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 399/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 400/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 401/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 402/500..  Training Loss: 0.009..  Test Loss: 0.016.. \n",
      "Epoch: 403/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 404/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 405/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 406/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 407/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 408/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 409/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 410/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 411/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 412/500..  Training Loss: 0.009..  Test Loss: 0.022.. \n",
      "Epoch: 413/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 414/500..  Training Loss: 0.011..  Test Loss: 0.013.. \n",
      "Epoch: 415/500..  Training Loss: 0.009..  Test Loss: 0.016.. \n",
      "Epoch: 416/500..  Training Loss: 0.009..  Test Loss: 0.017.. \n",
      "Epoch: 417/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 418/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 419/500..  Training Loss: 0.011..  Test Loss: 0.017.. \n",
      "Epoch: 420/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 421/500..  Training Loss: 0.009..  Test Loss: 0.014.. \n",
      "Epoch: 422/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 423/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 424/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 425/500..  Training Loss: 0.009..  Test Loss: 0.014.. \n",
      "Epoch: 426/500..  Training Loss: 0.009..  Test Loss: 0.019.. \n",
      "Epoch: 427/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 428/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 429/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 430/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 431/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 432/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 433/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 434/500..  Training Loss: 0.009..  Test Loss: 0.013.. \n",
      "Epoch: 435/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 436/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 437/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 438/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n",
      "Epoch: 439/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 440/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 441/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 442/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 443/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 444/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 445/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 446/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 447/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 448/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 449/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 450/500..  Training Loss: 0.010..  Test Loss: 0.013.. \n",
      "Epoch: 451/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 452/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 453/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n",
      "Epoch: 454/500..  Training Loss: 0.009..  Test Loss: 0.016.. \n",
      "Epoch: 455/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 456/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 457/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 458/500..  Training Loss: 0.010..  Test Loss: 0.021.. \n",
      "Epoch: 459/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 460/500..  Training Loss: 0.009..  Test Loss: 0.016.. \n",
      "Epoch: 461/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 462/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 463/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 464/500..  Training Loss: 0.009..  Test Loss: 0.017.. \n",
      "Epoch: 465/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 466/500..  Training Loss: 0.009..  Test Loss: 0.014.. \n",
      "Epoch: 467/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 468/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 469/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 470/500..  Training Loss: 0.009..  Test Loss: 0.020.. \n",
      "Epoch: 471/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 472/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 473/500..  Training Loss: 0.011..  Test Loss: 0.015.. \n",
      "Epoch: 474/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 475/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 476/500..  Training Loss: 0.009..  Test Loss: 0.019.. \n",
      "Epoch: 477/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 478/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 479/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 480/500..  Training Loss: 0.011..  Test Loss: 0.016.. \n",
      "Epoch: 481/500..  Training Loss: 0.010..  Test Loss: 0.016.. \n",
      "Epoch: 482/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 483/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 484/500..  Training Loss: 0.010..  Test Loss: 0.014.. \n",
      "Epoch: 485/500..  Training Loss: 0.010..  Test Loss: 0.017.. \n",
      "Epoch: 486/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 487/500..  Training Loss: 0.009..  Test Loss: 0.019.. \n",
      "Epoch: 488/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 489/500..  Training Loss: 0.009..  Test Loss: 0.018.. \n",
      "Epoch: 490/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 491/500..  Training Loss: 0.010..  Test Loss: 0.015.. \n",
      "Epoch: 492/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 493/500..  Training Loss: 0.009..  Test Loss: 0.015.. \n",
      "Epoch: 494/500..  Training Loss: 0.011..  Test Loss: 0.014.. \n",
      "Epoch: 495/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n",
      "Epoch: 496/500..  Training Loss: 0.010..  Test Loss: 0.019.. \n",
      "Epoch: 497/500..  Training Loss: 0.009..  Test Loss: 0.020.. \n",
      "Epoch: 498/500..  Training Loss: 0.010..  Test Loss: 0.020.. \n",
      "Epoch: 499/500..  Training Loss: 0.008..  Test Loss: 0.022.. \n",
      "Epoch: 500/500..  Training Loss: 0.010..  Test Loss: 0.018.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 4\n",
      "Epoch: 1/500..  Training Loss: 0.495..  Test Loss: 0.337.. \n",
      "Epoch: 2/500..  Training Loss: 0.372..  Test Loss: 0.283.. \n",
      "Epoch: 3/500..  Training Loss: 0.260..  Test Loss: 0.206.. \n",
      "Epoch: 4/500..  Training Loss: 0.220..  Test Loss: 0.179.. \n",
      "Epoch: 5/500..  Training Loss: 0.170..  Test Loss: 0.143.. \n",
      "Epoch: 6/500..  Training Loss: 0.141..  Test Loss: 0.129.. \n",
      "Epoch: 7/500..  Training Loss: 0.155..  Test Loss: 0.107.. \n",
      "Epoch: 8/500..  Training Loss: 0.110..  Test Loss: 0.093.. \n",
      "Epoch: 9/500..  Training Loss: 0.086..  Test Loss: 0.089.. \n",
      "Epoch: 10/500..  Training Loss: 0.072..  Test Loss: 0.085.. \n",
      "Epoch: 11/500..  Training Loss: 0.068..  Test Loss: 0.073.. \n",
      "Epoch: 12/500..  Training Loss: 0.059..  Test Loss: 0.061.. \n",
      "Epoch: 13/500..  Training Loss: 0.050..  Test Loss: 0.056.. \n",
      "Epoch: 14/500..  Training Loss: 0.045..  Test Loss: 0.048.. \n",
      "Epoch: 15/500..  Training Loss: 0.041..  Test Loss: 0.046.. \n",
      "Epoch: 16/500..  Training Loss: 0.037..  Test Loss: 0.036.. \n",
      "Epoch: 17/500..  Training Loss: 0.033..  Test Loss: 0.032.. \n",
      "Epoch: 18/500..  Training Loss: 0.033..  Test Loss: 0.035.. \n",
      "Epoch: 19/500..  Training Loss: 0.029..  Test Loss: 0.028.. \n",
      "Epoch: 20/500..  Training Loss: 0.027..  Test Loss: 0.028.. \n",
      "Epoch: 21/500..  Training Loss: 0.025..  Test Loss: 0.026.. \n",
      "Epoch: 22/500..  Training Loss: 0.023..  Test Loss: 0.027.. \n",
      "Epoch: 23/500..  Training Loss: 0.023..  Test Loss: 0.022.. \n",
      "Epoch: 24/500..  Training Loss: 0.021..  Test Loss: 0.026.. \n",
      "Epoch: 25/500..  Training Loss: 0.021..  Test Loss: 0.019.. \n",
      "Epoch: 26/500..  Training Loss: 0.020..  Test Loss: 0.023.. \n",
      "Epoch: 27/500..  Training Loss: 0.025..  Test Loss: 0.019.. \n",
      "Epoch: 28/500..  Training Loss: 0.020..  Test Loss: 0.022.. \n",
      "Epoch: 29/500..  Training Loss: 0.019..  Test Loss: 0.025.. \n",
      "Epoch: 30/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 31/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 32/500..  Training Loss: 0.018..  Test Loss: 0.019.. \n",
      "Epoch: 33/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 34/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 35/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 36/500..  Training Loss: 0.018..  Test Loss: 0.020.. \n",
      "Epoch: 37/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 38/500..  Training Loss: 0.018..  Test Loss: 0.020.. \n",
      "Epoch: 39/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 40/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 41/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 42/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 43/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 44/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 45/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 46/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 47/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 48/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 49/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 50/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 51/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 52/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 53/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 54/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 55/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 56/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 57/500..  Training Loss: 0.018..  Test Loss: 0.017.. \n",
      "Epoch: 58/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 59/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 60/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 61/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 62/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 63/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 64/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 65/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 66/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 67/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 68/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 69/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 70/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 71/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 72/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 73/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 74/500..  Training Loss: 0.017..  Test Loss: 0.013.. \n",
      "Epoch: 75/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 76/500..  Training Loss: 0.018..  Test Loss: 0.018.. \n",
      "Epoch: 77/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 78/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 79/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 80/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 81/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 82/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 83/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 84/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 85/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 86/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 87/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 88/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 89/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 90/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 91/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 92/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 93/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 94/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 95/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 96/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 97/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 98/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 99/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 100/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 101/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 102/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 103/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 104/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 105/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 106/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 107/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 108/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 109/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 110/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 111/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 112/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 113/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 114/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 115/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 116/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 117/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 118/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 119/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 120/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 121/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 122/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 123/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 124/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 125/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 126/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 127/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 128/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 129/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 130/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 131/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 132/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 133/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 134/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 136/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 137/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 138/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 139/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 140/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 141/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 142/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 143/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 144/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 145/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 146/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 147/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 148/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 149/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 150/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 151/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 152/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 153/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 154/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 155/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 156/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 157/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 158/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 159/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 160/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 161/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 162/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 163/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 164/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 165/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 166/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 167/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 168/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 169/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 170/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 171/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 172/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 173/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 174/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 175/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 176/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 177/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 178/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 179/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 180/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 181/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 182/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 183/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 184/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 185/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 186/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 187/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 188/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 189/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 190/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 191/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 192/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 193/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 194/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 195/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 196/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 197/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 198/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 199/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 200/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 201/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 202/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 203/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 204/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 205/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 206/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 207/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 208/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 209/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 210/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 211/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 212/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 213/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 214/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 215/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 216/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 217/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 218/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 219/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 220/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 221/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 222/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 223/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 224/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 225/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 226/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 227/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 228/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 229/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 230/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 231/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 232/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 233/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 234/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 235/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 236/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 237/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 238/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 239/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 240/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 241/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 242/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 243/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 244/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 245/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 246/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 247/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 248/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 249/500..  Training Loss: 0.018..  Test Loss: 0.016.. \n",
      "Epoch: 250/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 251/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 252/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 253/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 254/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 255/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 256/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 257/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 258/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 259/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 260/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 261/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 262/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 263/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 264/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 265/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 266/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 267/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 268/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 269/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 270/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 271/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 272/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 273/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 274/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 275/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 276/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 277/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 278/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 279/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 280/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 281/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 282/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 283/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 284/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 285/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 286/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 287/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 288/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 289/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 290/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 291/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 292/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 293/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 294/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 295/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 296/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 297/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 298/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 299/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 300/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 301/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 302/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 303/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 304/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 305/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 306/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 307/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 308/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 309/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 310/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 311/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 312/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 313/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 314/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 315/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 316/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 317/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 318/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 319/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 320/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 321/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 322/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 323/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 324/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 325/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 326/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 327/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 328/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 329/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 330/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 331/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 332/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 333/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 334/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 335/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 336/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 337/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 338/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 339/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 340/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 341/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 342/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 343/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 344/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 345/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 346/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 347/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 348/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 349/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 350/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 351/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 352/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 353/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 354/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 355/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 356/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 357/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 358/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 359/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 360/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 361/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 362/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 363/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 364/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 365/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 366/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 367/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 368/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 369/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 370/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 371/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 372/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 373/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 374/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 375/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 376/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 377/500..  Training Loss: 0.018..  Test Loss: 0.014.. \n",
      "Epoch: 378/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 379/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 380/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 381/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 382/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 383/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 384/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 385/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 386/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 387/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 388/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 389/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 390/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 391/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 392/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 393/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 394/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 395/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 396/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 397/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 398/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 399/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 400/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 401/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 402/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 403/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 404/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 405/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 406/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 407/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 408/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 409/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 410/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 411/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 412/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 413/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 414/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 415/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 416/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 417/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 418/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 419/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 420/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 421/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 422/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 423/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 424/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 425/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 426/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 427/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 428/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 429/500..  Training Loss: 0.017..  Test Loss: 0.013.. \n",
      "Epoch: 430/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 431/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 432/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 433/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 434/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 435/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 436/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 437/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 438/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 439/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 440/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 441/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 442/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 443/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 444/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 445/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 446/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 447/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 448/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 449/500..  Training Loss: 0.017..  Test Loss: 0.021.. \n",
      "Epoch: 450/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 451/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 452/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 453/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 454/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 455/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 456/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 457/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 458/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 459/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 460/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 461/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 462/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 463/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 464/500..  Training Loss: 0.017..  Test Loss: 0.020.. \n",
      "Epoch: 465/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 466/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 467/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 468/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 469/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 470/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 471/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 472/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 473/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 474/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 475/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 476/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 477/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 478/500..  Training Loss: 0.017..  Test Loss: 0.019.. \n",
      "Epoch: 479/500..  Training Loss: 0.017..  Test Loss: 0.018.. \n",
      "Epoch: 480/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 481/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 482/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 483/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 484/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 485/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 486/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 487/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 488/500..  Training Loss: 0.017..  Test Loss: 0.014.. \n",
      "Epoch: 489/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 490/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 491/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 492/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n",
      "Epoch: 493/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 494/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 495/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 496/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 497/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 498/500..  Training Loss: 0.017..  Test Loss: 0.017.. \n",
      "Epoch: 499/500..  Training Loss: 0.017..  Test Loss: 0.016.. \n",
      "Epoch: 500/500..  Training Loss: 0.017..  Test Loss: 0.015.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv = cv.split(X_train_scaled, y_train_scaled)\n",
    "\n",
    "m_hidden_layers = 10\n",
    "\n",
    "n_input = 6\n",
    "n_hidden = 4\n",
    "n_output = 1\n",
    "\n",
    "bs = 256\n",
    "device = \"cuda:0\"\n",
    "epochs = 500\n",
    "\n",
    "network_type = \"regression\"\n",
    "\n",
    "regressors = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "    print(\"Model for Fold: \" + str(fold))\n",
    "\n",
    "    train_set, train_labels = X_train_scaled[train_idx], y_train_scaled[train_idx]\n",
    "    valid_set, valid_labels = X_train_scaled[val_idx], y_train_scaled[val_idx]\n",
    "    \n",
    "    trainset = HousePriceDataset(train_set, train_labels)\n",
    "    trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    validset = HousePriceDataset(valid_set, valid_labels)\n",
    "    validloader = DataLoader(validset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    regressor = NeuralNetwork(m_hidden_layers, n_input, n_hidden, n_output, network_type).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion_2 = RMSLELoss\n",
    "    optimizer = optim.Adam(regressor.parameters(), lr = 0.003)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        for features, labels in trainloader:\n",
    "\n",
    "            regressor.train()\n",
    "\n",
    "            features = features.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = regressor(features.float())\n",
    "\n",
    "            loss = criterion(output, labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for features, labels in validloader:\n",
    "                    regressor.eval()\n",
    "\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    output = regressor(features.float())\n",
    "\n",
    "                    test_loss += criterion(output, labels)\n",
    "\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(validloader)))\n",
    "            \n",
    "        \n",
    "        \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets see predictions\n",
      "[ 84137.8    94764.68   91239.1    83861.56   84068.85   87937.305\n",
      "  84173.484  99618.8    84058.19   97120.805  84870.62  102794.19\n",
      "  94315.62   98489.08   84943.54   96062.95  103825.86  104198.016\n",
      " 100936.516  84090.5    94301.1    95313.34   84361.17   97668.48\n",
      "  88891.37   83982.484  84348.95   94439.04   91063.21   90551.305\n",
      "  84999.234  83950.55   96218.445  84908.59   94559.02   85162.12\n",
      "  94373.87   84552.31   84155.09   90709.93   85056.875  96730.36\n",
      "  84182.62   84096.055  91246.86   91271.22   90558.836  84706.516\n",
      "  94563.16  100485.31   94249.03   94359.91   94695.2    84289.08\n",
      "  94755.08   94525.83   84346.43   84108.125  84939.23   88058.91\n",
      "  84271.63   95771.47   90762.94   84847.28   84254.46   97727.69\n",
      "  94349.37   97817.086  84099.9   101920.836  97636.48   95966.734\n",
      "  85493.74   96766.69   91155.086  96249.93   94732.086  83963.68\n",
      "  91078.336  94144.16   84690.92   84160.11   94006.88   88019.234\n",
      "  94479.93   85438.62   99937.24   98159.766  84149.52   97289.66\n",
      "  84737.07   84431.87   94778.5    88057.35   84247.33   98006.84\n",
      "  99593.48   94329.336  94211.93   84462.18   94308.99  103054.16\n",
      " 109441.18   94259.82  107362.234  99605.37   93193.086  85078.96\n",
      "  94323.734  83959.78   87918.266  87939.305  84433.     84185.195\n",
      "  94230.4    84648.13   89021.24  104040.69   94137.27   84213.72\n",
      "  94072.44   97326.03   87913.51   97645.99   84392.49   84259.83\n",
      "  94645.59   94823.5    91728.13   84430.98   94287.914  94141.555\n",
      "  84026.31   94366.04   95609.67   98020.96   94899.84   94231.96\n",
      "  97600.33   84784.03   84474.85   85309.86   97877.61   94215.75\n",
      "  84238.06   94541.18   84205.95   95646.07   94276.39   91976.1\n",
      " 105585.51   98271.016  94404.48   84272.52   94838.38   94216.73\n",
      "  83997.85  101394.086  94377.99   94925.82   95701.6   106503.29\n",
      "  84265.65   96551.12   84616.49   85442.14   87948.05   92407.64\n",
      "  84048.38   94110.57   87915.59   87942.55   84850.83   84433.94\n",
      "  94105.88   95044.56   94601.195  95661.266  93845.91   90912.055\n",
      "  91213.27   84646.05   90490.914  90522.266  94268.57   84256.3\n",
      "  84338.82   84334.53   83995.805  98392.66  106915.9    96722.5\n",
      " 101710.59   96430.79   83895.     85245.18   96093.79  103536.63\n",
      "  84977.18  104359.81   94572.164  85452.95   84538.4    97663.32\n",
      "  85399.54   84182.98   84294.34   97167.414  95277.4    86509.89\n",
      "  84041.65   94516.92  102320.66   84333.695  96585.74   87974.29\n",
      "  98571.61   84236.41   94061.89   98258.7    94141.71   94401.445\n",
      "  84206.85   91246.02  100479.58   84842.12   94300.875  83999.75\n",
      "  84151.66  100288.76   84322.164  94152.19   83538.14   87981.45\n",
      "  94636.42   94593.86   94323.89   88089.61   94103.38   94238.94\n",
      "  89367.03   88158.95  102935.59   85380.97   94222.23   98384.695\n",
      "  88008.76   90869.86   96065.7    94756.14   84144.86   94437.72\n",
      "  85040.95   84953.336 101710.59   94332.61   85943.734  84551.46\n",
      "  92142.85   84546.31   91173.22   95235.27   84240.74   94412.945\n",
      "  84734.77   84183.586  98857.35   98881.63   87937.51   87910.36\n",
      "  94574.03   87915.28   91084.98   90410.51   94398.86   84938.22\n",
      "  84331.08   90490.46   94410.195  99196.39   94795.13   91200.34\n",
      "  84909.92   94820.01   95683.555  94238.52   94410.72   84269.56\n",
      "  84614.445  87959.266  84220.47   85305.87   84440.58   91140.01\n",
      " 100153.46   94777.266  95494.4    94281.21  102063.85   88083.96\n",
      "  84933.49   87971.1    88008.76   84039.27   84520.04   84226.61\n",
      "  92927.79   83875.5    84826.58   94434.03   87915.29   90082.26\n",
      "  91491.51   94357.21   98411.09   99834.4    94109.9    94767.61\n",
      "  84509.01   84455.336  91120.96   96986.484  90406.484  84163.586\n",
      "  83968.836  97153.31   87925.54   94395.09  103421.27   87991.805\n",
      "  99644.55   88236.01   94338.78   91165.03   94101.73   94300.875\n",
      "  98862.96   83977.5    95702.11   84417.445  87942.12   91066.99\n",
      "  97583.13   94090.44   94250.59   94570.99   84190.58   84191.39\n",
      "  94815.516  84331.08   84405.055 114534.305  94637.72   85007.984\n",
      "  88010.84   87939.26   84200.266  84139.43   93845.91   87472.766\n",
      "  91109.83   84183.83   87959.3    91907.85   94101.42  102346.\n",
      "  98875.39  101251.31   91419.625  94537.17   85094.76   87937.51\n",
      "  84024.99   95697.67   84001.836  84174.91   95593.375  94254.31\n",
      "  94553.87   98796.37   84330.88   84168.68   95086.97   94098.625\n",
      "  94130.52   99102.97   98563.98   94227.64  101149.94   85271.54\n",
      "  84131.64   84288.305  94844.15   92430.65   96930.805  99881.26\n",
      "  94134.77   84859.586  91665.21   83965.65   97070.41   84944.55\n",
      "  84185.33   84090.5    94676.26   85238.93  101249.03   84794.74\n",
      "  97644.     84061.67   84582.836  94802.25   91575.8    87909.45\n",
      "  96627.086  95748.73   91363.09   94353.16  101921.1    87913.74\n",
      "  83836.67   83822.836  96570.74   84033.28   87915.29   87986.55\n",
      "  91197.34   94837.88   87937.016  84068.625  94482.984  94422.31\n",
      "  93605.38   90516.945  94357.21   85354.53   83974.86   84233.73\n",
      "  97426.37   96662.24   90345.33  107436.42   98479.26   87959.21\n",
      "  94999.58   84115.38   99346.52   97368.73   85064.664  85081.37\n",
      "  84189.98   94728.58   94519.42   83784.15   95268.76   84996.99\n",
      "  91141.055 101367.055  97606.1    91249.55   87965.336  94158.53\n",
      "  84039.03   85177.664  84298.66   94574.03   87955.4    96659.64\n",
      "  94140.125 106122.59   84093.34   84118.92   94094.37  100215.305\n",
      "  94389.64   95023.1    96286.83   95819.76   94542.16   94105.02\n",
      "  98811.47  101589.734  87912.28   96936.65   91259.086  97562.195\n",
      "  84229.69   84195.54   94355.234  94304.16   84977.945  94728.58\n",
      "  95723.664  87972.93   94346.055  84097.92   94548.414  83532.125\n",
      "  94624.99   94105.11   84795.74   87992.81   92517.84   84928.77\n",
      "  98385.81   84253.945  84289.08   84671.71   95306.43   94697.46\n",
      "  97477.66   94258.19   94222.766  94826.43   99855.086 100137.77\n",
      "  85186.88   94392.14   97982.78   84154.59   96386.37   96220.52\n",
      " 105110.46  100548.81   84318.97  104038.125 101988.75   94906.71\n",
      "  84478.84   89367.03   94693.09   84160.125  94310.23   97819.83\n",
      "  85078.77   91759.46   95248.48   84089.02   94612.71   94518.09\n",
      "  84452.27   84718.9    89367.03   87959.2    87919.25   90008.98\n",
      "  94361.75  100482.26   94518.09   95576.86   98731.87   83593.12\n",
      "  84354.49   94581.6    92310.414  87916.19   94353.164  91777.79\n",
      "  94630.695  99073.36   94875.51   87909.266  84171.84   84501.74\n",
      " 107867.414  99546.89   94552.36   94847.555  83849.45   94645.95\n",
      "  84642.72   88137.05   84252.87   84615.9   103199.16   94288.19\n",
      "  94449.21   84291.41   83569.27   84307.23   98548.766  94234.016\n",
      "  94318.53   83954.57   95484.7    91295.46   94597.01   94794.98\n",
      "  83875.5    94115.79   84707.734 104139.88   83821.586  91292.375\n",
      "  87915.195  95205.61   84056.5    84197.6    91138.25   94130.52\n",
      "  98589.664  84130.49   91055.914  87937.1    97318.6    98864.56\n",
      "  84428.36   98666.86   97004.33   99103.94   94320.484  84796.03\n",
      "  87949.83   94387.49   95569.65   87933.86   87915.8    83613.414\n",
      "  94372.66   84118.39   91728.13   84938.22   97949.016  84122.58\n",
      "  94582.05   84352.336  94454.35   90715.445  84135.85   94432.94\n",
      "  84612.336 100382.83   84299.914  98276.65   98811.85   91174.25\n",
      "  87939.04   98717.74  111754.49   84196.36   94353.85   94113.63\n",
      "  84461.17   94752.73   84561.92   94203.44   94443.31   83937.84\n",
      "  91497.89   84291.12   94100.53  102146.984  87927.66   94940.99\n",
      "  98778.77   99184.34   91204.83   83886.05   84844.984  87939.23\n",
      "  84677.61   87995.53   95833.38   94124.76   94086.44   98760.98\n",
      " 105299.42   86223.79   94440.59   94297.2    87935.2    84160.17\n",
      "  87925.72   87930.16   94994.71   94530.09   88029.28   94281.21\n",
      "  93962.266  99012.5    94389.234  94316.78   94331.32   95194.77\n",
      "  84443.18  122870.76   94533.2    84105.414  94369.84  103039.59\n",
      "  84377.13   94085.83   83445.516  94937.56   84306.39   84001.96\n",
      "  94127.02   91091.695  83855.586  90762.48   98258.7    94986.31\n",
      " 101713.414  96670.15   84735.25   88097.73 ]\n",
      "[ 50500  94666 103500  34500  45505  74000  43650 185000  35500 113900\n",
      "  75500 445000  65000  90000  55000 145000 325000 305000 144000  57500\n",
      " 105574 127500  33860 124000  47000  45000  52000  85483  79500  53610\n",
      "  60500  40000 160000  64457  80000  82900 105000  72000  80000  73000\n",
      "  73500 160000  54000  40000  79000  80950  69850  69000  76934 289000\n",
      "  76500  85000 149000  46650 170000  74000  57500  62000  37764  84990\n",
      "  56300 120086  46750  74000  55800 126000  83000  85619  57700 280000\n",
      " 119000  94000  49000 179000 125000  79000 147000  32850  66300 124000\n",
      "  52900  34900  95000  55075  65700  56900 255000 150000  35000  89000\n",
      "  50500  54000 125000  55000  55000 139900 180000  83500 110000  75000\n",
      "  78600 300000 329000 118000 299000 180000  61500  64300  66999  54900\n",
      "  63000  54900  82000  60999  78599  50500  94500 240000  56953  49900\n",
      "  68240  81383  62900 218000  46500  53010  75000  95000  73715  80688\n",
      " 125000 145000  40272 130000 112000 130252 142000 100700 119000  71850\n",
      "  93000  32000 138000  91900  29900 123043  44000  73715 120000  65500\n",
      " 181500 209000  82375  49400  53900 113000  75900 270000  66414  68500\n",
      " 114750 275000  38500 139000  48999  39600  73000  59500  48900  77900\n",
      "  86000  52500 105000  75000  82000 135000 115000  89953 119000  45400\n",
      "  78500  53500  61020  76100  85000  83000  59950  45700  69000 100000\n",
      " 375000 152285 199000  83000  38000  45000 120000 390000  76000 435000\n",
      " 109440  33700  63900 169000  41000  57900  58000 152976 129508  53010\n",
      "  63000 123500 190000  56000 133820  64600 149000  51040  48500 157510\n",
      "  56953  81257  46900  61000 250000  48000 101500  34900  59800 229900\n",
      "  58999  82000  36190  86227 117000 110000 103000  78900  70500  78900\n",
      " 125000 101000 149000  45000 112000 128000  95000  61000 125500 179000\n",
      "  68500 136000  73000  79500 199000  74000  59900  49600  79900  55100\n",
      "  67500 125000  76500  90600  61000  44010 169000 196970  57000  59800\n",
      "  83800 125000  74500  69900  89000  48100  59000  59500  65000 219000\n",
      " 144000  73900  65000 189000 123219  73715 129000  42500  54900  50990\n",
      "  52600  23500  39000 101900 230000 132000  72760  77500 205000  75000\n",
      "  64000  63900  95000  56000  56953  57500  92200  52000  72000  79080\n",
      "  69900  87000  80000  90000 113900 174839  61500 126000  56500  68500\n",
      "  59000 108000  94000  51133  43000 143000  50400  97000 385000  60900\n",
      " 195000  77000  88000  58700  99000  74998  79900  86500 106257  47000\n",
      "  76930 127000 145000  89900  80687  91800  78500  62600  89953  44000\n",
      "  47500 320000 104500  78900  54900  59900  62500  35000  73000  74500\n",
      "  83500  52000  71000  80000  59900 330000 167000 245000  83000  92400\n",
      "  82500  57000  39500 100000  38300  53010 153500  89000  47000 178000\n",
      "  78300  68000 110188  60900  99800 185000 173000  87000 100000  54896\n",
      "  68000  51500  78100  78000  99900 199000  88000  66000  59500  19900\n",
      " 149000  56000  36500  62000 175759  55000 112900  64000 110000  36500\n",
      "  48500 116900  63500  58900 146000 125000  79900  87000 290000  58000\n",
      "  54900  35500 189000  49500  58900  71000  60000 135000  65000  59993\n",
      "  81900  83500  84630  68000  97000  25500  81000  57000 102300  97000\n",
      "  80130 400000 123500  71500 147300  41500 160000 100000  61500  75900\n",
      "  54000 125539  92000  52440  99726  75000  86900 239000 133820  75000\n",
      "  73000  65000  52000  97000  41500  83800  66957  96000  84900 400000\n",
      "  43000  53000  67000 225000 142000 142000 139000 137500 165000  64300\n",
      " 130000 280000  57900 125000  95000 115000  68000  39000  73715  78000\n",
      "  58000 125539  89953  78900  79500  79650 122900  30000 173000  65000\n",
      "  59000  60000  71000  57000 218000  62000  46500  63000 156000 139000\n",
      " 170000  71000  65000  93840 117500 115000  47900 100269 173500  53500\n",
      "  83000 138999 289000 160000  75672 329000  80000 125000  66800 125000\n",
      " 109000  45000  77900 110250  67500  79500 144500  63000  60000 130000\n",
      "  40999  57000 125000  57000  85000  59999  91500 255000  89000 128000\n",
      " 195000  47000  79900  67150 100000  73000 137000 102000 120089 165000\n",
      " 109000 115000  63900  68499 380000 124000 118500 197635  37000  67100\n",
      "  53000  64900  41900  74000 249000  67733 170000  49100  49500  42000\n",
      " 199000  65700  57000  52400 130000  67000 120089  64900  60000  85000\n",
      "  44900 367000  55000  79000  80824 162300  42000  67000  86900  99800\n",
      " 230000  60000  56000  70952 119000 175000  59500 174999 120000 171500\n",
      " 114500  44000  86100  92000 108131  63000  73000  62000 115000  48000\n",
      "  73715  50500 135000  75000 116500  59000 103000 105000  38900  88500\n",
      "  64160 139000  58900 148000 112455  84900  65760 139000 360000  32000\n",
      "  94300  76900  44500 116700  42800  60000  79000  55500  58500  84000\n",
      "  94000 199000  72900  95000 170400 167000 103000  64400  66500  55900\n",
      "  53500  51600  89000  83000  74500 112455 380000  68800 111466  71590\n",
      "  68100  65200 104500  65000 144500 134505  67143 119000  58000  96000\n",
      "  92900  59900  86000 115000  34500 450000  73000  30000  71700 137498\n",
      "  47000  69048  19905 110000  62000  45900  82000  96500  33400 125500\n",
      " 157510 130000 149500  89110  56000  69500]\n",
      "R2 Score: 0.12465369768787848\n",
      "Root Mean Squared Log Error: 11.225875854492188\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATZElEQVR4nO3df7DddX3n8edLQKjFlYQEjCF60aY7xmmLbEpRu11aXVG0xc6oC20lY9lJtwuzOutuJ+hupZ3SoZ2tdRlba7pSEX9Biy4ZwLoUbam7KxgQEQws0UaJSckFK9BqqcT3/nE+iYebc38k997cm899Pma+c77n8/18z/d9PpPzOt987veck6pCktSXpy10AZKkuWe4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHDXopTkL5P828O9b9v/7Un+x6HuLy0GhrvmVZIdSV6x0HXsk+TSJB8a0V5Jfgigqn67qqZ9c5jtm4g0nwx3aRFKcvRC16Ajm+GuBZFkWZIbkown+bu2fsqEbi9IcnuSR5Ncn2T50P5nJvk/Sb6V5ItJzprD2vaf3Sc5LsmHkjzSjvX5JCcnuQz4l8B7kvx9kve0/i9tfR5tty8detxTk9ya5PEkf5HkD4aOM9b+93Bhkq8Dn27tf5rkb9vj3ZrkRUOP94Ekf5jkk62G/53k2Une3cb0viQvnqtx0ZHFcNdCeRrwJ8DzgOcC3wHeM6HPBcAvA88BngSuAEiyGrgR+C1gOfCfgOuSrJyHOjcAzwLWACcC/w74TlW9A/hr4OKqOr6qLm5vPje2Ok8E3gXcmOTE9lgfAW5v2y4F3jTieP8KeCFwdrv/SWAtcBJwJ/DhCf3fCPwXYAXwBPB/W78VwJ+1GrQEGe5aEFX1SFVdV1XfrqrHgcsYBNuwq6vqnqr6B+C/Am9MchTwS8BNVXVTVX2vqm4GtgLnzPDwb2xn4fuXKfp+l0EY/1BV7a2qO6rqsUn6vgZ4oKqurqonq+qjwH3AzyZ5LvDjwK9X1T9V1WeBLSMe49Kq+oeq+g5AVV1ZVY9X1RMM3hB+LMmzhvp/otX0j8AngH+sqg9W1V7gGsAz9yXKcNeCSPKMJO9L8rUkjwG3Aie08N7nwaH1rwHHMDgjfR7whgnh/JPAqhke/tqqOmF4maLv1cCngI8l2ZXkd5McM0nf57Q6h30NWN22fbOqvj3J8zugLclRSS5P8pU2RjvaphVD/R8aWv/OiPvHT1KrOme4a6G8DfjnwE9U1T8Dfqq1Z6jPmqH15zI4i36YQQBePSGgf7CqLp/rIqvqu1X1G1W1Dngp8FoG00UAE79SdReDN55hzwW+AewGlid5xtC2NRxo+DF/ATgXeAWDqaGx1h6kaRjuOhyOaX+Y3LccDTyTwZnlt9pc9TtH7PdLSda1QPxN4M/adMOHGEx1nN3Obo9LctaIP8jOWpKfTvIj7X8UjzF4g9nbNj8EPH+o+03ADyf5hSRHJ/k3wDrghqr6GoOpo0uTPD3JS4Cfnebwz2Qwj/4I8Azgt+fsial7hrsOh5sYBPm+5VLg3cAPMDgT/xzw5yP2uxr4APC3wHHAfwCoqgcZnNG+HRhncCb/n5mff8/PZvCHyceAbcBfMXhzAfjvwOvblSlXVNUjDM7s38YgkH8NeG1VPdz6/yLwkrbttxjMiT8xxbE/yGBa5xvAlxmMkzQj8cc6pIWR5Brgvqoa9b8WaVY8c5cOkyQ/nuQFSZ6W5FUM/vfxPxe6LvXJT8FJh8+zgY8zuLRyJ/CrVfWFhS1JvXJaRpI65LSMJHVoUUzLrFixosbGxha6DEk6otxxxx0PV9XIr91YFOE+NjbG1q1bF7oMSTqiJJn4iej9nJaRpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOLYpPqB6pxjbduCDH3XH5axbkuJKOHJ65S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6NG24J1mT5DNJtiW5N8lbWvulSb6R5K62nDO0zyVJtie5P8nZ8/kEJEkHmskvMT0JvK2q7kzyTOCOJDe3bb9fVf9tuHOSdcB5wIuA5wB/keSHq2rvXBYuSZrctGfuVbW7qu5s648D24DVU+xyLvCxqnqiqv4G2A6cMRfFSpJm5qDm3JOMAS8GbmtNFye5O8mVSZa1ttXAg0O77WTEm0GSjUm2Jtk6Pj5+0IVLkiY343BPcjxwHfDWqnoMeC/wAuA0YDfwe/u6jti9Dmio2lxV66tq/cqVKw+6cEnS5GYU7kmOYRDsH66qjwNU1UNVtbeqvgf8Md+fetkJrBna/RRg19yVLEmazkyulgnwfmBbVb1rqH3VULefB+5p61uA85Icm+RUYC1w+9yVLEmazkyulnkZ8CbgS0nuam1vB85PchqDKZcdwK8AVNW9Sa4FvszgSpuLvFJGkg6vacO9qj7L6Hn0m6bY5zLgslnUJUmaBT+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOnT0QhcwW2ObblzoEiRp0fHMXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ9OGe5I1ST6TZFuSe5O8pbUvT3Jzkgfa7bLWniRXJNme5O4kp8/3k5AkPdVMztyfBN5WVS8EzgQuSrIO2ATcUlVrgVvafYBXA2vbshF475xXLUma0rThXlW7q+rOtv44sA1YDZwLXNW6XQW8rq2fC3ywBj4HnJBk1ZxXLkma1EHNuScZA14M3AacXFW7YfAGAJzUuq0GHhzabWdrm/hYG5NsTbJ1fHz84CuXJE1qxuGe5HjgOuCtVfXYVF1HtNUBDVWbq2p9Va1fuXLlTMuQJM3AjMI9yTEMgv3DVfXx1vzQvumWdrunte8E1gztfgqwa27KlSTNxEyulgnwfmBbVb1raNMWYENb3wBcP9R+Qbtq5kzg0X3TN5Kkw2MmXxz2MuBNwJeS3NXa3g5cDlyb5ELg68Ab2rabgHOA7cC3gTfPacWSpGlNG+5V9VlGz6MDvHxE/wIummVdkqRZ8BOqktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tC04Z7kyiR7ktwz1HZpkm8kuast5wxtuyTJ9iT3Jzl7vgqXJE1uJmfuHwBeNaL996vqtLbcBJBkHXAe8KK2zx8mOWquipUkzcy04V5VtwLfnOHjnQt8rKqeqKq/AbYDZ8yiPknSIZjNnPvFSe5u0zbLWttq4MGhPjtbmyTpMDrUcH8v8ALgNGA38HutPSP61qgHSLIxydYkW8fHxw+xDEnSKIcU7lX1UFXtrarvAX/M96dedgJrhrqeAuya5DE2V9X6qlq/cuXKQylDkjSJQwr3JKuG7v48sO9Kmi3AeUmOTXIqsBa4fXYlSpIO1tHTdUjyUeAsYEWSncA7gbOSnMZgymUH8CsAVXVvkmuBLwNPAhdV1d75KV2SNJlpw72qzh/R/P4p+l8GXDaboiRJs+MnVCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOTfsbqlp8xjbduGDH3nH5axbs2JJmzjN3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0LThnuTKJHuS3DPUtjzJzUkeaLfLWnuSXJFke5K7k5w+n8VLkkabyZn7B4BXTWjbBNxSVWuBW9p9gFcDa9uyEXjv3JQpSToY04Z7Vd0KfHNC87nAVW39KuB1Q+0frIHPASckWTVXxUqSZuZQ59xPrqrdAO32pNa+GnhwqN/O1naAJBuTbE2ydXx8/BDLkCSNMtd/UM2IthrVsao2V9X6qlq/cuXKOS5Dkpa2Qw33h/ZNt7TbPa19J7BmqN8pwK5DL0+SdCgONdy3ABva+gbg+qH2C9pVM2cCj+6bvpEkHT7T/lhHko8CZwErkuwE3glcDlyb5ELg68AbWvebgHOA7cC3gTfPQ82SpGlMG+5Vdf4km14+om8BF822KEnS7PgJVUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXo6NnsnGQH8DiwF3iyqtYnWQ5cA4wBO4A3VtXfza5MSdLBmIsz95+uqtOqan27vwm4parWAre0+5Kkw2g+pmXOBa5q61cBr5uHY0iSpjDbcC/gfyW5I8nG1nZyVe0GaLcnjdoxycYkW5NsHR8fn2UZkqRhs5pzB15WVbuSnATcnOS+me5YVZuBzQDr16+vWdYhSRoyqzP3qtrVbvcAnwDOAB5Ksgqg3e6ZbZGSpINzyGfuSX4QeFpVPd7WXwn8JrAF2ABc3m6vn4tCtTiMbbpxQY674/LXLMhxpSPVbKZlTgY+kWTf43ykqv48yeeBa5NcCHwdeMPsy5QkHYxDDveq+irwYyPaHwFePpuiJEmz4ydUJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1aDa/oSodNgv1w9zgj3PryOSZuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQl0JK01jIyzAXgpd+9sFwl7RoLNQbaY9vaE7LSFKHPHOX9BRLbRqqV/N25p7kVUnuT7I9yab5Oo4k6UDzcuae5CjgD4B/DewEPp9kS1V9eT6OJ0mz0eN3F83XmfsZwPaq+mpV/RPwMeDceTqWJGmC+ZpzXw08OHR/J/ATwx2SbAQ2trt/n+QR4OF5qudItwLHZjKOzeQcm9EW1bjkd2a1+/Mm2zBf4Z4RbfWUO1Wbgc37d0i2VtX6earniObYTM6xmZxjM9pSGZf5mpbZCawZun8KsGuejiVJmmC+wv3zwNokpyZ5OnAesGWejiVJmmBepmWq6skkFwOfAo4Crqyqe6fZbfM025cyx2Zyjs3kHJvRlsS4pKqm7yVJOqL49QOS1CHDXZI6tCjCvdevKkhyZZI9Se4Zalue5OYkD7TbZa09Sa5oY3B3ktOH9tnQ+j+QZMNQ+79I8qW2zxVJMtUxFpMka5J8Jsm2JPcmeUtrX/Ljk+S4JLcn+WIbm99o7acmua3VfU27WIEkx7b729v2saHHuqS135/k7KH2ka+5yY6xmCQ5KskXktzQ7jsuo1TVgi4M/uD6FeD5wNOBLwLrFrquOXpuPwWcDtwz1Pa7wKa2vgn4nbZ+DvBJBp8ROBO4rbUvB77abpe19WVt2+3AS9o+nwRePdUxFtMCrAJOb+vPBP4fsM7xKVq9x7f1Y4Db2nO+Fjivtf8R8Ktt/d8Df9TWzwOuaevr2uvpWODU9jo7aqrX3GTHWEwL8B+BjwA3TFXzUhuXA8ZpwQsYvPg+NXT/EuCSha5rDp/fGE8N9/uBVW19FXB/W38fcP7EfsD5wPuG2t/X2lYB9w217+832TEW8wJcz+C7iByfp47LM4A7GXzC+2Hg6Na+/3XD4Kq0l7T1o1u/THwt7es32Wuu7TPyGItlYfCZmVuAnwFumKrmpTQuo5bFMC0z6qsKVi9QLYfDyVW1G6DdntTaJxuHqdp3jmif6hiLUvvv8osZnKE6PuyfergL2APczOCM8ltV9WTrMvx89o9B2/4ocCIHP2YnTnGMxeLdwK8B32v3p6p5KY3LARZDuE/7VQVLxGTjcLDtR5QkxwPXAW+tqsem6jqirdvxqaq9VXUagzPVM4AXjurWbudqbBb1mCV5LbCnqu4Ybh7RdUmNy2QWQ7gvta8qeCjJKoB2u6e1TzYOU7WfMqJ9qmMsKkmOYRDsH66qj7dmx2dIVX0L+EsGc+4nJNn3wcPh57N/DNr2ZwHf5ODH7OEpjrEYvAz4uSQ7GHzT7M8wOJNf6uMy0mII96X2VQVbgH1XdGxgMNe8r/2CdlXImcCjbcrgU8ArkyxrV3W8ksF8327g8SRntqtALpjwWKOOsWi0mt8PbKuqdw1tWvLjk2RlkhPa+g8ArwC2AZ8BXt+6TRybfc/n9cCnazA5vAU4r101ciqwlsEfmUe+5to+kx1jwVXVJVV1SlWNMaj501X1iyzxcZnUQk/6tz9QnMPgaomvAO9Y6Hrm8Hl9FNgNfJfBWcGFDObvbgEeaLfLW98w+IGTrwBfAtYPPc4vA9vb8uah9vXAPW2f9/D9TxyPPMZiWoCfZPBf27uBu9pyjuNTAD8KfKGNzT3Ar7f25zMIoe3AnwLHtvbj2v3tbfvzhx7rHe3530+7Wqi1j3zNTXaMxbYAZ/H9q2UclxGLXz8gSR1aDNMykqQ5ZrhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDv1/W/khD3zS7NIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evalset = HousePriceDataset(X_test_scaled, y_test)\n",
    "loader  = DataLoader(evalset, batch_size = len(X_test_scaled))\n",
    " \n",
    "with torch.no_grad():\n",
    "    for features, labels in loader: \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = 0\n",
    "        for regressor in regressors:\n",
    "            regressor.eval()\n",
    "            output = regressor(features.float())\n",
    "            outputs += output\n",
    "        \n",
    "        outputs = outputs / len(models)\n",
    "        \n",
    "Ypred = outputs.cpu().numpy()\n",
    "\n",
    "Ypred = min_max_scaler.inverse_transform(Ypred)\n",
    "\n",
    "Yreal = labels.cpu().numpy()\n",
    "\n",
    "# print(\"Loss on Testing Data:\", criterion(output, labels).item())\n",
    "\n",
    "print(\"Lets see predictions\")\n",
    "print(Ypred.reshape(-1))\n",
    "print(Yreal.reshape(-1))\n",
    "\n",
    "rmsle = RMSLELoss(output, labels)\n",
    "r2 = r2_score(Yreal, Ypred)\n",
    "\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Root Mean Squared Log Error:\", rmsle.item())\n",
    "\n",
    "plt.hist(Ypred)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(Yreal)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This could use some fine-tuning, but for now we solved the predictions problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for improvements\n",
    "- Bayesion Optimization for neural network parameters (num_layers, num_neurons, etc.)\n",
    "- Meta-Models for the regresion part, with stacking or blending methodology\n",
    "- Other type of date preprocessing and feature extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
