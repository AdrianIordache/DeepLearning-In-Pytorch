{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X_train, X_test):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler.fit(X_train) \n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_test = scaler.transform(X_test)  \n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_correlation_matrix(data):\n",
    "    \n",
    "    corr_matrix = data.corr()\n",
    "    \n",
    "    display(corr_matrix)\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=np.bool))\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=1, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_correlated_features(data, threshold = 0.99):\n",
    "\n",
    "    corr_matrix = data.corr().abs()\n",
    "\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    print(\"Features to drop for Threshold \" + str(threshold), to_drop)\n",
    "    \n",
    "    data.drop(data[to_drop], axis = 1, inplace = True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_importance(model, features, labels):\n",
    "    print(\"Features: \", features.columns.values)\n",
    "    importance = PermutationImportance(model).fit(features, y_test)\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__ (self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, m_hidden_layers, n_input, n_hidden, n_output, network_type = \"classification\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.m_hidden_layers = m_hidden_layers\n",
    "        \n",
    "        self.input_layer = nn.Linear(n_input, n_hidden)\n",
    "    \n",
    "        self.hidden_layer = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.output_layer = nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "        self.bn  = nn.BatchNorm1d(n_hidden)\n",
    "        \n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "        assert network_type in [\"classification\", \"regression\"]\n",
    "        \n",
    "        self.network_type = network_type\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Use dropout only for regression\n",
    "        \n",
    "        if self.network_type == \"regression\":\n",
    "            \n",
    "            x = self.dropout(self.activation(self.input_layer(x)))\n",
    "\n",
    "            for step in range(self.m_hidden_layers):\n",
    "                x = self.dropout(self.activation(self.bn(self.hidden_layer(x))))\n",
    "\n",
    "            x = self.output_layer(x)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            x = self.activation(self.input_layer(x))\n",
    "\n",
    "            for step in range(self.m_hidden_layers):\n",
    "                x = self.activation(self.bn(self.hidden_layer(x)))\n",
    "\n",
    "            x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    def __init__(self):\n",
    "        self.coef = 0\n",
    "\n",
    "    def loss(self, coef, samples, labels):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        limit = [-np.inf] + list(np.sort(coef)) + [np.inf]\n",
    "\n",
    "        opt_labels = pd.cut(samples, limit, labels = [0, 1, 2, 3, 4])\n",
    "\n",
    "        return -accuracy_score(opt_labels, labels) \n",
    "\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self.loss, samples = X, labels=y)\n",
    "        \n",
    "        initial_coef = [1, 2, 3, 4]\n",
    "\n",
    "        self.coef = minimize(loss_partial, initial_coef, method='Nelder-Mead')\n",
    "        \n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        \n",
    "        limit = [-np.inf] + list(np.sort(self.coef['x'])) + [np.inf]\n",
    "\n",
    "        return pd.cut(X, limit, labels = [0, 1, 2, 3, 4])\n",
    "    \n",
    "    def coefficients(self):\n",
    "        return self.coef['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLELoss(y_true, y_hat):\n",
    "    return torch.abs(torch.sqrt(torch.mean((torch.log(y_true + 1) - torch.log(y_hat.float() + 1)) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLELoss_for_numpy(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "    \n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset\n",
    "- Will separate the labels from features\n",
    "- And will map the labels from (1 - 5) to (0 - 4) for convenience in the softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr Camere</th>\n",
       "      <th>Suprafata</th>\n",
       "      <th>Etaj</th>\n",
       "      <th>Total Etaje</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scor</th>\n",
       "      <th>Pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>108.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63.52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>84900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>62.00</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>132.00</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>349990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>49.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>36500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>92.00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>68.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>110.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nr Camere  Suprafata  Etaj  Total Etaje  Sector  Scor    Pret\n",
       "0          4     108.00     2            3       4     5   83000\n",
       "1          1      41.00     1            8       1     1   39900\n",
       "2          3      63.52     1            3       2     3   84900\n",
       "3          1      33.00     3           10       5     1   45500\n",
       "4          2      62.00     5            9       5     5   54900\n",
       "5          3     132.00     2            6       1     2  349990\n",
       "6          2      49.00     6            6       6     4   36500\n",
       "7          3      92.00     4            8       2     2  119000\n",
       "8          3      68.00     3            5       4     5   67500\n",
       "9          3     110.00     1            2       1     1  133000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Bucharest_HousePriceDataset.csv\")\n",
    "\n",
    "display(data.head(n = 10))\n",
    "\n",
    "features = data.drop(['Scor'], axis = 1, inplace = False)\n",
    "\n",
    "labels   = data[\"Scor\"].apply(lambda x : x - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the correlation matrix \n",
    "- Drop higgly correlated features (if necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr Camere</th>\n",
       "      <th>Suprafata</th>\n",
       "      <th>Etaj</th>\n",
       "      <th>Total Etaje</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scor</th>\n",
       "      <th>Pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nr Camere</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807278</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>-0.012815</td>\n",
       "      <td>-0.183737</td>\n",
       "      <td>-0.215591</td>\n",
       "      <td>0.635789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suprafata</th>\n",
       "      <td>0.807278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060527</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>-0.240274</td>\n",
       "      <td>-0.299838</td>\n",
       "      <td>0.807414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etaj</th>\n",
       "      <td>0.066427</td>\n",
       "      <td>0.060527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.559217</td>\n",
       "      <td>0.061581</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.038719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Etaje</th>\n",
       "      <td>-0.012815</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>0.559217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103467</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.006063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sector</th>\n",
       "      <td>-0.183737</td>\n",
       "      <td>-0.240274</td>\n",
       "      <td>0.061581</td>\n",
       "      <td>0.103467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577602</td>\n",
       "      <td>-0.409052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scor</th>\n",
       "      <td>-0.215591</td>\n",
       "      <td>-0.299838</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.577602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.531826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pret</th>\n",
       "      <td>0.635789</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.038719</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>-0.409052</td>\n",
       "      <td>-0.531826</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Nr Camere  Suprafata      Etaj  Total Etaje    Sector      Scor  \\\n",
       "Nr Camere     1.000000   0.807278  0.066427    -0.012815 -0.183737 -0.215591   \n",
       "Suprafata     0.807278   1.000000  0.060527    -0.041367 -0.240274 -0.299838   \n",
       "Etaj          0.066427   0.060527  1.000000     0.559217  0.061581  0.027381   \n",
       "Total Etaje  -0.012815  -0.041367  0.559217     1.000000  0.103467  0.036039   \n",
       "Sector       -0.183737  -0.240274  0.061581     0.103467  1.000000  0.577602   \n",
       "Scor         -0.215591  -0.299838  0.027381     0.036039  0.577602  1.000000   \n",
       "Pret          0.635789   0.807414  0.038719     0.006063 -0.409052 -0.531826   \n",
       "\n",
       "                 Pret  \n",
       "Nr Camere    0.635789  \n",
       "Suprafata    0.807414  \n",
       "Etaj         0.038719  \n",
       "Total Etaje  0.006063  \n",
       "Sector      -0.409052  \n",
       "Scor        -0.531826  \n",
       "Pret         1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_correlation_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to drop for Threshold 0.99 []\n"
     ]
    }
   ],
   "source": [
    "data = drop_highly_correlated_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data Methodology\n",
    "- First step: Will get a hold out set (train set - test set: 0.8 - 0.2)\n",
    "- Second step: Will use a cross-validation with 5 fold (4 training fold - 1 validation fold)\n",
    "\n",
    "- As note: This Methodology is typically used in deep learning for large datasets, this concludes that for our 3529 samples may not be fitted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels.values, train_size = 0.9, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets get a baseline model without cross-validation\n",
    "\n",
    "- To get a sense of the problem will display the accuracy and the feature importance of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Random Forest:  0.7932011331444759\n",
      "Features:  ['Nr Camere' 'Suprafata' 'Etaj' 'Total Etaje' 'Sector' 'Pret']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4414\n",
       "                \n",
       "                    &plusmn; 0.0576\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2765\n",
       "                \n",
       "                    &plusmn; 0.0508\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0657\n",
       "                \n",
       "                    &plusmn; 0.0458\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.15%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0584\n",
       "                \n",
       "                    &plusmn; 0.0292\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0323\n",
       "                \n",
       "                    &plusmn; 0.0205\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0221\n",
       "                \n",
       "                    &plusmn; 0.0225\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print(\"Baseline Random Forest: \", accuracy)\n",
    "\n",
    "importance = display_feature_importance(model, X_test, y_test)\n",
    "\n",
    "eli5.show_weights(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lets do the same for a neural network from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Neural Network:  0.2096317280453258\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes = (10, 10, 10, 10))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print(\"Baseline Neural Network: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Something went wrong...\n",
    "- As you can see the results are quite disappointing, and the reason for this difference in each model accuracy is that tree base models (such as Random Forrest) are invariant to features scaling, but the neural networks are not\n",
    "\n",
    "# Lets use a mean normalization over data and retry the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3176\n",
      "353\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = preprocessing(X_train, X_test)\n",
    "print(len(X_train_scaled))\n",
    "print(len(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Neural Network:  0.7592067988668555\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes = (12, 12, 12, 12, 12), max_iter = 500)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print(\"Baseline Neural Network: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's much better, now lets do that in Pytorch\n",
    "- But now with cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 0\n",
      "Epoch: 1/100..  Training Loss: 1.244..  Test Loss: 1.098..  Test Accuracy: 0.520\n",
      "Epoch: 2/100..  Training Loss: 0.997..  Test Loss: 0.799..  Test Accuracy: 0.653\n",
      "Epoch: 3/100..  Training Loss: 0.809..  Test Loss: 0.673..  Test Accuracy: 0.728\n",
      "Epoch: 4/100..  Training Loss: 0.780..  Test Loss: 0.643..  Test Accuracy: 0.743\n",
      "Epoch: 5/100..  Training Loss: 0.758..  Test Loss: 0.640..  Test Accuracy: 0.721\n",
      "Epoch: 6/100..  Training Loss: 0.717..  Test Loss: 0.639..  Test Accuracy: 0.701\n",
      "Epoch: 7/100..  Training Loss: 0.688..  Test Loss: 0.650..  Test Accuracy: 0.701\n",
      "Epoch: 8/100..  Training Loss: 0.707..  Test Loss: 0.586..  Test Accuracy: 0.743\n",
      "Epoch: 9/100..  Training Loss: 0.700..  Test Loss: 0.598..  Test Accuracy: 0.718\n",
      "Epoch: 10/100..  Training Loss: 0.677..  Test Loss: 0.623..  Test Accuracy: 0.711\n",
      "Epoch: 11/100..  Training Loss: 0.670..  Test Loss: 0.579..  Test Accuracy: 0.748\n",
      "Epoch: 12/100..  Training Loss: 0.667..  Test Loss: 0.560..  Test Accuracy: 0.740\n",
      "Epoch: 13/100..  Training Loss: 0.691..  Test Loss: 0.578..  Test Accuracy: 0.732\n",
      "Epoch: 14/100..  Training Loss: 0.663..  Test Loss: 0.600..  Test Accuracy: 0.724\n",
      "Epoch: 15/100..  Training Loss: 0.668..  Test Loss: 0.561..  Test Accuracy: 0.738\n",
      "Epoch: 16/100..  Training Loss: 0.674..  Test Loss: 0.615..  Test Accuracy: 0.728\n",
      "Epoch: 17/100..  Training Loss: 0.666..  Test Loss: 0.560..  Test Accuracy: 0.751\n",
      "Epoch: 18/100..  Training Loss: 0.666..  Test Loss: 0.580..  Test Accuracy: 0.729\n",
      "Epoch: 19/100..  Training Loss: 0.648..  Test Loss: 0.590..  Test Accuracy: 0.740\n",
      "Epoch: 20/100..  Training Loss: 0.653..  Test Loss: 0.585..  Test Accuracy: 0.724\n",
      "Epoch: 21/100..  Training Loss: 0.661..  Test Loss: 0.689..  Test Accuracy: 0.717\n",
      "Epoch: 22/100..  Training Loss: 0.674..  Test Loss: 0.612..  Test Accuracy: 0.707\n",
      "Epoch: 23/100..  Training Loss: 0.653..  Test Loss: 0.554..  Test Accuracy: 0.735\n",
      "Epoch: 24/100..  Training Loss: 0.658..  Test Loss: 0.577..  Test Accuracy: 0.728\n",
      "Epoch: 25/100..  Training Loss: 0.651..  Test Loss: 0.563..  Test Accuracy: 0.750\n",
      "Epoch: 26/100..  Training Loss: 0.649..  Test Loss: 0.565..  Test Accuracy: 0.748\n",
      "Epoch: 27/100..  Training Loss: 0.647..  Test Loss: 0.611..  Test Accuracy: 0.744\n",
      "Epoch: 28/100..  Training Loss: 0.650..  Test Loss: 0.580..  Test Accuracy: 0.729\n",
      "Epoch: 29/100..  Training Loss: 0.641..  Test Loss: 0.601..  Test Accuracy: 0.738\n",
      "Epoch: 30/100..  Training Loss: 0.634..  Test Loss: 0.574..  Test Accuracy: 0.750\n",
      "Epoch: 31/100..  Training Loss: 0.658..  Test Loss: 0.582..  Test Accuracy: 0.726\n",
      "Epoch: 32/100..  Training Loss: 0.656..  Test Loss: 0.552..  Test Accuracy: 0.766\n",
      "Epoch: 33/100..  Training Loss: 0.659..  Test Loss: 0.573..  Test Accuracy: 0.762\n",
      "Epoch: 34/100..  Training Loss: 0.632..  Test Loss: 0.570..  Test Accuracy: 0.754\n",
      "Epoch: 35/100..  Training Loss: 0.654..  Test Loss: 0.561..  Test Accuracy: 0.743\n",
      "Epoch: 36/100..  Training Loss: 0.635..  Test Loss: 0.602..  Test Accuracy: 0.706\n",
      "Epoch: 37/100..  Training Loss: 0.650..  Test Loss: 0.566..  Test Accuracy: 0.754\n",
      "Epoch: 38/100..  Training Loss: 0.629..  Test Loss: 0.574..  Test Accuracy: 0.760\n",
      "Epoch: 39/100..  Training Loss: 0.659..  Test Loss: 0.584..  Test Accuracy: 0.740\n",
      "Epoch: 40/100..  Training Loss: 0.635..  Test Loss: 0.622..  Test Accuracy: 0.737\n",
      "Epoch: 41/100..  Training Loss: 0.653..  Test Loss: 0.571..  Test Accuracy: 0.747\n",
      "Epoch: 42/100..  Training Loss: 0.654..  Test Loss: 0.602..  Test Accuracy: 0.741\n",
      "Epoch: 43/100..  Training Loss: 0.626..  Test Loss: 0.607..  Test Accuracy: 0.731\n",
      "Epoch: 44/100..  Training Loss: 0.650..  Test Loss: 0.565..  Test Accuracy: 0.770\n",
      "Epoch: 45/100..  Training Loss: 0.653..  Test Loss: 0.576..  Test Accuracy: 0.729\n",
      "Epoch: 46/100..  Training Loss: 0.649..  Test Loss: 0.579..  Test Accuracy: 0.738\n",
      "Epoch: 47/100..  Training Loss: 0.637..  Test Loss: 0.560..  Test Accuracy: 0.764\n",
      "Epoch: 48/100..  Training Loss: 0.647..  Test Loss: 0.575..  Test Accuracy: 0.746\n",
      "Epoch: 49/100..  Training Loss: 0.640..  Test Loss: 0.576..  Test Accuracy: 0.749\n",
      "Epoch: 50/100..  Training Loss: 0.622..  Test Loss: 0.585..  Test Accuracy: 0.756\n",
      "Epoch: 51/100..  Training Loss: 0.636..  Test Loss: 0.546..  Test Accuracy: 0.754\n",
      "Epoch: 52/100..  Training Loss: 0.640..  Test Loss: 0.574..  Test Accuracy: 0.742\n",
      "Epoch: 53/100..  Training Loss: 0.650..  Test Loss: 0.651..  Test Accuracy: 0.737\n",
      "Epoch: 54/100..  Training Loss: 0.654..  Test Loss: 0.543..  Test Accuracy: 0.772\n",
      "Epoch: 55/100..  Training Loss: 0.629..  Test Loss: 0.564..  Test Accuracy: 0.759\n",
      "Epoch: 56/100..  Training Loss: 0.648..  Test Loss: 0.572..  Test Accuracy: 0.771\n",
      "Epoch: 57/100..  Training Loss: 0.635..  Test Loss: 0.566..  Test Accuracy: 0.750\n",
      "Epoch: 58/100..  Training Loss: 0.631..  Test Loss: 0.576..  Test Accuracy: 0.749\n",
      "Epoch: 59/100..  Training Loss: 0.615..  Test Loss: 0.550..  Test Accuracy: 0.767\n",
      "Epoch: 60/100..  Training Loss: 0.618..  Test Loss: 0.557..  Test Accuracy: 0.769\n",
      "Epoch: 61/100..  Training Loss: 0.637..  Test Loss: 0.577..  Test Accuracy: 0.736\n",
      "Epoch: 62/100..  Training Loss: 0.640..  Test Loss: 0.576..  Test Accuracy: 0.732\n",
      "Epoch: 63/100..  Training Loss: 0.634..  Test Loss: 0.599..  Test Accuracy: 0.728\n",
      "Epoch: 64/100..  Training Loss: 0.623..  Test Loss: 0.560..  Test Accuracy: 0.753\n",
      "Epoch: 65/100..  Training Loss: 0.632..  Test Loss: 0.607..  Test Accuracy: 0.745\n",
      "Epoch: 66/100..  Training Loss: 0.638..  Test Loss: 0.553..  Test Accuracy: 0.752\n",
      "Epoch: 67/100..  Training Loss: 0.632..  Test Loss: 0.571..  Test Accuracy: 0.767\n",
      "Epoch: 68/100..  Training Loss: 0.629..  Test Loss: 0.553..  Test Accuracy: 0.759\n",
      "Epoch: 69/100..  Training Loss: 0.632..  Test Loss: 0.574..  Test Accuracy: 0.736\n",
      "Epoch: 70/100..  Training Loss: 0.644..  Test Loss: 0.545..  Test Accuracy: 0.768\n",
      "Epoch: 71/100..  Training Loss: 0.637..  Test Loss: 0.558..  Test Accuracy: 0.745\n",
      "Epoch: 72/100..  Training Loss: 0.630..  Test Loss: 0.553..  Test Accuracy: 0.743\n",
      "Epoch: 73/100..  Training Loss: 0.612..  Test Loss: 0.561..  Test Accuracy: 0.763\n",
      "Epoch: 74/100..  Training Loss: 0.628..  Test Loss: 0.583..  Test Accuracy: 0.750\n",
      "Epoch: 75/100..  Training Loss: 0.633..  Test Loss: 0.593..  Test Accuracy: 0.732\n",
      "Epoch: 76/100..  Training Loss: 0.618..  Test Loss: 0.570..  Test Accuracy: 0.749\n",
      "Epoch: 77/100..  Training Loss: 0.637..  Test Loss: 0.559..  Test Accuracy: 0.765\n",
      "Epoch: 78/100..  Training Loss: 0.635..  Test Loss: 0.599..  Test Accuracy: 0.762\n",
      "Epoch: 79/100..  Training Loss: 0.626..  Test Loss: 0.581..  Test Accuracy: 0.742\n",
      "Epoch: 80/100..  Training Loss: 0.636..  Test Loss: 0.596..  Test Accuracy: 0.736\n",
      "Epoch: 81/100..  Training Loss: 0.636..  Test Loss: 0.586..  Test Accuracy: 0.712\n",
      "Epoch: 82/100..  Training Loss: 0.629..  Test Loss: 0.601..  Test Accuracy: 0.736\n",
      "Epoch: 83/100..  Training Loss: 0.627..  Test Loss: 0.550..  Test Accuracy: 0.771\n",
      "Epoch: 84/100..  Training Loss: 0.649..  Test Loss: 0.566..  Test Accuracy: 0.756\n",
      "Epoch: 85/100..  Training Loss: 0.627..  Test Loss: 0.579..  Test Accuracy: 0.751\n",
      "Epoch: 86/100..  Training Loss: 0.622..  Test Loss: 0.567..  Test Accuracy: 0.756\n",
      "Epoch: 87/100..  Training Loss: 0.618..  Test Loss: 0.557..  Test Accuracy: 0.759\n",
      "Epoch: 88/100..  Training Loss: 0.612..  Test Loss: 0.585..  Test Accuracy: 0.755\n",
      "Epoch: 89/100..  Training Loss: 0.636..  Test Loss: 0.557..  Test Accuracy: 0.763\n",
      "Epoch: 90/100..  Training Loss: 0.603..  Test Loss: 0.572..  Test Accuracy: 0.741\n",
      "Epoch: 91/100..  Training Loss: 0.629..  Test Loss: 0.560..  Test Accuracy: 0.763\n",
      "Epoch: 92/100..  Training Loss: 0.622..  Test Loss: 0.575..  Test Accuracy: 0.745\n",
      "Epoch: 93/100..  Training Loss: 0.627..  Test Loss: 0.569..  Test Accuracy: 0.762\n",
      "Epoch: 94/100..  Training Loss: 0.608..  Test Loss: 0.542..  Test Accuracy: 0.770\n",
      "Epoch: 95/100..  Training Loss: 0.626..  Test Loss: 0.564..  Test Accuracy: 0.761\n",
      "Epoch: 96/100..  Training Loss: 0.634..  Test Loss: 0.552..  Test Accuracy: 0.754\n",
      "Epoch: 97/100..  Training Loss: 0.618..  Test Loss: 0.550..  Test Accuracy: 0.752\n",
      "Epoch: 98/100..  Training Loss: 0.617..  Test Loss: 0.598..  Test Accuracy: 0.752\n",
      "Epoch: 99/100..  Training Loss: 0.613..  Test Loss: 0.559..  Test Accuracy: 0.776\n",
      "Epoch: 100/100..  Training Loss: 0.617..  Test Loss: 0.562..  Test Accuracy: 0.757\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 1\n",
      "Epoch: 1/100..  Training Loss: 1.219..  Test Loss: 0.997..  Test Accuracy: 0.590\n",
      "Epoch: 2/100..  Training Loss: 0.997..  Test Loss: 0.804..  Test Accuracy: 0.688\n",
      "Epoch: 3/100..  Training Loss: 0.850..  Test Loss: 0.679..  Test Accuracy: 0.711\n",
      "Epoch: 4/100..  Training Loss: 0.780..  Test Loss: 0.667..  Test Accuracy: 0.693\n",
      "Epoch: 5/100..  Training Loss: 0.745..  Test Loss: 0.647..  Test Accuracy: 0.722\n",
      "Epoch: 6/100..  Training Loss: 0.714..  Test Loss: 0.631..  Test Accuracy: 0.743\n",
      "Epoch: 7/100..  Training Loss: 0.710..  Test Loss: 0.608..  Test Accuracy: 0.714\n",
      "Epoch: 8/100..  Training Loss: 0.708..  Test Loss: 0.618..  Test Accuracy: 0.734\n",
      "Epoch: 9/100..  Training Loss: 0.703..  Test Loss: 0.622..  Test Accuracy: 0.727\n",
      "Epoch: 10/100..  Training Loss: 0.695..  Test Loss: 0.594..  Test Accuracy: 0.718\n",
      "Epoch: 11/100..  Training Loss: 0.691..  Test Loss: 0.630..  Test Accuracy: 0.726\n",
      "Epoch: 12/100..  Training Loss: 0.698..  Test Loss: 0.622..  Test Accuracy: 0.738\n",
      "Epoch: 13/100..  Training Loss: 0.670..  Test Loss: 0.573..  Test Accuracy: 0.745\n",
      "Epoch: 14/100..  Training Loss: 0.683..  Test Loss: 0.613..  Test Accuracy: 0.707\n",
      "Epoch: 15/100..  Training Loss: 0.669..  Test Loss: 0.586..  Test Accuracy: 0.729\n",
      "Epoch: 16/100..  Training Loss: 0.674..  Test Loss: 0.603..  Test Accuracy: 0.713\n",
      "Epoch: 17/100..  Training Loss: 0.663..  Test Loss: 0.617..  Test Accuracy: 0.720\n",
      "Epoch: 18/100..  Training Loss: 0.682..  Test Loss: 0.605..  Test Accuracy: 0.701\n",
      "Epoch: 19/100..  Training Loss: 0.663..  Test Loss: 0.615..  Test Accuracy: 0.719\n",
      "Epoch: 20/100..  Training Loss: 0.654..  Test Loss: 0.616..  Test Accuracy: 0.723\n",
      "Epoch: 21/100..  Training Loss: 0.638..  Test Loss: 0.582..  Test Accuracy: 0.739\n",
      "Epoch: 22/100..  Training Loss: 0.653..  Test Loss: 0.548..  Test Accuracy: 0.738\n",
      "Epoch: 23/100..  Training Loss: 0.661..  Test Loss: 0.596..  Test Accuracy: 0.724\n",
      "Epoch: 24/100..  Training Loss: 0.654..  Test Loss: 0.572..  Test Accuracy: 0.742\n",
      "Epoch: 25/100..  Training Loss: 0.652..  Test Loss: 0.587..  Test Accuracy: 0.710\n",
      "Epoch: 26/100..  Training Loss: 0.637..  Test Loss: 0.611..  Test Accuracy: 0.706\n",
      "Epoch: 27/100..  Training Loss: 0.643..  Test Loss: 0.570..  Test Accuracy: 0.738\n",
      "Epoch: 28/100..  Training Loss: 0.637..  Test Loss: 0.564..  Test Accuracy: 0.736\n",
      "Epoch: 29/100..  Training Loss: 0.635..  Test Loss: 0.585..  Test Accuracy: 0.735\n",
      "Epoch: 30/100..  Training Loss: 0.622..  Test Loss: 0.579..  Test Accuracy: 0.706\n",
      "Epoch: 31/100..  Training Loss: 0.641..  Test Loss: 0.558..  Test Accuracy: 0.736\n",
      "Epoch: 32/100..  Training Loss: 0.646..  Test Loss: 0.639..  Test Accuracy: 0.733\n",
      "Epoch: 33/100..  Training Loss: 0.651..  Test Loss: 0.570..  Test Accuracy: 0.712\n",
      "Epoch: 34/100..  Training Loss: 0.630..  Test Loss: 0.598..  Test Accuracy: 0.704\n",
      "Epoch: 35/100..  Training Loss: 0.626..  Test Loss: 0.582..  Test Accuracy: 0.712\n",
      "Epoch: 36/100..  Training Loss: 0.617..  Test Loss: 0.592..  Test Accuracy: 0.706\n",
      "Epoch: 37/100..  Training Loss: 0.649..  Test Loss: 0.578..  Test Accuracy: 0.724\n",
      "Epoch: 38/100..  Training Loss: 0.629..  Test Loss: 0.561..  Test Accuracy: 0.734\n",
      "Epoch: 39/100..  Training Loss: 0.629..  Test Loss: 0.572..  Test Accuracy: 0.722\n",
      "Epoch: 40/100..  Training Loss: 0.637..  Test Loss: 0.561..  Test Accuracy: 0.742\n",
      "Epoch: 41/100..  Training Loss: 0.634..  Test Loss: 0.579..  Test Accuracy: 0.720\n",
      "Epoch: 42/100..  Training Loss: 0.616..  Test Loss: 0.579..  Test Accuracy: 0.719\n",
      "Epoch: 43/100..  Training Loss: 0.640..  Test Loss: 0.572..  Test Accuracy: 0.729\n",
      "Epoch: 44/100..  Training Loss: 0.621..  Test Loss: 0.568..  Test Accuracy: 0.736\n",
      "Epoch: 45/100..  Training Loss: 0.597..  Test Loss: 0.562..  Test Accuracy: 0.717\n",
      "Epoch: 46/100..  Training Loss: 0.628..  Test Loss: 0.577..  Test Accuracy: 0.715\n",
      "Epoch: 47/100..  Training Loss: 0.629..  Test Loss: 0.581..  Test Accuracy: 0.726\n",
      "Epoch: 48/100..  Training Loss: 0.633..  Test Loss: 0.567..  Test Accuracy: 0.725\n",
      "Epoch: 49/100..  Training Loss: 0.607..  Test Loss: 0.585..  Test Accuracy: 0.720\n",
      "Epoch: 50/100..  Training Loss: 0.631..  Test Loss: 0.589..  Test Accuracy: 0.726\n",
      "Epoch: 51/100..  Training Loss: 0.618..  Test Loss: 0.564..  Test Accuracy: 0.726\n",
      "Epoch: 52/100..  Training Loss: 0.601..  Test Loss: 0.580..  Test Accuracy: 0.707\n",
      "Epoch: 53/100..  Training Loss: 0.618..  Test Loss: 0.601..  Test Accuracy: 0.722\n",
      "Epoch: 54/100..  Training Loss: 0.634..  Test Loss: 0.562..  Test Accuracy: 0.721\n",
      "Epoch: 55/100..  Training Loss: 0.618..  Test Loss: 0.603..  Test Accuracy: 0.723\n",
      "Epoch: 56/100..  Training Loss: 0.626..  Test Loss: 0.588..  Test Accuracy: 0.713\n",
      "Epoch: 57/100..  Training Loss: 0.619..  Test Loss: 0.568..  Test Accuracy: 0.722\n",
      "Epoch: 58/100..  Training Loss: 0.615..  Test Loss: 0.560..  Test Accuracy: 0.754\n",
      "Epoch: 59/100..  Training Loss: 0.604..  Test Loss: 0.581..  Test Accuracy: 0.733\n",
      "Epoch: 60/100..  Training Loss: 0.618..  Test Loss: 0.588..  Test Accuracy: 0.705\n",
      "Epoch: 61/100..  Training Loss: 0.613..  Test Loss: 0.587..  Test Accuracy: 0.728\n",
      "Epoch: 62/100..  Training Loss: 0.601..  Test Loss: 0.564..  Test Accuracy: 0.744\n",
      "Epoch: 63/100..  Training Loss: 0.602..  Test Loss: 0.589..  Test Accuracy: 0.728\n",
      "Epoch: 64/100..  Training Loss: 0.593..  Test Loss: 0.594..  Test Accuracy: 0.716\n",
      "Epoch: 65/100..  Training Loss: 0.614..  Test Loss: 0.576..  Test Accuracy: 0.724\n",
      "Epoch: 66/100..  Training Loss: 0.596..  Test Loss: 0.583..  Test Accuracy: 0.729\n",
      "Epoch: 67/100..  Training Loss: 0.620..  Test Loss: 0.581..  Test Accuracy: 0.714\n",
      "Epoch: 68/100..  Training Loss: 0.607..  Test Loss: 0.597..  Test Accuracy: 0.727\n",
      "Epoch: 69/100..  Training Loss: 0.606..  Test Loss: 0.569..  Test Accuracy: 0.741\n",
      "Epoch: 70/100..  Training Loss: 0.595..  Test Loss: 0.568..  Test Accuracy: 0.739\n",
      "Epoch: 71/100..  Training Loss: 0.606..  Test Loss: 0.564..  Test Accuracy: 0.744\n",
      "Epoch: 72/100..  Training Loss: 0.604..  Test Loss: 0.565..  Test Accuracy: 0.738\n",
      "Epoch: 73/100..  Training Loss: 0.605..  Test Loss: 0.594..  Test Accuracy: 0.729\n",
      "Epoch: 74/100..  Training Loss: 0.604..  Test Loss: 0.566..  Test Accuracy: 0.744\n",
      "Epoch: 75/100..  Training Loss: 0.597..  Test Loss: 0.587..  Test Accuracy: 0.738\n",
      "Epoch: 76/100..  Training Loss: 0.595..  Test Loss: 0.562..  Test Accuracy: 0.726\n",
      "Epoch: 77/100..  Training Loss: 0.599..  Test Loss: 0.555..  Test Accuracy: 0.733\n",
      "Epoch: 78/100..  Training Loss: 0.612..  Test Loss: 0.561..  Test Accuracy: 0.736\n",
      "Epoch: 79/100..  Training Loss: 0.597..  Test Loss: 0.581..  Test Accuracy: 0.743\n",
      "Epoch: 80/100..  Training Loss: 0.604..  Test Loss: 0.560..  Test Accuracy: 0.733\n",
      "Epoch: 81/100..  Training Loss: 0.599..  Test Loss: 0.572..  Test Accuracy: 0.712\n",
      "Epoch: 82/100..  Training Loss: 0.612..  Test Loss: 0.582..  Test Accuracy: 0.720\n",
      "Epoch: 83/100..  Training Loss: 0.596..  Test Loss: 0.597..  Test Accuracy: 0.731\n",
      "Epoch: 84/100..  Training Loss: 0.628..  Test Loss: 0.579..  Test Accuracy: 0.729\n",
      "Epoch: 85/100..  Training Loss: 0.602..  Test Loss: 0.576..  Test Accuracy: 0.726\n",
      "Epoch: 86/100..  Training Loss: 0.590..  Test Loss: 0.578..  Test Accuracy: 0.728\n",
      "Epoch: 87/100..  Training Loss: 0.609..  Test Loss: 0.590..  Test Accuracy: 0.744\n",
      "Epoch: 88/100..  Training Loss: 0.612..  Test Loss: 0.599..  Test Accuracy: 0.712\n",
      "Epoch: 89/100..  Training Loss: 0.584..  Test Loss: 0.617..  Test Accuracy: 0.724\n",
      "Epoch: 90/100..  Training Loss: 0.581..  Test Loss: 0.578..  Test Accuracy: 0.739\n",
      "Epoch: 91/100..  Training Loss: 0.612..  Test Loss: 0.578..  Test Accuracy: 0.718\n",
      "Epoch: 92/100..  Training Loss: 0.608..  Test Loss: 0.563..  Test Accuracy: 0.730\n",
      "Epoch: 93/100..  Training Loss: 0.615..  Test Loss: 0.578..  Test Accuracy: 0.750\n",
      "Epoch: 94/100..  Training Loss: 0.595..  Test Loss: 0.567..  Test Accuracy: 0.744\n",
      "Epoch: 95/100..  Training Loss: 0.588..  Test Loss: 0.571..  Test Accuracy: 0.729\n",
      "Epoch: 96/100..  Training Loss: 0.599..  Test Loss: 0.605..  Test Accuracy: 0.720\n",
      "Epoch: 97/100..  Training Loss: 0.599..  Test Loss: 0.571..  Test Accuracy: 0.715\n",
      "Epoch: 98/100..  Training Loss: 0.605..  Test Loss: 0.570..  Test Accuracy: 0.708\n",
      "Epoch: 99/100..  Training Loss: 0.598..  Test Loss: 0.579..  Test Accuracy: 0.725\n",
      "Epoch: 100/100..  Training Loss: 0.608..  Test Loss: 0.570..  Test Accuracy: 0.722\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 2\n",
      "Epoch: 1/100..  Training Loss: 1.186..  Test Loss: 1.071..  Test Accuracy: 0.558\n",
      "Epoch: 2/100..  Training Loss: 0.923..  Test Loss: 0.862..  Test Accuracy: 0.666\n",
      "Epoch: 3/100..  Training Loss: 0.809..  Test Loss: 0.707..  Test Accuracy: 0.719\n",
      "Epoch: 4/100..  Training Loss: 0.728..  Test Loss: 0.747..  Test Accuracy: 0.656\n",
      "Epoch: 5/100..  Training Loss: 0.736..  Test Loss: 0.764..  Test Accuracy: 0.665\n",
      "Epoch: 6/100..  Training Loss: 0.695..  Test Loss: 0.658..  Test Accuracy: 0.729\n",
      "Epoch: 7/100..  Training Loss: 0.700..  Test Loss: 0.679..  Test Accuracy: 0.712\n",
      "Epoch: 8/100..  Training Loss: 0.698..  Test Loss: 0.665..  Test Accuracy: 0.712\n",
      "Epoch: 9/100..  Training Loss: 0.686..  Test Loss: 0.629..  Test Accuracy: 0.737\n",
      "Epoch: 10/100..  Training Loss: 0.676..  Test Loss: 0.643..  Test Accuracy: 0.731\n",
      "Epoch: 11/100..  Training Loss: 0.663..  Test Loss: 0.628..  Test Accuracy: 0.726\n",
      "Epoch: 12/100..  Training Loss: 0.686..  Test Loss: 0.665..  Test Accuracy: 0.716\n",
      "Epoch: 13/100..  Training Loss: 0.675..  Test Loss: 0.657..  Test Accuracy: 0.702\n",
      "Epoch: 14/100..  Training Loss: 0.648..  Test Loss: 0.664..  Test Accuracy: 0.720\n",
      "Epoch: 15/100..  Training Loss: 0.680..  Test Loss: 0.614..  Test Accuracy: 0.739\n",
      "Epoch: 16/100..  Training Loss: 0.683..  Test Loss: 0.703..  Test Accuracy: 0.730\n",
      "Epoch: 17/100..  Training Loss: 0.643..  Test Loss: 0.669..  Test Accuracy: 0.715\n",
      "Epoch: 18/100..  Training Loss: 0.644..  Test Loss: 0.631..  Test Accuracy: 0.742\n",
      "Epoch: 19/100..  Training Loss: 0.653..  Test Loss: 0.628..  Test Accuracy: 0.732\n",
      "Epoch: 20/100..  Training Loss: 0.649..  Test Loss: 0.633..  Test Accuracy: 0.725\n",
      "Epoch: 21/100..  Training Loss: 0.655..  Test Loss: 0.644..  Test Accuracy: 0.713\n",
      "Epoch: 22/100..  Training Loss: 0.653..  Test Loss: 0.621..  Test Accuracy: 0.743\n",
      "Epoch: 23/100..  Training Loss: 0.638..  Test Loss: 0.648..  Test Accuracy: 0.718\n",
      "Epoch: 24/100..  Training Loss: 0.642..  Test Loss: 0.628..  Test Accuracy: 0.704\n",
      "Epoch: 25/100..  Training Loss: 0.641..  Test Loss: 0.637..  Test Accuracy: 0.703\n",
      "Epoch: 26/100..  Training Loss: 0.642..  Test Loss: 0.624..  Test Accuracy: 0.733\n",
      "Epoch: 27/100..  Training Loss: 0.627..  Test Loss: 0.628..  Test Accuracy: 0.734\n",
      "Epoch: 28/100..  Training Loss: 0.637..  Test Loss: 0.636..  Test Accuracy: 0.737\n",
      "Epoch: 29/100..  Training Loss: 0.641..  Test Loss: 0.654..  Test Accuracy: 0.714\n",
      "Epoch: 30/100..  Training Loss: 0.617..  Test Loss: 0.641..  Test Accuracy: 0.703\n",
      "Epoch: 31/100..  Training Loss: 0.639..  Test Loss: 0.648..  Test Accuracy: 0.704\n",
      "Epoch: 32/100..  Training Loss: 0.645..  Test Loss: 0.650..  Test Accuracy: 0.727\n",
      "Epoch: 33/100..  Training Loss: 0.641..  Test Loss: 0.619..  Test Accuracy: 0.743\n",
      "Epoch: 34/100..  Training Loss: 0.632..  Test Loss: 0.627..  Test Accuracy: 0.732\n",
      "Epoch: 35/100..  Training Loss: 0.636..  Test Loss: 0.610..  Test Accuracy: 0.715\n",
      "Epoch: 36/100..  Training Loss: 0.624..  Test Loss: 0.610..  Test Accuracy: 0.739\n",
      "Epoch: 37/100..  Training Loss: 0.627..  Test Loss: 0.608..  Test Accuracy: 0.703\n",
      "Epoch: 38/100..  Training Loss: 0.625..  Test Loss: 0.630..  Test Accuracy: 0.702\n",
      "Epoch: 39/100..  Training Loss: 0.619..  Test Loss: 0.632..  Test Accuracy: 0.725\n",
      "Epoch: 40/100..  Training Loss: 0.620..  Test Loss: 0.642..  Test Accuracy: 0.710\n",
      "Epoch: 41/100..  Training Loss: 0.623..  Test Loss: 0.625..  Test Accuracy: 0.726\n",
      "Epoch: 42/100..  Training Loss: 0.622..  Test Loss: 0.615..  Test Accuracy: 0.732\n",
      "Epoch: 43/100..  Training Loss: 0.614..  Test Loss: 0.593..  Test Accuracy: 0.759\n",
      "Epoch: 44/100..  Training Loss: 0.617..  Test Loss: 0.635..  Test Accuracy: 0.710\n",
      "Epoch: 45/100..  Training Loss: 0.597..  Test Loss: 0.619..  Test Accuracy: 0.742\n",
      "Epoch: 46/100..  Training Loss: 0.612..  Test Loss: 0.629..  Test Accuracy: 0.732\n",
      "Epoch: 47/100..  Training Loss: 0.629..  Test Loss: 0.602..  Test Accuracy: 0.729\n",
      "Epoch: 48/100..  Training Loss: 0.635..  Test Loss: 0.605..  Test Accuracy: 0.716\n",
      "Epoch: 49/100..  Training Loss: 0.608..  Test Loss: 0.626..  Test Accuracy: 0.745\n",
      "Epoch: 50/100..  Training Loss: 0.607..  Test Loss: 0.620..  Test Accuracy: 0.736\n",
      "Epoch: 51/100..  Training Loss: 0.617..  Test Loss: 0.628..  Test Accuracy: 0.715\n",
      "Epoch: 52/100..  Training Loss: 0.615..  Test Loss: 0.635..  Test Accuracy: 0.735\n",
      "Epoch: 53/100..  Training Loss: 0.610..  Test Loss: 0.602..  Test Accuracy: 0.733\n",
      "Epoch: 54/100..  Training Loss: 0.612..  Test Loss: 0.591..  Test Accuracy: 0.741\n",
      "Epoch: 55/100..  Training Loss: 0.606..  Test Loss: 0.621..  Test Accuracy: 0.731\n",
      "Epoch: 56/100..  Training Loss: 0.604..  Test Loss: 0.599..  Test Accuracy: 0.745\n",
      "Epoch: 57/100..  Training Loss: 0.603..  Test Loss: 0.607..  Test Accuracy: 0.704\n",
      "Epoch: 58/100..  Training Loss: 0.622..  Test Loss: 0.618..  Test Accuracy: 0.722\n",
      "Epoch: 59/100..  Training Loss: 0.606..  Test Loss: 0.599..  Test Accuracy: 0.743\n",
      "Epoch: 60/100..  Training Loss: 0.618..  Test Loss: 0.644..  Test Accuracy: 0.726\n",
      "Epoch: 61/100..  Training Loss: 0.605..  Test Loss: 0.606..  Test Accuracy: 0.733\n",
      "Epoch: 62/100..  Training Loss: 0.606..  Test Loss: 0.625..  Test Accuracy: 0.712\n",
      "Epoch: 63/100..  Training Loss: 0.587..  Test Loss: 0.615..  Test Accuracy: 0.708\n",
      "Epoch: 64/100..  Training Loss: 0.610..  Test Loss: 0.596..  Test Accuracy: 0.738\n",
      "Epoch: 65/100..  Training Loss: 0.612..  Test Loss: 0.641..  Test Accuracy: 0.724\n",
      "Epoch: 66/100..  Training Loss: 0.598..  Test Loss: 0.631..  Test Accuracy: 0.728\n",
      "Epoch: 67/100..  Training Loss: 0.609..  Test Loss: 0.601..  Test Accuracy: 0.732\n",
      "Epoch: 68/100..  Training Loss: 0.598..  Test Loss: 0.626..  Test Accuracy: 0.722\n",
      "Epoch: 69/100..  Training Loss: 0.608..  Test Loss: 0.638..  Test Accuracy: 0.710\n",
      "Epoch: 70/100..  Training Loss: 0.593..  Test Loss: 0.620..  Test Accuracy: 0.717\n",
      "Epoch: 71/100..  Training Loss: 0.594..  Test Loss: 0.647..  Test Accuracy: 0.702\n",
      "Epoch: 72/100..  Training Loss: 0.591..  Test Loss: 0.610..  Test Accuracy: 0.717\n",
      "Epoch: 73/100..  Training Loss: 0.604..  Test Loss: 0.608..  Test Accuracy: 0.735\n",
      "Epoch: 74/100..  Training Loss: 0.612..  Test Loss: 0.610..  Test Accuracy: 0.732\n",
      "Epoch: 75/100..  Training Loss: 0.613..  Test Loss: 0.633..  Test Accuracy: 0.731\n",
      "Epoch: 76/100..  Training Loss: 0.606..  Test Loss: 0.600..  Test Accuracy: 0.723\n",
      "Epoch: 77/100..  Training Loss: 0.598..  Test Loss: 0.677..  Test Accuracy: 0.727\n",
      "Epoch: 78/100..  Training Loss: 0.600..  Test Loss: 0.637..  Test Accuracy: 0.727\n",
      "Epoch: 79/100..  Training Loss: 0.582..  Test Loss: 0.623..  Test Accuracy: 0.723\n",
      "Epoch: 80/100..  Training Loss: 0.595..  Test Loss: 0.646..  Test Accuracy: 0.696\n",
      "Epoch: 81/100..  Training Loss: 0.581..  Test Loss: 0.601..  Test Accuracy: 0.738\n",
      "Epoch: 82/100..  Training Loss: 0.589..  Test Loss: 0.626..  Test Accuracy: 0.707\n",
      "Epoch: 83/100..  Training Loss: 0.581..  Test Loss: 0.596..  Test Accuracy: 0.734\n",
      "Epoch: 84/100..  Training Loss: 0.592..  Test Loss: 0.608..  Test Accuracy: 0.721\n",
      "Epoch: 85/100..  Training Loss: 0.594..  Test Loss: 0.627..  Test Accuracy: 0.730\n",
      "Epoch: 86/100..  Training Loss: 0.617..  Test Loss: 0.636..  Test Accuracy: 0.723\n",
      "Epoch: 87/100..  Training Loss: 0.601..  Test Loss: 0.636..  Test Accuracy: 0.714\n",
      "Epoch: 88/100..  Training Loss: 0.597..  Test Loss: 0.594..  Test Accuracy: 0.726\n",
      "Epoch: 89/100..  Training Loss: 0.594..  Test Loss: 0.585..  Test Accuracy: 0.733\n",
      "Epoch: 90/100..  Training Loss: 0.586..  Test Loss: 0.666..  Test Accuracy: 0.700\n",
      "Epoch: 91/100..  Training Loss: 0.592..  Test Loss: 0.635..  Test Accuracy: 0.715\n",
      "Epoch: 92/100..  Training Loss: 0.585..  Test Loss: 0.620..  Test Accuracy: 0.736\n",
      "Epoch: 93/100..  Training Loss: 0.601..  Test Loss: 0.596..  Test Accuracy: 0.749\n",
      "Epoch: 94/100..  Training Loss: 0.589..  Test Loss: 0.624..  Test Accuracy: 0.709\n",
      "Epoch: 95/100..  Training Loss: 0.581..  Test Loss: 0.602..  Test Accuracy: 0.733\n",
      "Epoch: 96/100..  Training Loss: 0.582..  Test Loss: 0.599..  Test Accuracy: 0.738\n",
      "Epoch: 97/100..  Training Loss: 0.610..  Test Loss: 0.618..  Test Accuracy: 0.738\n",
      "Epoch: 98/100..  Training Loss: 0.577..  Test Loss: 0.624..  Test Accuracy: 0.742\n",
      "Epoch: 99/100..  Training Loss: 0.593..  Test Loss: 0.650..  Test Accuracy: 0.740\n",
      "Epoch: 100/100..  Training Loss: 0.600..  Test Loss: 0.657..  Test Accuracy: 0.722\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 3\n",
      "Epoch: 1/100..  Training Loss: 1.158..  Test Loss: 0.980..  Test Accuracy: 0.531\n",
      "Epoch: 2/100..  Training Loss: 0.937..  Test Loss: 0.818..  Test Accuracy: 0.634\n",
      "Epoch: 3/100..  Training Loss: 0.834..  Test Loss: 0.679..  Test Accuracy: 0.708\n",
      "Epoch: 4/100..  Training Loss: 0.778..  Test Loss: 0.654..  Test Accuracy: 0.733\n",
      "Epoch: 5/100..  Training Loss: 0.725..  Test Loss: 0.642..  Test Accuracy: 0.726\n",
      "Epoch: 6/100..  Training Loss: 0.716..  Test Loss: 0.648..  Test Accuracy: 0.738\n",
      "Epoch: 7/100..  Training Loss: 0.735..  Test Loss: 0.643..  Test Accuracy: 0.728\n",
      "Epoch: 8/100..  Training Loss: 0.711..  Test Loss: 0.630..  Test Accuracy: 0.725\n",
      "Epoch: 9/100..  Training Loss: 0.688..  Test Loss: 0.679..  Test Accuracy: 0.696\n",
      "Epoch: 10/100..  Training Loss: 0.716..  Test Loss: 0.641..  Test Accuracy: 0.735\n",
      "Epoch: 11/100..  Training Loss: 0.725..  Test Loss: 0.639..  Test Accuracy: 0.732\n",
      "Epoch: 12/100..  Training Loss: 0.688..  Test Loss: 0.693..  Test Accuracy: 0.704\n",
      "Epoch: 13/100..  Training Loss: 0.714..  Test Loss: 0.634..  Test Accuracy: 0.725\n",
      "Epoch: 14/100..  Training Loss: 0.670..  Test Loss: 0.632..  Test Accuracy: 0.731\n",
      "Epoch: 15/100..  Training Loss: 0.680..  Test Loss: 0.631..  Test Accuracy: 0.707\n",
      "Epoch: 16/100..  Training Loss: 0.677..  Test Loss: 0.607..  Test Accuracy: 0.731\n",
      "Epoch: 17/100..  Training Loss: 0.694..  Test Loss: 0.664..  Test Accuracy: 0.697\n",
      "Epoch: 18/100..  Training Loss: 0.686..  Test Loss: 0.614..  Test Accuracy: 0.727\n",
      "Epoch: 19/100..  Training Loss: 0.668..  Test Loss: 0.634..  Test Accuracy: 0.701\n",
      "Epoch: 20/100..  Training Loss: 0.692..  Test Loss: 0.642..  Test Accuracy: 0.710\n",
      "Epoch: 21/100..  Training Loss: 0.678..  Test Loss: 0.661..  Test Accuracy: 0.698\n",
      "Epoch: 22/100..  Training Loss: 0.661..  Test Loss: 0.638..  Test Accuracy: 0.737\n",
      "Epoch: 23/100..  Training Loss: 0.665..  Test Loss: 0.639..  Test Accuracy: 0.715\n",
      "Epoch: 24/100..  Training Loss: 0.662..  Test Loss: 0.626..  Test Accuracy: 0.725\n",
      "Epoch: 25/100..  Training Loss: 0.659..  Test Loss: 0.647..  Test Accuracy: 0.727\n",
      "Epoch: 26/100..  Training Loss: 0.655..  Test Loss: 0.638..  Test Accuracy: 0.717\n",
      "Epoch: 27/100..  Training Loss: 0.669..  Test Loss: 0.610..  Test Accuracy: 0.712\n",
      "Epoch: 28/100..  Training Loss: 0.666..  Test Loss: 0.607..  Test Accuracy: 0.715\n",
      "Epoch: 29/100..  Training Loss: 0.671..  Test Loss: 0.616..  Test Accuracy: 0.729\n",
      "Epoch: 30/100..  Training Loss: 0.648..  Test Loss: 0.651..  Test Accuracy: 0.714\n",
      "Epoch: 31/100..  Training Loss: 0.658..  Test Loss: 0.627..  Test Accuracy: 0.728\n",
      "Epoch: 32/100..  Training Loss: 0.646..  Test Loss: 0.624..  Test Accuracy: 0.711\n",
      "Epoch: 33/100..  Training Loss: 0.675..  Test Loss: 0.627..  Test Accuracy: 0.718\n",
      "Epoch: 34/100..  Training Loss: 0.621..  Test Loss: 0.621..  Test Accuracy: 0.729\n",
      "Epoch: 35/100..  Training Loss: 0.641..  Test Loss: 0.645..  Test Accuracy: 0.703\n",
      "Epoch: 36/100..  Training Loss: 0.642..  Test Loss: 0.620..  Test Accuracy: 0.716\n",
      "Epoch: 37/100..  Training Loss: 0.628..  Test Loss: 0.631..  Test Accuracy: 0.728\n",
      "Epoch: 38/100..  Training Loss: 0.640..  Test Loss: 0.628..  Test Accuracy: 0.690\n",
      "Epoch: 39/100..  Training Loss: 0.617..  Test Loss: 0.624..  Test Accuracy: 0.712\n",
      "Epoch: 40/100..  Training Loss: 0.646..  Test Loss: 0.617..  Test Accuracy: 0.728\n",
      "Epoch: 41/100..  Training Loss: 0.641..  Test Loss: 0.623..  Test Accuracy: 0.722\n",
      "Epoch: 42/100..  Training Loss: 0.649..  Test Loss: 0.633..  Test Accuracy: 0.728\n",
      "Epoch: 43/100..  Training Loss: 0.618..  Test Loss: 0.612..  Test Accuracy: 0.703\n",
      "Epoch: 44/100..  Training Loss: 0.653..  Test Loss: 0.656..  Test Accuracy: 0.705\n",
      "Epoch: 45/100..  Training Loss: 0.649..  Test Loss: 0.611..  Test Accuracy: 0.726\n",
      "Epoch: 46/100..  Training Loss: 0.613..  Test Loss: 0.618..  Test Accuracy: 0.744\n",
      "Epoch: 47/100..  Training Loss: 0.654..  Test Loss: 0.610..  Test Accuracy: 0.727\n",
      "Epoch: 48/100..  Training Loss: 0.620..  Test Loss: 0.627..  Test Accuracy: 0.730\n",
      "Epoch: 49/100..  Training Loss: 0.618..  Test Loss: 0.620..  Test Accuracy: 0.727\n",
      "Epoch: 50/100..  Training Loss: 0.632..  Test Loss: 0.624..  Test Accuracy: 0.716\n",
      "Epoch: 51/100..  Training Loss: 0.630..  Test Loss: 0.620..  Test Accuracy: 0.689\n",
      "Epoch: 52/100..  Training Loss: 0.618..  Test Loss: 0.619..  Test Accuracy: 0.733\n",
      "Epoch: 53/100..  Training Loss: 0.621..  Test Loss: 0.634..  Test Accuracy: 0.718\n",
      "Epoch: 54/100..  Training Loss: 0.597..  Test Loss: 0.604..  Test Accuracy: 0.731\n",
      "Epoch: 55/100..  Training Loss: 0.642..  Test Loss: 0.648..  Test Accuracy: 0.739\n",
      "Epoch: 56/100..  Training Loss: 0.630..  Test Loss: 0.643..  Test Accuracy: 0.726\n",
      "Epoch: 57/100..  Training Loss: 0.605..  Test Loss: 0.612..  Test Accuracy: 0.728\n",
      "Epoch: 58/100..  Training Loss: 0.630..  Test Loss: 0.604..  Test Accuracy: 0.734\n",
      "Epoch: 59/100..  Training Loss: 0.611..  Test Loss: 0.608..  Test Accuracy: 0.743\n",
      "Epoch: 60/100..  Training Loss: 0.601..  Test Loss: 0.612..  Test Accuracy: 0.732\n",
      "Epoch: 61/100..  Training Loss: 0.609..  Test Loss: 0.617..  Test Accuracy: 0.730\n",
      "Epoch: 62/100..  Training Loss: 0.620..  Test Loss: 0.629..  Test Accuracy: 0.728\n",
      "Epoch: 63/100..  Training Loss: 0.606..  Test Loss: 0.639..  Test Accuracy: 0.725\n",
      "Epoch: 64/100..  Training Loss: 0.596..  Test Loss: 0.608..  Test Accuracy: 0.755\n",
      "Epoch: 65/100..  Training Loss: 0.604..  Test Loss: 0.624..  Test Accuracy: 0.726\n",
      "Epoch: 66/100..  Training Loss: 0.614..  Test Loss: 0.628..  Test Accuracy: 0.720\n",
      "Epoch: 67/100..  Training Loss: 0.603..  Test Loss: 0.611..  Test Accuracy: 0.698\n",
      "Epoch: 68/100..  Training Loss: 0.613..  Test Loss: 0.624..  Test Accuracy: 0.723\n",
      "Epoch: 69/100..  Training Loss: 0.596..  Test Loss: 0.619..  Test Accuracy: 0.743\n",
      "Epoch: 70/100..  Training Loss: 0.611..  Test Loss: 0.653..  Test Accuracy: 0.725\n",
      "Epoch: 71/100..  Training Loss: 0.604..  Test Loss: 0.609..  Test Accuracy: 0.730\n",
      "Epoch: 72/100..  Training Loss: 0.576..  Test Loss: 0.631..  Test Accuracy: 0.723\n",
      "Epoch: 73/100..  Training Loss: 0.621..  Test Loss: 0.648..  Test Accuracy: 0.734\n",
      "Epoch: 74/100..  Training Loss: 0.610..  Test Loss: 0.623..  Test Accuracy: 0.730\n",
      "Epoch: 75/100..  Training Loss: 0.607..  Test Loss: 0.626..  Test Accuracy: 0.735\n",
      "Epoch: 76/100..  Training Loss: 0.611..  Test Loss: 0.626..  Test Accuracy: 0.732\n",
      "Epoch: 77/100..  Training Loss: 0.586..  Test Loss: 0.638..  Test Accuracy: 0.719\n",
      "Epoch: 78/100..  Training Loss: 0.628..  Test Loss: 0.649..  Test Accuracy: 0.723\n",
      "Epoch: 79/100..  Training Loss: 0.581..  Test Loss: 0.608..  Test Accuracy: 0.715\n",
      "Epoch: 80/100..  Training Loss: 0.604..  Test Loss: 0.607..  Test Accuracy: 0.725\n",
      "Epoch: 81/100..  Training Loss: 0.588..  Test Loss: 0.614..  Test Accuracy: 0.726\n",
      "Epoch: 82/100..  Training Loss: 0.610..  Test Loss: 0.627..  Test Accuracy: 0.716\n",
      "Epoch: 83/100..  Training Loss: 0.605..  Test Loss: 0.653..  Test Accuracy: 0.697\n",
      "Epoch: 84/100..  Training Loss: 0.595..  Test Loss: 0.666..  Test Accuracy: 0.732\n",
      "Epoch: 85/100..  Training Loss: 0.590..  Test Loss: 0.633..  Test Accuracy: 0.721\n",
      "Epoch: 86/100..  Training Loss: 0.582..  Test Loss: 0.617..  Test Accuracy: 0.735\n",
      "Epoch: 87/100..  Training Loss: 0.589..  Test Loss: 0.599..  Test Accuracy: 0.741\n",
      "Epoch: 88/100..  Training Loss: 0.618..  Test Loss: 0.620..  Test Accuracy: 0.735\n",
      "Epoch: 89/100..  Training Loss: 0.584..  Test Loss: 0.642..  Test Accuracy: 0.728\n",
      "Epoch: 90/100..  Training Loss: 0.579..  Test Loss: 0.631..  Test Accuracy: 0.748\n",
      "Epoch: 91/100..  Training Loss: 0.581..  Test Loss: 0.619..  Test Accuracy: 0.745\n",
      "Epoch: 92/100..  Training Loss: 0.584..  Test Loss: 0.646..  Test Accuracy: 0.705\n",
      "Epoch: 93/100..  Training Loss: 0.587..  Test Loss: 0.631..  Test Accuracy: 0.750\n",
      "Epoch: 94/100..  Training Loss: 0.585..  Test Loss: 0.620..  Test Accuracy: 0.736\n",
      "Epoch: 95/100..  Training Loss: 0.601..  Test Loss: 0.623..  Test Accuracy: 0.732\n",
      "Epoch: 96/100..  Training Loss: 0.611..  Test Loss: 0.644..  Test Accuracy: 0.724\n",
      "Epoch: 97/100..  Training Loss: 0.595..  Test Loss: 0.626..  Test Accuracy: 0.718\n",
      "Epoch: 98/100..  Training Loss: 0.593..  Test Loss: 0.611..  Test Accuracy: 0.748\n",
      "Epoch: 99/100..  Training Loss: 0.607..  Test Loss: 0.623..  Test Accuracy: 0.737\n",
      "Epoch: 100/100..  Training Loss: 0.574..  Test Loss: 0.630..  Test Accuracy: 0.730\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 4\n",
      "Epoch: 1/100..  Training Loss: 1.129..  Test Loss: 0.970..  Test Accuracy: 0.568\n",
      "Epoch: 2/100..  Training Loss: 0.899..  Test Loss: 0.757..  Test Accuracy: 0.699\n",
      "Epoch: 3/100..  Training Loss: 0.810..  Test Loss: 0.715..  Test Accuracy: 0.691\n",
      "Epoch: 4/100..  Training Loss: 0.804..  Test Loss: 0.683..  Test Accuracy: 0.701\n",
      "Epoch: 5/100..  Training Loss: 0.761..  Test Loss: 0.627..  Test Accuracy: 0.718\n",
      "Epoch: 6/100..  Training Loss: 0.742..  Test Loss: 0.607..  Test Accuracy: 0.734\n",
      "Epoch: 7/100..  Training Loss: 0.758..  Test Loss: 0.659..  Test Accuracy: 0.693\n",
      "Epoch: 8/100..  Training Loss: 0.720..  Test Loss: 0.616..  Test Accuracy: 0.723\n",
      "Epoch: 9/100..  Training Loss: 0.693..  Test Loss: 0.661..  Test Accuracy: 0.714\n",
      "Epoch: 10/100..  Training Loss: 0.697..  Test Loss: 0.642..  Test Accuracy: 0.709\n",
      "Epoch: 11/100..  Training Loss: 0.710..  Test Loss: 0.646..  Test Accuracy: 0.701\n",
      "Epoch: 12/100..  Training Loss: 0.712..  Test Loss: 0.613..  Test Accuracy: 0.725\n",
      "Epoch: 13/100..  Training Loss: 0.717..  Test Loss: 0.643..  Test Accuracy: 0.726\n",
      "Epoch: 14/100..  Training Loss: 0.699..  Test Loss: 0.658..  Test Accuracy: 0.707\n",
      "Epoch: 15/100..  Training Loss: 0.677..  Test Loss: 0.622..  Test Accuracy: 0.716\n",
      "Epoch: 16/100..  Training Loss: 0.674..  Test Loss: 0.631..  Test Accuracy: 0.690\n",
      "Epoch: 17/100..  Training Loss: 0.674..  Test Loss: 0.612..  Test Accuracy: 0.712\n",
      "Epoch: 18/100..  Training Loss: 0.695..  Test Loss: 0.609..  Test Accuracy: 0.710\n",
      "Epoch: 19/100..  Training Loss: 0.676..  Test Loss: 0.597..  Test Accuracy: 0.736\n",
      "Epoch: 20/100..  Training Loss: 0.669..  Test Loss: 0.610..  Test Accuracy: 0.736\n",
      "Epoch: 21/100..  Training Loss: 0.664..  Test Loss: 0.613..  Test Accuracy: 0.701\n",
      "Epoch: 22/100..  Training Loss: 0.661..  Test Loss: 0.597..  Test Accuracy: 0.713\n",
      "Epoch: 23/100..  Training Loss: 0.672..  Test Loss: 0.596..  Test Accuracy: 0.717\n",
      "Epoch: 24/100..  Training Loss: 0.663..  Test Loss: 0.605..  Test Accuracy: 0.721\n",
      "Epoch: 25/100..  Training Loss: 0.657..  Test Loss: 0.577..  Test Accuracy: 0.714\n",
      "Epoch: 26/100..  Training Loss: 0.642..  Test Loss: 0.580..  Test Accuracy: 0.721\n",
      "Epoch: 27/100..  Training Loss: 0.663..  Test Loss: 0.616..  Test Accuracy: 0.721\n",
      "Epoch: 28/100..  Training Loss: 0.661..  Test Loss: 0.580..  Test Accuracy: 0.721\n",
      "Epoch: 29/100..  Training Loss: 0.635..  Test Loss: 0.580..  Test Accuracy: 0.719\n",
      "Epoch: 30/100..  Training Loss: 0.635..  Test Loss: 0.603..  Test Accuracy: 0.723\n",
      "Epoch: 31/100..  Training Loss: 0.661..  Test Loss: 0.596..  Test Accuracy: 0.721\n",
      "Epoch: 32/100..  Training Loss: 0.645..  Test Loss: 0.601..  Test Accuracy: 0.714\n",
      "Epoch: 33/100..  Training Loss: 0.667..  Test Loss: 0.597..  Test Accuracy: 0.723\n",
      "Epoch: 34/100..  Training Loss: 0.621..  Test Loss: 0.587..  Test Accuracy: 0.718\n",
      "Epoch: 35/100..  Training Loss: 0.641..  Test Loss: 0.590..  Test Accuracy: 0.728\n",
      "Epoch: 36/100..  Training Loss: 0.635..  Test Loss: 0.569..  Test Accuracy: 0.730\n",
      "Epoch: 37/100..  Training Loss: 0.632..  Test Loss: 0.577..  Test Accuracy: 0.716\n",
      "Epoch: 38/100..  Training Loss: 0.661..  Test Loss: 0.577..  Test Accuracy: 0.724\n",
      "Epoch: 39/100..  Training Loss: 0.653..  Test Loss: 0.583..  Test Accuracy: 0.710\n",
      "Epoch: 40/100..  Training Loss: 0.642..  Test Loss: 0.555..  Test Accuracy: 0.727\n",
      "Epoch: 41/100..  Training Loss: 0.633..  Test Loss: 0.594..  Test Accuracy: 0.707\n",
      "Epoch: 42/100..  Training Loss: 0.646..  Test Loss: 0.592..  Test Accuracy: 0.727\n",
      "Epoch: 43/100..  Training Loss: 0.634..  Test Loss: 0.549..  Test Accuracy: 0.741\n",
      "Epoch: 44/100..  Training Loss: 0.646..  Test Loss: 0.602..  Test Accuracy: 0.714\n",
      "Epoch: 45/100..  Training Loss: 0.646..  Test Loss: 0.587..  Test Accuracy: 0.724\n",
      "Epoch: 46/100..  Training Loss: 0.622..  Test Loss: 0.586..  Test Accuracy: 0.721\n",
      "Epoch: 47/100..  Training Loss: 0.635..  Test Loss: 0.575..  Test Accuracy: 0.732\n",
      "Epoch: 48/100..  Training Loss: 0.622..  Test Loss: 0.569..  Test Accuracy: 0.723\n",
      "Epoch: 49/100..  Training Loss: 0.618..  Test Loss: 0.564..  Test Accuracy: 0.732\n",
      "Epoch: 50/100..  Training Loss: 0.650..  Test Loss: 0.570..  Test Accuracy: 0.712\n",
      "Epoch: 51/100..  Training Loss: 0.616..  Test Loss: 0.582..  Test Accuracy: 0.709\n",
      "Epoch: 52/100..  Training Loss: 0.621..  Test Loss: 0.571..  Test Accuracy: 0.703\n",
      "Epoch: 53/100..  Training Loss: 0.638..  Test Loss: 0.562..  Test Accuracy: 0.724\n",
      "Epoch: 54/100..  Training Loss: 0.632..  Test Loss: 0.579..  Test Accuracy: 0.737\n",
      "Epoch: 55/100..  Training Loss: 0.641..  Test Loss: 0.587..  Test Accuracy: 0.726\n",
      "Epoch: 56/100..  Training Loss: 0.625..  Test Loss: 0.559..  Test Accuracy: 0.741\n",
      "Epoch: 57/100..  Training Loss: 0.629..  Test Loss: 0.577..  Test Accuracy: 0.726\n",
      "Epoch: 58/100..  Training Loss: 0.621..  Test Loss: 0.566..  Test Accuracy: 0.737\n",
      "Epoch: 59/100..  Training Loss: 0.639..  Test Loss: 0.575..  Test Accuracy: 0.747\n",
      "Epoch: 60/100..  Training Loss: 0.614..  Test Loss: 0.564..  Test Accuracy: 0.717\n",
      "Epoch: 61/100..  Training Loss: 0.618..  Test Loss: 0.566..  Test Accuracy: 0.726\n",
      "Epoch: 62/100..  Training Loss: 0.630..  Test Loss: 0.584..  Test Accuracy: 0.742\n",
      "Epoch: 63/100..  Training Loss: 0.638..  Test Loss: 0.566..  Test Accuracy: 0.710\n",
      "Epoch: 64/100..  Training Loss: 0.607..  Test Loss: 0.563..  Test Accuracy: 0.710\n",
      "Epoch: 65/100..  Training Loss: 0.594..  Test Loss: 0.578..  Test Accuracy: 0.721\n",
      "Epoch: 66/100..  Training Loss: 0.631..  Test Loss: 0.557..  Test Accuracy: 0.719\n",
      "Epoch: 67/100..  Training Loss: 0.608..  Test Loss: 0.563..  Test Accuracy: 0.728\n",
      "Epoch: 68/100..  Training Loss: 0.614..  Test Loss: 0.579..  Test Accuracy: 0.715\n",
      "Epoch: 69/100..  Training Loss: 0.623..  Test Loss: 0.542..  Test Accuracy: 0.747\n",
      "Epoch: 70/100..  Training Loss: 0.593..  Test Loss: 0.584..  Test Accuracy: 0.732\n",
      "Epoch: 71/100..  Training Loss: 0.613..  Test Loss: 0.549..  Test Accuracy: 0.739\n",
      "Epoch: 72/100..  Training Loss: 0.601..  Test Loss: 0.578..  Test Accuracy: 0.744\n",
      "Epoch: 73/100..  Training Loss: 0.596..  Test Loss: 0.554..  Test Accuracy: 0.737\n",
      "Epoch: 74/100..  Training Loss: 0.599..  Test Loss: 0.542..  Test Accuracy: 0.746\n",
      "Epoch: 75/100..  Training Loss: 0.599..  Test Loss: 0.568..  Test Accuracy: 0.727\n",
      "Epoch: 76/100..  Training Loss: 0.605..  Test Loss: 0.566..  Test Accuracy: 0.746\n",
      "Epoch: 77/100..  Training Loss: 0.607..  Test Loss: 0.564..  Test Accuracy: 0.733\n",
      "Epoch: 78/100..  Training Loss: 0.602..  Test Loss: 0.546..  Test Accuracy: 0.743\n",
      "Epoch: 79/100..  Training Loss: 0.603..  Test Loss: 0.553..  Test Accuracy: 0.723\n",
      "Epoch: 80/100..  Training Loss: 0.617..  Test Loss: 0.567..  Test Accuracy: 0.744\n",
      "Epoch: 81/100..  Training Loss: 0.607..  Test Loss: 0.545..  Test Accuracy: 0.731\n",
      "Epoch: 82/100..  Training Loss: 0.604..  Test Loss: 0.536..  Test Accuracy: 0.742\n",
      "Epoch: 83/100..  Training Loss: 0.613..  Test Loss: 0.540..  Test Accuracy: 0.748\n",
      "Epoch: 84/100..  Training Loss: 0.609..  Test Loss: 0.556..  Test Accuracy: 0.728\n",
      "Epoch: 85/100..  Training Loss: 0.595..  Test Loss: 0.545..  Test Accuracy: 0.751\n",
      "Epoch: 86/100..  Training Loss: 0.571..  Test Loss: 0.543..  Test Accuracy: 0.734\n",
      "Epoch: 87/100..  Training Loss: 0.596..  Test Loss: 0.578..  Test Accuracy: 0.726\n",
      "Epoch: 88/100..  Training Loss: 0.601..  Test Loss: 0.555..  Test Accuracy: 0.727\n",
      "Epoch: 89/100..  Training Loss: 0.626..  Test Loss: 0.537..  Test Accuracy: 0.718\n",
      "Epoch: 90/100..  Training Loss: 0.598..  Test Loss: 0.566..  Test Accuracy: 0.735\n",
      "Epoch: 91/100..  Training Loss: 0.606..  Test Loss: 0.551..  Test Accuracy: 0.713\n",
      "Epoch: 92/100..  Training Loss: 0.592..  Test Loss: 0.536..  Test Accuracy: 0.730\n",
      "Epoch: 93/100..  Training Loss: 0.593..  Test Loss: 0.552..  Test Accuracy: 0.752\n",
      "Epoch: 94/100..  Training Loss: 0.598..  Test Loss: 0.552..  Test Accuracy: 0.705\n",
      "Epoch: 95/100..  Training Loss: 0.596..  Test Loss: 0.568..  Test Accuracy: 0.731\n",
      "Epoch: 96/100..  Training Loss: 0.604..  Test Loss: 0.548..  Test Accuracy: 0.756\n",
      "Epoch: 97/100..  Training Loss: 0.601..  Test Loss: 0.538..  Test Accuracy: 0.753\n",
      "Epoch: 98/100..  Training Loss: 0.603..  Test Loss: 0.554..  Test Accuracy: 0.739\n",
      "Epoch: 99/100..  Training Loss: 0.592..  Test Loss: 0.540..  Test Accuracy: 0.732\n",
      "Epoch: 100/100..  Training Loss: 0.598..  Test Loss: 0.524..  Test Accuracy: 0.747\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv = cv.split(X_train_scaled, y_train)\n",
    "\n",
    "m_hidden_layers = 1\n",
    "n_input = 6\n",
    "n_hidden = 12\n",
    "n_output = 5\n",
    "network_type = \"classification\"\n",
    "\n",
    "bs = 16\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "models = []\n",
    "max_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "    print(\"Model for Fold: \" + str(fold))\n",
    "\n",
    "    train_set, train_labels = X_train_scaled[train_idx], y_train[train_idx]\n",
    "    valid_set, valid_labels = X_train_scaled[val_idx], y_train[val_idx]\n",
    "    \n",
    "    trainset = HousePriceDataset(train_set, train_labels)\n",
    "    trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    validset = HousePriceDataset(valid_set, valid_labels)\n",
    "    validloader = DataLoader(validset, batch_size = bs, shuffle = True)\n",
    "    \n",
    "    model = NeuralNetwork(m_hidden_layers, n_input, n_hidden, n_output, network_type).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "    epochs = 100\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model_checkpoint = None\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "    \n",
    "        for features, labels in trainloader:\n",
    "            model.train()\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_ps = model(features.float())\n",
    "\n",
    "            loss = criterion(log_ps, labels)\n",
    "        \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for features, labels in validloader:\n",
    "                    \n",
    "                    model.eval()\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    log_ps = model(features.float())\n",
    "\n",
    "                    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                    top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    \n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))\n",
    "            \n",
    "            if (accuracy / len(validloader)) > best_accuracy:\n",
    "                best_accuracy = accuracy/len(validloader)\n",
    "                best_model_checkpoint = model\n",
    "            \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(validloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(validloader)))\n",
    "            \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "    models.append(best_model_checkpoint)\n",
    "    max_scores.append(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, with score: 0.776\n",
      "Fold: 1, with score: 0.754\n",
      "Fold: 2, with score: 0.759\n",
      "Fold: 3, with score: 0.755\n",
      "Fold: 4, with score: 0.756\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for score in max_scores:\n",
    "    print(\"Fold: {}, with score: {:.3f}\" .format(index, score.item()))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Testing Score: 0.7337110481586402\n"
     ]
    }
   ],
   "source": [
    "evalset = HousePriceDataset(X_test_scaled, y_test)\n",
    "loader  = DataLoader(evalset, batch_size=len(X_test_scaled))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in loader: \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        logs = 0\n",
    "        index = 0\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            log_ps = model(features.float())\n",
    "            logs += (log_ps * max_scores[index]) / sum(max_scores)\n",
    "            index += 1\n",
    "        \n",
    "        logs = logs / len(models)\n",
    "        \n",
    "        ps = torch.exp(logs)\n",
    "            \n",
    "        _, indices = torch.max(ps, dim = 1)\n",
    "        \n",
    "y_predict = indices.cpu().numpy()\n",
    "print(\"Final Model Testing Score: \" + str(accuracy_score(y_predict, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_predict)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Part \n",
    "- The differences will be: \n",
    "1. The loss function: Mean Squared Error\n",
    "2. Number of neurons in the final layer will one (a continuous value)\n",
    "3. Will need to find some optim thresholds to map that continuous value in the discrete labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 0\n",
      "Epoch: 1/100..  Training Loss: 8.904..  Test Loss: 8.117.. \n",
      "Epoch: 2/100..  Training Loss: 8.225..  Test Loss: 7.681.. \n",
      "Epoch: 3/100..  Training Loss: 7.618..  Test Loss: 7.253.. \n",
      "Epoch: 4/100..  Training Loss: 7.153..  Test Loss: 6.855.. \n",
      "Epoch: 5/100..  Training Loss: 6.746..  Test Loss: 6.517.. \n",
      "Epoch: 6/100..  Training Loss: 6.436..  Test Loss: 6.176.. \n",
      "Epoch: 7/100..  Training Loss: 6.122..  Test Loss: 5.866.. \n",
      "Epoch: 8/100..  Training Loss: 5.772..  Test Loss: 5.555.. \n",
      "Epoch: 9/100..  Training Loss: 5.476..  Test Loss: 5.171.. \n",
      "Epoch: 10/100..  Training Loss: 5.132..  Test Loss: 4.970.. \n",
      "Epoch: 11/100..  Training Loss: 4.938..  Test Loss: 4.764.. \n",
      "Epoch: 12/100..  Training Loss: 4.754..  Test Loss: 4.663.. \n",
      "Epoch: 13/100..  Training Loss: 4.470..  Test Loss: 4.511.. \n",
      "Epoch: 14/100..  Training Loss: 4.313..  Test Loss: 4.100.. \n",
      "Epoch: 15/100..  Training Loss: 4.073..  Test Loss: 3.931.. \n",
      "Epoch: 16/100..  Training Loss: 3.851..  Test Loss: 3.626.. \n",
      "Epoch: 17/100..  Training Loss: 3.656..  Test Loss: 3.631.. \n",
      "Epoch: 18/100..  Training Loss: 3.472..  Test Loss: 3.311.. \n",
      "Epoch: 19/100..  Training Loss: 3.337..  Test Loss: 3.301.. \n",
      "Epoch: 20/100..  Training Loss: 3.139..  Test Loss: 3.052.. \n",
      "Epoch: 21/100..  Training Loss: 3.044..  Test Loss: 2.949.. \n",
      "Epoch: 22/100..  Training Loss: 2.852..  Test Loss: 2.917.. \n",
      "Epoch: 23/100..  Training Loss: 2.776..  Test Loss: 2.758.. \n",
      "Epoch: 24/100..  Training Loss: 2.736..  Test Loss: 2.719.. \n",
      "Epoch: 25/100..  Training Loss: 2.668..  Test Loss: 2.683.. \n",
      "Epoch: 26/100..  Training Loss: 2.665..  Test Loss: 2.526.. \n",
      "Epoch: 27/100..  Training Loss: 2.653..  Test Loss: 2.542.. \n",
      "Epoch: 28/100..  Training Loss: 2.613..  Test Loss: 2.514.. \n",
      "Epoch: 29/100..  Training Loss: 2.616..  Test Loss: 2.476.. \n",
      "Epoch: 30/100..  Training Loss: 2.571..  Test Loss: 2.454.. \n",
      "Epoch: 31/100..  Training Loss: 2.554..  Test Loss: 2.377.. \n",
      "Epoch: 32/100..  Training Loss: 2.551..  Test Loss: 2.352.. \n",
      "Epoch: 33/100..  Training Loss: 2.536..  Test Loss: 2.356.. \n",
      "Epoch: 34/100..  Training Loss: 2.507..  Test Loss: 2.352.. \n",
      "Epoch: 35/100..  Training Loss: 2.496..  Test Loss: 2.366.. \n",
      "Epoch: 36/100..  Training Loss: 2.491..  Test Loss: 2.339.. \n",
      "Epoch: 37/100..  Training Loss: 2.485..  Test Loss: 2.321.. \n",
      "Epoch: 38/100..  Training Loss: 2.457..  Test Loss: 2.318.. \n",
      "Epoch: 39/100..  Training Loss: 2.417..  Test Loss: 2.297.. \n",
      "Epoch: 40/100..  Training Loss: 2.464..  Test Loss: 2.286.. \n",
      "Epoch: 41/100..  Training Loss: 2.431..  Test Loss: 2.267.. \n",
      "Epoch: 42/100..  Training Loss: 2.430..  Test Loss: 2.265.. \n",
      "Epoch: 43/100..  Training Loss: 2.422..  Test Loss: 2.249.. \n",
      "Epoch: 44/100..  Training Loss: 2.430..  Test Loss: 2.246.. \n",
      "Epoch: 45/100..  Training Loss: 2.418..  Test Loss: 2.230.. \n",
      "Epoch: 46/100..  Training Loss: 2.392..  Test Loss: 2.237.. \n",
      "Epoch: 47/100..  Training Loss: 2.388..  Test Loss: 2.233.. \n",
      "Epoch: 48/100..  Training Loss: 2.368..  Test Loss: 2.198.. \n",
      "Epoch: 49/100..  Training Loss: 2.377..  Test Loss: 2.207.. \n",
      "Epoch: 50/100..  Training Loss: 2.358..  Test Loss: 2.196.. \n",
      "Epoch: 51/100..  Training Loss: 2.365..  Test Loss: 2.188.. \n",
      "Epoch: 52/100..  Training Loss: 2.347..  Test Loss: 2.183.. \n",
      "Epoch: 53/100..  Training Loss: 2.350..  Test Loss: 2.170.. \n",
      "Epoch: 54/100..  Training Loss: 2.337..  Test Loss: 2.172.. \n",
      "Epoch: 55/100..  Training Loss: 2.331..  Test Loss: 2.166.. \n",
      "Epoch: 56/100..  Training Loss: 2.340..  Test Loss: 2.156.. \n",
      "Epoch: 57/100..  Training Loss: 2.330..  Test Loss: 2.154.. \n",
      "Epoch: 58/100..  Training Loss: 2.308..  Test Loss: 2.139.. \n",
      "Epoch: 59/100..  Training Loss: 2.326..  Test Loss: 2.145.. \n",
      "Epoch: 60/100..  Training Loss: 2.296..  Test Loss: 2.138.. \n",
      "Epoch: 61/100..  Training Loss: 2.299..  Test Loss: 2.130.. \n",
      "Epoch: 62/100..  Training Loss: 2.296..  Test Loss: 2.134.. \n",
      "Epoch: 63/100..  Training Loss: 2.284..  Test Loss: 2.128.. \n",
      "Epoch: 64/100..  Training Loss: 2.287..  Test Loss: 2.129.. \n",
      "Epoch: 65/100..  Training Loss: 2.283..  Test Loss: 2.123.. \n",
      "Epoch: 66/100..  Training Loss: 2.274..  Test Loss: 2.118.. \n",
      "Epoch: 67/100..  Training Loss: 2.261..  Test Loss: 2.124.. \n",
      "Epoch: 68/100..  Training Loss: 2.256..  Test Loss: 2.118.. \n",
      "Epoch: 69/100..  Training Loss: 2.246..  Test Loss: 2.117.. \n",
      "Epoch: 70/100..  Training Loss: 2.250..  Test Loss: 2.119.. \n",
      "Epoch: 71/100..  Training Loss: 2.243..  Test Loss: 2.113.. \n",
      "Epoch: 72/100..  Training Loss: 2.247..  Test Loss: 2.115.. \n",
      "Epoch: 73/100..  Training Loss: 2.247..  Test Loss: 2.113.. \n",
      "Epoch: 74/100..  Training Loss: 2.236..  Test Loss: 2.110.. \n",
      "Epoch: 75/100..  Training Loss: 2.238..  Test Loss: 2.109.. \n",
      "Epoch: 76/100..  Training Loss: 2.226..  Test Loss: 2.113.. \n",
      "Epoch: 77/100..  Training Loss: 2.236..  Test Loss: 2.104.. \n",
      "Epoch: 78/100..  Training Loss: 2.230..  Test Loss: 2.111.. \n",
      "Epoch: 79/100..  Training Loss: 2.227..  Test Loss: 2.107.. \n",
      "Epoch: 80/100..  Training Loss: 2.218..  Test Loss: 2.108.. \n",
      "Epoch: 81/100..  Training Loss: 2.226..  Test Loss: 2.103.. \n",
      "Epoch: 82/100..  Training Loss: 2.205..  Test Loss: 2.105.. \n",
      "Epoch: 83/100..  Training Loss: 2.204..  Test Loss: 2.101.. \n",
      "Epoch: 84/100..  Training Loss: 2.209..  Test Loss: 2.102.. \n",
      "Epoch: 85/100..  Training Loss: 2.212..  Test Loss: 2.101.. \n",
      "Epoch: 86/100..  Training Loss: 2.199..  Test Loss: 2.102.. \n",
      "Epoch: 87/100..  Training Loss: 2.199..  Test Loss: 2.094.. \n",
      "Epoch: 88/100..  Training Loss: 2.193..  Test Loss: 2.097.. \n",
      "Epoch: 89/100..  Training Loss: 2.188..  Test Loss: 2.095.. \n",
      "Epoch: 90/100..  Training Loss: 2.185..  Test Loss: 2.097.. \n",
      "Epoch: 91/100..  Training Loss: 2.182..  Test Loss: 2.093.. \n",
      "Epoch: 92/100..  Training Loss: 2.193..  Test Loss: 2.097.. \n",
      "Epoch: 93/100..  Training Loss: 2.186..  Test Loss: 2.095.. \n",
      "Epoch: 94/100..  Training Loss: 2.175..  Test Loss: 2.089.. \n",
      "Epoch: 95/100..  Training Loss: 2.175..  Test Loss: 2.091.. \n",
      "Epoch: 96/100..  Training Loss: 2.178..  Test Loss: 2.094.. \n",
      "Epoch: 97/100..  Training Loss: 2.176..  Test Loss: 2.093.. \n",
      "Epoch: 98/100..  Training Loss: 2.175..  Test Loss: 2.089.. \n",
      "Epoch: 99/100..  Training Loss: 2.172..  Test Loss: 2.091.. \n",
      "Epoch: 100/100..  Training Loss: 2.165..  Test Loss: 2.092.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 1\n",
      "Epoch: 1/100..  Training Loss: 9.569..  Test Loss: 8.788.. \n",
      "Epoch: 2/100..  Training Loss: 8.861..  Test Loss: 8.536.. \n",
      "Epoch: 3/100..  Training Loss: 8.263..  Test Loss: 8.074.. \n",
      "Epoch: 4/100..  Training Loss: 7.719..  Test Loss: 7.602.. \n",
      "Epoch: 5/100..  Training Loss: 7.160..  Test Loss: 7.056.. \n",
      "Epoch: 6/100..  Training Loss: 6.563..  Test Loss: 6.447.. \n",
      "Epoch: 7/100..  Training Loss: 6.067..  Test Loss: 5.976.. \n",
      "Epoch: 8/100..  Training Loss: 5.524..  Test Loss: 5.486.. \n",
      "Epoch: 9/100..  Training Loss: 5.043..  Test Loss: 5.016.. \n",
      "Epoch: 10/100..  Training Loss: 4.575..  Test Loss: 4.518.. \n",
      "Epoch: 11/100..  Training Loss: 4.219..  Test Loss: 4.157.. \n",
      "Epoch: 12/100..  Training Loss: 3.860..  Test Loss: 3.760.. \n",
      "Epoch: 13/100..  Training Loss: 3.584..  Test Loss: 3.508.. \n",
      "Epoch: 14/100..  Training Loss: 3.384..  Test Loss: 3.191.. \n",
      "Epoch: 15/100..  Training Loss: 3.170..  Test Loss: 2.978.. \n",
      "Epoch: 16/100..  Training Loss: 3.061..  Test Loss: 2.790.. \n",
      "Epoch: 17/100..  Training Loss: 2.900..  Test Loss: 2.617.. \n",
      "Epoch: 18/100..  Training Loss: 2.886..  Test Loss: 2.506.. \n",
      "Epoch: 19/100..  Training Loss: 2.801..  Test Loss: 2.420.. \n",
      "Epoch: 20/100..  Training Loss: 2.702..  Test Loss: 2.358.. \n",
      "Epoch: 21/100..  Training Loss: 2.795..  Test Loss: 2.341.. \n",
      "Epoch: 22/100..  Training Loss: 2.749..  Test Loss: 2.311.. \n",
      "Epoch: 23/100..  Training Loss: 2.681..  Test Loss: 2.317.. \n",
      "Epoch: 24/100..  Training Loss: 2.658..  Test Loss: 2.286.. \n",
      "Epoch: 25/100..  Training Loss: 2.694..  Test Loss: 2.256.. \n",
      "Epoch: 26/100..  Training Loss: 2.678..  Test Loss: 2.273.. \n",
      "Epoch: 27/100..  Training Loss: 2.657..  Test Loss: 2.287.. \n",
      "Epoch: 28/100..  Training Loss: 2.623..  Test Loss: 2.291.. \n",
      "Epoch: 29/100..  Training Loss: 2.631..  Test Loss: 2.272.. \n",
      "Epoch: 30/100..  Training Loss: 2.590..  Test Loss: 2.252.. \n",
      "Epoch: 31/100..  Training Loss: 2.600..  Test Loss: 2.261.. \n",
      "Epoch: 32/100..  Training Loss: 2.599..  Test Loss: 2.268.. \n",
      "Epoch: 33/100..  Training Loss: 2.580..  Test Loss: 2.278.. \n",
      "Epoch: 34/100..  Training Loss: 2.567..  Test Loss: 2.302.. \n",
      "Epoch: 35/100..  Training Loss: 2.554..  Test Loss: 2.276.. \n",
      "Epoch: 36/100..  Training Loss: 2.553..  Test Loss: 2.292.. \n",
      "Epoch: 37/100..  Training Loss: 2.537..  Test Loss: 2.253.. \n",
      "Epoch: 38/100..  Training Loss: 2.528..  Test Loss: 2.256.. \n",
      "Epoch: 39/100..  Training Loss: 2.530..  Test Loss: 2.240.. \n",
      "Epoch: 40/100..  Training Loss: 2.524..  Test Loss: 2.223.. \n",
      "Epoch: 41/100..  Training Loss: 2.497..  Test Loss: 2.249.. \n",
      "Epoch: 42/100..  Training Loss: 2.495..  Test Loss: 2.222.. \n",
      "Epoch: 43/100..  Training Loss: 2.501..  Test Loss: 2.224.. \n",
      "Epoch: 44/100..  Training Loss: 2.477..  Test Loss: 2.228.. \n",
      "Epoch: 45/100..  Training Loss: 2.467..  Test Loss: 2.214.. \n",
      "Epoch: 46/100..  Training Loss: 2.458..  Test Loss: 2.233.. \n",
      "Epoch: 47/100..  Training Loss: 2.455..  Test Loss: 2.211.. \n",
      "Epoch: 48/100..  Training Loss: 2.460..  Test Loss: 2.276.. \n",
      "Epoch: 49/100..  Training Loss: 2.424..  Test Loss: 2.186.. \n",
      "Epoch: 50/100..  Training Loss: 2.443..  Test Loss: 2.249.. \n",
      "Epoch: 51/100..  Training Loss: 2.451..  Test Loss: 2.212.. \n",
      "Epoch: 52/100..  Training Loss: 2.416..  Test Loss: 2.171.. \n",
      "Epoch: 53/100..  Training Loss: 2.409..  Test Loss: 2.162.. \n",
      "Epoch: 54/100..  Training Loss: 2.399..  Test Loss: 2.177.. \n",
      "Epoch: 55/100..  Training Loss: 2.416..  Test Loss: 2.168.. \n",
      "Epoch: 56/100..  Training Loss: 2.372..  Test Loss: 2.184.. \n",
      "Epoch: 57/100..  Training Loss: 2.389..  Test Loss: 2.185.. \n",
      "Epoch: 58/100..  Training Loss: 2.370..  Test Loss: 2.180.. \n",
      "Epoch: 59/100..  Training Loss: 2.372..  Test Loss: 2.169.. \n",
      "Epoch: 60/100..  Training Loss: 2.379..  Test Loss: 2.176.. \n",
      "Epoch: 61/100..  Training Loss: 2.374..  Test Loss: 2.157.. \n",
      "Epoch: 62/100..  Training Loss: 2.352..  Test Loss: 2.180.. \n",
      "Epoch: 63/100..  Training Loss: 2.367..  Test Loss: 2.141.. \n",
      "Epoch: 64/100..  Training Loss: 2.346..  Test Loss: 2.161.. \n",
      "Epoch: 65/100..  Training Loss: 2.324..  Test Loss: 2.183.. \n",
      "Epoch: 66/100..  Training Loss: 2.362..  Test Loss: 2.293.. \n",
      "Epoch: 67/100..  Training Loss: 2.335..  Test Loss: 2.154.. \n",
      "Epoch: 68/100..  Training Loss: 2.371..  Test Loss: 2.152.. \n",
      "Epoch: 69/100..  Training Loss: 2.343..  Test Loss: 2.174.. \n",
      "Epoch: 70/100..  Training Loss: 2.326..  Test Loss: 2.155.. \n",
      "Epoch: 71/100..  Training Loss: 2.309..  Test Loss: 2.140.. \n",
      "Epoch: 72/100..  Training Loss: 2.323..  Test Loss: 2.132.. \n",
      "Epoch: 73/100..  Training Loss: 2.316..  Test Loss: 2.142.. \n",
      "Epoch: 74/100..  Training Loss: 2.307..  Test Loss: 2.141.. \n",
      "Epoch: 75/100..  Training Loss: 2.295..  Test Loss: 2.138.. \n",
      "Epoch: 76/100..  Training Loss: 2.323..  Test Loss: 2.139.. \n",
      "Epoch: 77/100..  Training Loss: 2.301..  Test Loss: 2.142.. \n",
      "Epoch: 78/100..  Training Loss: 2.325..  Test Loss: 2.134.. \n",
      "Epoch: 79/100..  Training Loss: 2.289..  Test Loss: 2.133.. \n",
      "Epoch: 80/100..  Training Loss: 2.297..  Test Loss: 2.148.. \n",
      "Epoch: 81/100..  Training Loss: 2.281..  Test Loss: 2.137.. \n",
      "Epoch: 82/100..  Training Loss: 2.294..  Test Loss: 2.125.. \n",
      "Epoch: 83/100..  Training Loss: 2.291..  Test Loss: 2.147.. \n",
      "Epoch: 84/100..  Training Loss: 2.267..  Test Loss: 2.145.. \n",
      "Epoch: 85/100..  Training Loss: 2.281..  Test Loss: 2.131.. \n",
      "Epoch: 86/100..  Training Loss: 2.269..  Test Loss: 2.129.. \n",
      "Epoch: 87/100..  Training Loss: 2.270..  Test Loss: 2.138.. \n",
      "Epoch: 88/100..  Training Loss: 2.252..  Test Loss: 2.125.. \n",
      "Epoch: 89/100..  Training Loss: 2.255..  Test Loss: 2.125.. \n",
      "Epoch: 90/100..  Training Loss: 2.245..  Test Loss: 2.131.. \n",
      "Epoch: 91/100..  Training Loss: 2.243..  Test Loss: 2.113.. \n",
      "Epoch: 92/100..  Training Loss: 2.243..  Test Loss: 2.134.. \n",
      "Epoch: 93/100..  Training Loss: 2.245..  Test Loss: 2.125.. \n",
      "Epoch: 94/100..  Training Loss: 2.246..  Test Loss: 2.128.. \n",
      "Epoch: 95/100..  Training Loss: 2.244..  Test Loss: 2.112.. \n",
      "Epoch: 96/100..  Training Loss: 2.231..  Test Loss: 2.122.. \n",
      "Epoch: 97/100..  Training Loss: 2.226..  Test Loss: 2.120.. \n",
      "Epoch: 98/100..  Training Loss: 2.229..  Test Loss: 2.113.. \n",
      "Epoch: 99/100..  Training Loss: 2.237..  Test Loss: 2.118.. \n",
      "Epoch: 100/100..  Training Loss: 2.218..  Test Loss: 2.117.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 2\n",
      "Epoch: 1/100..  Training Loss: 8.080..  Test Loss: 7.724.. \n",
      "Epoch: 2/100..  Training Loss: 7.460..  Test Loss: 7.213.. \n",
      "Epoch: 3/100..  Training Loss: 6.914..  Test Loss: 6.734.. \n",
      "Epoch: 4/100..  Training Loss: 6.384..  Test Loss: 6.236.. \n",
      "Epoch: 5/100..  Training Loss: 5.906..  Test Loss: 5.833.. \n",
      "Epoch: 6/100..  Training Loss: 5.422..  Test Loss: 5.425.. \n",
      "Epoch: 7/100..  Training Loss: 5.054..  Test Loss: 4.904.. \n",
      "Epoch: 8/100..  Training Loss: 4.617..  Test Loss: 4.555.. \n",
      "Epoch: 9/100..  Training Loss: 4.243..  Test Loss: 4.215.. \n",
      "Epoch: 10/100..  Training Loss: 3.921..  Test Loss: 3.831.. \n",
      "Epoch: 11/100..  Training Loss: 3.650..  Test Loss: 3.492.. \n",
      "Epoch: 12/100..  Training Loss: 3.385..  Test Loss: 3.248.. \n",
      "Epoch: 13/100..  Training Loss: 3.192..  Test Loss: 2.966.. \n",
      "Epoch: 14/100..  Training Loss: 3.006..  Test Loss: 2.742.. \n",
      "Epoch: 15/100..  Training Loss: 2.910..  Test Loss: 2.638.. \n",
      "Epoch: 16/100..  Training Loss: 2.775..  Test Loss: 2.490.. \n",
      "Epoch: 17/100..  Training Loss: 2.742..  Test Loss: 2.384.. \n",
      "Epoch: 18/100..  Training Loss: 2.702..  Test Loss: 2.363.. \n",
      "Epoch: 19/100..  Training Loss: 2.658..  Test Loss: 2.337.. \n",
      "Epoch: 20/100..  Training Loss: 2.638..  Test Loss: 2.303.. \n",
      "Epoch: 21/100..  Training Loss: 2.623..  Test Loss: 2.286.. \n",
      "Epoch: 22/100..  Training Loss: 2.568..  Test Loss: 2.286.. \n",
      "Epoch: 23/100..  Training Loss: 2.574..  Test Loss: 2.290.. \n",
      "Epoch: 24/100..  Training Loss: 2.562..  Test Loss: 2.261.. \n",
      "Epoch: 25/100..  Training Loss: 2.563..  Test Loss: 2.265.. \n",
      "Epoch: 26/100..  Training Loss: 2.530..  Test Loss: 2.219.. \n",
      "Epoch: 27/100..  Training Loss: 2.546..  Test Loss: 2.210.. \n",
      "Epoch: 28/100..  Training Loss: 2.505..  Test Loss: 2.253.. \n",
      "Epoch: 29/100..  Training Loss: 2.521..  Test Loss: 2.237.. \n",
      "Epoch: 30/100..  Training Loss: 2.519..  Test Loss: 2.213.. \n",
      "Epoch: 31/100..  Training Loss: 2.484..  Test Loss: 2.217.. \n",
      "Epoch: 32/100..  Training Loss: 2.502..  Test Loss: 2.209.. \n",
      "Epoch: 33/100..  Training Loss: 2.462..  Test Loss: 2.197.. \n",
      "Epoch: 34/100..  Training Loss: 2.482..  Test Loss: 2.234.. \n",
      "Epoch: 35/100..  Training Loss: 2.449..  Test Loss: 2.191.. \n",
      "Epoch: 36/100..  Training Loss: 2.439..  Test Loss: 2.182.. \n",
      "Epoch: 37/100..  Training Loss: 2.455..  Test Loss: 2.174.. \n",
      "Epoch: 38/100..  Training Loss: 2.452..  Test Loss: 2.167.. \n",
      "Epoch: 39/100..  Training Loss: 2.435..  Test Loss: 2.166.. \n",
      "Epoch: 40/100..  Training Loss: 2.408..  Test Loss: 2.160.. \n",
      "Epoch: 41/100..  Training Loss: 2.397..  Test Loss: 2.180.. \n",
      "Epoch: 42/100..  Training Loss: 2.419..  Test Loss: 2.199.. \n",
      "Epoch: 43/100..  Training Loss: 2.405..  Test Loss: 2.189.. \n",
      "Epoch: 44/100..  Training Loss: 2.401..  Test Loss: 2.175.. \n",
      "Epoch: 45/100..  Training Loss: 2.409..  Test Loss: 2.172.. \n",
      "Epoch: 46/100..  Training Loss: 2.395..  Test Loss: 2.194.. \n",
      "Epoch: 47/100..  Training Loss: 2.384..  Test Loss: 2.178.. \n",
      "Epoch: 48/100..  Training Loss: 2.359..  Test Loss: 2.165.. \n",
      "Epoch: 49/100..  Training Loss: 2.368..  Test Loss: 2.147.. \n",
      "Epoch: 50/100..  Training Loss: 2.338..  Test Loss: 2.170.. \n",
      "Epoch: 51/100..  Training Loss: 2.363..  Test Loss: 2.149.. \n",
      "Epoch: 52/100..  Training Loss: 2.332..  Test Loss: 2.136.. \n",
      "Epoch: 53/100..  Training Loss: 2.349..  Test Loss: 2.146.. \n",
      "Epoch: 54/100..  Training Loss: 2.344..  Test Loss: 2.162.. \n",
      "Epoch: 55/100..  Training Loss: 2.359..  Test Loss: 2.171.. \n",
      "Epoch: 56/100..  Training Loss: 2.341..  Test Loss: 2.228.. \n",
      "Epoch: 57/100..  Training Loss: 2.325..  Test Loss: 2.144.. \n",
      "Epoch: 58/100..  Training Loss: 2.345..  Test Loss: 2.143.. \n",
      "Epoch: 59/100..  Training Loss: 2.321..  Test Loss: 2.142.. \n",
      "Epoch: 60/100..  Training Loss: 2.328..  Test Loss: 2.157.. \n",
      "Epoch: 61/100..  Training Loss: 2.314..  Test Loss: 2.164.. \n",
      "Epoch: 62/100..  Training Loss: 2.297..  Test Loss: 2.141.. \n",
      "Epoch: 63/100..  Training Loss: 2.298..  Test Loss: 2.137.. \n",
      "Epoch: 64/100..  Training Loss: 2.315..  Test Loss: 2.164.. \n",
      "Epoch: 65/100..  Training Loss: 2.302..  Test Loss: 2.138.. \n",
      "Epoch: 66/100..  Training Loss: 2.308..  Test Loss: 2.130.. \n",
      "Epoch: 67/100..  Training Loss: 2.307..  Test Loss: 2.140.. \n",
      "Epoch: 68/100..  Training Loss: 2.289..  Test Loss: 2.129.. \n",
      "Epoch: 69/100..  Training Loss: 2.287..  Test Loss: 2.134.. \n",
      "Epoch: 70/100..  Training Loss: 2.283..  Test Loss: 2.136.. \n",
      "Epoch: 71/100..  Training Loss: 2.276..  Test Loss: 2.134.. \n",
      "Epoch: 72/100..  Training Loss: 2.257..  Test Loss: 2.128.. \n",
      "Epoch: 73/100..  Training Loss: 2.273..  Test Loss: 2.130.. \n",
      "Epoch: 74/100..  Training Loss: 2.282..  Test Loss: 2.126.. \n",
      "Epoch: 75/100..  Training Loss: 2.277..  Test Loss: 2.128.. \n",
      "Epoch: 76/100..  Training Loss: 2.254..  Test Loss: 2.124.. \n",
      "Epoch: 77/100..  Training Loss: 2.275..  Test Loss: 2.118.. \n",
      "Epoch: 78/100..  Training Loss: 2.243..  Test Loss: 2.126.. \n",
      "Epoch: 79/100..  Training Loss: 2.245..  Test Loss: 2.122.. \n",
      "Epoch: 80/100..  Training Loss: 2.254..  Test Loss: 2.120.. \n",
      "Epoch: 81/100..  Training Loss: 2.256..  Test Loss: 2.125.. \n",
      "Epoch: 82/100..  Training Loss: 2.246..  Test Loss: 2.118.. \n",
      "Epoch: 83/100..  Training Loss: 2.245..  Test Loss: 2.121.. \n",
      "Epoch: 84/100..  Training Loss: 2.223..  Test Loss: 2.121.. \n",
      "Epoch: 85/100..  Training Loss: 2.239..  Test Loss: 2.119.. \n",
      "Epoch: 86/100..  Training Loss: 2.240..  Test Loss: 2.116.. \n",
      "Epoch: 87/100..  Training Loss: 2.242..  Test Loss: 2.113.. \n",
      "Epoch: 88/100..  Training Loss: 2.222..  Test Loss: 2.114.. \n",
      "Epoch: 89/100..  Training Loss: 2.225..  Test Loss: 2.115.. \n",
      "Epoch: 90/100..  Training Loss: 2.209..  Test Loss: 2.116.. \n",
      "Epoch: 91/100..  Training Loss: 2.211..  Test Loss: 2.108.. \n",
      "Epoch: 92/100..  Training Loss: 2.202..  Test Loss: 2.119.. \n",
      "Epoch: 93/100..  Training Loss: 2.203..  Test Loss: 2.111.. \n",
      "Epoch: 94/100..  Training Loss: 2.209..  Test Loss: 2.106.. \n",
      "Epoch: 95/100..  Training Loss: 2.199..  Test Loss: 2.101.. \n",
      "Epoch: 96/100..  Training Loss: 2.208..  Test Loss: 2.110.. \n",
      "Epoch: 97/100..  Training Loss: 2.192..  Test Loss: 2.105.. \n",
      "Epoch: 98/100..  Training Loss: 2.196..  Test Loss: 2.104.. \n",
      "Epoch: 99/100..  Training Loss: 2.192..  Test Loss: 2.104.. \n",
      "Epoch: 100/100..  Training Loss: 2.193..  Test Loss: 2.113.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 3\n",
      "Epoch: 1/100..  Training Loss: 8.178..  Test Loss: 7.917.. \n",
      "Epoch: 2/100..  Training Loss: 7.619..  Test Loss: 7.362.. \n",
      "Epoch: 3/100..  Training Loss: 7.080..  Test Loss: 6.972.. \n",
      "Epoch: 4/100..  Training Loss: 6.613..  Test Loss: 6.550.. \n",
      "Epoch: 5/100..  Training Loss: 6.158..  Test Loss: 6.086.. \n",
      "Epoch: 6/100..  Training Loss: 5.691..  Test Loss: 5.673.. \n",
      "Epoch: 7/100..  Training Loss: 5.286..  Test Loss: 5.270.. \n",
      "Epoch: 8/100..  Training Loss: 4.864..  Test Loss: 4.812.. \n",
      "Epoch: 9/100..  Training Loss: 4.517..  Test Loss: 4.415.. \n",
      "Epoch: 10/100..  Training Loss: 4.121..  Test Loss: 4.070.. \n",
      "Epoch: 11/100..  Training Loss: 3.790..  Test Loss: 3.623.. \n",
      "Epoch: 12/100..  Training Loss: 3.471..  Test Loss: 3.385.. \n",
      "Epoch: 13/100..  Training Loss: 3.234..  Test Loss: 3.097.. \n",
      "Epoch: 14/100..  Training Loss: 3.032..  Test Loss: 2.863.. \n",
      "Epoch: 15/100..  Training Loss: 2.956..  Test Loss: 2.708.. \n",
      "Epoch: 16/100..  Training Loss: 2.817..  Test Loss: 2.619.. \n",
      "Epoch: 17/100..  Training Loss: 2.778..  Test Loss: 2.532.. \n",
      "Epoch: 18/100..  Training Loss: 2.734..  Test Loss: 2.458.. \n",
      "Epoch: 19/100..  Training Loss: 2.755..  Test Loss: 2.440.. \n",
      "Epoch: 20/100..  Training Loss: 2.704..  Test Loss: 2.405.. \n",
      "Epoch: 21/100..  Training Loss: 2.673..  Test Loss: 2.359.. \n",
      "Epoch: 22/100..  Training Loss: 2.683..  Test Loss: 2.353.. \n",
      "Epoch: 23/100..  Training Loss: 2.650..  Test Loss: 2.331.. \n",
      "Epoch: 24/100..  Training Loss: 2.643..  Test Loss: 2.333.. \n",
      "Epoch: 25/100..  Training Loss: 2.629..  Test Loss: 2.310.. \n",
      "Epoch: 26/100..  Training Loss: 2.603..  Test Loss: 2.311.. \n",
      "Epoch: 27/100..  Training Loss: 2.601..  Test Loss: 2.301.. \n",
      "Epoch: 28/100..  Training Loss: 2.578..  Test Loss: 2.281.. \n",
      "Epoch: 29/100..  Training Loss: 2.569..  Test Loss: 2.271.. \n",
      "Epoch: 30/100..  Training Loss: 2.556..  Test Loss: 2.251.. \n",
      "Epoch: 31/100..  Training Loss: 2.536..  Test Loss: 2.260.. \n",
      "Epoch: 32/100..  Training Loss: 2.513..  Test Loss: 2.250.. \n",
      "Epoch: 33/100..  Training Loss: 2.503..  Test Loss: 2.245.. \n",
      "Epoch: 34/100..  Training Loss: 2.517..  Test Loss: 2.250.. \n",
      "Epoch: 35/100..  Training Loss: 2.490..  Test Loss: 2.250.. \n",
      "Epoch: 36/100..  Training Loss: 2.496..  Test Loss: 2.242.. \n",
      "Epoch: 37/100..  Training Loss: 2.463..  Test Loss: 2.228.. \n",
      "Epoch: 38/100..  Training Loss: 2.473..  Test Loss: 2.219.. \n",
      "Epoch: 39/100..  Training Loss: 2.482..  Test Loss: 2.224.. \n",
      "Epoch: 40/100..  Training Loss: 2.443..  Test Loss: 2.216.. \n",
      "Epoch: 41/100..  Training Loss: 2.407..  Test Loss: 2.214.. \n",
      "Epoch: 42/100..  Training Loss: 2.420..  Test Loss: 2.198.. \n",
      "Epoch: 43/100..  Training Loss: 2.429..  Test Loss: 2.204.. \n",
      "Epoch: 44/100..  Training Loss: 2.406..  Test Loss: 2.193.. \n",
      "Epoch: 45/100..  Training Loss: 2.425..  Test Loss: 2.199.. \n",
      "Epoch: 46/100..  Training Loss: 2.388..  Test Loss: 2.181.. \n",
      "Epoch: 47/100..  Training Loss: 2.384..  Test Loss: 2.181.. \n",
      "Epoch: 48/100..  Training Loss: 2.378..  Test Loss: 2.188.. \n",
      "Epoch: 49/100..  Training Loss: 2.376..  Test Loss: 2.183.. \n",
      "Epoch: 50/100..  Training Loss: 2.365..  Test Loss: 2.181.. \n",
      "Epoch: 51/100..  Training Loss: 2.386..  Test Loss: 2.178.. \n",
      "Epoch: 52/100..  Training Loss: 2.352..  Test Loss: 2.176.. \n",
      "Epoch: 53/100..  Training Loss: 2.360..  Test Loss: 2.181.. \n",
      "Epoch: 54/100..  Training Loss: 2.351..  Test Loss: 2.163.. \n",
      "Epoch: 55/100..  Training Loss: 2.352..  Test Loss: 2.164.. \n",
      "Epoch: 56/100..  Training Loss: 2.327..  Test Loss: 2.163.. \n",
      "Epoch: 57/100..  Training Loss: 2.319..  Test Loss: 2.156.. \n",
      "Epoch: 58/100..  Training Loss: 2.312..  Test Loss: 2.148.. \n",
      "Epoch: 59/100..  Training Loss: 2.316..  Test Loss: 2.160.. \n",
      "Epoch: 60/100..  Training Loss: 2.307..  Test Loss: 2.152.. \n",
      "Epoch: 61/100..  Training Loss: 2.314..  Test Loss: 2.151.. \n",
      "Epoch: 62/100..  Training Loss: 2.285..  Test Loss: 2.140.. \n",
      "Epoch: 63/100..  Training Loss: 2.290..  Test Loss: 2.138.. \n",
      "Epoch: 64/100..  Training Loss: 2.302..  Test Loss: 2.136.. \n",
      "Epoch: 65/100..  Training Loss: 2.282..  Test Loss: 2.143.. \n",
      "Epoch: 66/100..  Training Loss: 2.284..  Test Loss: 2.133.. \n",
      "Epoch: 67/100..  Training Loss: 2.275..  Test Loss: 2.129.. \n",
      "Epoch: 68/100..  Training Loss: 2.268..  Test Loss: 2.125.. \n",
      "Epoch: 69/100..  Training Loss: 2.259..  Test Loss: 2.124.. \n",
      "Epoch: 70/100..  Training Loss: 2.270..  Test Loss: 2.127.. \n",
      "Epoch: 71/100..  Training Loss: 2.263..  Test Loss: 2.119.. \n",
      "Epoch: 72/100..  Training Loss: 2.272..  Test Loss: 2.121.. \n",
      "Epoch: 73/100..  Training Loss: 2.260..  Test Loss: 2.123.. \n",
      "Epoch: 74/100..  Training Loss: 2.237..  Test Loss: 2.130.. \n",
      "Epoch: 75/100..  Training Loss: 2.254..  Test Loss: 2.122.. \n",
      "Epoch: 76/100..  Training Loss: 2.244..  Test Loss: 2.124.. \n",
      "Epoch: 77/100..  Training Loss: 2.241..  Test Loss: 2.116.. \n",
      "Epoch: 78/100..  Training Loss: 2.236..  Test Loss: 2.121.. \n",
      "Epoch: 79/100..  Training Loss: 2.249..  Test Loss: 2.109.. \n",
      "Epoch: 80/100..  Training Loss: 2.238..  Test Loss: 2.115.. \n",
      "Epoch: 81/100..  Training Loss: 2.235..  Test Loss: 2.115.. \n",
      "Epoch: 82/100..  Training Loss: 2.210..  Test Loss: 2.106.. \n",
      "Epoch: 83/100..  Training Loss: 2.223..  Test Loss: 2.108.. \n",
      "Epoch: 84/100..  Training Loss: 2.224..  Test Loss: 2.111.. \n",
      "Epoch: 85/100..  Training Loss: 2.224..  Test Loss: 2.107.. \n",
      "Epoch: 86/100..  Training Loss: 2.211..  Test Loss: 2.107.. \n",
      "Epoch: 87/100..  Training Loss: 2.216..  Test Loss: 2.107.. \n",
      "Epoch: 88/100..  Training Loss: 2.204..  Test Loss: 2.105.. \n",
      "Epoch: 89/100..  Training Loss: 2.207..  Test Loss: 2.098.. \n",
      "Epoch: 90/100..  Training Loss: 2.203..  Test Loss: 2.103.. \n",
      "Epoch: 91/100..  Training Loss: 2.198..  Test Loss: 2.108.. \n",
      "Epoch: 92/100..  Training Loss: 2.196..  Test Loss: 2.097.. \n",
      "Epoch: 93/100..  Training Loss: 2.196..  Test Loss: 2.103.. \n",
      "Epoch: 94/100..  Training Loss: 2.190..  Test Loss: 2.109.. \n",
      "Epoch: 95/100..  Training Loss: 2.192..  Test Loss: 2.103.. \n",
      "Epoch: 96/100..  Training Loss: 2.188..  Test Loss: 2.100.. \n",
      "Epoch: 97/100..  Training Loss: 2.189..  Test Loss: 2.099.. \n",
      "Epoch: 98/100..  Training Loss: 2.185..  Test Loss: 2.097.. \n",
      "Epoch: 99/100..  Training Loss: 2.187..  Test Loss: 2.103.. \n",
      "Epoch: 100/100..  Training Loss: 2.182..  Test Loss: 2.100.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 4\n",
      "Epoch: 1/100..  Training Loss: 3.902..  Test Loss: 3.821.. \n",
      "Epoch: 2/100..  Training Loss: 3.614..  Test Loss: 3.541.. \n",
      "Epoch: 3/100..  Training Loss: 3.468..  Test Loss: 3.216.. \n",
      "Epoch: 4/100..  Training Loss: 3.254..  Test Loss: 3.087.. \n",
      "Epoch: 5/100..  Training Loss: 3.009..  Test Loss: 2.893.. \n",
      "Epoch: 6/100..  Training Loss: 2.828..  Test Loss: 2.715.. \n",
      "Epoch: 7/100..  Training Loss: 2.678..  Test Loss: 2.553.. \n",
      "Epoch: 8/100..  Training Loss: 2.576..  Test Loss: 2.447.. \n",
      "Epoch: 9/100..  Training Loss: 2.518..  Test Loss: 2.382.. \n",
      "Epoch: 10/100..  Training Loss: 2.467..  Test Loss: 2.333.. \n",
      "Epoch: 11/100..  Training Loss: 2.439..  Test Loss: 2.305.. \n",
      "Epoch: 12/100..  Training Loss: 2.408..  Test Loss: 2.266.. \n",
      "Epoch: 13/100..  Training Loss: 2.402..  Test Loss: 2.249.. \n",
      "Epoch: 14/100..  Training Loss: 2.375..  Test Loss: 2.238.. \n",
      "Epoch: 15/100..  Training Loss: 2.359..  Test Loss: 2.228.. \n",
      "Epoch: 16/100..  Training Loss: 2.335..  Test Loss: 2.205.. \n",
      "Epoch: 17/100..  Training Loss: 2.326..  Test Loss: 2.206.. \n",
      "Epoch: 18/100..  Training Loss: 2.321..  Test Loss: 2.202.. \n",
      "Epoch: 19/100..  Training Loss: 2.310..  Test Loss: 2.184.. \n",
      "Epoch: 20/100..  Training Loss: 2.289..  Test Loss: 2.180.. \n",
      "Epoch: 21/100..  Training Loss: 2.310..  Test Loss: 2.171.. \n",
      "Epoch: 22/100..  Training Loss: 2.272..  Test Loss: 2.161.. \n",
      "Epoch: 23/100..  Training Loss: 2.258..  Test Loss: 2.158.. \n",
      "Epoch: 24/100..  Training Loss: 2.263..  Test Loss: 2.154.. \n",
      "Epoch: 25/100..  Training Loss: 2.261..  Test Loss: 2.157.. \n",
      "Epoch: 26/100..  Training Loss: 2.258..  Test Loss: 2.146.. \n",
      "Epoch: 27/100..  Training Loss: 2.255..  Test Loss: 2.142.. \n",
      "Epoch: 28/100..  Training Loss: 2.254..  Test Loss: 2.141.. \n",
      "Epoch: 29/100..  Training Loss: 2.233..  Test Loss: 2.140.. \n",
      "Epoch: 30/100..  Training Loss: 2.237..  Test Loss: 2.134.. \n",
      "Epoch: 31/100..  Training Loss: 2.230..  Test Loss: 2.142.. \n",
      "Epoch: 32/100..  Training Loss: 2.221..  Test Loss: 2.134.. \n",
      "Epoch: 33/100..  Training Loss: 2.224..  Test Loss: 2.137.. \n",
      "Epoch: 34/100..  Training Loss: 2.212..  Test Loss: 2.133.. \n",
      "Epoch: 35/100..  Training Loss: 2.218..  Test Loss: 2.125.. \n",
      "Epoch: 36/100..  Training Loss: 2.213..  Test Loss: 2.130.. \n",
      "Epoch: 37/100..  Training Loss: 2.208..  Test Loss: 2.129.. \n",
      "Epoch: 38/100..  Training Loss: 2.201..  Test Loss: 2.120.. \n",
      "Epoch: 39/100..  Training Loss: 2.200..  Test Loss: 2.120.. \n",
      "Epoch: 40/100..  Training Loss: 2.193..  Test Loss: 2.117.. \n",
      "Epoch: 41/100..  Training Loss: 2.191..  Test Loss: 2.114.. \n",
      "Epoch: 42/100..  Training Loss: 2.193..  Test Loss: 2.115.. \n",
      "Epoch: 43/100..  Training Loss: 2.188..  Test Loss: 2.109.. \n",
      "Epoch: 44/100..  Training Loss: 2.189..  Test Loss: 2.108.. \n",
      "Epoch: 45/100..  Training Loss: 2.174..  Test Loss: 2.110.. \n",
      "Epoch: 46/100..  Training Loss: 2.180..  Test Loss: 2.108.. \n",
      "Epoch: 47/100..  Training Loss: 2.175..  Test Loss: 2.106.. \n",
      "Epoch: 48/100..  Training Loss: 2.168..  Test Loss: 2.109.. \n",
      "Epoch: 49/100..  Training Loss: 2.171..  Test Loss: 2.111.. \n",
      "Epoch: 50/100..  Training Loss: 2.170..  Test Loss: 2.106.. \n",
      "Epoch: 51/100..  Training Loss: 2.157..  Test Loss: 2.102.. \n",
      "Epoch: 52/100..  Training Loss: 2.157..  Test Loss: 2.105.. \n",
      "Epoch: 53/100..  Training Loss: 2.161..  Test Loss: 2.102.. \n",
      "Epoch: 54/100..  Training Loss: 2.155..  Test Loss: 2.105.. \n",
      "Epoch: 55/100..  Training Loss: 2.146..  Test Loss: 2.104.. \n",
      "Epoch: 56/100..  Training Loss: 2.158..  Test Loss: 2.103.. \n",
      "Epoch: 57/100..  Training Loss: 2.148..  Test Loss: 2.101.. \n",
      "Epoch: 58/100..  Training Loss: 2.150..  Test Loss: 2.096.. \n",
      "Epoch: 59/100..  Training Loss: 2.147..  Test Loss: 2.099.. \n",
      "Epoch: 60/100..  Training Loss: 2.143..  Test Loss: 2.094.. \n",
      "Epoch: 61/100..  Training Loss: 2.146..  Test Loss: 2.097.. \n",
      "Epoch: 62/100..  Training Loss: 2.141..  Test Loss: 2.101.. \n",
      "Epoch: 63/100..  Training Loss: 2.137..  Test Loss: 2.092.. \n",
      "Epoch: 64/100..  Training Loss: 2.131..  Test Loss: 2.097.. \n",
      "Epoch: 65/100..  Training Loss: 2.131..  Test Loss: 2.097.. \n",
      "Epoch: 66/100..  Training Loss: 2.137..  Test Loss: 2.095.. \n",
      "Epoch: 67/100..  Training Loss: 2.128..  Test Loss: 2.098.. \n",
      "Epoch: 68/100..  Training Loss: 2.133..  Test Loss: 2.089.. \n",
      "Epoch: 69/100..  Training Loss: 2.125..  Test Loss: 2.096.. \n",
      "Epoch: 70/100..  Training Loss: 2.127..  Test Loss: 2.095.. \n",
      "Epoch: 71/100..  Training Loss: 2.123..  Test Loss: 2.095.. \n",
      "Epoch: 72/100..  Training Loss: 2.123..  Test Loss: 2.091.. \n",
      "Epoch: 73/100..  Training Loss: 2.124..  Test Loss: 2.093.. \n",
      "Epoch: 74/100..  Training Loss: 2.120..  Test Loss: 2.090.. \n",
      "Epoch: 75/100..  Training Loss: 2.125..  Test Loss: 2.087.. \n",
      "Epoch: 76/100..  Training Loss: 2.119..  Test Loss: 2.087.. \n",
      "Epoch: 77/100..  Training Loss: 2.118..  Test Loss: 2.086.. \n",
      "Epoch: 78/100..  Training Loss: 2.116..  Test Loss: 2.091.. \n",
      "Epoch: 79/100..  Training Loss: 2.114..  Test Loss: 2.086.. \n",
      "Epoch: 80/100..  Training Loss: 2.116..  Test Loss: 2.088.. \n",
      "Epoch: 81/100..  Training Loss: 2.116..  Test Loss: 2.086.. \n",
      "Epoch: 82/100..  Training Loss: 2.112..  Test Loss: 2.091.. \n",
      "Epoch: 83/100..  Training Loss: 2.113..  Test Loss: 2.089.. \n",
      "Epoch: 84/100..  Training Loss: 2.108..  Test Loss: 2.089.. \n",
      "Epoch: 85/100..  Training Loss: 2.114..  Test Loss: 2.086.. \n",
      "Epoch: 86/100..  Training Loss: 2.106..  Test Loss: 2.088.. \n",
      "Epoch: 87/100..  Training Loss: 2.108..  Test Loss: 2.087.. \n",
      "Epoch: 88/100..  Training Loss: 2.106..  Test Loss: 2.087.. \n",
      "Epoch: 89/100..  Training Loss: 2.105..  Test Loss: 2.084.. \n",
      "Epoch: 90/100..  Training Loss: 2.108..  Test Loss: 2.088.. \n",
      "Epoch: 91/100..  Training Loss: 2.107..  Test Loss: 2.084.. \n",
      "Epoch: 92/100..  Training Loss: 2.105..  Test Loss: 2.085.. \n",
      "Epoch: 93/100..  Training Loss: 2.104..  Test Loss: 2.085.. \n",
      "Epoch: 94/100..  Training Loss: 2.102..  Test Loss: 2.089.. \n",
      "Epoch: 95/100..  Training Loss: 2.099..  Test Loss: 2.081.. \n",
      "Epoch: 96/100..  Training Loss: 2.100..  Test Loss: 2.086.. \n",
      "Epoch: 97/100..  Training Loss: 2.101..  Test Loss: 2.082.. \n",
      "Epoch: 98/100..  Training Loss: 2.103..  Test Loss: 2.085.. \n",
      "Epoch: 99/100..  Training Loss: 2.095..  Test Loss: 2.082.. \n",
      "Epoch: 100/100..  Training Loss: 2.099..  Test Loss: 2.084.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv = cv.split(X_train_scaled, y_train)\n",
    "\n",
    "m_hidden_layers = 1\n",
    "\n",
    "n_input = 6\n",
    "n_hidden = 4\n",
    "n_output = 1\n",
    "\n",
    "bs = 64\n",
    "device = \"cuda:0\"\n",
    "epochs = 100\n",
    "\n",
    "network_type = \"regression\"\n",
    "\n",
    "regressors = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "    print(\"Model for Fold: \" + str(fold))\n",
    "\n",
    "    train_set, train_labels = X_train_scaled[train_idx], y_train[train_idx]\n",
    "    valid_set, valid_labels = X_train_scaled[val_idx], y_train[val_idx]\n",
    "    \n",
    "    trainset = HousePriceDataset(train_set, train_labels)\n",
    "    trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    validset = HousePriceDataset(valid_set, valid_labels)\n",
    "    validloader = DataLoader(validset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    regressor = NeuralNetwork(m_hidden_layers, n_input, n_hidden, n_output, network_type).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(regressor.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        for features, labels in trainloader:\n",
    "\n",
    "            regressor.train()\n",
    "\n",
    "            features = features.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = regressor(features.float())\n",
    "\n",
    "            loss = criterion(output, labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for features, labels in validloader:\n",
    "                    regressor.eval()\n",
    "\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    output = regressor(features.float())\n",
    "\n",
    "                    test_loss += criterion(output, labels)\n",
    "\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(validloader)))\n",
    "        \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The regression problem \n",
    "- As you will see below, my regression model has a tendency to predict values close to the mean (labels are from 0 to 4)\n",
    "- The reason for that could be that the label distribution for the \"Scor\" feature is a bimodal distribution, this could represent that my model is uncertain what to predict between (0 or 1) and (3, 4) so for minimizing the loss he chooses the center value, in this case (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on Testing Data: 2.1273207664489746\n",
      "Lets see predictions\n",
      "[1.9572906 2.0131636 1.9561352 1.9569539 2.0255775 2.0422404 1.9462433\n",
      " 1.9433167 1.9522823 1.9993387 2.0202413 1.9600004 1.9597759 2.0308492\n",
      " 1.9736875 2.040694  1.9322666 1.9309467 2.024765  2.0165992 1.9488125\n",
      " 2.0188253 1.8769009 1.9991906 1.9723225 2.0205634 2.0186431 1.9537085\n",
      " 1.9377298 1.9561428 1.9718456 1.9698213 2.0235128 1.8961937 2.032653\n",
      " 2.0222726 1.9524393 2.027067  2.0213337 1.9752455 2.0332685 2.0354342\n",
      " 1.9496174 1.9353653 2.0233364 1.9990166 2.0393794 2.0378222 1.9100236\n",
      " 1.9881575 2.0273232 2.0467665 2.0127168 2.0251386 2.0496337 2.006668\n",
      " 2.0189614 2.0003963 1.9920803 2.03413   2.0182178 2.0138307 1.9578007\n",
      " 2.0404878 1.9516476 1.9782885 2.0202353 2.0374286 2.003162  1.927589\n",
      " 1.9441544 2.0360596 1.9949181 1.9955758 2.0197449 2.0440311 2.0023925\n",
      " 2.0142076 1.9718825 2.0110652 1.9413977 1.936945  2.0468714 1.9500214\n",
      " 1.9578412 1.9538052 1.8832535 1.9980115 2.006127  1.9889097 1.971925\n",
      " 1.9904139 2.0323997 2.016587  1.9707562 2.0021777 1.9579573 1.9380839\n",
      " 2.0239842 1.9994118 2.0348496 1.9237732 1.9504689 2.033811  1.950861\n",
      " 2.0234482 1.9380811 2.0073392 2.0221786 2.0422666 1.9552172 1.9852288\n",
      " 2.0124855 1.9542454 1.9524571 2.011617  2.0135064 1.8977337 2.0262897\n",
      " 1.9651841 1.9612349 2.0170827 1.9397916 2.0145693 2.0231552 1.9499663\n",
      " 1.944698  1.9125942 2.0409584 2.027289  2.017384  2.036106  1.9433373\n",
      " 2.0426064 2.0337675 2.0092933 1.9930899 2.0348043 1.9450539 1.9987952\n",
      " 2.0125444 1.979646  1.9397267 1.957352  1.9442376 2.0084393 1.8942665\n",
      " 2.0367138 2.0381238 2.010712  1.9594367 2.0146027 1.9887336 1.9966166\n",
      " 1.995599  1.9866676 2.0048907 1.9182628 1.9702307 2.034742  2.0277064\n",
      " 1.8941087 2.0132086 2.0180676 2.0090363 1.9392035 2.010856  1.9498014\n",
      " 2.0190494 2.0282483 2.0384812 1.9776528 2.0207422 1.9896802 2.0316782\n",
      " 2.0078628 2.0305212 2.0284379 2.033056  1.9401    2.0301206 1.9958477\n",
      " 1.9585358 1.9706662 2.0429494 2.0198808 1.9529179 2.0034158 2.0174236\n",
      " 2.021014  1.9396054 2.0288532 1.9401951 2.0062969 1.946513  1.9918009\n",
      " 2.0065064 1.9364182 1.9831069 2.005181  1.95635   1.9851862 1.902084\n",
      " 2.0086792 1.9415257 2.0012732 1.9881327 2.0243375 1.9618771 1.9499663\n",
      " 2.027061  2.0339952 1.9512669 2.0373628 2.0006695 2.039748  2.002372\n",
      " 2.0127056 1.963168  2.0093625 1.9630597 2.0191479 2.019203  1.9570715\n",
      " 1.9300915 1.9765835 2.0296543 2.0065768 2.0052912 2.0145288 1.9959404\n",
      " 1.9938444 1.9324896 2.0116317 2.0214334 2.0239646 2.0225785 2.006102\n",
      " 2.0298886 2.0030262 1.9823513 1.845604  2.026281  1.9451071 2.033805\n",
      " 2.0014305 2.0346363 2.0153308 1.9306015 2.0282304 2.026786  2.0058076\n",
      " 2.0366998 1.9853146 1.9401951 1.9112114 2.0035143 1.9849423 2.0026584\n",
      " 2.0204036 1.978455  2.0009248 2.0284495 2.020335  1.8929132 2.0195863\n",
      " 2.0353992 2.0234537 1.9628464 2.0159128 1.9536107 2.02459   2.0339863\n",
      " 1.8989931 2.0433056 1.973432  1.9939679 1.9601487 1.9739116 1.944086\n",
      " 2.0537841 2.0238225 2.029867  2.0372057 1.9660562 2.0367138 2.0090303\n",
      " 2.0000618 1.9959606 1.989831  2.0217838 2.0078576 1.992367  2.017045\n",
      " 1.976537  2.001744  2.0368695 1.9592358 1.8922417 2.0234783 2.0162864\n",
      " 2.0296333 2.0346363 2.0408647 2.0318027 2.0005465 2.0298824 2.0242155\n",
      " 2.0129907 2.0273485 2.0238316 1.9587173 2.0445728 1.9613665 2.0026748\n",
      " 2.0036116 2.0339098 2.0327966 2.0190055 2.0399172 2.0081484 2.0113525\n",
      " 2.0278733 1.9588352 1.898394  2.0081837 1.9803063 2.0364392 1.9823531\n",
      " 1.9673427 1.9206017 2.009248  2.019326  2.0226445 2.0187385 2.016583\n",
      " 1.9799643 2.0167072 2.0300088 2.0204818 1.8973335 1.9742492 2.000189\n",
      " 1.9726084 2.0275872 2.0194752 1.9433268 2.0135849 2.001021  2.0082479\n",
      " 2.0189123 2.0633242 2.0429122]\n",
      "Thresholds: [1.  2.1 3.  4. ]\n",
      "Regerssion Accuracy with Rounded Values: 0.06515580736543909\n",
      "Regerssion Accuracy with Optimized Thresholds: 0.24929178470254956\n"
     ]
    }
   ],
   "source": [
    "evalset = HousePriceDataset(X_test_scaled, y_test)\n",
    "loader  = DataLoader(evalset, batch_size=len(X_test_scaled))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in loader: \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        \n",
    "        outputs = 0\n",
    "        for regressor in regressors:\n",
    "            output = regressor(features.float())\n",
    "            outputs += output\n",
    "        \n",
    "        outputs = outputs / len(models)\n",
    "        \n",
    "Ypred = outputs.cpu().numpy().squeeze()\n",
    "Yreal = labels.cpu().numpy()\n",
    "\n",
    "print(\"Loss on Testing Data:\", criterion(outputs, labels).item())\n",
    "\n",
    "print(\"Lets see predictions\")\n",
    "print(Ypred)\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "\n",
    "optR.fit(Ypred, Yreal)\n",
    "\n",
    "coefficients = optR.coefficients()\n",
    "\n",
    "print(\"Thresholds:\", coefficients)\n",
    "\n",
    "optimized = optR.predict(Ypred)\n",
    "rounded   = np.round(Ypred)\n",
    "\n",
    "print(\"Regerssion Accuracy with Rounded Values:\", accuracy_score(rounded, y_test))\n",
    "print(\"Regerssion Accuracy with Optimized Thresholds:\", accuracy_score(optimized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, optimized)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still one more question to ask\n",
    "- To verify myself, I trained a neural network from Sklearn, which obtains a smaller loss (approx. 0.6) then the pytorch model (approx. 2.1), and the question is \"What is different?\"\n",
    "- Both models use Adam as default with the default momentum hyperparameters, with constant learning rate and sam preprocessing methodology, relu activation and batch_size (at the moment of writing this I did not add LeakyReLU, BN or DropOut Regularization)\n",
    "# And a possible answer:\n",
    "- The MLPRegressor uses as loss function \"squared_errors\" with the regularization term that the MSELoss from Pytorch does not use, but I tried to simulate that regularization term by adding weight_decay to the Adam Optimizer... And it showed the same result.. so the question remains... What is different?\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/blob/95d4f0841/sklearn/neural_network/_multilayer_perceptron.py#L1083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Neural Network Sklearn:  0.7684701309987394\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes = (4), batch_size = 64, max_iter = 100)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Mean Squared Error Neural Network Sklearn: \", mean_squared_error(y_predict, y_test))\n",
    "\n",
    "plt.hist(y_predict)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_test)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And a simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Linear Regression Sklearn 1.1400216456050454\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "y_predict = regressor.predict(X_test_scaled)\n",
    "print(\"Mean Squared Error Linear Regression Sklearn\", mean_squared_error(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And  now a more suitable regression problem for Price\n",
    "- With Root Mean Square Log Error as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr Camere</th>\n",
       "      <th>Suprafata</th>\n",
       "      <th>Etaj</th>\n",
       "      <th>Total Etaje</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scor</th>\n",
       "      <th>Pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>108.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63.52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>84900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>62.00</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>132.00</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>349990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>49.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>36500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>92.00</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>68.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>110.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nr Camere  Suprafata  Etaj  Total Etaje  Sector  Scor    Pret\n",
       "0          4     108.00     2            3       4     5   83000\n",
       "1          1      41.00     1            8       1     1   39900\n",
       "2          3      63.52     1            3       2     3   84900\n",
       "3          1      33.00     3           10       5     1   45500\n",
       "4          2      62.00     5            9       5     5   54900\n",
       "5          3     132.00     2            6       1     2  349990\n",
       "6          2      49.00     6            6       6     4   36500\n",
       "7          3      92.00     4            8       2     2  119000\n",
       "8          3      68.00     3            5       4     5   67500\n",
       "9          3     110.00     1            2       1     1  133000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Bucharest_HousePriceDataset.csv\")\n",
    "\n",
    "display(data.head(n = 10))\n",
    "\n",
    "features = data.drop(['Pret'], axis = 1, inplace = False)\n",
    "\n",
    "labels   = data[\"Pret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features.values, labels.values, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = preprocessing(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to MSE\n",
    "- I choose to use RMSLE Loss function to to get a better sense of the problem, but in some situations it was not well defined and it returned \"nan\" as loss value for training and validating steps, so I went back to MSE Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 0\n",
      "Epoch: 1/1000..  Training Loss: 13515285284.571..  Test Loss: 12923674624.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13402358842.514..  Test Loss: 13014110208.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13463888866.743..  Test Loss: 12936766464.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13520831122.286..  Test Loss: 12921446400.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13438556042.971..  Test Loss: 12834472960.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13397687530.057..  Test Loss: 12981255168.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13426617929.143..  Test Loss: 12868491264.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13363622853.486..  Test Loss: 12862898176.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13533633770.057..  Test Loss: 12840486912.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13483960202.971..  Test Loss: 12896653312.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13705900704.914..  Test Loss: 12744640512.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13478868904.229..  Test Loss: 12756696064.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13418273879.771..  Test Loss: 12990724096.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13486721024.000..  Test Loss: 12787910656.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13395159654.400..  Test Loss: 12897713152.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13404375376.457..  Test Loss: 12870086656.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13504095758.629..  Test Loss: 13018012672.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13554041475.657..  Test Loss: 12769887232.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13442527466.057..  Test Loss: 12934548480.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13628985109.943..  Test Loss: 12954217472.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13490152155.429..  Test Loss: 13200447488.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13487127786.057..  Test Loss: 13053855744.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13500681420.800..  Test Loss: 12909652992.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13397080298.057..  Test Loss: 12838131712.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13370937504.914..  Test Loss: 12798350336.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13471104819.200..  Test Loss: 13129253888.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13583073514.057..  Test Loss: 12868658176.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13421244650.057..  Test Loss: 12845897728.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13492657532.343..  Test Loss: 12916084736.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13428481784.686..  Test Loss: 12887448576.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13344042276.571..  Test Loss: 12978536448.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13369085864.229..  Test Loss: 12792586240.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13380608409.600..  Test Loss: 12876139520.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13468817086.171..  Test Loss: 12828974080.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13405542546.286..  Test Loss: 12770977792.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13399592082.286..  Test Loss: 12903464960.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13338964670.171..  Test Loss: 12850119680.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13366587392.000..  Test Loss: 12804374528.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13317252973.714..  Test Loss: 12888446976.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13457128696.686..  Test Loss: 12852237312.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13387204871.314..  Test Loss: 12862031872.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13332610984.229..  Test Loss: 12790982656.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13327270955.886..  Test Loss: 12937976832.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13452084106.971..  Test Loss: 12983909376.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13336624625.371..  Test Loss: 12862200832.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13261964668.343..  Test Loss: 12785413120.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13362626442.971..  Test Loss: 13120768000.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13435444106.971..  Test Loss: 12795929600.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13262240226.743..  Test Loss: 12952561664.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13241502793.143..  Test Loss: 12728740864.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13282876971.886..  Test Loss: 12810505216.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13333933114.514..  Test Loss: 12808840192.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13322315366.400..  Test Loss: 12823060480.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13280283706.514..  Test Loss: 12832385024.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13228203739.429..  Test Loss: 12842339328.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13397831445.943..  Test Loss: 12884311040.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13353651200.000..  Test Loss: 12898501632.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13347806515.200..  Test Loss: 12885080064.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13221751690.971..  Test Loss: 12907986944.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13200779468.800..  Test Loss: 12890229760.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13232804659.200..  Test Loss: 12727340032.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13178641086.171..  Test Loss: 12681011200.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13281386057.143..  Test Loss: 12675320832.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13174194848.914..  Test Loss: 12718771200.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13212424455.314..  Test Loss: 12682206208.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13269150398.171..  Test Loss: 12637244416.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13248489442.743..  Test Loss: 12965766144.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13220304296.229..  Test Loss: 12776216576.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13188415049.143..  Test Loss: 12899826688.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13147469824.000..  Test Loss: 12831519744.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13110201080.686..  Test Loss: 12924163072.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13195482784.914..  Test Loss: 12948113408.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13148805675.886..  Test Loss: 12710083584.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13100090602.057..  Test Loss: 12852071424.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13296760802.743..  Test Loss: 12722879488.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13103405904.457..  Test Loss: 12736101376.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13051146634.971..  Test Loss: 12722347008.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13081122201.600..  Test Loss: 12821998592.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13205432817.371..  Test Loss: 12770980864.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13159440735.086..  Test Loss: 12706661376.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13146377069.714..  Test Loss: 12776549376.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13099234069.943..  Test Loss: 12757199872.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13123178320.457..  Test Loss: 12849695744.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13196076353.829..  Test Loss: 12671614976.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13082236342.857..  Test Loss: 12715351040.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13039992042.057..  Test Loss: 12707736576.000.. \n",
      "Epoch: 87/1000..  Training Loss: 13090889786.514..  Test Loss: 12866636800.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13088164834.743..  Test Loss: 12604981248.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13109157507.657..  Test Loss: 12606684160.000.. \n",
      "Epoch: 90/1000..  Training Loss: 12988795377.371..  Test Loss: 12797171712.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13043736751.543..  Test Loss: 12669534208.000.. \n",
      "Epoch: 92/1000..  Training Loss: 12904591681.829..  Test Loss: 12834385920.000.. \n",
      "Epoch: 93/1000..  Training Loss: 12972577192.229..  Test Loss: 12981307392.000.. \n",
      "Epoch: 94/1000..  Training Loss: 12938479893.943..  Test Loss: 12724746240.000.. \n",
      "Epoch: 95/1000..  Training Loss: 12988240442.514..  Test Loss: 12918158336.000.. \n",
      "Epoch: 96/1000..  Training Loss: 12912653282.743..  Test Loss: 12704803840.000.. \n",
      "Epoch: 97/1000..  Training Loss: 13062360970.971..  Test Loss: 12716592128.000.. \n",
      "Epoch: 98/1000..  Training Loss: 13045577186.743..  Test Loss: 12672251904.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12976429728.914..  Test Loss: 12850290688.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12945994225.371..  Test Loss: 12755989504.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000..  Training Loss: 12882639023.543..  Test Loss: 12707293184.000.. \n",
      "Epoch: 102/1000..  Training Loss: 12896347896.686..  Test Loss: 12586532864.000.. \n",
      "Epoch: 103/1000..  Training Loss: 13085101670.400..  Test Loss: 12598896640.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12821063285.029..  Test Loss: 12738316288.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12931879058.286..  Test Loss: 12655011840.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12854310692.571..  Test Loss: 12722673664.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12842741730.743..  Test Loss: 12677559296.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12998872385.829..  Test Loss: 12861750272.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12936164820.114..  Test Loss: 12579836928.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12872943762.286..  Test Loss: 12711038976.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12819432916.114..  Test Loss: 12583846912.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12951684242.286..  Test Loss: 12656585728.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12850291536.457..  Test Loss: 12608606208.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12806905973.029..  Test Loss: 12683377664.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12837228134.400..  Test Loss: 12912315392.000.. \n",
      "Epoch: 116/1000..  Training Loss: 12826694787.657..  Test Loss: 12637976576.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12804009135.543..  Test Loss: 12528734208.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12690109747.200..  Test Loss: 12650585088.000.. \n",
      "Epoch: 119/1000..  Training Loss: 12846293621.029..  Test Loss: 12648755200.000.. \n",
      "Epoch: 120/1000..  Training Loss: 12638721828.571..  Test Loss: 12820768768.000.. \n",
      "Epoch: 121/1000..  Training Loss: 12830069028.571..  Test Loss: 12605966336.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12734441969.371..  Test Loss: 12630604800.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12821607043.657..  Test Loss: 12735033344.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12737720115.200..  Test Loss: 12622034944.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12788238643.200..  Test Loss: 12662969344.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12665755472.457..  Test Loss: 12746300416.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12625855561.143..  Test Loss: 12522158080.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12685915194.514..  Test Loss: 12657209344.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12624739562.057..  Test Loss: 12565514240.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12722910090.971..  Test Loss: 12652260352.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12651557770.971..  Test Loss: 12482650112.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12776228395.886..  Test Loss: 12741312512.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12570932253.257..  Test Loss: 12533146624.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12582209448.229..  Test Loss: 12624695296.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12499992195.657..  Test Loss: 12728641536.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12561198767.543..  Test Loss: 12459252736.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12503681916.343..  Test Loss: 12894124032.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12547872138.971..  Test Loss: 12607682560.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12546717769.143..  Test Loss: 12559186944.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12509408841.143..  Test Loss: 12797250560.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12491077836.800..  Test Loss: 12509813760.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12479283185.371..  Test Loss: 12597426176.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12434809578.057..  Test Loss: 12489246720.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12459903473.371..  Test Loss: 12501207040.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12486492745.143..  Test Loss: 12508214272.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12478414935.771..  Test Loss: 12593633280.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12390592980.114..  Test Loss: 12520894464.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12535332395.886..  Test Loss: 12417112064.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12448210505.143..  Test Loss: 12695018496.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12561132690.286..  Test Loss: 12446886912.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12482709299.200..  Test Loss: 12681687040.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12342884673.829..  Test Loss: 12522712064.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12447469553.371..  Test Loss: 12503223296.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12405445544.229..  Test Loss: 12537121792.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12346213946.514..  Test Loss: 12482868224.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12466644392.229..  Test Loss: 12609580032.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12533217060.571..  Test Loss: 12760474624.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12377508893.257..  Test Loss: 12481117184.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12488483108.571..  Test Loss: 12487336960.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12330140949.943..  Test Loss: 12481909760.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12259531834.514..  Test Loss: 12309800960.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12295310467.657..  Test Loss: 12534673408.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12263325959.314..  Test Loss: 12461173760.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12317829939.200..  Test Loss: 12527221760.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12293211501.714..  Test Loss: 12354116608.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12326225364.114..  Test Loss: 12557491200.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12164684741.486..  Test Loss: 12456756224.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12317802788.571..  Test Loss: 12664372224.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12408502886.400..  Test Loss: 12423435264.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12155897856.000..  Test Loss: 12411599872.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12343960766.171..  Test Loss: 12326558720.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12265753439.086..  Test Loss: 12414969856.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12236612022.857..  Test Loss: 12389084160.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12149861961.143..  Test Loss: 12340577280.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12293603152.457..  Test Loss: 12298039296.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12066376133.486..  Test Loss: 12379607040.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12100982944.914..  Test Loss: 12430085120.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12084777120.914..  Test Loss: 12323515392.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12180422261.029..  Test Loss: 12479368192.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12034941557.029..  Test Loss: 12343754752.000.. \n",
      "Epoch: 181/1000..  Training Loss: 12067833753.600..  Test Loss: 12345708544.000.. \n",
      "Epoch: 182/1000..  Training Loss: 12025658016.914..  Test Loss: 12382562304.000.. \n",
      "Epoch: 183/1000..  Training Loss: 12023329967.543..  Test Loss: 12472849408.000.. \n",
      "Epoch: 184/1000..  Training Loss: 12117451658.971..  Test Loss: 12290400256.000.. \n",
      "Epoch: 185/1000..  Training Loss: 12092280656.457..  Test Loss: 12323504128.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11981743674.514..  Test Loss: 12255433728.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11979671434.971..  Test Loss: 12300155904.000.. \n",
      "Epoch: 188/1000..  Training Loss: 12064421829.486..  Test Loss: 12334504960.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11896056246.857..  Test Loss: 12429270016.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11931931823.543..  Test Loss: 12279408640.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11990996523.886..  Test Loss: 12453370880.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11935226002.286..  Test Loss: 12255385600.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11954200283.429..  Test Loss: 12455369728.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11866031616.000..  Test Loss: 12273956864.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11932153768.229..  Test Loss: 12174716928.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11976107958.857..  Test Loss: 12384015360.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11898866878.171..  Test Loss: 12252905472.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11912745281.829..  Test Loss: 12222040064.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11815139298.743..  Test Loss: 12378639360.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200/1000..  Training Loss: 11811637569.829..  Test Loss: 12240013312.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11934290446.629..  Test Loss: 12410071040.000.. \n",
      "Epoch: 202/1000..  Training Loss: 11782398698.057..  Test Loss: 12334196736.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11725575138.743..  Test Loss: 12333290496.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11868161448.229..  Test Loss: 12290534400.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11921485750.857..  Test Loss: 12202082304.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11635671054.629..  Test Loss: 12438251520.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11707455502.629..  Test Loss: 12274987008.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11634680861.257..  Test Loss: 12273696768.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11656783506.286..  Test Loss: 12304342016.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11756454473.143..  Test Loss: 12360205312.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11621896221.257..  Test Loss: 12298094592.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11683803077.486..  Test Loss: 12401950720.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11654491048.229..  Test Loss: 12251958272.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11617693461.943..  Test Loss: 12326022144.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11616543539.200..  Test Loss: 12190088192.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11692988050.286..  Test Loss: 12130195456.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11548971783.314..  Test Loss: 12178322432.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11568336574.171..  Test Loss: 12171406336.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11702341836.800..  Test Loss: 12314457088.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11515978210.743..  Test Loss: 12318682112.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11534766694.400..  Test Loss: 12131172352.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11579383705.600..  Test Loss: 11892120576.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11473708251.429..  Test Loss: 12237727744.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11493382407.314..  Test Loss: 12210269184.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11473505952.914..  Test Loss: 12091512832.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11465563648.000..  Test Loss: 11886865408.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11369463603.200..  Test Loss: 12108297216.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11360540320.914..  Test Loss: 12116560896.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11454024206.629..  Test Loss: 12266927104.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11341691172.571..  Test Loss: 12064543744.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11446611529.143..  Test Loss: 12108873728.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11329095943.314..  Test Loss: 11995264000.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11335449263.543..  Test Loss: 12028116992.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11348175374.629..  Test Loss: 12061657088.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11311822935.771..  Test Loss: 12119946240.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11383791001.600..  Test Loss: 11803970560.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11415175855.543..  Test Loss: 12145471488.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11275915337.143..  Test Loss: 12466472960.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11409062926.629..  Test Loss: 12161255424.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11325590030.629..  Test Loss: 11994569728.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11291620981.029..  Test Loss: 12139635712.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11292052231.314..  Test Loss: 11998538752.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11263868913.371..  Test Loss: 12026262528.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11153257676.800..  Test Loss: 11985379328.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11153776362.057..  Test Loss: 12021465088.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11138628681.143..  Test Loss: 11858823168.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11277103352.686..  Test Loss: 12150867968.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11134731395.657..  Test Loss: 11930148864.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11217988827.429..  Test Loss: 11904855040.000.. \n",
      "Epoch: 250/1000..  Training Loss: 11250711361.829..  Test Loss: 11961835520.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11081177804.800..  Test Loss: 12068326400.000.. \n",
      "Epoch: 252/1000..  Training Loss: 11013821834.971..  Test Loss: 11774182400.000.. \n",
      "Epoch: 253/1000..  Training Loss: 11004803832.686..  Test Loss: 11960865792.000.. \n",
      "Epoch: 254/1000..  Training Loss: 10997795957.029..  Test Loss: 11715205120.000.. \n",
      "Epoch: 255/1000..  Training Loss: 11185989061.486..  Test Loss: 11886128128.000.. \n",
      "Epoch: 256/1000..  Training Loss: 11048463316.114..  Test Loss: 12148747264.000.. \n",
      "Epoch: 257/1000..  Training Loss: 11084253154.743..  Test Loss: 11860372480.000.. \n",
      "Epoch: 258/1000..  Training Loss: 11040050600.229..  Test Loss: 12108218368.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10997888219.429..  Test Loss: 11906187264.000.. \n",
      "Epoch: 260/1000..  Training Loss: 11019700136.229..  Test Loss: 11710538752.000.. \n",
      "Epoch: 261/1000..  Training Loss: 11166406831.543..  Test Loss: 11960527872.000.. \n",
      "Epoch: 262/1000..  Training Loss: 10910437990.400..  Test Loss: 11783172096.000.. \n",
      "Epoch: 263/1000..  Training Loss: 11102774593.829..  Test Loss: 11850825728.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10877397109.029..  Test Loss: 11981763584.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10915524432.457..  Test Loss: 11738352640.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10968198553.600..  Test Loss: 11702505472.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10844442799.543..  Test Loss: 11961050112.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10864137801.143..  Test Loss: 11801717760.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10830081272.686..  Test Loss: 11905293312.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10814996874.971..  Test Loss: 11847301120.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10764544394.971..  Test Loss: 11807725568.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10731742266.514..  Test Loss: 11725503488.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10871374306.743..  Test Loss: 11959581696.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10767726401.829..  Test Loss: 12031423488.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10767306064.457..  Test Loss: 11995343872.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10762770768.457..  Test Loss: 11773462528.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10743386858.057..  Test Loss: 11856105472.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10723277048.686..  Test Loss: 11893156864.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10735017062.400..  Test Loss: 11708902400.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10683197015.771..  Test Loss: 11698105344.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10735699924.114..  Test Loss: 11773733888.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10702997504.000..  Test Loss: 11711812608.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10688357039.543..  Test Loss: 11668343808.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10605755201.829..  Test Loss: 11703533568.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10596037310.171..  Test Loss: 11624606720.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10605613275.429..  Test Loss: 11992994816.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10655838544.457..  Test Loss: 11735256064.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10463348092.343..  Test Loss: 11412675584.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10563215374.629..  Test Loss: 11704314880.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10497165107.200..  Test Loss: 11679958016.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10431406738.286..  Test Loss: 11798590464.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10483446052.571..  Test Loss: 11615313920.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10486351769.600..  Test Loss: 11390519296.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10466388918.857..  Test Loss: 11484384256.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10471723856.457..  Test Loss: 11865349120.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10515941317.486..  Test Loss: 11694729216.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10419902727.314..  Test Loss: 11649551360.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10447865592.686..  Test Loss: 11664395264.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/1000..  Training Loss: 10358679917.714..  Test Loss: 11610210304.000.. \n",
      "Epoch: 300/1000..  Training Loss: 10334333015.771..  Test Loss: 11867512832.000.. \n",
      "Epoch: 301/1000..  Training Loss: 10287826900.114..  Test Loss: 11601643520.000.. \n",
      "Epoch: 302/1000..  Training Loss: 10317946177.829..  Test Loss: 11552724992.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10274681826.743..  Test Loss: 11643977728.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10260163935.086..  Test Loss: 11535318016.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10368131744.914..  Test Loss: 11587288064.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10216752318.171..  Test Loss: 11201914880.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10253467925.943..  Test Loss: 11569544192.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10402172840.229..  Test Loss: 11428291584.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10222834805.029..  Test Loss: 11497774080.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10274728725.943..  Test Loss: 11268389888.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10165082989.714..  Test Loss: 11483515904.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10202845930.057..  Test Loss: 11709420544.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10312477461.943..  Test Loss: 11603173376.000.. \n",
      "Epoch: 314/1000..  Training Loss: 10186970799.543..  Test Loss: 11569214464.000.. \n",
      "Epoch: 315/1000..  Training Loss: 10140874459.429..  Test Loss: 11372801024.000.. \n",
      "Epoch: 316/1000..  Training Loss: 10071509445.486..  Test Loss: 11510736896.000.. \n",
      "Epoch: 317/1000..  Training Loss: 10139679188.114..  Test Loss: 11490878464.000.. \n",
      "Epoch: 318/1000..  Training Loss: 10107780871.314..  Test Loss: 11531140096.000.. \n",
      "Epoch: 319/1000..  Training Loss: 10157187349.943..  Test Loss: 11389679616.000.. \n",
      "Epoch: 320/1000..  Training Loss: 10123003567.543..  Test Loss: 11431375872.000.. \n",
      "Epoch: 321/1000..  Training Loss: 10023951199.086..  Test Loss: 11768622080.000.. \n",
      "Epoch: 322/1000..  Training Loss: 10147586296.686..  Test Loss: 11427322880.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9956131796.114..  Test Loss: 11366002688.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9996599573.943..  Test Loss: 11397157888.000.. \n",
      "Epoch: 325/1000..  Training Loss: 10042993576.229..  Test Loss: 11372674048.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9940470769.371..  Test Loss: 11403926528.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9923082956.800..  Test Loss: 11264354304.000.. \n",
      "Epoch: 328/1000..  Training Loss: 10032767180.800..  Test Loss: 11413707776.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9942168502.857..  Test Loss: 11564617728.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9893682293.029..  Test Loss: 11617896448.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9848397780.114..  Test Loss: 11496541184.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9859671712.914..  Test Loss: 11269118976.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9785502288.457..  Test Loss: 11290626048.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9762265614.629..  Test Loss: 11330714624.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9826478855.314..  Test Loss: 11346816000.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9875139320.686..  Test Loss: 11357144064.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9831888179.200..  Test Loss: 11353099264.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9745937568.914..  Test Loss: 11180723200.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9797563318.857..  Test Loss: 10975979520.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9791948185.600..  Test Loss: 11352344576.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9716950030.629..  Test Loss: 11142774784.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9740925966.629..  Test Loss: 10861436928.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9752586561.829..  Test Loss: 11086586880.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9721238513.371..  Test Loss: 11478977536.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9831029130.971..  Test Loss: 11128547328.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9644633205.029..  Test Loss: 10760334336.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9558432314.514..  Test Loss: 11102258176.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9596178139.429..  Test Loss: 11032836096.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9602288201.143..  Test Loss: 11278477312.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9667605401.600..  Test Loss: 11142771712.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9565786038.857..  Test Loss: 11084044288.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9649982244.571..  Test Loss: 11156158464.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9504398877.257..  Test Loss: 10620520448.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9531421432.686..  Test Loss: 11214763008.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9543921576.229..  Test Loss: 10878326784.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9489451783.314..  Test Loss: 10855227392.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9578796441.600..  Test Loss: 10785815552.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9370191506.286..  Test Loss: 10786624512.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9457186245.486..  Test Loss: 11166243840.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9389984416.914..  Test Loss: 11031387136.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9359363306.057..  Test Loss: 10773907456.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9414385239.771..  Test Loss: 10787858432.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9701582657.829..  Test Loss: 11098831872.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9395145128.229..  Test Loss: 10682927104.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9480707496.229..  Test Loss: 11025368064.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9487075810.743..  Test Loss: 10691378176.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9273645597.257..  Test Loss: 10672557056.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9366398551.771..  Test Loss: 10948579328.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9361889850.514..  Test Loss: 10576655360.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9235369837.714..  Test Loss: 10590167040.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9274052125.257..  Test Loss: 10817839104.000.. \n",
      "Epoch: 372/1000..  Training Loss: 9293847303.314..  Test Loss: 10841161728.000.. \n",
      "Epoch: 373/1000..  Training Loss: 9279838456.686..  Test Loss: 10771127296.000.. \n",
      "Epoch: 374/1000..  Training Loss: 9256133646.629..  Test Loss: 11047233536.000.. \n",
      "Epoch: 375/1000..  Training Loss: 9399553141.029..  Test Loss: 10553750528.000.. \n",
      "Epoch: 376/1000..  Training Loss: 9097463252.114..  Test Loss: 10770099200.000.. \n",
      "Epoch: 377/1000..  Training Loss: 9107028260.571..  Test Loss: 10832526336.000.. \n",
      "Epoch: 378/1000..  Training Loss: 9033736462.629..  Test Loss: 10421109760.000.. \n",
      "Epoch: 379/1000..  Training Loss: 9228956467.200..  Test Loss: 10425203712.000.. \n",
      "Epoch: 380/1000..  Training Loss: 9167299905.829..  Test Loss: 10722150400.000.. \n",
      "Epoch: 381/1000..  Training Loss: 9156266042.514..  Test Loss: 10448423936.000.. \n",
      "Epoch: 382/1000..  Training Loss: 9227118548.114..  Test Loss: 10323634176.000.. \n",
      "Epoch: 383/1000..  Training Loss: 9121450291.200..  Test Loss: 10510086144.000.. \n",
      "Epoch: 384/1000..  Training Loss: 9025841152.000..  Test Loss: 10413919232.000.. \n",
      "Epoch: 385/1000..  Training Loss: 9079632354.743..  Test Loss: 10553596928.000.. \n",
      "Epoch: 386/1000..  Training Loss: 9035912221.257..  Test Loss: 9930237952.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8974332035.657..  Test Loss: 10615434240.000.. \n",
      "Epoch: 388/1000..  Training Loss: 9044580498.286..  Test Loss: 10362123264.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8999660032.000..  Test Loss: 10545724416.000.. \n",
      "Epoch: 390/1000..  Training Loss: 9014840714.971..  Test Loss: 10560598016.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8944170949.486..  Test Loss: 10206036992.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8974929773.714..  Test Loss: 10364293120.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8896917855.086..  Test Loss: 10484677632.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8865429299.200..  Test Loss: 10450899968.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8834407350.857..  Test Loss: 10310974464.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8973806972.343..  Test Loss: 10534566912.000.. \n",
      "Epoch: 397/1000..  Training Loss: 9035292452.571..  Test Loss: 10451094528.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8879531285.943..  Test Loss: 9950880768.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8892211697.371..  Test Loss: 10355088384.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400/1000..  Training Loss: 8880372180.114..  Test Loss: 10098648064.000.. \n",
      "Epoch: 401/1000..  Training Loss: 8902987556.571..  Test Loss: 10180942848.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8790363340.800..  Test Loss: 10106909696.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8791151835.429..  Test Loss: 10392285184.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8751960780.800..  Test Loss: 10390005760.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8674922027.886..  Test Loss: 10372085760.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8668903336.229..  Test Loss: 10191518720.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8712731428.571..  Test Loss: 10028547072.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8619525661.257..  Test Loss: 10198441984.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8778095030.857..  Test Loss: 10218131456.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8702441018.514..  Test Loss: 9937532928.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8721342712.686..  Test Loss: 9932457984.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8718485694.171..  Test Loss: 10093919232.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8638117536.914..  Test Loss: 10140883968.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8683055060.114..  Test Loss: 10009698304.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8708538192.457..  Test Loss: 10081146880.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8531516796.343..  Test Loss: 10273707008.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8516194011.429..  Test Loss: 10155345920.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8613878637.714..  Test Loss: 10284140544.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8596344583.314..  Test Loss: 9996758016.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8438264956.343..  Test Loss: 10168049664.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8586554382.629..  Test Loss: 10026485760.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8472011951.543..  Test Loss: 9386506240.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8462457921.829..  Test Loss: 9783403520.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8567505144.686..  Test Loss: 9883262976.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8551370517.943..  Test Loss: 10125230080.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8434024630.857..  Test Loss: 10099644416.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8382952228.571..  Test Loss: 10299615232.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8346872758.857..  Test Loss: 9881622528.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8425345082.514..  Test Loss: 9606790144.000.. \n",
      "Epoch: 430/1000..  Training Loss: 8363936314.514..  Test Loss: 9921681408.000.. \n",
      "Epoch: 431/1000..  Training Loss: 8358940203.886..  Test Loss: 10035314688.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8461620501.943..  Test Loss: 9967372288.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8352528340.114..  Test Loss: 9854776320.000.. \n",
      "Epoch: 434/1000..  Training Loss: 8226618550.857..  Test Loss: 9970567168.000.. \n",
      "Epoch: 435/1000..  Training Loss: 8272728078.629..  Test Loss: 10043936768.000.. \n",
      "Epoch: 436/1000..  Training Loss: 8293273658.514..  Test Loss: 10169320448.000.. \n",
      "Epoch: 437/1000..  Training Loss: 8317010936.686..  Test Loss: 9954348032.000.. \n",
      "Epoch: 438/1000..  Training Loss: 8224216056.686..  Test Loss: 9802507264.000.. \n",
      "Epoch: 439/1000..  Training Loss: 8302766460.343..  Test Loss: 9640517632.000.. \n",
      "Epoch: 440/1000..  Training Loss: 8132722863.543..  Test Loss: 9630522368.000.. \n",
      "Epoch: 441/1000..  Training Loss: 8314799864.686..  Test Loss: 9799791616.000.. \n",
      "Epoch: 442/1000..  Training Loss: 8378222226.286..  Test Loss: 9788877824.000.. \n",
      "Epoch: 443/1000..  Training Loss: 8171511266.743..  Test Loss: 9952622592.000.. \n",
      "Epoch: 444/1000..  Training Loss: 8189779960.686..  Test Loss: 9649359872.000.. \n",
      "Epoch: 445/1000..  Training Loss: 8192068622.629..  Test Loss: 9905010688.000.. \n",
      "Epoch: 446/1000..  Training Loss: 8135619518.171..  Test Loss: 9792191488.000.. \n",
      "Epoch: 447/1000..  Training Loss: 8109067359.086..  Test Loss: 9543993344.000.. \n",
      "Epoch: 448/1000..  Training Loss: 8103437472.914..  Test Loss: 9944402944.000.. \n",
      "Epoch: 449/1000..  Training Loss: 8102541487.543..  Test Loss: 9706521600.000.. \n",
      "Epoch: 450/1000..  Training Loss: 8037758654.171..  Test Loss: 9661914112.000.. \n",
      "Epoch: 451/1000..  Training Loss: 8098305448.229..  Test Loss: 9443405824.000.. \n",
      "Epoch: 452/1000..  Training Loss: 8026519990.857..  Test Loss: 9334373376.000.. \n",
      "Epoch: 453/1000..  Training Loss: 8129748640.914..  Test Loss: 9756264448.000.. \n",
      "Epoch: 454/1000..  Training Loss: 8117436006.400..  Test Loss: 9815572480.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7889966197.029..  Test Loss: 9739321344.000.. \n",
      "Epoch: 456/1000..  Training Loss: 8007832605.257..  Test Loss: 9589682176.000.. \n",
      "Epoch: 457/1000..  Training Loss: 8002385173.943..  Test Loss: 9822678016.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7946971472.457..  Test Loss: 9472242688.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7941898942.171..  Test Loss: 9827637248.000.. \n",
      "Epoch: 460/1000..  Training Loss: 8067903312.457..  Test Loss: 9509203968.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7836736731.429..  Test Loss: 9319503872.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7961826260.114..  Test Loss: 9348307968.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7827669811.200..  Test Loss: 9325180928.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7787832846.629..  Test Loss: 9348272128.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7888948487.314..  Test Loss: 9451850752.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7764719001.600..  Test Loss: 9652580352.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7795903531.886..  Test Loss: 9603718144.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7814273609.143..  Test Loss: 9319098368.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7750427289.600..  Test Loss: 9208022016.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7833154764.800..  Test Loss: 9297833984.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7803575025.371..  Test Loss: 9226098688.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7744094017.829..  Test Loss: 9406274560.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7687488555.886..  Test Loss: 9319104512.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7729484858.514..  Test Loss: 9299656704.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7696461341.257..  Test Loss: 9266293760.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7620968016.457..  Test Loss: 9261140992.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7634605114.514..  Test Loss: 9189651456.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7933280351.086..  Test Loss: 9251378176.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7638893509.486..  Test Loss: 9347100672.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7636182220.800..  Test Loss: 9210447872.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7493596818.286..  Test Loss: 9315420160.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7645889784.686..  Test Loss: 9139866624.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7513081753.600..  Test Loss: 9034278912.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7476309277.257..  Test Loss: 9086460928.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7530172935.314..  Test Loss: 9242779648.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7619925723.429..  Test Loss: 8808345600.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7379551363.657..  Test Loss: 9270704128.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7693448118.857..  Test Loss: 8853834752.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7482744122.514..  Test Loss: 9078775808.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7584639261.257..  Test Loss: 9027300352.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7466809036.800..  Test Loss: 9246548992.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7485122516.114..  Test Loss: 9180067840.000.. \n",
      "Epoch: 493/1000..  Training Loss: 7425200259.657..  Test Loss: 9063453696.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7515189094.400..  Test Loss: 9075473408.000.. \n",
      "Epoch: 495/1000..  Training Loss: 7373516280.686..  Test Loss: 8751074304.000.. \n",
      "Epoch: 496/1000..  Training Loss: 7399674777.600..  Test Loss: 8536866816.000.. \n",
      "Epoch: 497/1000..  Training Loss: 7537295784.229..  Test Loss: 8337392640.000.. \n",
      "Epoch: 498/1000..  Training Loss: 7390830036.114..  Test Loss: 9004846080.000.. \n",
      "Epoch: 499/1000..  Training Loss: 7401616954.514..  Test Loss: 8887369728.000.. \n",
      "Epoch: 500/1000..  Training Loss: 7321826552.686..  Test Loss: 8811207680.000.. \n",
      "Epoch: 501/1000..  Training Loss: 7341881380.571..  Test Loss: 8601228288.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 502/1000..  Training Loss: 7300244333.714..  Test Loss: 8787844096.000.. \n",
      "Epoch: 503/1000..  Training Loss: 7269609325.714..  Test Loss: 8943645696.000.. \n",
      "Epoch: 504/1000..  Training Loss: 7464929258.057..  Test Loss: 8945576960.000.. \n",
      "Epoch: 505/1000..  Training Loss: 7258892814.629..  Test Loss: 8814935040.000.. \n",
      "Epoch: 506/1000..  Training Loss: 7275249810.286..  Test Loss: 8796396544.000.. \n",
      "Epoch: 507/1000..  Training Loss: 7350756498.286..  Test Loss: 8749225984.000.. \n",
      "Epoch: 508/1000..  Training Loss: 7288555351.771..  Test Loss: 9005579264.000.. \n",
      "Epoch: 509/1000..  Training Loss: 7209154121.143..  Test Loss: 8901658624.000.. \n",
      "Epoch: 510/1000..  Training Loss: 7164030522.514..  Test Loss: 8762915840.000.. \n",
      "Epoch: 511/1000..  Training Loss: 7229908816.457..  Test Loss: 8401226240.000.. \n",
      "Epoch: 512/1000..  Training Loss: 7242114113.829..  Test Loss: 8286484992.000.. \n",
      "Epoch: 513/1000..  Training Loss: 7214333220.571..  Test Loss: 7796155392.000.. \n",
      "Epoch: 514/1000..  Training Loss: 7078490836.114..  Test Loss: 7681885184.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6996661196.800..  Test Loss: 7058291200.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6985578869.029..  Test Loss: 7058051072.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6958627313.371..  Test Loss: 6854269952.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6970705283.657..  Test Loss: 7036831232.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6863887996.343..  Test Loss: 6804304384.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6904399513.600..  Test Loss: 7035080192.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6950565953.829..  Test Loss: 6929141248.000.. \n",
      "Epoch: 522/1000..  Training Loss: 7053998511.543..  Test Loss: 6702650880.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6908491073.829..  Test Loss: 6789001728.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6826793047.771..  Test Loss: 6766227968.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6796857080.686..  Test Loss: 6680375296.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6710558025.143..  Test Loss: 6839625216.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6781788869.486..  Test Loss: 6715725824.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6742632074.971..  Test Loss: 6782441472.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6762983658.057..  Test Loss: 6720099328.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6779084046.629..  Test Loss: 6675281408.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6711646976.000..  Test Loss: 6750515200.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6715064078.629..  Test Loss: 6690802176.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6608508086.857..  Test Loss: 6654754816.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6546710290.286..  Test Loss: 6636891136.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6619257782.857..  Test Loss: 6552321536.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6587429632.000..  Test Loss: 6797983232.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6659922080.914..  Test Loss: 6779684864.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6613933319.314..  Test Loss: 6557395456.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6727231005.257..  Test Loss: 6538216960.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6536544343.771..  Test Loss: 6636563456.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6568378558.171..  Test Loss: 6504194560.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6514526127.543..  Test Loss: 6432652288.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6513695597.714..  Test Loss: 6579005952.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6641877708.800..  Test Loss: 6523618816.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6574422915.657..  Test Loss: 6355159040.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6595688674.743..  Test Loss: 6450867712.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6500950301.257..  Test Loss: 6301296128.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6475504618.057..  Test Loss: 6478803968.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6452980004.571..  Test Loss: 6354081792.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6582222891.886..  Test Loss: 6420127232.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6365278493.257..  Test Loss: 6313573888.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6365031753.143..  Test Loss: 6256201216.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6343144755.200..  Test Loss: 6231250944.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6415382564.571..  Test Loss: 6319629824.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6339297499.429..  Test Loss: 6371318272.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6325673530.514..  Test Loss: 6407471104.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6421696936.229..  Test Loss: 6355312128.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6397757732.571..  Test Loss: 6424315392.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6331834492.343..  Test Loss: 6222439936.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6331107905.829..  Test Loss: 6544564224.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6271988341.029..  Test Loss: 6234144256.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6348007424.000..  Test Loss: 6224705536.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6329538538.057..  Test Loss: 6376554496.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6346170397.257..  Test Loss: 6286958592.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6316444796.343..  Test Loss: 6322824192.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6272426415.543..  Test Loss: 6230154752.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6347342606.629..  Test Loss: 6186533888.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6247179776.000..  Test Loss: 6246692352.000.. \n",
      "Epoch: 569/1000..  Training Loss: 6159609278.171..  Test Loss: 5966717440.000.. \n",
      "Epoch: 570/1000..  Training Loss: 6191551232.000..  Test Loss: 6022243840.000.. \n",
      "Epoch: 571/1000..  Training Loss: 6223326537.143..  Test Loss: 6071648768.000.. \n",
      "Epoch: 572/1000..  Training Loss: 6261823290.514..  Test Loss: 6106659840.000.. \n",
      "Epoch: 573/1000..  Training Loss: 6334768961.829..  Test Loss: 5981517312.000.. \n",
      "Epoch: 574/1000..  Training Loss: 6115449512.229..  Test Loss: 6075846656.000.. \n",
      "Epoch: 575/1000..  Training Loss: 6139119835.429..  Test Loss: 5957344768.000.. \n",
      "Epoch: 576/1000..  Training Loss: 6119507836.343..  Test Loss: 5927535104.000.. \n",
      "Epoch: 577/1000..  Training Loss: 6042474942.171..  Test Loss: 5878636032.000.. \n",
      "Epoch: 578/1000..  Training Loss: 6041834086.400..  Test Loss: 6020092416.000.. \n",
      "Epoch: 579/1000..  Training Loss: 6026577459.200..  Test Loss: 5884582912.000.. \n",
      "Epoch: 580/1000..  Training Loss: 6102129364.114..  Test Loss: 5962308608.000.. \n",
      "Epoch: 581/1000..  Training Loss: 6116744952.686..  Test Loss: 6000178688.000.. \n",
      "Epoch: 582/1000..  Training Loss: 6126376235.886..  Test Loss: 6092393984.000.. \n",
      "Epoch: 583/1000..  Training Loss: 6129693169.371..  Test Loss: 6062466560.000.. \n",
      "Epoch: 584/1000..  Training Loss: 6060299812.571..  Test Loss: 5940737536.000.. \n",
      "Epoch: 585/1000..  Training Loss: 6057439839.086..  Test Loss: 6022641152.000.. \n",
      "Epoch: 586/1000..  Training Loss: 6071958926.629..  Test Loss: 5726301696.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5901862860.800..  Test Loss: 5825021440.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5954555201.829..  Test Loss: 5871345664.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5979812352.000..  Test Loss: 5879027200.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5949882704.457..  Test Loss: 5947833344.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5972992160.914..  Test Loss: 5907258880.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5941809817.600..  Test Loss: 5896893440.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5983406767.543..  Test Loss: 5779039232.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5991692485.486..  Test Loss: 5614804992.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5928425333.029..  Test Loss: 5893171712.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5934171925.943..  Test Loss: 5679523840.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5926403298.743..  Test Loss: 5581762048.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5841876326.400..  Test Loss: 5937756672.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5947450872.686..  Test Loss: 5654801920.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5809727253.943..  Test Loss: 5691731456.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5943196825.600..  Test Loss: 5815741952.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5969721643.886..  Test Loss: 5546223104.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5874309222.400..  Test Loss: 5429104128.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 604/1000..  Training Loss: 5844240698.514..  Test Loss: 5615781888.000.. \n",
      "Epoch: 605/1000..  Training Loss: 5798152257.829..  Test Loss: 5443348480.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5824511882.971..  Test Loss: 5781926400.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5746565968.457..  Test Loss: 5573495808.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5855962909.257..  Test Loss: 5635715584.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5829352418.743..  Test Loss: 5713070080.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5779169192.229..  Test Loss: 5507495424.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5791545344.000..  Test Loss: 5809550848.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5691397405.257..  Test Loss: 5560077824.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5688817049.600..  Test Loss: 5559434752.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5760521508.571..  Test Loss: 5486863872.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5666516523.886..  Test Loss: 5500170240.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5649493664.914..  Test Loss: 5425198592.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5706188573.257..  Test Loss: 5454652416.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5626515832.686..  Test Loss: 5424519680.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5588029630.171..  Test Loss: 5452679168.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5724587944.229..  Test Loss: 5324400640.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5593805494.857..  Test Loss: 5351345664.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5649065830.400..  Test Loss: 5376905216.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5661760833.829..  Test Loss: 5354673152.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5656016727.771..  Test Loss: 5267600896.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5726331889.371..  Test Loss: 5397528064.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5668828013.714..  Test Loss: 5373828608.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5578060858.514..  Test Loss: 5367539200.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5563055959.771..  Test Loss: 5418918400.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5517433285.486..  Test Loss: 5434750464.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5613154574.629..  Test Loss: 5423221248.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5575437509.486..  Test Loss: 5313267200.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5594918670.629..  Test Loss: 5203910144.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5456645302.857..  Test Loss: 5186036224.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5488005653.943..  Test Loss: 5262462464.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5586542939.429..  Test Loss: 5278259712.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5536956847.543..  Test Loss: 5206523904.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5433596851.200..  Test Loss: 5300661760.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5501823897.600..  Test Loss: 5458186752.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5435871180.800..  Test Loss: 5206117376.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5500274124.800..  Test Loss: 5124152832.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5642074455.771..  Test Loss: 5172903936.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5364144939.886..  Test Loss: 5186584064.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5502485833.143..  Test Loss: 5127714304.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5547838376.229..  Test Loss: 5078169600.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5452417389.714..  Test Loss: 5101379072.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5421457671.314..  Test Loss: 5148266496.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5481542846.171..  Test Loss: 5130520576.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5413716494.629..  Test Loss: 5162597888.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5467028670.171..  Test Loss: 5103938048.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5417959526.400..  Test Loss: 5028817408.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5370644984.686..  Test Loss: 5069404672.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5337394490.514..  Test Loss: 4920591872.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5398367561.143..  Test Loss: 5011506176.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5402171443.200..  Test Loss: 4982171136.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5446216916.114..  Test Loss: 4995767808.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5224876478.171..  Test Loss: 5108306432.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5377259008.000..  Test Loss: 4993029632.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5287414546.286..  Test Loss: 4921395712.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5332013377.829..  Test Loss: 4943078912.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5331407400.229..  Test Loss: 5001976320.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5283714790.400..  Test Loss: 4890155008.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5237560312.686..  Test Loss: 4731246080.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5461517224.229..  Test Loss: 4787082752.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5227139386.514..  Test Loss: 4919505920.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5234620342.857..  Test Loss: 4757167104.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5241378903.771..  Test Loss: 4858573312.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5296552250.514..  Test Loss: 4831936000.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5404486597.486..  Test Loss: 4845254144.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5154439445.943..  Test Loss: 4856606720.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5309485341.257..  Test Loss: 4818163200.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5206288457.143..  Test Loss: 4799071744.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5225716066.743..  Test Loss: 4858841600.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5176262977.829..  Test Loss: 4978117120.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5147154205.257..  Test Loss: 4964795392.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5194458777.600..  Test Loss: 4832965120.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5173895219.200..  Test Loss: 4966400000.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5107347463.314..  Test Loss: 4652471808.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5295697620.114..  Test Loss: 4795517440.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5242466794.057..  Test Loss: 4722439680.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5156154433.829..  Test Loss: 4925950976.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5116084761.600..  Test Loss: 4849832448.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5141551338.057..  Test Loss: 4707084800.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5136309877.029..  Test Loss: 4836157440.000.. \n",
      "Epoch: 684/1000..  Training Loss: 5203085597.257..  Test Loss: 4674549760.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5205729119.086..  Test Loss: 4734343168.000.. \n",
      "Epoch: 686/1000..  Training Loss: 5160394890.971..  Test Loss: 4779202048.000.. \n",
      "Epoch: 687/1000..  Training Loss: 5127351815.314..  Test Loss: 4740326400.000.. \n",
      "Epoch: 688/1000..  Training Loss: 5126338157.714..  Test Loss: 4628125184.000.. \n",
      "Epoch: 689/1000..  Training Loss: 5212295628.800..  Test Loss: 4705481216.000.. \n",
      "Epoch: 690/1000..  Training Loss: 5031965370.514..  Test Loss: 4751603200.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5114053862.400..  Test Loss: 4563271168.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5145500869.486..  Test Loss: 4534722048.000.. \n",
      "Epoch: 693/1000..  Training Loss: 5026907582.171..  Test Loss: 4680599040.000.. \n",
      "Epoch: 694/1000..  Training Loss: 5067598006.857..  Test Loss: 4634143744.000.. \n",
      "Epoch: 695/1000..  Training Loss: 5096103365.486..  Test Loss: 4595694080.000.. \n",
      "Epoch: 696/1000..  Training Loss: 5162477421.714..  Test Loss: 4746819072.000.. \n",
      "Epoch: 697/1000..  Training Loss: 4941982932.114..  Test Loss: 4556835840.000.. \n",
      "Epoch: 698/1000..  Training Loss: 5049630149.486..  Test Loss: 4605651968.000.. \n",
      "Epoch: 699/1000..  Training Loss: 5093911456.914..  Test Loss: 4627882496.000.. \n",
      "Epoch: 700/1000..  Training Loss: 5019400755.200..  Test Loss: 4519186432.000.. \n",
      "Epoch: 701/1000..  Training Loss: 5143821158.400..  Test Loss: 4580365824.000.. \n",
      "Epoch: 702/1000..  Training Loss: 5047526963.200..  Test Loss: 4739892736.000.. \n",
      "Epoch: 703/1000..  Training Loss: 5094649965.714..  Test Loss: 4539026432.000.. \n",
      "Epoch: 704/1000..  Training Loss: 5058885909.943..  Test Loss: 4508966400.000.. \n",
      "Epoch: 705/1000..  Training Loss: 5123558268.343..  Test Loss: 4444625408.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 706/1000..  Training Loss: 5071442636.800..  Test Loss: 4521434112.000.. \n",
      "Epoch: 707/1000..  Training Loss: 5044562914.743..  Test Loss: 4627219968.000.. \n",
      "Epoch: 708/1000..  Training Loss: 5117788408.686..  Test Loss: 4452464640.000.. \n",
      "Epoch: 709/1000..  Training Loss: 4955478915.657..  Test Loss: 4550712832.000.. \n",
      "Epoch: 710/1000..  Training Loss: 5077589412.571..  Test Loss: 4580944384.000.. \n",
      "Epoch: 711/1000..  Training Loss: 5155296672.914..  Test Loss: 4563168768.000.. \n",
      "Epoch: 712/1000..  Training Loss: 5018689312.914..  Test Loss: 4513658368.000.. \n",
      "Epoch: 713/1000..  Training Loss: 4954510438.400..  Test Loss: 4465175040.000.. \n",
      "Epoch: 714/1000..  Training Loss: 5022741752.686..  Test Loss: 4438442496.000.. \n",
      "Epoch: 715/1000..  Training Loss: 5018021112.686..  Test Loss: 4564102144.000.. \n",
      "Epoch: 716/1000..  Training Loss: 5032473746.286..  Test Loss: 4404280320.000.. \n",
      "Epoch: 717/1000..  Training Loss: 5037022273.829..  Test Loss: 4543516672.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4910484231.314..  Test Loss: 4401999872.000.. \n",
      "Epoch: 719/1000..  Training Loss: 5002034863.543..  Test Loss: 4526411776.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4967400111.543..  Test Loss: 4385691136.000.. \n",
      "Epoch: 721/1000..  Training Loss: 5019792062.171..  Test Loss: 4641396224.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4989345828.571..  Test Loss: 4566630400.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4887353757.257..  Test Loss: 4445207040.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4873400265.143..  Test Loss: 4311379456.000.. \n",
      "Epoch: 725/1000..  Training Loss: 5031049450.057..  Test Loss: 4370007552.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4924434987.886..  Test Loss: 4400320512.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4974663226.514..  Test Loss: 4386416128.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4872896204.800..  Test Loss: 4384378368.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4882179891.200..  Test Loss: 4347440640.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4936863890.286..  Test Loss: 4237041664.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4947213897.143..  Test Loss: 4391214592.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4934995221.943..  Test Loss: 4361393664.000.. \n",
      "Epoch: 733/1000..  Training Loss: 5024637293.714..  Test Loss: 4369707008.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4994435847.314..  Test Loss: 4320392704.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4971619693.714..  Test Loss: 4353520640.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4890996216.686..  Test Loss: 4354355712.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4989192864.914..  Test Loss: 4330446848.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4840738750.171..  Test Loss: 4403258880.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4855290624.000..  Test Loss: 4420637184.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4852248773.486..  Test Loss: 4347841536.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4980028489.143..  Test Loss: 4375729152.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4920672921.600..  Test Loss: 4241425664.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4836695584.914..  Test Loss: 4250167808.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4926838272.000..  Test Loss: 4262023168.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4875443898.514..  Test Loss: 4261579264.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4873549955.657..  Test Loss: 4255085312.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4965969590.857..  Test Loss: 4245061376.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4905803432.229..  Test Loss: 4283408896.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4871289131.886..  Test Loss: 4230597376.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4910416742.400..  Test Loss: 4335225344.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4849485363.200..  Test Loss: 4255022848.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4798874104.686..  Test Loss: 4182105856.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4897795349.943..  Test Loss: 4192179968.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4997378479.543..  Test Loss: 4212668928.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4784275777.829..  Test Loss: 4226556672.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4923644459.886..  Test Loss: 4121248256.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4831054548.114..  Test Loss: 4098512640.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4843810186.971..  Test Loss: 4183235328.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4894966864.457..  Test Loss: 4118594816.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4808929887.086..  Test Loss: 4079555328.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4879121203.200..  Test Loss: 4132812032.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4893351197.257..  Test Loss: 4094412544.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4832910621.257..  Test Loss: 4172546816.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4808754984.229..  Test Loss: 4105189888.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4767816294.400..  Test Loss: 4160278528.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4798737137.371..  Test Loss: 4035921152.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4784989074.286..  Test Loss: 4089577984.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4794459618.743..  Test Loss: 4161520128.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4842058722.743..  Test Loss: 4065944064.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4821460692.114..  Test Loss: 4020141312.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4801313078.857..  Test Loss: 4071460864.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4754497872.457..  Test Loss: 4046521088.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4819284282.514..  Test Loss: 4035057664.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4765247802.514..  Test Loss: 3985390336.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4754458741.029..  Test Loss: 3993079040.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4876624533.943..  Test Loss: 4170072576.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4783355128.686..  Test Loss: 4088019456.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4749499033.600..  Test Loss: 4052555776.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4831996690.286..  Test Loss: 3992870912.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4813456062.171..  Test Loss: 4067864320.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4792288753.371..  Test Loss: 4021686272.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4673118866.286..  Test Loss: 4226363136.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4779775634.286..  Test Loss: 4119199744.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4798796295.314..  Test Loss: 4053637888.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4796103782.400..  Test Loss: 4065523456.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4833815252.114..  Test Loss: 4178781952.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4801396377.600..  Test Loss: 3982068224.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4884832299.886..  Test Loss: 3964797696.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4846472978.286..  Test Loss: 4129392640.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4797870306.743..  Test Loss: 4033644288.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4765294160.457..  Test Loss: 4007791872.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4787468390.400..  Test Loss: 4019370496.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4716318837.029..  Test Loss: 3901349632.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4703145025.829..  Test Loss: 3954315776.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4765005143.771..  Test Loss: 4157660416.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4694967581.257..  Test Loss: 3966086400.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4786757829.486..  Test Loss: 3966883840.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4748954711.771..  Test Loss: 3983538176.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4810524116.114..  Test Loss: 4035646720.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4767418792.229..  Test Loss: 3944898560.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4709664256.000..  Test Loss: 3940008448.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4826074265.600..  Test Loss: 3918658048.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4872214762.057..  Test Loss: 3927846656.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4737658536.229..  Test Loss: 3908773120.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4852580461.714..  Test Loss: 3914972416.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4740596962.743..  Test Loss: 3965660928.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4767228789.029..  Test Loss: 3918933248.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 808/1000..  Training Loss: 4773277615.543..  Test Loss: 3942930944.000.. \n",
      "Epoch: 809/1000..  Training Loss: 4755986373.486..  Test Loss: 3945754624.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4820754991.543..  Test Loss: 3846039296.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4714496914.286..  Test Loss: 3954073344.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4751948712.229..  Test Loss: 3913688320.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4745531139.657..  Test Loss: 3858392832.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4763979366.400..  Test Loss: 3944147712.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4747737530.514..  Test Loss: 3886355200.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4784774794.971..  Test Loss: 3934072576.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4810649307.429..  Test Loss: 3898252544.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4751461412.571..  Test Loss: 3840886528.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4747613410.743..  Test Loss: 3846225664.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4759383372.800..  Test Loss: 3822488064.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4792089402.514..  Test Loss: 3953945088.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4674755744.914..  Test Loss: 3818708736.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4661346995.200..  Test Loss: 3901631744.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4765939163.429..  Test Loss: 3927652096.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4829855963.429..  Test Loss: 3907357184.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4714985237.943..  Test Loss: 3873749504.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4700444957.257..  Test Loss: 3834486784.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4723200299.886..  Test Loss: 3814094592.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4716677917.257..  Test Loss: 3842559744.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4778513795.657..  Test Loss: 3871999232.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4755848404.114..  Test Loss: 3852765184.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4686153252.571..  Test Loss: 3852483840.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4773504614.400..  Test Loss: 3861673216.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4648004015.543..  Test Loss: 3811548416.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4727023352.686..  Test Loss: 3881677312.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4745431720.229..  Test Loss: 3861164032.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4774157487.543..  Test Loss: 3878390528.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4746027885.714..  Test Loss: 3856439040.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4759953627.429..  Test Loss: 3854150912.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4696100447.086..  Test Loss: 3840513792.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4701567564.800..  Test Loss: 3878872320.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4767312508.343..  Test Loss: 3785035008.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4860265728.000..  Test Loss: 3849361152.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4755541957.486..  Test Loss: 3928751360.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4761675637.029..  Test Loss: 3826329344.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4709067059.200..  Test Loss: 3842286336.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4694513422.629..  Test Loss: 3909652480.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4685288638.171..  Test Loss: 3804919808.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4712359745.829..  Test Loss: 3907981824.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4747450126.629..  Test Loss: 3848614400.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4705441711.543..  Test Loss: 3824620800.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4611071879.314..  Test Loss: 3782618368.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4803043532.800..  Test Loss: 3869828352.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4736051529.143..  Test Loss: 3897366528.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4673098236.343..  Test Loss: 3840733184.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4740067613.257..  Test Loss: 3803151616.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4728883938.743..  Test Loss: 3867691008.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4703975957.943..  Test Loss: 3787621632.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4714328027.429..  Test Loss: 3771165952.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4693821162.057..  Test Loss: 3822212864.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4787355739.429..  Test Loss: 3801988352.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4629063372.800..  Test Loss: 3821112064.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4858086517.029..  Test Loss: 3799730688.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4715022266.514..  Test Loss: 3757947648.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4721826728.229..  Test Loss: 3798116096.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4740279032.686..  Test Loss: 3770387712.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4765382553.600..  Test Loss: 3877666816.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4815435059.200..  Test Loss: 3780250112.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4688845202.286..  Test Loss: 3760680192.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4697846531.657..  Test Loss: 3865901568.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4699886248.229..  Test Loss: 3859206656.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4677003022.629..  Test Loss: 3888368128.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4847803648.000..  Test Loss: 3756347392.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4761613502.171..  Test Loss: 3786518272.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4663507510.857..  Test Loss: 3789582080.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4672295848.229..  Test Loss: 3778447360.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4835775787.886..  Test Loss: 3777477120.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4657305607.314..  Test Loss: 3879870464.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4834052041.143..  Test Loss: 3758497024.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4664537475.657..  Test Loss: 3769489152.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4743573438.171..  Test Loss: 3891347456.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4670000354.743..  Test Loss: 3848466176.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4698215965.257..  Test Loss: 3795068672.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4643103451.429..  Test Loss: 3767587328.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4738469171.200..  Test Loss: 3736140544.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4722980798.171..  Test Loss: 3817572096.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4700829608.229..  Test Loss: 3857423104.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4738848138.971..  Test Loss: 3837854976.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4702518228.114..  Test Loss: 3842413312.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4675262478.629..  Test Loss: 3859980288.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4703808746.057..  Test Loss: 3774627072.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4722976658.286..  Test Loss: 3789073664.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4732899686.400..  Test Loss: 3771209472.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4672604196.571..  Test Loss: 3758087936.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4668271177.143..  Test Loss: 3735131904.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4668363454.171..  Test Loss: 3760531456.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4718285597.257..  Test Loss: 3758519040.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4723333975.771..  Test Loss: 3721351680.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4766141059.657..  Test Loss: 3715961600.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4666660425.143..  Test Loss: 3755672064.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4765311985.371..  Test Loss: 3806550784.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4641632475.429..  Test Loss: 3836975616.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4654993941.943..  Test Loss: 3738339328.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4722231903.086..  Test Loss: 3762357504.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4660990752.914..  Test Loss: 3715807232.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4703852149.029..  Test Loss: 3760648192.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4717945446.400..  Test Loss: 3786131200.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4676919449.600..  Test Loss: 3838670080.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4682336585.143..  Test Loss: 3775120640.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4670666261.943..  Test Loss: 3828388608.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 911/1000..  Training Loss: 4669837059.657..  Test Loss: 3704952832.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4756435302.400..  Test Loss: 3790771968.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4727163940.571..  Test Loss: 3846703616.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4668486634.057..  Test Loss: 3755687936.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4707720111.543..  Test Loss: 3716934144.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4685040036.571..  Test Loss: 3768918016.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4673480192.000..  Test Loss: 3715923968.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4675092165.486..  Test Loss: 3821533952.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4727239204.571..  Test Loss: 3737632512.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4681900061.257..  Test Loss: 3870052096.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4730419097.600..  Test Loss: 3756740352.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4727870840.686..  Test Loss: 3731194624.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4621164346.514..  Test Loss: 3813605888.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4712800446.171..  Test Loss: 3716460288.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4671264636.343..  Test Loss: 3713753088.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4684773895.314..  Test Loss: 3771398656.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4789293546.057..  Test Loss: 3881130752.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4686762517.943..  Test Loss: 3766536704.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4720113056.914..  Test Loss: 3892428544.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4661717288.229..  Test Loss: 3756799744.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4755163728.457..  Test Loss: 3811235840.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4685837531.429..  Test Loss: 3784528384.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4633090581.943..  Test Loss: 3742763520.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4744040506.514..  Test Loss: 3824213248.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4666660147.200..  Test Loss: 3702344192.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4672394561.829..  Test Loss: 3779476736.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4703157182.171..  Test Loss: 3757307648.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4702204928.000..  Test Loss: 3714272512.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4695396088.686..  Test Loss: 3766196736.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4671020865.829..  Test Loss: 3721177856.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4713368656.457..  Test Loss: 3846255104.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4739178602.057..  Test Loss: 3719573248.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4660252467.200..  Test Loss: 3829791232.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4719818430.171..  Test Loss: 3759604480.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4725591347.200..  Test Loss: 3793129472.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4640162925.714..  Test Loss: 3680075520.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4651980127.086..  Test Loss: 3701518080.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4689801450.057..  Test Loss: 3783353088.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4739528411.429..  Test Loss: 3732371968.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4613635068.343..  Test Loss: 3742947072.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4658391925.029..  Test Loss: 3732701184.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4689287775.086..  Test Loss: 3848275712.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4669753709.714..  Test Loss: 3737192448.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4672292249.600..  Test Loss: 3699404032.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4711539997.257..  Test Loss: 3691153920.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4628910259.200..  Test Loss: 3887336192.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4628775950.629..  Test Loss: 3751218432.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4618351195.429..  Test Loss: 3758985984.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4619725831.314..  Test Loss: 3682700544.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4722175136.914..  Test Loss: 3761915648.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4633938900.114..  Test Loss: 3686235392.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4695948214.857..  Test Loss: 3725593344.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4816097638.400..  Test Loss: 3860930560.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4628674947.657..  Test Loss: 3758426624.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4694423932.343..  Test Loss: 3733574400.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4585971631.543..  Test Loss: 3736199936.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4787375703.771..  Test Loss: 3766768128.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4653447124.114..  Test Loss: 3736739840.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4664871899.429..  Test Loss: 3723895552.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4663162090.057..  Test Loss: 3688176896.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4652586766.629..  Test Loss: 3676689152.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4633597937.371..  Test Loss: 3833451008.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4696516586.057..  Test Loss: 3689316864.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4739791981.714..  Test Loss: 3713574144.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4689139200.000..  Test Loss: 3696092416.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4709701939.200..  Test Loss: 3733716992.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4721966328.686..  Test Loss: 3735878912.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4706527868.343..  Test Loss: 3774898688.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4673107126.857..  Test Loss: 3742282240.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4593513369.600..  Test Loss: 3692414720.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4633807974.400..  Test Loss: 3760637952.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4627616190.171..  Test Loss: 3801701120.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4592745311.086..  Test Loss: 3753971456.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4706250357.029..  Test Loss: 3739802112.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4625016283.429..  Test Loss: 3827051776.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4738085061.486..  Test Loss: 3742357504.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4648035825.371..  Test Loss: 3733990144.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4650682481.371..  Test Loss: 3753368832.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4573464429.714..  Test Loss: 3720783104.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4676498388.114..  Test Loss: 3795830016.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4673340715.886..  Test Loss: 3762075392.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4640546117.486..  Test Loss: 3744958208.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4681359594.057..  Test Loss: 3779790592.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4695967564.800..  Test Loss: 3705966592.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4775603434.057..  Test Loss: 3754559488.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4766618660.571..  Test Loss: 3686135552.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4716808689.371..  Test Loss: 3716883200.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4677735936.000..  Test Loss: 3691464448.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4654709328.457..  Test Loss: 3710904832.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4643590560.914..  Test Loss: 3727533824.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 1\n",
      "Epoch: 1/1000..  Training Loss: 13551294976.000..  Test Loss: 12103532544.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13630256042.667..  Test Loss: 12177615872.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13667639608.889..  Test Loss: 12138308608.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13739495793.778..  Test Loss: 12125950976.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13547457991.111..  Test Loss: 12032274432.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13573363200.000..  Test Loss: 12176612352.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13614168576.000..  Test Loss: 12116027392.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13630072177.778..  Test Loss: 12178544640.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13649168810.667..  Test Loss: 12177377280.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13562805333.333..  Test Loss: 12194646016.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13572339427.556..  Test Loss: 12134126592.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13652739925.333..  Test Loss: 12312712192.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13661839089.778..  Test Loss: 12134319104.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13587961941.333..  Test Loss: 12091181056.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13592805376.000..  Test Loss: 12040322048.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13576647992.889..  Test Loss: 12093554688.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13643682218.667..  Test Loss: 12199032832.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13573569038.222..  Test Loss: 12155635712.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13590427278.222..  Test Loss: 12194325504.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13625050965.333..  Test Loss: 12053348352.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13627592419.556..  Test Loss: 12261842944.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13647854762.667..  Test Loss: 12306582528.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13608921457.778..  Test Loss: 12030682112.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13600188117.333..  Test Loss: 12165051392.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13573716963.556..  Test Loss: 12243136512.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13540990108.444..  Test Loss: 12104683520.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13536344064.000..  Test Loss: 12327091200.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13509725539.556..  Test Loss: 12223235072.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13536948508.444..  Test Loss: 11961538560.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13707729578.667..  Test Loss: 12275397632.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13636124444.444..  Test Loss: 12040656896.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13538861539.556..  Test Loss: 12064355328.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13597955470.222..  Test Loss: 12145948672.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13535868316.444..  Test Loss: 12236526592.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13555995192.889..  Test Loss: 12093810688.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13544779477.333..  Test Loss: 12030961664.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13482411292.444..  Test Loss: 12016450560.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13546423936.000..  Test Loss: 12257867776.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13485344796.444..  Test Loss: 12130756608.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13525248142.222..  Test Loss: 12193390592.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13503971669.333..  Test Loss: 12223877120.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13556770560.000..  Test Loss: 12096254976.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13428314524.444..  Test Loss: 12309947392.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13580071822.222..  Test Loss: 12093314048.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13464277560.889..  Test Loss: 12265365504.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13469507612.444..  Test Loss: 12309535744.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13458652188.444..  Test Loss: 12201303040.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13514773432.889..  Test Loss: 12106274816.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13487947349.333..  Test Loss: 12066654208.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13562386631.111..  Test Loss: 11969209344.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13555067648.000..  Test Loss: 12161499136.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13445856199.111..  Test Loss: 12111840256.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13407232256.000..  Test Loss: 12016175104.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13518932465.778..  Test Loss: 12263886848.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13454877923.556..  Test Loss: 11907240960.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13465124736.000..  Test Loss: 12080423936.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13528035854.222..  Test Loss: 12147341312.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13412662129.778..  Test Loss: 11949164544.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13435063239.111..  Test Loss: 11955582976.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13320067072.000..  Test Loss: 11991672832.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13340721180.444..  Test Loss: 12094814208.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13406501063.111..  Test Loss: 12238746624.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13472686392.889..  Test Loss: 11962068992.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13363232355.556..  Test Loss: 12168880128.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13316662897.778..  Test Loss: 12249864192.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13406636103.111..  Test Loss: 12041342976.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13367144220.444..  Test Loss: 12054146048.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13351957248.000..  Test Loss: 12143431680.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13403883377.778..  Test Loss: 12062931968.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13505830456.889..  Test Loss: 12009752576.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13300615168.000..  Test Loss: 11920076800.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13304502016.000..  Test Loss: 12117664768.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13303392839.111..  Test Loss: 11926782976.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13305795655.111..  Test Loss: 11991412736.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13293464177.778..  Test Loss: 12056552448.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13312207658.667..  Test Loss: 12104557568.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13261150492.444..  Test Loss: 12057249792.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13215666218.667..  Test Loss: 12131074048.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13231508309.333..  Test Loss: 11889861632.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13254504078.222..  Test Loss: 12040511488.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13362113976.889..  Test Loss: 12099064832.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13235613980.444..  Test Loss: 12019299328.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13190085489.778..  Test Loss: 12002752512.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13283171640.889..  Test Loss: 11983182848.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13280690033.778..  Test Loss: 12208246784.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13137040341.333..  Test Loss: 12061848576.000.. \n",
      "Epoch: 87/1000..  Training Loss: 13186607815.111..  Test Loss: 11858141184.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13217328782.222..  Test Loss: 11909235712.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13405964928.000..  Test Loss: 12204183552.000.. \n",
      "Epoch: 90/1000..  Training Loss: 13147487502.222..  Test Loss: 12126221312.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13205083847.111..  Test Loss: 11995928576.000.. \n",
      "Epoch: 92/1000..  Training Loss: 13139620266.667..  Test Loss: 12089664512.000.. \n",
      "Epoch: 93/1000..  Training Loss: 13148160995.556..  Test Loss: 11999449088.000.. \n",
      "Epoch: 94/1000..  Training Loss: 13168723797.333..  Test Loss: 12024568832.000.. \n",
      "Epoch: 95/1000..  Training Loss: 13200264049.778..  Test Loss: 12028102656.000.. \n",
      "Epoch: 96/1000..  Training Loss: 13143907356.444..  Test Loss: 12141714432.000.. \n",
      "Epoch: 97/1000..  Training Loss: 13137320135.111..  Test Loss: 12094083072.000.. \n",
      "Epoch: 98/1000..  Training Loss: 13155544291.556..  Test Loss: 12063675392.000.. \n",
      "Epoch: 99/1000..  Training Loss: 13107634602.667..  Test Loss: 12008094720.000.. \n",
      "Epoch: 100/1000..  Training Loss: 13086872320.000..  Test Loss: 11873476608.000.. \n",
      "Epoch: 101/1000..  Training Loss: 13075328768.000..  Test Loss: 11975278592.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102/1000..  Training Loss: 13029666816.000..  Test Loss: 11955723264.000.. \n",
      "Epoch: 103/1000..  Training Loss: 13042966044.444..  Test Loss: 11824829440.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12988799203.556..  Test Loss: 11753464832.000.. \n",
      "Epoch: 105/1000..  Training Loss: 13211366656.000..  Test Loss: 11844481024.000.. \n",
      "Epoch: 106/1000..  Training Loss: 13133116430.222..  Test Loss: 11888657408.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12943237632.000..  Test Loss: 11901972480.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12960786005.333..  Test Loss: 12112748544.000.. \n",
      "Epoch: 109/1000..  Training Loss: 13012723854.222..  Test Loss: 11770006528.000.. \n",
      "Epoch: 110/1000..  Training Loss: 13014518954.667..  Test Loss: 11814377472.000.. \n",
      "Epoch: 111/1000..  Training Loss: 13041468871.111..  Test Loss: 12067850240.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12984080568.889..  Test Loss: 11879684096.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12993900017.778..  Test Loss: 12068163584.000.. \n",
      "Epoch: 114/1000..  Training Loss: 13079712170.667..  Test Loss: 12093335552.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12919629511.111..  Test Loss: 11950799872.000.. \n",
      "Epoch: 116/1000..  Training Loss: 13007835904.000..  Test Loss: 11924188160.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12938627896.889..  Test Loss: 11878395904.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12962071779.556..  Test Loss: 11852693504.000.. \n",
      "Epoch: 119/1000..  Training Loss: 13011593941.333..  Test Loss: 11796782080.000.. \n",
      "Epoch: 120/1000..  Training Loss: 13020869063.111..  Test Loss: 11892492288.000.. \n",
      "Epoch: 121/1000..  Training Loss: 13026015431.111..  Test Loss: 11963301888.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12849033045.333..  Test Loss: 11683431424.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12970747776.000..  Test Loss: 11697431552.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12888030037.333..  Test Loss: 11817546752.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12853347953.778..  Test Loss: 11850061824.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12929300536.889..  Test Loss: 11822050304.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12856234865.778..  Test Loss: 11904792576.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12774010936.889..  Test Loss: 11881539584.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12730962204.444..  Test Loss: 11788271616.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12846337223.111..  Test Loss: 11838042112.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12767000931.556..  Test Loss: 11755771904.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12740339399.111..  Test Loss: 11639665664.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12721994154.667..  Test Loss: 11829103616.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12671316110.222..  Test Loss: 11941914624.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12767510784.000..  Test Loss: 11953211392.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12746708110.222..  Test Loss: 11710627840.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12767674567.111..  Test Loss: 12000560128.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12647444394.667..  Test Loss: 11874797568.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12674314538.667..  Test Loss: 11774508032.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12745956679.111..  Test Loss: 11913148416.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12685448092.444..  Test Loss: 11817906176.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12645630620.444..  Test Loss: 11819578368.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12576186823.111..  Test Loss: 11697876992.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12668435697.778..  Test Loss: 11834337280.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12637420430.222..  Test Loss: 11936081920.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12564079047.111..  Test Loss: 11921809408.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12755327431.111..  Test Loss: 11689210880.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12518119537.778..  Test Loss: 11872690176.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12580366961.778..  Test Loss: 11552670720.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12572311153.778..  Test Loss: 11690771456.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12492016284.444..  Test Loss: 11774333952.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12561516700.444..  Test Loss: 11593714688.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12535740928.000..  Test Loss: 11595379712.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12436576540.444..  Test Loss: 11970233344.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12505782912.000..  Test Loss: 11738006528.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12506012273.778..  Test Loss: 11818755072.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12503351978.667..  Test Loss: 11614073856.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12675673116.444..  Test Loss: 11664812032.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12394290104.889..  Test Loss: 11779696640.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12487003448.889..  Test Loss: 11744406528.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12433904782.222..  Test Loss: 11648281600.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12384968590.222..  Test Loss: 11779112960.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12448830833.778..  Test Loss: 11780428800.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12478527943.111..  Test Loss: 11822155776.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12371044337.778..  Test Loss: 11656327168.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12336505486.222..  Test Loss: 11610554368.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12335466254.222..  Test Loss: 11636327424.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12314113720.889..  Test Loss: 11731392512.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12355169479.111..  Test Loss: 11568421888.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12464299576.889..  Test Loss: 11483165696.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12200487352.889..  Test Loss: 11499497472.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12295203996.444..  Test Loss: 11741492224.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12162733482.667..  Test Loss: 11813974016.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12208156728.889..  Test Loss: 11808642048.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12237640135.111..  Test Loss: 11892282368.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12238112355.556..  Test Loss: 11530252288.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12185864291.556..  Test Loss: 11823406080.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12159130453.333..  Test Loss: 11737790464.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12176370474.667..  Test Loss: 11609144320.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12191628302.222..  Test Loss: 11469686784.000.. \n",
      "Epoch: 181/1000..  Training Loss: 12193342535.111..  Test Loss: 11473664000.000.. \n",
      "Epoch: 182/1000..  Training Loss: 12190717397.333..  Test Loss: 11550571520.000.. \n",
      "Epoch: 183/1000..  Training Loss: 12316366421.333..  Test Loss: 11657540608.000.. \n",
      "Epoch: 184/1000..  Training Loss: 12066167367.111..  Test Loss: 11563917312.000.. \n",
      "Epoch: 185/1000..  Training Loss: 12117729934.222..  Test Loss: 11611005952.000.. \n",
      "Epoch: 186/1000..  Training Loss: 12091277624.889..  Test Loss: 11434984448.000.. \n",
      "Epoch: 187/1000..  Training Loss: 12125845120.000..  Test Loss: 11661743104.000.. \n",
      "Epoch: 188/1000..  Training Loss: 12161513016.889..  Test Loss: 11571095552.000.. \n",
      "Epoch: 189/1000..  Training Loss: 12020532010.667..  Test Loss: 11501076480.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11958963953.778..  Test Loss: 11596974080.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11944955207.111..  Test Loss: 11489932288.000.. \n",
      "Epoch: 192/1000..  Training Loss: 12048651363.556..  Test Loss: 11459177472.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11980015360.000..  Test Loss: 11491348480.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11957516672.000..  Test Loss: 11669259264.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11968461681.778..  Test Loss: 11504454656.000.. \n",
      "Epoch: 196/1000..  Training Loss: 12106873841.778..  Test Loss: 11592245248.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11971231630.222..  Test Loss: 11518607360.000.. \n",
      "Epoch: 198/1000..  Training Loss: 12042460956.444..  Test Loss: 11322799104.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11923827896.889..  Test Loss: 11414694912.000.. \n",
      "Epoch: 200/1000..  Training Loss: 12019147918.222..  Test Loss: 11637645312.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11938045738.667..  Test Loss: 11432211456.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202/1000..  Training Loss: 11877954958.222..  Test Loss: 11267553280.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11869922958.222..  Test Loss: 11406100480.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11904685809.778..  Test Loss: 11573318656.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11929347740.444..  Test Loss: 11256829952.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11788680177.778..  Test Loss: 11419537408.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11808388352.000..  Test Loss: 11237274624.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11760987847.111..  Test Loss: 11355227136.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11778500679.111..  Test Loss: 11554695168.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11801678407.111..  Test Loss: 11297942528.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11778377685.333..  Test Loss: 11307337728.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11785617735.111..  Test Loss: 11341860864.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11699544860.444..  Test Loss: 11555997696.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11690449379.556..  Test Loss: 11264249856.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11743053468.444..  Test Loss: 11473317888.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11646205440.000..  Test Loss: 11316737024.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11733323377.778..  Test Loss: 11499616256.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11590007566.222..  Test Loss: 11317301248.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11681622769.778..  Test Loss: 11200097280.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11627677027.556..  Test Loss: 11304747008.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11580087623.111..  Test Loss: 11311580160.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11626388366.222..  Test Loss: 11249213440.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11610045752.889..  Test Loss: 11200214016.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11616680533.333..  Test Loss: 11153534976.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11634460871.111..  Test Loss: 11412215808.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11538099370.667..  Test Loss: 11101800448.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11620999338.667..  Test Loss: 11367668736.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11523914666.667..  Test Loss: 11496727552.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11429665308.444..  Test Loss: 11214810112.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11477528988.444..  Test Loss: 11126322176.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11528559843.556..  Test Loss: 11197645824.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11656271459.556..  Test Loss: 11274974208.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11426490254.222..  Test Loss: 11361771520.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11458143971.556..  Test Loss: 11484500992.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11415624704.000..  Test Loss: 11279375360.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11371345592.889..  Test Loss: 11158295552.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11362420010.667..  Test Loss: 11145816064.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11420744149.333..  Test Loss: 11391075328.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11311097528.889..  Test Loss: 11293095936.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11350994033.778..  Test Loss: 11109883904.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11310832014.222..  Test Loss: 11287997440.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11251704049.778..  Test Loss: 11430145024.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11272835726.222..  Test Loss: 11034660864.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11330944170.667..  Test Loss: 11329208320.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11300116920.889..  Test Loss: 11238557696.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11242096298.667..  Test Loss: 11078571008.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11192678385.778..  Test Loss: 11110719488.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11219288547.556..  Test Loss: 11093545984.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11141379171.556..  Test Loss: 11066772480.000.. \n",
      "Epoch: 250/1000..  Training Loss: 11177177472.000..  Test Loss: 11054348288.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11193343274.667..  Test Loss: 11240004608.000.. \n",
      "Epoch: 252/1000..  Training Loss: 11245655623.111..  Test Loss: 10791272448.000.. \n",
      "Epoch: 253/1000..  Training Loss: 11124327111.111..  Test Loss: 10965613568.000.. \n",
      "Epoch: 254/1000..  Training Loss: 11100017408.000..  Test Loss: 11017081856.000.. \n",
      "Epoch: 255/1000..  Training Loss: 11149781290.667..  Test Loss: 11248120832.000.. \n",
      "Epoch: 256/1000..  Training Loss: 11046299064.889..  Test Loss: 11016713216.000.. \n",
      "Epoch: 257/1000..  Training Loss: 11072085304.889..  Test Loss: 11030221824.000.. \n",
      "Epoch: 258/1000..  Training Loss: 11013050225.778..  Test Loss: 11352361984.000.. \n",
      "Epoch: 259/1000..  Training Loss: 11121861432.889..  Test Loss: 10942011392.000.. \n",
      "Epoch: 260/1000..  Training Loss: 11012485219.556..  Test Loss: 11030254592.000.. \n",
      "Epoch: 261/1000..  Training Loss: 11078504391.111..  Test Loss: 10994421760.000.. \n",
      "Epoch: 262/1000..  Training Loss: 11076881877.333..  Test Loss: 11262023680.000.. \n",
      "Epoch: 263/1000..  Training Loss: 11066890410.667..  Test Loss: 10910769152.000.. \n",
      "Epoch: 264/1000..  Training Loss: 11052093539.556..  Test Loss: 11088412672.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10979578353.778..  Test Loss: 11037946880.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10961390805.333..  Test Loss: 10862031872.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10880488604.444..  Test Loss: 10938427392.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10855187214.222..  Test Loss: 10949725184.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10798648355.556..  Test Loss: 10944737280.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10893794872.889..  Test Loss: 10879491072.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10853074901.333..  Test Loss: 10902825984.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10807423786.667..  Test Loss: 10856204288.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10811143210.667..  Test Loss: 10844446720.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10839587612.444..  Test Loss: 10764430336.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10783642311.111..  Test Loss: 10872954880.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10815285703.111..  Test Loss: 10919372800.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10727794602.667..  Test Loss: 10906080256.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10722443633.778..  Test Loss: 10923248640.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10750386503.111..  Test Loss: 10817479680.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10752698467.556..  Test Loss: 10739694592.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10732805816.889..  Test Loss: 11141985280.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10674483015.111..  Test Loss: 10655541248.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10669849870.222..  Test Loss: 10950521856.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10581798158.222..  Test Loss: 10773509120.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10862453873.778..  Test Loss: 10754252800.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10559628302.222..  Test Loss: 10793568256.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10635303324.444..  Test Loss: 10749620224.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10666748344.889..  Test Loss: 10643143680.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10563124252.444..  Test Loss: 10698118144.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10494584035.556..  Test Loss: 10775566336.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10554656967.111..  Test Loss: 10500835328.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10500266709.333..  Test Loss: 10582462464.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10505234602.667..  Test Loss: 10857700352.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10477831637.333..  Test Loss: 10703710208.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10580308039.111..  Test Loss: 10825404416.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10382897763.556..  Test Loss: 10456853504.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10445261397.333..  Test Loss: 10811237376.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10431767082.667..  Test Loss: 10574420992.000.. \n",
      "Epoch: 299/1000..  Training Loss: 10378261546.667..  Test Loss: 10569166848.000.. \n",
      "Epoch: 300/1000..  Training Loss: 10429308259.556..  Test Loss: 10497757184.000.. \n",
      "Epoch: 301/1000..  Training Loss: 10362608753.778..  Test Loss: 10542552064.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 302/1000..  Training Loss: 10405857265.778..  Test Loss: 10904693760.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10381649848.889..  Test Loss: 10554187776.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10320110805.333..  Test Loss: 10563356672.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10319287808.000..  Test Loss: 10535277568.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10362334520.889..  Test Loss: 10451918848.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10244105130.667..  Test Loss: 10553249792.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10293398058.667..  Test Loss: 10662582272.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10207770894.222..  Test Loss: 10393010176.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10259959239.111..  Test Loss: 10366047232.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10237106801.778..  Test Loss: 10787889152.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10364991104.000..  Test Loss: 10364192768.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10194175772.444..  Test Loss: 10232367104.000.. \n",
      "Epoch: 314/1000..  Training Loss: 10166221184.000..  Test Loss: 10303770624.000.. \n",
      "Epoch: 315/1000..  Training Loss: 10095161571.556..  Test Loss: 10381604864.000.. \n",
      "Epoch: 316/1000..  Training Loss: 10110636487.111..  Test Loss: 10403849216.000.. \n",
      "Epoch: 317/1000..  Training Loss: 10159471317.333..  Test Loss: 10390325248.000.. \n",
      "Epoch: 318/1000..  Training Loss: 10055741717.333..  Test Loss: 10480872448.000.. \n",
      "Epoch: 319/1000..  Training Loss: 10197258126.222..  Test Loss: 10415151104.000.. \n",
      "Epoch: 320/1000..  Training Loss: 10097546538.667..  Test Loss: 10359940096.000.. \n",
      "Epoch: 321/1000..  Training Loss: 10041566791.111..  Test Loss: 10324569088.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9985618005.333..  Test Loss: 10366734336.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9993257358.222..  Test Loss: 10360486912.000.. \n",
      "Epoch: 324/1000..  Training Loss: 10021382499.556..  Test Loss: 10328342528.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9989345208.889..  Test Loss: 10268691456.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9997929585.778..  Test Loss: 10336457728.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9956766634.667..  Test Loss: 10349007872.000.. \n",
      "Epoch: 328/1000..  Training Loss: 10028100480.000..  Test Loss: 10327455744.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9923403420.444..  Test Loss: 10198722560.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9913882936.889..  Test Loss: 10299563008.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9925657201.778..  Test Loss: 10236376064.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9923882680.889..  Test Loss: 10316946432.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9898006030.222..  Test Loss: 10254288896.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9820467342.222..  Test Loss: 10214323200.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9860423111.111..  Test Loss: 10186337280.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9860913152.000..  Test Loss: 10031328256.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9839193400.889..  Test Loss: 10195620864.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9752176156.444..  Test Loss: 10179792896.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9833881073.778..  Test Loss: 10174709760.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9736012672.000..  Test Loss: 10147811328.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9728224270.222..  Test Loss: 10217814016.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9707598535.111..  Test Loss: 10014736384.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9733450752.000..  Test Loss: 10063404032.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9848800995.556..  Test Loss: 10156399616.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9689589589.333..  Test Loss: 9980032000.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9634513912.889..  Test Loss: 10050475008.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9646190208.000..  Test Loss: 9996205056.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9667693767.111..  Test Loss: 9960961024.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9709738126.222..  Test Loss: 10342667264.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9559824668.444..  Test Loss: 9932282880.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9578456049.778..  Test Loss: 10075802624.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9551938816.000..  Test Loss: 10034947072.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9591891342.222..  Test Loss: 10178924544.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9506807822.222..  Test Loss: 9917985792.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9563068160.000..  Test Loss: 10091069440.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9592603278.222..  Test Loss: 9963042816.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9579465742.222..  Test Loss: 9752677376.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9454918001.778..  Test Loss: 9826725888.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9461085411.556..  Test Loss: 9789264896.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9540727992.889..  Test Loss: 9938250752.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9414486741.333..  Test Loss: 10145705984.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9382174264.889..  Test Loss: 10141576192.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9370891804.444..  Test Loss: 9898207232.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9381484970.667..  Test Loss: 9947506688.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9328395178.667..  Test Loss: 9820052480.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9275268138.667..  Test Loss: 10032956416.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9267483463.111..  Test Loss: 10191692800.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9403829048.889..  Test Loss: 9887792128.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9194640497.778..  Test Loss: 9803546624.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9368435783.111..  Test Loss: 9964778496.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9397482339.556..  Test Loss: 9696079872.000.. \n",
      "Epoch: 372/1000..  Training Loss: 9233923939.556..  Test Loss: 9854687232.000.. \n",
      "Epoch: 373/1000..  Training Loss: 9264307555.556..  Test Loss: 9984200704.000.. \n",
      "Epoch: 374/1000..  Training Loss: 9252772266.667..  Test Loss: 9852824576.000.. \n",
      "Epoch: 375/1000..  Training Loss: 9335593329.778..  Test Loss: 9743397888.000.. \n",
      "Epoch: 376/1000..  Training Loss: 9160956145.778..  Test Loss: 10044183552.000.. \n",
      "Epoch: 377/1000..  Training Loss: 9106875477.333..  Test Loss: 9785507840.000.. \n",
      "Epoch: 378/1000..  Training Loss: 9131212060.444..  Test Loss: 9818444800.000.. \n",
      "Epoch: 379/1000..  Training Loss: 9173175096.889..  Test Loss: 9742368768.000.. \n",
      "Epoch: 380/1000..  Training Loss: 9171661568.000..  Test Loss: 9500070912.000.. \n",
      "Epoch: 381/1000..  Training Loss: 9195378787.556..  Test Loss: 9874588672.000.. \n",
      "Epoch: 382/1000..  Training Loss: 8997419363.556..  Test Loss: 9580884992.000.. \n",
      "Epoch: 383/1000..  Training Loss: 8971172138.667..  Test Loss: 9788422144.000.. \n",
      "Epoch: 384/1000..  Training Loss: 9048412231.111..  Test Loss: 9663375360.000.. \n",
      "Epoch: 385/1000..  Training Loss: 9104123989.333..  Test Loss: 9565596672.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8988031886.222..  Test Loss: 9591043072.000.. \n",
      "Epoch: 387/1000..  Training Loss: 9067082794.667..  Test Loss: 9590503424.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8924476074.667..  Test Loss: 9691953152.000.. \n",
      "Epoch: 389/1000..  Training Loss: 9014583537.778..  Test Loss: 9710690304.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8886305152.000..  Test Loss: 9540211712.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8892171633.778..  Test Loss: 9798894592.000.. \n",
      "Epoch: 392/1000..  Training Loss: 9053126357.333..  Test Loss: 9518475264.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8902928832.000..  Test Loss: 9595777024.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8863076999.111..  Test Loss: 9418451968.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8780663772.444..  Test Loss: 9557329920.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8836996679.111..  Test Loss: 9648480256.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8811600241.778..  Test Loss: 9575131136.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8752871694.222..  Test Loss: 9587213312.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8779578296.889..  Test Loss: 9436720128.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8817664128.000..  Test Loss: 9345236992.000.. \n",
      "Epoch: 401/1000..  Training Loss: 8801009095.111..  Test Loss: 9511566336.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8714253240.889..  Test Loss: 9534584832.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8820269895.111..  Test Loss: 9268325376.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 404/1000..  Training Loss: 8644546332.444..  Test Loss: 9448628224.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8690880967.111..  Test Loss: 9387593728.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8750379911.111..  Test Loss: 9254344704.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8699914496.000..  Test Loss: 9323811840.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8677331726.222..  Test Loss: 9171580928.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8559478542.222..  Test Loss: 9632393216.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8548868138.667..  Test Loss: 9312138240.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8560110023.111..  Test Loss: 9310583808.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8566685312.000..  Test Loss: 9280438272.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8570963456.000..  Test Loss: 9389470720.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8609741226.667..  Test Loss: 9199952896.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8605252736.000..  Test Loss: 9186910208.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8503501297.778..  Test Loss: 9067492352.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8560520448.000..  Test Loss: 9405900800.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8412250560.000..  Test Loss: 9151239168.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8398626915.556..  Test Loss: 9122825216.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8361487857.778..  Test Loss: 9309754368.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8521015381.333..  Test Loss: 9190242304.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8432564849.778..  Test Loss: 9184064512.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8414247338.667..  Test Loss: 9321205760.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8453841891.556..  Test Loss: 9208473600.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8387398570.667..  Test Loss: 9139426304.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8320653639.111..  Test Loss: 9341578240.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8301666161.778..  Test Loss: 9059418112.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8285910222.222..  Test Loss: 9047746560.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8288199125.333..  Test Loss: 9099400192.000.. \n",
      "Epoch: 430/1000..  Training Loss: 8378454421.333..  Test Loss: 9084990464.000.. \n",
      "Epoch: 431/1000..  Training Loss: 8276794574.222..  Test Loss: 9451725824.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8316048888.889..  Test Loss: 9026243584.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8317770005.333..  Test Loss: 9039262720.000.. \n",
      "Epoch: 434/1000..  Training Loss: 8248549376.000..  Test Loss: 8984288256.000.. \n",
      "Epoch: 435/1000..  Training Loss: 8213990556.444..  Test Loss: 9192136704.000.. \n",
      "Epoch: 436/1000..  Training Loss: 8248618908.444..  Test Loss: 8959160320.000.. \n",
      "Epoch: 437/1000..  Training Loss: 8186267975.111..  Test Loss: 9181981696.000.. \n",
      "Epoch: 438/1000..  Training Loss: 8202943857.778..  Test Loss: 9361911808.000.. \n",
      "Epoch: 439/1000..  Training Loss: 8279387619.556..  Test Loss: 9008541696.000.. \n",
      "Epoch: 440/1000..  Training Loss: 8314588871.111..  Test Loss: 9067067392.000.. \n",
      "Epoch: 441/1000..  Training Loss: 8168483968.000..  Test Loss: 9159473152.000.. \n",
      "Epoch: 442/1000..  Training Loss: 8050889144.889..  Test Loss: 8996598784.000.. \n",
      "Epoch: 443/1000..  Training Loss: 8128680448.000..  Test Loss: 8965581824.000.. \n",
      "Epoch: 444/1000..  Training Loss: 8155629582.222..  Test Loss: 9013196800.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7993783111.111..  Test Loss: 8710124544.000.. \n",
      "Epoch: 446/1000..  Training Loss: 8005325774.222..  Test Loss: 9068867584.000.. \n",
      "Epoch: 447/1000..  Training Loss: 8133735665.778..  Test Loss: 8874615808.000.. \n",
      "Epoch: 448/1000..  Training Loss: 8121461859.556..  Test Loss: 8930399232.000.. \n",
      "Epoch: 449/1000..  Training Loss: 8071816576.000..  Test Loss: 8832499712.000.. \n",
      "Epoch: 450/1000..  Training Loss: 8067173077.333..  Test Loss: 8845744128.000.. \n",
      "Epoch: 451/1000..  Training Loss: 8033933226.667..  Test Loss: 8775296000.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7964215637.333..  Test Loss: 8589070848.000.. \n",
      "Epoch: 453/1000..  Training Loss: 8059180572.444..  Test Loss: 8875407360.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7950195868.444..  Test Loss: 8665723904.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7919296206.222..  Test Loss: 8561813504.000.. \n",
      "Epoch: 456/1000..  Training Loss: 8004069546.667..  Test Loss: 8690385920.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7901467164.444..  Test Loss: 8686490624.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7863098808.889..  Test Loss: 8503676416.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7843919687.111..  Test Loss: 8778376192.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7975056376.889..  Test Loss: 8687361024.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7815793137.778..  Test Loss: 8544957952.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7838487623.111..  Test Loss: 8554321408.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7844020266.667..  Test Loss: 8478731776.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7822854016.000..  Test Loss: 8437431296.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7787196920.889..  Test Loss: 8549884928.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7868934769.778..  Test Loss: 8524115456.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7786870855.111..  Test Loss: 8600262656.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7726550087.111..  Test Loss: 8587563520.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7742264071.111..  Test Loss: 8428982784.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7676874218.667..  Test Loss: 8610676736.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7681407402.667..  Test Loss: 8452936192.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7733378631.111..  Test Loss: 8534714368.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7634760853.333..  Test Loss: 8586220032.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7720377479.111..  Test Loss: 8340451840.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7641215943.111..  Test Loss: 8348710400.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7727405440.000..  Test Loss: 8440928768.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7595102983.111..  Test Loss: 8234160640.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7669736220.444..  Test Loss: 8503919616.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7500174528.000..  Test Loss: 8389607424.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7578173134.222..  Test Loss: 8274565632.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7523510094.222..  Test Loss: 8246943744.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7529641777.778..  Test Loss: 8210627072.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7530720177.778..  Test Loss: 8468167680.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7463107925.333..  Test Loss: 8207643136.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7537588693.333..  Test Loss: 8365285376.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7517964003.556..  Test Loss: 8303947264.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7581194936.889..  Test Loss: 8382279168.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7495529237.333..  Test Loss: 8392749568.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7523106944.000..  Test Loss: 8362392064.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7412838179.556..  Test Loss: 8267568640.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7438496554.667..  Test Loss: 8366001664.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7425774862.222..  Test Loss: 7937146880.000.. \n",
      "Epoch: 493/1000..  Training Loss: 7400307868.444..  Test Loss: 8114014720.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7344103516.444..  Test Loss: 7925248512.000.. \n",
      "Epoch: 495/1000..  Training Loss: 7428462776.889..  Test Loss: 8113153024.000.. \n",
      "Epoch: 496/1000..  Training Loss: 7345250069.333..  Test Loss: 8559319552.000.. \n",
      "Epoch: 497/1000..  Training Loss: 7346477155.556..  Test Loss: 7954271744.000.. \n",
      "Epoch: 498/1000..  Training Loss: 7444710136.889..  Test Loss: 8017440256.000.. \n",
      "Epoch: 499/1000..  Training Loss: 7320436842.667..  Test Loss: 8374075392.000.. \n",
      "Epoch: 500/1000..  Training Loss: 7255748039.111..  Test Loss: 8133478912.000.. \n",
      "Epoch: 501/1000..  Training Loss: 7371196103.111..  Test Loss: 8012317696.000.. \n",
      "Epoch: 502/1000..  Training Loss: 7206083911.111..  Test Loss: 7804688896.000.. \n",
      "Epoch: 503/1000..  Training Loss: 7239930652.444..  Test Loss: 7498675712.000.. \n",
      "Epoch: 504/1000..  Training Loss: 7279672711.111..  Test Loss: 7370945536.000.. \n",
      "Epoch: 505/1000..  Training Loss: 7094640334.222..  Test Loss: 6978003968.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 506/1000..  Training Loss: 7022273870.222..  Test Loss: 6530877952.000.. \n",
      "Epoch: 507/1000..  Training Loss: 7048702449.778..  Test Loss: 6252819456.000.. \n",
      "Epoch: 508/1000..  Training Loss: 6956483975.111..  Test Loss: 6083594752.000.. \n",
      "Epoch: 509/1000..  Training Loss: 7009435811.556..  Test Loss: 6246375424.000.. \n",
      "Epoch: 510/1000..  Training Loss: 7004996558.222..  Test Loss: 5983418880.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6956163377.778..  Test Loss: 6145321472.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6934000817.778..  Test Loss: 6134278656.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6906001848.889..  Test Loss: 6275005440.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6895912775.111..  Test Loss: 6183068672.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6802282538.667..  Test Loss: 6321076224.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6847343111.111..  Test Loss: 6068106752.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6770460295.111..  Test Loss: 6151697920.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6862006350.222..  Test Loss: 6071023104.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6842873187.556..  Test Loss: 6117228032.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6811718549.333..  Test Loss: 6081534976.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6848524814.222..  Test Loss: 6004890112.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6906457678.222..  Test Loss: 5957444096.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6813100288.000..  Test Loss: 5972556800.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6802150072.889..  Test Loss: 6020410368.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6745343025.778..  Test Loss: 5988185600.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6832004117.333..  Test Loss: 6017172992.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6749948586.667..  Test Loss: 5992413184.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6708044529.778..  Test Loss: 5933818880.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6623171000.889..  Test Loss: 5966755328.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6605779036.444..  Test Loss: 5858688512.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6642742115.556..  Test Loss: 5859425280.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6701912156.444..  Test Loss: 5832456704.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6685286919.111..  Test Loss: 6105723392.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6527619768.889..  Test Loss: 5747418624.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6606090403.556..  Test Loss: 5884254720.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6577597176.889..  Test Loss: 6036216832.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6610383857.778..  Test Loss: 5792674816.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6532261440.000..  Test Loss: 5824834048.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6566908593.778..  Test Loss: 5752722944.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6596324721.778..  Test Loss: 5854996480.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6459488853.333..  Test Loss: 5717736960.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6445073799.111..  Test Loss: 5824054272.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6508136021.333..  Test Loss: 5598139904.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6422931619.556..  Test Loss: 5654325248.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6408195484.444..  Test Loss: 5743963648.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6490693176.889..  Test Loss: 5869405696.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6492558755.556..  Test Loss: 5646310400.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6419037909.333..  Test Loss: 5656391680.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6390876700.444..  Test Loss: 5640197120.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6467405006.222..  Test Loss: 5549765120.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6439277724.444..  Test Loss: 5479029248.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6346935736.889..  Test Loss: 5637726208.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6362979669.333..  Test Loss: 5634419200.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6388592362.667..  Test Loss: 5458420224.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6349840768.000..  Test Loss: 5522509824.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6380340359.111..  Test Loss: 5587858944.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6278627896.889..  Test Loss: 5647518208.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6361299868.444..  Test Loss: 5431802368.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6237234424.889..  Test Loss: 5391383040.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6224531619.556..  Test Loss: 5402176512.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6314789852.444..  Test Loss: 5380136960.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6274985763.556..  Test Loss: 5425379840.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6225098176.000..  Test Loss: 5418292736.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6283310912.000..  Test Loss: 5350684160.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6209178304.000..  Test Loss: 5344755712.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6219364124.444..  Test Loss: 5531508224.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6200915925.333..  Test Loss: 5289636352.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6258433251.556..  Test Loss: 5211674112.000.. \n",
      "Epoch: 569/1000..  Training Loss: 6171239537.778..  Test Loss: 5293389312.000.. \n",
      "Epoch: 570/1000..  Training Loss: 6122107761.778..  Test Loss: 5402787328.000.. \n",
      "Epoch: 571/1000..  Training Loss: 6205755669.333..  Test Loss: 5273252352.000.. \n",
      "Epoch: 572/1000..  Training Loss: 5989283680.000..  Test Loss: 5131340288.000.. \n",
      "Epoch: 573/1000..  Training Loss: 6187897713.778..  Test Loss: 5312589312.000.. \n",
      "Epoch: 574/1000..  Training Loss: 6110795847.111..  Test Loss: 5092559872.000.. \n",
      "Epoch: 575/1000..  Training Loss: 6060445376.000..  Test Loss: 5386714624.000.. \n",
      "Epoch: 576/1000..  Training Loss: 6050577998.222..  Test Loss: 5149923840.000.. \n",
      "Epoch: 577/1000..  Training Loss: 6018127957.333..  Test Loss: 5096737280.000.. \n",
      "Epoch: 578/1000..  Training Loss: 5980725511.111..  Test Loss: 5076872704.000.. \n",
      "Epoch: 579/1000..  Training Loss: 6048766720.000..  Test Loss: 5037541888.000.. \n",
      "Epoch: 580/1000..  Training Loss: 6008426944.000..  Test Loss: 5112048128.000.. \n",
      "Epoch: 581/1000..  Training Loss: 6169905244.444..  Test Loss: 5246665216.000.. \n",
      "Epoch: 582/1000..  Training Loss: 6052023345.778..  Test Loss: 5023500800.000.. \n",
      "Epoch: 583/1000..  Training Loss: 6010844949.333..  Test Loss: 4969548288.000.. \n",
      "Epoch: 584/1000..  Training Loss: 6007240440.889..  Test Loss: 5079322624.000.. \n",
      "Epoch: 585/1000..  Training Loss: 6065526001.778..  Test Loss: 4896912384.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5934974883.556..  Test Loss: 5091504128.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5872801422.222..  Test Loss: 5099617792.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5953958193.778..  Test Loss: 5035386880.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5868152931.556..  Test Loss: 4891747328.000.. \n",
      "Epoch: 590/1000..  Training Loss: 6003634232.889..  Test Loss: 5046071296.000.. \n",
      "Epoch: 591/1000..  Training Loss: 6037937422.222..  Test Loss: 4930527744.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5925456768.000..  Test Loss: 4950614528.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5839494005.333..  Test Loss: 5005839872.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5885817130.667..  Test Loss: 4976575488.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5845316032.000..  Test Loss: 4928869376.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5986540451.556..  Test Loss: 4893246464.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5951178346.667..  Test Loss: 5058019328.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5732715228.444..  Test Loss: 5043114496.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5811229760.000..  Test Loss: 4710714368.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5840783118.222..  Test Loss: 4860339712.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5943035896.889..  Test Loss: 4643664384.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5829175075.556..  Test Loss: 4904371200.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5771201244.444..  Test Loss: 4847744000.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5782527168.000..  Test Loss: 4820220416.000.. \n",
      "Epoch: 605/1000..  Training Loss: 5788691761.778..  Test Loss: 4889328128.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5753290460.444..  Test Loss: 5049128960.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5729218090.667..  Test Loss: 4720025088.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 608/1000..  Training Loss: 5717509717.333..  Test Loss: 4704890880.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5710242723.556..  Test Loss: 4705091072.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5709689201.778..  Test Loss: 4916590592.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5630175160.889..  Test Loss: 4874809344.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5722024014.222..  Test Loss: 4587250688.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5768781880.889..  Test Loss: 4713391104.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5616859121.778..  Test Loss: 4806493696.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5667117959.111..  Test Loss: 4682440192.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5666619925.333..  Test Loss: 4787541504.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5650960629.333..  Test Loss: 4525574656.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5698340657.778..  Test Loss: 4696148480.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5608010638.222..  Test Loss: 4667311616.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5644901127.111..  Test Loss: 4635175424.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5633342293.333..  Test Loss: 4629199872.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5575825308.444..  Test Loss: 4714809856.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5510471864.889..  Test Loss: 4560636416.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5671251569.778..  Test Loss: 4536644096.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5573141696.000..  Test Loss: 4721262592.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5616220593.778..  Test Loss: 4572624896.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5544722161.778..  Test Loss: 4580783104.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5477788472.889..  Test Loss: 4605091328.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5583453440.000..  Test Loss: 4531368448.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5551103505.778..  Test Loss: 4582244352.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5549733802.667..  Test Loss: 4518067200.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5698709763.556..  Test Loss: 4515977728.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5454660330.667..  Test Loss: 4412418560.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5534328348.444..  Test Loss: 4567664640.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5491397418.667..  Test Loss: 4423665152.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5558634531.556..  Test Loss: 4451868160.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5526155424.000..  Test Loss: 4419537408.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5426911342.222..  Test Loss: 4451326464.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5410607416.889..  Test Loss: 4484747776.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5430042936.889..  Test Loss: 4514213888.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5481313728.000..  Test Loss: 4427615232.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5459448263.111..  Test Loss: 4600947200.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5545186446.222..  Test Loss: 4458612736.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5517856028.444..  Test Loss: 4365383680.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5368774769.778..  Test Loss: 4327158784.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5401181792.000..  Test Loss: 4347808256.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5488796430.222..  Test Loss: 4223709696.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5381989319.111..  Test Loss: 4206898688.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5386404764.444..  Test Loss: 4315644928.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5418855054.222..  Test Loss: 4291849472.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5396332323.556..  Test Loss: 4322601984.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5310031473.778..  Test Loss: 4266502400.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5343986780.444..  Test Loss: 4426310144.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5357282922.667..  Test Loss: 4432863232.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5406146652.444..  Test Loss: 4185898496.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5297153450.667..  Test Loss: 4238892288.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5363947598.222..  Test Loss: 4241752064.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5362568085.333..  Test Loss: 4364710912.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5344437134.222..  Test Loss: 4322728448.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5419486051.556..  Test Loss: 4177332480.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5361200561.778..  Test Loss: 4155983104.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5256432967.111..  Test Loss: 4193988608.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5329605809.778..  Test Loss: 4000291584.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5294561667.556..  Test Loss: 4178241280.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5272039136.000..  Test Loss: 4275967232.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5284534670.222..  Test Loss: 4143546368.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5300274368.000..  Test Loss: 4062655488.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5266917792.000..  Test Loss: 4129223936.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5291833301.333..  Test Loss: 4098002432.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5212601180.444..  Test Loss: 4106339328.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5338808924.444..  Test Loss: 4039353600.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5233117411.556..  Test Loss: 4106706432.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5193482428.444..  Test Loss: 4002160640.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5191346588.444..  Test Loss: 4119044096.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5140332721.778..  Test Loss: 4145192960.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5240970097.778..  Test Loss: 4099556608.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5190387740.444..  Test Loss: 3951622400.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5277877653.333..  Test Loss: 4156531200.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5242301461.333..  Test Loss: 4082577408.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5260607328.000..  Test Loss: 3975843840.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5172374190.222..  Test Loss: 4096419072.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5246355264.000..  Test Loss: 4028654592.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5161344896.000..  Test Loss: 4000813056.000.. \n",
      "Epoch: 684/1000..  Training Loss: 5198920106.667..  Test Loss: 4005100288.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5074662215.111..  Test Loss: 4082478592.000.. \n",
      "Epoch: 686/1000..  Training Loss: 5145835121.778..  Test Loss: 4163747072.000.. \n",
      "Epoch: 687/1000..  Training Loss: 5183416540.444..  Test Loss: 4084430080.000.. \n",
      "Epoch: 688/1000..  Training Loss: 5161658424.889..  Test Loss: 3898108672.000.. \n",
      "Epoch: 689/1000..  Training Loss: 5110533312.000..  Test Loss: 4010010880.000.. \n",
      "Epoch: 690/1000..  Training Loss: 5034602460.444..  Test Loss: 3941278976.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5133784135.111..  Test Loss: 3859050496.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5056171015.111..  Test Loss: 3964677376.000.. \n",
      "Epoch: 693/1000..  Training Loss: 5051060103.111..  Test Loss: 4079335680.000.. \n",
      "Epoch: 694/1000..  Training Loss: 5107164344.889..  Test Loss: 4126123776.000.. \n",
      "Epoch: 695/1000..  Training Loss: 5118695669.333..  Test Loss: 3954739968.000.. \n",
      "Epoch: 696/1000..  Training Loss: 5066477518.222..  Test Loss: 4064755712.000.. \n",
      "Epoch: 697/1000..  Training Loss: 5046026097.778..  Test Loss: 3927525632.000.. \n",
      "Epoch: 698/1000..  Training Loss: 5104755530.667..  Test Loss: 3951142144.000.. \n",
      "Epoch: 699/1000..  Training Loss: 5082351758.222..  Test Loss: 3905778176.000.. \n",
      "Epoch: 700/1000..  Training Loss: 5059771662.222..  Test Loss: 3937046016.000.. \n",
      "Epoch: 701/1000..  Training Loss: 5095714353.778..  Test Loss: 3916971520.000.. \n",
      "Epoch: 702/1000..  Training Loss: 5137587747.556..  Test Loss: 3918714112.000.. \n",
      "Epoch: 703/1000..  Training Loss: 5173938837.333..  Test Loss: 3832347392.000.. \n",
      "Epoch: 704/1000..  Training Loss: 5055018901.333..  Test Loss: 3756096768.000.. \n",
      "Epoch: 705/1000..  Training Loss: 5140932494.222..  Test Loss: 3762492160.000.. \n",
      "Epoch: 706/1000..  Training Loss: 5060346104.889..  Test Loss: 3933038336.000.. \n",
      "Epoch: 707/1000..  Training Loss: 5072263793.778..  Test Loss: 3871720448.000.. \n",
      "Epoch: 708/1000..  Training Loss: 5003321265.778..  Test Loss: 3661411840.000.. \n",
      "Epoch: 709/1000..  Training Loss: 5056911580.444..  Test Loss: 3719638272.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 710/1000..  Training Loss: 5072406723.556..  Test Loss: 3842903552.000.. \n",
      "Epoch: 711/1000..  Training Loss: 5004884213.333..  Test Loss: 3787301376.000.. \n",
      "Epoch: 712/1000..  Training Loss: 5021060380.444..  Test Loss: 3953386496.000.. \n",
      "Epoch: 713/1000..  Training Loss: 5012202040.889..  Test Loss: 3929473024.000.. \n",
      "Epoch: 714/1000..  Training Loss: 4968171221.333..  Test Loss: 3797701632.000.. \n",
      "Epoch: 715/1000..  Training Loss: 5092177258.667..  Test Loss: 3787703808.000.. \n",
      "Epoch: 716/1000..  Training Loss: 5028251868.444..  Test Loss: 3815292672.000.. \n",
      "Epoch: 717/1000..  Training Loss: 5123156785.778..  Test Loss: 3791665920.000.. \n",
      "Epoch: 718/1000..  Training Loss: 5014581368.889..  Test Loss: 3784395520.000.. \n",
      "Epoch: 719/1000..  Training Loss: 5079707157.333..  Test Loss: 3797652736.000.. \n",
      "Epoch: 720/1000..  Training Loss: 5031560028.444..  Test Loss: 3679398656.000.. \n",
      "Epoch: 721/1000..  Training Loss: 5048220323.556..  Test Loss: 3718430976.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4994456426.667..  Test Loss: 3638351104.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4990526552.889..  Test Loss: 3770292992.000.. \n",
      "Epoch: 724/1000..  Training Loss: 5108915235.556..  Test Loss: 3769856000.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4986760270.222..  Test Loss: 3647015680.000.. \n",
      "Epoch: 726/1000..  Training Loss: 5031064789.333..  Test Loss: 3623684864.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4904319509.333..  Test Loss: 3792440064.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4915920120.889..  Test Loss: 3606774784.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4946510222.222..  Test Loss: 3710518528.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4977154787.556..  Test Loss: 3616849152.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4947120067.556..  Test Loss: 3807189248.000.. \n",
      "Epoch: 732/1000..  Training Loss: 5032006350.222..  Test Loss: 3635898112.000.. \n",
      "Epoch: 733/1000..  Training Loss: 5016455221.333..  Test Loss: 3643843328.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4975862641.778..  Test Loss: 3735524352.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4936444536.889..  Test Loss: 3628805632.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4964801592.889..  Test Loss: 3655375616.000.. \n",
      "Epoch: 737/1000..  Training Loss: 5003399658.667..  Test Loss: 3632684032.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4902586453.333..  Test Loss: 3524498688.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4944748408.889..  Test Loss: 3657162496.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4907613863.111..  Test Loss: 3665420288.000.. \n",
      "Epoch: 741/1000..  Training Loss: 5045522513.778..  Test Loss: 3618342144.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4967636650.667..  Test Loss: 3653842944.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4993443036.444..  Test Loss: 3556748288.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4959887694.222..  Test Loss: 3707206912.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4905982442.667..  Test Loss: 3750480896.000.. \n",
      "Epoch: 746/1000..  Training Loss: 5006767779.556..  Test Loss: 3624876288.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4948285219.556..  Test Loss: 3616859648.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4945224206.222..  Test Loss: 3624045312.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4987796195.556..  Test Loss: 3517883136.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4927794684.444..  Test Loss: 3589954816.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4941361159.111..  Test Loss: 3678762496.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4906403022.222..  Test Loss: 3477472256.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4891580572.444..  Test Loss: 3654939648.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4934089692.444..  Test Loss: 3570422784.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4825823089.778..  Test Loss: 3722917888.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4854044981.333..  Test Loss: 3509418496.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4931781358.222..  Test Loss: 3559880448.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4953585365.333..  Test Loss: 3580139264.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4902213041.778..  Test Loss: 3735202304.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4888171882.667..  Test Loss: 3549946880.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4932866069.333..  Test Loss: 3534802176.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4979041144.889..  Test Loss: 3477812480.000.. \n",
      "Epoch: 763/1000..  Training Loss: 5008045568.000..  Test Loss: 3499163648.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4928979832.889..  Test Loss: 3503327488.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4961430065.778..  Test Loss: 3751880192.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4938525546.667..  Test Loss: 3471996416.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4994835832.889..  Test Loss: 3492269568.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4856529276.444..  Test Loss: 3513882368.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4994922247.111..  Test Loss: 3515698688.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4892549888.000..  Test Loss: 3507971328.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4918473166.222..  Test Loss: 3453446656.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4932869795.556..  Test Loss: 3443778560.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4862695616.000..  Test Loss: 3460259840.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4850757532.444..  Test Loss: 3404396032.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4852668732.444..  Test Loss: 3445221888.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4848972312.889..  Test Loss: 3425466368.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4905961884.444..  Test Loss: 3407592704.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4897731726.222..  Test Loss: 3514983936.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4867004586.667..  Test Loss: 3392358656.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4903131448.889..  Test Loss: 3450181888.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4923926798.222..  Test Loss: 3397864704.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4950913166.222..  Test Loss: 3456414976.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4862516408.889..  Test Loss: 3424111104.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4904694030.222..  Test Loss: 3441362176.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4822189888.000..  Test Loss: 3562990848.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4861132209.778..  Test Loss: 3429400320.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4848362567.111..  Test Loss: 3503583488.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4908468736.000..  Test Loss: 3422810624.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4905181297.778..  Test Loss: 3518257664.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4864439644.444..  Test Loss: 3490105600.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4892027050.667..  Test Loss: 3506874624.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4955612352.000..  Test Loss: 3394977024.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4826467310.222..  Test Loss: 3444833536.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4938027655.111..  Test Loss: 3457626112.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4841967217.778..  Test Loss: 3375388928.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4874910030.222..  Test Loss: 3385392128.000.. \n",
      "Epoch: 797/1000..  Training Loss: 5027787690.667..  Test Loss: 3442028032.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4850006709.333..  Test Loss: 3375938048.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4870303232.000..  Test Loss: 3375680000.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4875466154.667..  Test Loss: 3349708032.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4882301902.222..  Test Loss: 3380378880.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4795920522.667..  Test Loss: 3413109504.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4870751651.556..  Test Loss: 3389787904.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4796421496.889..  Test Loss: 3332593664.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4777542058.667..  Test Loss: 3435457792.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4758948064.000..  Test Loss: 3390936576.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4971999637.333..  Test Loss: 3380952064.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4825687907.556..  Test Loss: 3354220544.000.. \n",
      "Epoch: 809/1000..  Training Loss: 4882861767.111..  Test Loss: 3357536512.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4866406848.000..  Test Loss: 3267540224.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4821191281.778..  Test Loss: 3407841536.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 812/1000..  Training Loss: 4804597617.778..  Test Loss: 3368830976.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4878268636.444..  Test Loss: 3438535936.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4845115420.444..  Test Loss: 3382211840.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4853376426.667..  Test Loss: 3388006656.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4882573294.222..  Test Loss: 3302276352.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4838994496.000..  Test Loss: 3454822144.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4806702471.111..  Test Loss: 3303645440.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4844200807.111..  Test Loss: 3360320000.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4884265991.111..  Test Loss: 3334863104.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4846870072.889..  Test Loss: 3455114496.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4854331932.444..  Test Loss: 3288896000.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4773086435.556..  Test Loss: 3343200256.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4844929571.556..  Test Loss: 3403011840.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4833236849.778..  Test Loss: 3295397376.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4879155889.778..  Test Loss: 3277073664.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4833622328.889..  Test Loss: 3411551232.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4855972188.444..  Test Loss: 3318600192.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4846182887.111..  Test Loss: 3310548480.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4819944448.000..  Test Loss: 3298476800.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4820443175.111..  Test Loss: 3355922944.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4827651413.333..  Test Loss: 3380243200.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4835509440.000..  Test Loss: 3280342784.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4794492344.889..  Test Loss: 3301011712.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4867765752.889..  Test Loss: 3341492480.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4811180920.889..  Test Loss: 3361453824.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4782919658.667..  Test Loss: 3333764864.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4859951431.111..  Test Loss: 3349445120.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4849641592.889..  Test Loss: 3278192896.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4825742400.000..  Test Loss: 3303742720.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4917644352.000..  Test Loss: 3329574400.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4857860401.778..  Test Loss: 3383273728.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4832336256.000..  Test Loss: 3258907904.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4833016384.000..  Test Loss: 3249714176.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4814420849.778..  Test Loss: 3387469824.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4874679715.556..  Test Loss: 3332621568.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4829102819.556..  Test Loss: 3251384576.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4834794609.778..  Test Loss: 3274688256.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4881230300.444..  Test Loss: 3374873600.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4832261952.000..  Test Loss: 3317943040.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4848683676.444..  Test Loss: 3257432320.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4877234083.556..  Test Loss: 3260119552.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4818377258.667..  Test Loss: 3258776832.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4815739104.000..  Test Loss: 3332560128.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4827136391.111..  Test Loss: 3286645248.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4797943612.444..  Test Loss: 3308373248.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4871625144.889..  Test Loss: 3266126336.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4897364014.222..  Test Loss: 3233235712.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4775340803.556..  Test Loss: 3282280704.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4876342961.778..  Test Loss: 3368414464.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4769738062.222..  Test Loss: 3219804160.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4825140010.667..  Test Loss: 3256501504.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4779006833.778..  Test Loss: 3323798016.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4818473237.333..  Test Loss: 3353395968.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4801577735.111..  Test Loss: 3269731584.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4944373610.667..  Test Loss: 3255364096.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4850449415.111..  Test Loss: 3323874560.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4840655260.444..  Test Loss: 3302583296.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4800706012.444..  Test Loss: 3218427136.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4838331328.000..  Test Loss: 3265146624.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4840371758.222..  Test Loss: 3371578624.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4828847203.556..  Test Loss: 3391752960.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4882544405.333..  Test Loss: 3322489600.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4764545991.111..  Test Loss: 3234342144.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4852733127.111..  Test Loss: 3305632256.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4763363232.000..  Test Loss: 3272890112.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4784246691.556..  Test Loss: 3208390144.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4743964216.889..  Test Loss: 3363177984.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4848016931.556..  Test Loss: 3288564736.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4804887402.667..  Test Loss: 3194334720.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4810421895.111..  Test Loss: 3258016512.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4729611822.222..  Test Loss: 3257017600.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4791469717.333..  Test Loss: 3295331584.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4821324956.444..  Test Loss: 3394575872.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4781750065.778..  Test Loss: 3332584192.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4880635818.667..  Test Loss: 3225470208.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4830157297.778..  Test Loss: 3315324160.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4849282503.111..  Test Loss: 3379938560.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4749385230.222..  Test Loss: 3331732736.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4759190549.333..  Test Loss: 3260983040.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4860455086.222..  Test Loss: 3268949248.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4780470200.889..  Test Loss: 3421900800.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4874016433.778..  Test Loss: 3303400448.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4792967047.111..  Test Loss: 3217938688.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4810297621.333..  Test Loss: 3230418944.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4978047032.889..  Test Loss: 3438759168.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4739214272.000..  Test Loss: 3331646720.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4832998983.111..  Test Loss: 3316705536.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4816941824.000..  Test Loss: 3258706944.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4780036330.667..  Test Loss: 3227560192.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4737168113.778..  Test Loss: 3212423680.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4769116366.222..  Test Loss: 3230021376.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4794352593.778..  Test Loss: 3291079168.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4775804714.667..  Test Loss: 3209148928.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4847972074.667..  Test Loss: 3329137152.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4712230826.667..  Test Loss: 3301206272.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4787098563.556..  Test Loss: 3288818944.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4773509980.444..  Test Loss: 3327101696.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4806248007.111..  Test Loss: 3191832064.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4711247146.667..  Test Loss: 3390060032.000.. \n",
      "Epoch: 911/1000..  Training Loss: 4783642631.111..  Test Loss: 3218716928.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4768633685.333..  Test Loss: 3194416896.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4812415864.889..  Test Loss: 3266569472.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 914/1000..  Training Loss: 4878603768.889..  Test Loss: 3240715776.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4791607367.111..  Test Loss: 3262732800.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4754203420.444..  Test Loss: 3255596288.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4821649912.889..  Test Loss: 3253460224.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4795517895.111..  Test Loss: 3221543424.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4750387758.222..  Test Loss: 3343812352.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4777746759.111..  Test Loss: 3252836864.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4735912028.444..  Test Loss: 3304993280.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4864227644.444..  Test Loss: 3297136640.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4796256760.889..  Test Loss: 3218886400.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4816245952.000..  Test Loss: 3218134528.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4810691399.111..  Test Loss: 3312549376.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4723867093.333..  Test Loss: 3255719168.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4893629006.222..  Test Loss: 3335981312.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4752712846.222..  Test Loss: 3273839360.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4813635548.444..  Test Loss: 3342909952.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4774552853.333..  Test Loss: 3235544832.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4802918549.333..  Test Loss: 3238290944.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4708682752.000..  Test Loss: 3215284992.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4811733432.889..  Test Loss: 3254797568.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4919286641.778..  Test Loss: 3283817728.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4824208689.778..  Test Loss: 3311922944.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4831607345.778..  Test Loss: 3178862080.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4750715399.111..  Test Loss: 3276619776.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4737465223.111..  Test Loss: 3285927680.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4723974986.667..  Test Loss: 3431457536.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4710879552.000..  Test Loss: 3286355456.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4837875079.111..  Test Loss: 3218028800.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4736306812.444..  Test Loss: 3285993728.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4810612856.889..  Test Loss: 3234736640.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4843714887.111..  Test Loss: 3226168576.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4806029831.111..  Test Loss: 3219952128.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4797883811.556..  Test Loss: 3198552832.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4872673578.667..  Test Loss: 3215968768.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4824279822.222..  Test Loss: 3281855744.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4743514986.667..  Test Loss: 3233139712.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4778358136.889..  Test Loss: 3348865536.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4773760476.444..  Test Loss: 3315949312.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4738892295.111..  Test Loss: 3205355520.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4801411612.444..  Test Loss: 3200769280.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4757578410.667..  Test Loss: 3235161344.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4801643484.444..  Test Loss: 3220727552.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4822995776.000..  Test Loss: 3168600576.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4758108330.667..  Test Loss: 3326814208.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4799213148.444..  Test Loss: 3179261696.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4761778154.667..  Test Loss: 3238457600.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4737345571.556..  Test Loss: 3188869888.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4788862087.111..  Test Loss: 3280354048.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4737644238.222..  Test Loss: 3301518080.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4740075953.778..  Test Loss: 3202330112.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4791875854.222..  Test Loss: 3245948416.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4761783381.333..  Test Loss: 3368011264.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4757046008.889..  Test Loss: 3248133120.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4845345016.889..  Test Loss: 3184372480.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4792218837.333..  Test Loss: 3346796800.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4761406414.222..  Test Loss: 3218603520.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4771858808.889..  Test Loss: 3292288256.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4730646663.111..  Test Loss: 3252626432.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4800427000.889..  Test Loss: 3216377600.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4741914126.222..  Test Loss: 3310083328.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4854786147.556..  Test Loss: 3242900480.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4804397162.667..  Test Loss: 3225579008.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4787552362.667..  Test Loss: 3231895296.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4788197112.889..  Test Loss: 3282836224.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4812386488.889..  Test Loss: 3229975296.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4748067914.667..  Test Loss: 3356860416.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4725075633.778..  Test Loss: 3158937600.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4825024163.556..  Test Loss: 3185334272.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4765042204.444..  Test Loss: 3204265216.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4733238464.000..  Test Loss: 3192710144.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4754543825.778..  Test Loss: 3283289088.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4791283776.000..  Test Loss: 3248927232.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4812911637.333..  Test Loss: 3230140672.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4795616860.444..  Test Loss: 3270213120.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4871284586.667..  Test Loss: 3334313216.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4797453902.222..  Test Loss: 3198214912.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4729522936.889..  Test Loss: 3266346752.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4748310019.556..  Test Loss: 3286282496.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4806787228.444..  Test Loss: 3291950080.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4776645198.222..  Test Loss: 3255049472.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4757974528.000..  Test Loss: 3314420736.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4744844024.889..  Test Loss: 3172930816.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4794066624.000..  Test Loss: 3181507840.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4736328668.444..  Test Loss: 3199681792.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4713944508.444..  Test Loss: 3185981952.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4727050154.667..  Test Loss: 3403932672.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4721026737.778..  Test Loss: 3254070528.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 2\n",
      "Epoch: 1/1000..  Training Loss: 12664658519.771..  Test Loss: 17399717888.000.. \n",
      "Epoch: 2/1000..  Training Loss: 12675197805.714..  Test Loss: 16764051456.000.. \n",
      "Epoch: 3/1000..  Training Loss: 12671662460.343..  Test Loss: 15575094272.000.. \n",
      "Epoch: 4/1000..  Training Loss: 12656543100.343..  Test Loss: 15870418944.000.. \n",
      "Epoch: 5/1000..  Training Loss: 12652327380.114..  Test Loss: 15383773184.000.. \n",
      "Epoch: 6/1000..  Training Loss: 12647389754.514..  Test Loss: 15297803264.000.. \n",
      "Epoch: 7/1000..  Training Loss: 12649447745.829..  Test Loss: 16220178432.000.. \n",
      "Epoch: 8/1000..  Training Loss: 12670565156.571..  Test Loss: 15771207680.000.. \n",
      "Epoch: 9/1000..  Training Loss: 12658631299.657..  Test Loss: 15855490048.000.. \n",
      "Epoch: 10/1000..  Training Loss: 12652049115.429..  Test Loss: 18207827968.000.. \n",
      "Epoch: 11/1000..  Training Loss: 12654550747.429..  Test Loss: 15154000896.000.. \n",
      "Epoch: 12/1000..  Training Loss: 12641167886.629..  Test Loss: 15837113344.000.. \n",
      "Epoch: 13/1000..  Training Loss: 12649471093.029..  Test Loss: 16378339328.000.. \n",
      "Epoch: 14/1000..  Training Loss: 12637909167.543..  Test Loss: 15396434944.000.. \n",
      "Epoch: 15/1000..  Training Loss: 12652500699.429..  Test Loss: 15802417152.000.. \n",
      "Epoch: 16/1000..  Training Loss: 12653931666.286..  Test Loss: 15700271104.000.. \n",
      "Epoch: 17/1000..  Training Loss: 12651261600.914..  Test Loss: 15975068672.000.. \n",
      "Epoch: 18/1000..  Training Loss: 12634308198.400..  Test Loss: 18037407744.000.. \n",
      "Epoch: 19/1000..  Training Loss: 12642100341.029..  Test Loss: 15828980736.000.. \n",
      "Epoch: 20/1000..  Training Loss: 12659961212.343..  Test Loss: 16275987456.000.. \n",
      "Epoch: 21/1000..  Training Loss: 12620157834.971..  Test Loss: 15681404928.000.. \n",
      "Epoch: 22/1000..  Training Loss: 12620642816.000..  Test Loss: 15320017920.000.. \n",
      "Epoch: 23/1000..  Training Loss: 12632300997.486..  Test Loss: 16139077632.000.. \n",
      "Epoch: 24/1000..  Training Loss: 12609946506.971..  Test Loss: 16161415168.000.. \n",
      "Epoch: 25/1000..  Training Loss: 12618802146.743..  Test Loss: 17147214848.000.. \n",
      "Epoch: 26/1000..  Training Loss: 12608907264.000..  Test Loss: 17140585472.000.. \n",
      "Epoch: 27/1000..  Training Loss: 12598331377.371..  Test Loss: 15735498752.000.. \n",
      "Epoch: 28/1000..  Training Loss: 12595489806.629..  Test Loss: 15495377920.000.. \n",
      "Epoch: 29/1000..  Training Loss: 12598237973.943..  Test Loss: 15681290240.000.. \n",
      "Epoch: 30/1000..  Training Loss: 12597266373.486..  Test Loss: 15454483456.000.. \n",
      "Epoch: 31/1000..  Training Loss: 12640258472.229..  Test Loss: 15721196544.000.. \n",
      "Epoch: 32/1000..  Training Loss: 12601425510.400..  Test Loss: 15695972352.000.. \n",
      "Epoch: 33/1000..  Training Loss: 12586095352.686..  Test Loss: 16000425984.000.. \n",
      "Epoch: 34/1000..  Training Loss: 12601932682.971..  Test Loss: 15559576576.000.. \n",
      "Epoch: 35/1000..  Training Loss: 12573285653.943..  Test Loss: 16561011712.000.. \n",
      "Epoch: 36/1000..  Training Loss: 12582429154.743..  Test Loss: 16755214336.000.. \n",
      "Epoch: 37/1000..  Training Loss: 12576736416.914..  Test Loss: 15607670784.000.. \n",
      "Epoch: 38/1000..  Training Loss: 12570469141.943..  Test Loss: 15382862848.000.. \n",
      "Epoch: 39/1000..  Training Loss: 12560939797.943..  Test Loss: 15748261888.000.. \n",
      "Epoch: 40/1000..  Training Loss: 12542324399.543..  Test Loss: 15269718016.000.. \n",
      "Epoch: 41/1000..  Training Loss: 12546065086.171..  Test Loss: 15972357120.000.. \n",
      "Epoch: 42/1000..  Training Loss: 12558614674.286..  Test Loss: 15723322368.000.. \n",
      "Epoch: 43/1000..  Training Loss: 12554644553.143..  Test Loss: 15400124416.000.. \n",
      "Epoch: 44/1000..  Training Loss: 12545710109.257..  Test Loss: 16482397184.000.. \n",
      "Epoch: 45/1000..  Training Loss: 12525782952.229..  Test Loss: 15948002304.000.. \n",
      "Epoch: 46/1000..  Training Loss: 12528843249.371..  Test Loss: 16767831040.000.. \n",
      "Epoch: 47/1000..  Training Loss: 12525085988.571..  Test Loss: 17075365888.000.. \n",
      "Epoch: 48/1000..  Training Loss: 12519237163.886..  Test Loss: 15339998208.000.. \n",
      "Epoch: 49/1000..  Training Loss: 12507090446.629..  Test Loss: 16227575808.000.. \n",
      "Epoch: 50/1000..  Training Loss: 12524882856.229..  Test Loss: 17175745536.000.. \n",
      "Epoch: 51/1000..  Training Loss: 12497989368.686..  Test Loss: 15297751040.000.. \n",
      "Epoch: 52/1000..  Training Loss: 12496268302.629..  Test Loss: 15946011648.000.. \n",
      "Epoch: 53/1000..  Training Loss: 12486306201.600..  Test Loss: 17189713920.000.. \n",
      "Epoch: 54/1000..  Training Loss: 12481084971.886..  Test Loss: 15484602368.000.. \n",
      "Epoch: 55/1000..  Training Loss: 12471436873.143..  Test Loss: 15593539584.000.. \n",
      "Epoch: 56/1000..  Training Loss: 12480289909.029..  Test Loss: 15394165760.000.. \n",
      "Epoch: 57/1000..  Training Loss: 12461383021.714..  Test Loss: 15861304320.000.. \n",
      "Epoch: 58/1000..  Training Loss: 12460758922.971..  Test Loss: 15974585344.000.. \n",
      "Epoch: 59/1000..  Training Loss: 12453130152.229..  Test Loss: 15944619008.000.. \n",
      "Epoch: 60/1000..  Training Loss: 12476260410.514..  Test Loss: 16110766080.000.. \n",
      "Epoch: 61/1000..  Training Loss: 12445755070.171..  Test Loss: 16324880384.000.. \n",
      "Epoch: 62/1000..  Training Loss: 12431514536.229..  Test Loss: 15792348160.000.. \n",
      "Epoch: 63/1000..  Training Loss: 12425389889.829..  Test Loss: 15667112960.000.. \n",
      "Epoch: 64/1000..  Training Loss: 12425577179.429..  Test Loss: 15999016960.000.. \n",
      "Epoch: 65/1000..  Training Loss: 12406679464.229..  Test Loss: 15857977344.000.. \n",
      "Epoch: 66/1000..  Training Loss: 12424041530.514..  Test Loss: 15165221888.000.. \n",
      "Epoch: 67/1000..  Training Loss: 12407497771.886..  Test Loss: 15919713280.000.. \n",
      "Epoch: 68/1000..  Training Loss: 12409088980.114..  Test Loss: 15479086080.000.. \n",
      "Epoch: 69/1000..  Training Loss: 12396379955.200..  Test Loss: 16044427264.000.. \n",
      "Epoch: 70/1000..  Training Loss: 12395016586.971..  Test Loss: 15196343296.000.. \n",
      "Epoch: 71/1000..  Training Loss: 12372497963.886..  Test Loss: 15580646400.000.. \n",
      "Epoch: 72/1000..  Training Loss: 12366905563.429..  Test Loss: 15883119616.000.. \n",
      "Epoch: 73/1000..  Training Loss: 12361243852.800..  Test Loss: 15421092864.000.. \n",
      "Epoch: 74/1000..  Training Loss: 12341671950.629..  Test Loss: 16083901440.000.. \n",
      "Epoch: 75/1000..  Training Loss: 12347837396.114..  Test Loss: 15735376896.000.. \n",
      "Epoch: 76/1000..  Training Loss: 12333734999.771..  Test Loss: 15520003072.000.. \n",
      "Epoch: 77/1000..  Training Loss: 12327861686.857..  Test Loss: 15065656320.000.. \n",
      "Epoch: 78/1000..  Training Loss: 12329596840.229..  Test Loss: 15280690176.000.. \n",
      "Epoch: 79/1000..  Training Loss: 12335351266.743..  Test Loss: 15770249216.000.. \n",
      "Epoch: 80/1000..  Training Loss: 12295229966.629..  Test Loss: 16239541248.000.. \n",
      "Epoch: 81/1000..  Training Loss: 12296123406.629..  Test Loss: 15084257280.000.. \n",
      "Epoch: 82/1000..  Training Loss: 12292564918.857..  Test Loss: 15732197376.000.. \n",
      "Epoch: 83/1000..  Training Loss: 12291970135.771..  Test Loss: 15170805760.000.. \n",
      "Epoch: 84/1000..  Training Loss: 12289483746.743..  Test Loss: 15068964864.000.. \n",
      "Epoch: 85/1000..  Training Loss: 12275893072.457..  Test Loss: 15830886400.000.. \n",
      "Epoch: 86/1000..  Training Loss: 12265473960.229..  Test Loss: 14939785216.000.. \n",
      "Epoch: 87/1000..  Training Loss: 12261111310.629..  Test Loss: 15495571456.000.. \n",
      "Epoch: 88/1000..  Training Loss: 12262147320.686..  Test Loss: 15383342080.000.. \n",
      "Epoch: 89/1000..  Training Loss: 12235631089.371..  Test Loss: 15917239296.000.. \n",
      "Epoch: 90/1000..  Training Loss: 12225139594.971..  Test Loss: 15905065984.000.. \n",
      "Epoch: 91/1000..  Training Loss: 12226685220.571..  Test Loss: 15021587456.000.. \n",
      "Epoch: 92/1000..  Training Loss: 12223650186.971..  Test Loss: 15312846848.000.. \n",
      "Epoch: 93/1000..  Training Loss: 12204099744.914..  Test Loss: 15664706560.000.. \n",
      "Epoch: 94/1000..  Training Loss: 12211461778.286..  Test Loss: 15465995264.000.. \n",
      "Epoch: 95/1000..  Training Loss: 12184177459.200..  Test Loss: 15879168000.000.. \n",
      "Epoch: 96/1000..  Training Loss: 12196757123.657..  Test Loss: 15094469632.000.. \n",
      "Epoch: 97/1000..  Training Loss: 12160998165.943..  Test Loss: 15457705984.000.. \n",
      "Epoch: 98/1000..  Training Loss: 12167805761.829..  Test Loss: 15688984576.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12154661888.000..  Test Loss: 15816616960.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12144922419.200..  Test Loss: 15498387456.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000..  Training Loss: 12144637922.743..  Test Loss: 15673976832.000.. \n",
      "Epoch: 102/1000..  Training Loss: 12129683251.200..  Test Loss: 15806621696.000.. \n",
      "Epoch: 103/1000..  Training Loss: 12119809960.229..  Test Loss: 15307697152.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12121697221.486..  Test Loss: 16906387456.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12090978830.629..  Test Loss: 15430715392.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12091096897.829..  Test Loss: 16192539648.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12082334281.143..  Test Loss: 15854187520.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12078031637.943..  Test Loss: 16027372544.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12058776897.829..  Test Loss: 15082220544.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12045380754.286..  Test Loss: 15194491904.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12036293529.600..  Test Loss: 15312257024.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12029311634.286..  Test Loss: 14853460992.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12054908971.886..  Test Loss: 15332903936.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12022879641.600..  Test Loss: 15953982464.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12041018104.686..  Test Loss: 15701223424.000.. \n",
      "Epoch: 116/1000..  Training Loss: 12011139247.543..  Test Loss: 15835498496.000.. \n",
      "Epoch: 117/1000..  Training Loss: 11995122834.286..  Test Loss: 15361084416.000.. \n",
      "Epoch: 118/1000..  Training Loss: 11982081872.457..  Test Loss: 15208294400.000.. \n",
      "Epoch: 119/1000..  Training Loss: 11975539331.657..  Test Loss: 15151199232.000.. \n",
      "Epoch: 120/1000..  Training Loss: 11986067192.686..  Test Loss: 15041403904.000.. \n",
      "Epoch: 121/1000..  Training Loss: 11948391716.571..  Test Loss: 14903820288.000.. \n",
      "Epoch: 122/1000..  Training Loss: 11976908990.171..  Test Loss: 15309414400.000.. \n",
      "Epoch: 123/1000..  Training Loss: 11932985109.943..  Test Loss: 14674078720.000.. \n",
      "Epoch: 124/1000..  Training Loss: 11924780704.914..  Test Loss: 15480465408.000.. \n",
      "Epoch: 125/1000..  Training Loss: 11955449300.114..  Test Loss: 15238499328.000.. \n",
      "Epoch: 126/1000..  Training Loss: 11910071208.229..  Test Loss: 15363640320.000.. \n",
      "Epoch: 127/1000..  Training Loss: 11909105312.914..  Test Loss: 15924297728.000.. \n",
      "Epoch: 128/1000..  Training Loss: 11899045961.143..  Test Loss: 15775866880.000.. \n",
      "Epoch: 129/1000..  Training Loss: 11868804885.943..  Test Loss: 14681975808.000.. \n",
      "Epoch: 130/1000..  Training Loss: 11868058506.971..  Test Loss: 15571765248.000.. \n",
      "Epoch: 131/1000..  Training Loss: 11857800265.143..  Test Loss: 17460971520.000.. \n",
      "Epoch: 132/1000..  Training Loss: 11849667218.286..  Test Loss: 14935883776.000.. \n",
      "Epoch: 133/1000..  Training Loss: 11830924712.229..  Test Loss: 15255873536.000.. \n",
      "Epoch: 134/1000..  Training Loss: 11826926167.771..  Test Loss: 15854259200.000.. \n",
      "Epoch: 135/1000..  Training Loss: 11818669845.943..  Test Loss: 15362885632.000.. \n",
      "Epoch: 136/1000..  Training Loss: 11801750133.029..  Test Loss: 14747860992.000.. \n",
      "Epoch: 137/1000..  Training Loss: 11798871698.286..  Test Loss: 14730836992.000.. \n",
      "Epoch: 138/1000..  Training Loss: 11772031897.600..  Test Loss: 14495483904.000.. \n",
      "Epoch: 139/1000..  Training Loss: 11760219662.629..  Test Loss: 14628929536.000.. \n",
      "Epoch: 140/1000..  Training Loss: 11764643371.886..  Test Loss: 14858095616.000.. \n",
      "Epoch: 141/1000..  Training Loss: 11738560307.200..  Test Loss: 15059183616.000.. \n",
      "Epoch: 142/1000..  Training Loss: 11723262493.257..  Test Loss: 15394626560.000.. \n",
      "Epoch: 143/1000..  Training Loss: 11748939176.229..  Test Loss: 15840939008.000.. \n",
      "Epoch: 144/1000..  Training Loss: 11723466664.229..  Test Loss: 14946864128.000.. \n",
      "Epoch: 145/1000..  Training Loss: 11690990284.800..  Test Loss: 14483204096.000.. \n",
      "Epoch: 146/1000..  Training Loss: 11682179466.971..  Test Loss: 14686775296.000.. \n",
      "Epoch: 147/1000..  Training Loss: 11679424175.543..  Test Loss: 14504083456.000.. \n",
      "Epoch: 148/1000..  Training Loss: 11685715441.371..  Test Loss: 16099319808.000.. \n",
      "Epoch: 149/1000..  Training Loss: 11671227889.371..  Test Loss: 15051371520.000.. \n",
      "Epoch: 150/1000..  Training Loss: 11664364500.114..  Test Loss: 14380124160.000.. \n",
      "Epoch: 151/1000..  Training Loss: 11630303349.029..  Test Loss: 15195719680.000.. \n",
      "Epoch: 152/1000..  Training Loss: 11649225888.914..  Test Loss: 14998744064.000.. \n",
      "Epoch: 153/1000..  Training Loss: 11601136245.029..  Test Loss: 14970028032.000.. \n",
      "Epoch: 154/1000..  Training Loss: 11592890894.629..  Test Loss: 14772423680.000.. \n",
      "Epoch: 155/1000..  Training Loss: 11610080197.486..  Test Loss: 16113950720.000.. \n",
      "Epoch: 156/1000..  Training Loss: 11589924000.914..  Test Loss: 14855728128.000.. \n",
      "Epoch: 157/1000..  Training Loss: 11586373719.771..  Test Loss: 14354717696.000.. \n",
      "Epoch: 158/1000..  Training Loss: 11564541776.457..  Test Loss: 15183449088.000.. \n",
      "Epoch: 159/1000..  Training Loss: 11542843260.343..  Test Loss: 15534304256.000.. \n",
      "Epoch: 160/1000..  Training Loss: 11544468743.314..  Test Loss: 14578258944.000.. \n",
      "Epoch: 161/1000..  Training Loss: 11538915532.800..  Test Loss: 14145585152.000.. \n",
      "Epoch: 162/1000..  Training Loss: 11507473144.686..  Test Loss: 14816747520.000.. \n",
      "Epoch: 163/1000..  Training Loss: 11520401773.714..  Test Loss: 14784702464.000.. \n",
      "Epoch: 164/1000..  Training Loss: 11481877328.457..  Test Loss: 15332029440.000.. \n",
      "Epoch: 165/1000..  Training Loss: 11484190032.457..  Test Loss: 14988435456.000.. \n",
      "Epoch: 166/1000..  Training Loss: 11460708776.229..  Test Loss: 15787485184.000.. \n",
      "Epoch: 167/1000..  Training Loss: 11471494304.914..  Test Loss: 14822829056.000.. \n",
      "Epoch: 168/1000..  Training Loss: 11447685120.000..  Test Loss: 15621641216.000.. \n",
      "Epoch: 169/1000..  Training Loss: 11423223061.943..  Test Loss: 14455963648.000.. \n",
      "Epoch: 170/1000..  Training Loss: 11415794058.971..  Test Loss: 14270446592.000.. \n",
      "Epoch: 171/1000..  Training Loss: 11406661983.086..  Test Loss: 14428268544.000.. \n",
      "Epoch: 172/1000..  Training Loss: 11402238537.143..  Test Loss: 14898672640.000.. \n",
      "Epoch: 173/1000..  Training Loss: 11396829388.800..  Test Loss: 15422692352.000.. \n",
      "Epoch: 174/1000..  Training Loss: 11389650490.514..  Test Loss: 14337673216.000.. \n",
      "Epoch: 175/1000..  Training Loss: 11379012856.686..  Test Loss: 15519279104.000.. \n",
      "Epoch: 176/1000..  Training Loss: 11348364609.829..  Test Loss: 15957980160.000.. \n",
      "Epoch: 177/1000..  Training Loss: 11328157725.257..  Test Loss: 14276345856.000.. \n",
      "Epoch: 178/1000..  Training Loss: 11314238551.771..  Test Loss: 14737398784.000.. \n",
      "Epoch: 179/1000..  Training Loss: 11328964856.686..  Test Loss: 15048760320.000.. \n",
      "Epoch: 180/1000..  Training Loss: 11300530234.514..  Test Loss: 15477341184.000.. \n",
      "Epoch: 181/1000..  Training Loss: 11280521055.086..  Test Loss: 14710532096.000.. \n",
      "Epoch: 182/1000..  Training Loss: 11276166334.171..  Test Loss: 14812920832.000.. \n",
      "Epoch: 183/1000..  Training Loss: 11263571982.629..  Test Loss: 14345450496.000.. \n",
      "Epoch: 184/1000..  Training Loss: 11255845317.486..  Test Loss: 14786272256.000.. \n",
      "Epoch: 185/1000..  Training Loss: 11242461110.857..  Test Loss: 14980592640.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11246961839.543..  Test Loss: 14320066560.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11222418314.971..  Test Loss: 14382674944.000.. \n",
      "Epoch: 188/1000..  Training Loss: 11196635633.371..  Test Loss: 15517150208.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11199182248.229..  Test Loss: 14202873856.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11172764964.571..  Test Loss: 14259850240.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11154621981.257..  Test Loss: 14570740736.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11158512435.200..  Test Loss: 14175567872.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11159331796.114..  Test Loss: 13965371392.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11122872012.800..  Test Loss: 14044981248.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11114432980.114..  Test Loss: 13915471872.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11114913733.486..  Test Loss: 13770588160.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11084989337.600..  Test Loss: 14961685504.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11077248936.229..  Test Loss: 14961464320.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11064020538.514..  Test Loss: 14640854016.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200/1000..  Training Loss: 11063710837.029..  Test Loss: 14017958912.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11026420516.571..  Test Loss: 14557631488.000.. \n",
      "Epoch: 202/1000..  Training Loss: 11020178709.943..  Test Loss: 15189490688.000.. \n",
      "Epoch: 203/1000..  Training Loss: 10991543325.257..  Test Loss: 14643267584.000.. \n",
      "Epoch: 204/1000..  Training Loss: 10991725772.800..  Test Loss: 14465954816.000.. \n",
      "Epoch: 205/1000..  Training Loss: 10993656071.314..  Test Loss: 15323840512.000.. \n",
      "Epoch: 206/1000..  Training Loss: 10983640766.171..  Test Loss: 14456730624.000.. \n",
      "Epoch: 207/1000..  Training Loss: 10945549253.486..  Test Loss: 15089795072.000.. \n",
      "Epoch: 208/1000..  Training Loss: 10942486659.657..  Test Loss: 14080960512.000.. \n",
      "Epoch: 209/1000..  Training Loss: 10953232179.200..  Test Loss: 14095436800.000.. \n",
      "Epoch: 210/1000..  Training Loss: 10915889883.429..  Test Loss: 13700134912.000.. \n",
      "Epoch: 211/1000..  Training Loss: 10888067145.143..  Test Loss: 14906490880.000.. \n",
      "Epoch: 212/1000..  Training Loss: 10900603245.714..  Test Loss: 14051494912.000.. \n",
      "Epoch: 213/1000..  Training Loss: 10860082497.829..  Test Loss: 14011995136.000.. \n",
      "Epoch: 214/1000..  Training Loss: 10893362366.171..  Test Loss: 14781712384.000.. \n",
      "Epoch: 215/1000..  Training Loss: 10848724538.514..  Test Loss: 15477112832.000.. \n",
      "Epoch: 216/1000..  Training Loss: 10857032396.800..  Test Loss: 14868925440.000.. \n",
      "Epoch: 217/1000..  Training Loss: 10829937005.714..  Test Loss: 14284901376.000.. \n",
      "Epoch: 218/1000..  Training Loss: 10801895160.686..  Test Loss: 14762187776.000.. \n",
      "Epoch: 219/1000..  Training Loss: 10772107541.943..  Test Loss: 14135058432.000.. \n",
      "Epoch: 220/1000..  Training Loss: 10764291584.000..  Test Loss: 13948182528.000.. \n",
      "Epoch: 221/1000..  Training Loss: 10786384852.114..  Test Loss: 13826792448.000.. \n",
      "Epoch: 222/1000..  Training Loss: 10766030365.257..  Test Loss: 13806590976.000.. \n",
      "Epoch: 223/1000..  Training Loss: 10758102835.200..  Test Loss: 14776262656.000.. \n",
      "Epoch: 224/1000..  Training Loss: 10743993387.886..  Test Loss: 14424885248.000.. \n",
      "Epoch: 225/1000..  Training Loss: 10704151420.343..  Test Loss: 14416698368.000.. \n",
      "Epoch: 226/1000..  Training Loss: 10718144453.486..  Test Loss: 14326578176.000.. \n",
      "Epoch: 227/1000..  Training Loss: 10673643520.000..  Test Loss: 13992989696.000.. \n",
      "Epoch: 228/1000..  Training Loss: 10667448992.914..  Test Loss: 14668070912.000.. \n",
      "Epoch: 229/1000..  Training Loss: 10634289517.714..  Test Loss: 13996179456.000.. \n",
      "Epoch: 230/1000..  Training Loss: 10648082622.171..  Test Loss: 14000831488.000.. \n",
      "Epoch: 231/1000..  Training Loss: 10626430420.114..  Test Loss: 14020480000.000.. \n",
      "Epoch: 232/1000..  Training Loss: 10616883112.229..  Test Loss: 14329577472.000.. \n",
      "Epoch: 233/1000..  Training Loss: 10579833812.114..  Test Loss: 13598159872.000.. \n",
      "Epoch: 234/1000..  Training Loss: 10609606407.314..  Test Loss: 14526488576.000.. \n",
      "Epoch: 235/1000..  Training Loss: 10565573968.457..  Test Loss: 13993946112.000.. \n",
      "Epoch: 236/1000..  Training Loss: 10581625197.714..  Test Loss: 14158664704.000.. \n",
      "Epoch: 237/1000..  Training Loss: 10583945040.457..  Test Loss: 14374322176.000.. \n",
      "Epoch: 238/1000..  Training Loss: 10536507962.514..  Test Loss: 13856286720.000.. \n",
      "Epoch: 239/1000..  Training Loss: 10511105360.457..  Test Loss: 14236164096.000.. \n",
      "Epoch: 240/1000..  Training Loss: 10519644042.971..  Test Loss: 13979849728.000.. \n",
      "Epoch: 241/1000..  Training Loss: 10490557498.514..  Test Loss: 13767952384.000.. \n",
      "Epoch: 242/1000..  Training Loss: 10485772200.229..  Test Loss: 13766909952.000.. \n",
      "Epoch: 243/1000..  Training Loss: 10462660022.857..  Test Loss: 13422252032.000.. \n",
      "Epoch: 244/1000..  Training Loss: 10430438473.143..  Test Loss: 14875707392.000.. \n",
      "Epoch: 245/1000..  Training Loss: 10415401091.657..  Test Loss: 14358454272.000.. \n",
      "Epoch: 246/1000..  Training Loss: 10442006805.943..  Test Loss: 13578411008.000.. \n",
      "Epoch: 247/1000..  Training Loss: 10397046418.286..  Test Loss: 13293253632.000.. \n",
      "Epoch: 248/1000..  Training Loss: 10383551546.514..  Test Loss: 13559678976.000.. \n",
      "Epoch: 249/1000..  Training Loss: 10339286147.657..  Test Loss: 14589170688.000.. \n",
      "Epoch: 250/1000..  Training Loss: 10389187891.200..  Test Loss: 15991326720.000.. \n",
      "Epoch: 251/1000..  Training Loss: 10325155605.943..  Test Loss: 13404953600.000.. \n",
      "Epoch: 252/1000..  Training Loss: 10319709169.371..  Test Loss: 14720822272.000.. \n",
      "Epoch: 253/1000..  Training Loss: 10346635439.543..  Test Loss: 14073561088.000.. \n",
      "Epoch: 254/1000..  Training Loss: 10322297856.000..  Test Loss: 15045044224.000.. \n",
      "Epoch: 255/1000..  Training Loss: 10312610816.000..  Test Loss: 13499437056.000.. \n",
      "Epoch: 256/1000..  Training Loss: 10278298653.257..  Test Loss: 13376345088.000.. \n",
      "Epoch: 257/1000..  Training Loss: 10257718637.714..  Test Loss: 13608086528.000.. \n",
      "Epoch: 258/1000..  Training Loss: 10267371242.057..  Test Loss: 15162176512.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10260570038.857..  Test Loss: 13436447744.000.. \n",
      "Epoch: 260/1000..  Training Loss: 10237917315.657..  Test Loss: 14208242688.000.. \n",
      "Epoch: 261/1000..  Training Loss: 10228905691.429..  Test Loss: 14215675904.000.. \n",
      "Epoch: 262/1000..  Training Loss: 10221237013.943..  Test Loss: 13187300352.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10205168976.457..  Test Loss: 12943441920.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10186319520.914..  Test Loss: 13856084992.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10156433013.029..  Test Loss: 13037904896.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10146733114.514..  Test Loss: 12964911104.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10144762090.057..  Test Loss: 13964494848.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10125063753.143..  Test Loss: 14045713408.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10091088515.657..  Test Loss: 13233835008.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10062495861.029..  Test Loss: 13721476096.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10063442783.086..  Test Loss: 13413321728.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10039156618.971..  Test Loss: 13383873536.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10023471513.600..  Test Loss: 12908541952.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10023173163.886..  Test Loss: 13023986688.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10025534200.686..  Test Loss: 14425112576.000.. \n",
      "Epoch: 276/1000..  Training Loss: 9994008941.714..  Test Loss: 13472218112.000.. \n",
      "Epoch: 277/1000..  Training Loss: 9953587243.886..  Test Loss: 13023520768.000.. \n",
      "Epoch: 278/1000..  Training Loss: 9970151306.971..  Test Loss: 12867170304.000.. \n",
      "Epoch: 279/1000..  Training Loss: 9969206871.771..  Test Loss: 12924095488.000.. \n",
      "Epoch: 280/1000..  Training Loss: 9908669030.400..  Test Loss: 13652715520.000.. \n",
      "Epoch: 281/1000..  Training Loss: 9905995073.829..  Test Loss: 12922992640.000.. \n",
      "Epoch: 282/1000..  Training Loss: 9935930324.114..  Test Loss: 13520382976.000.. \n",
      "Epoch: 283/1000..  Training Loss: 9889277878.857..  Test Loss: 12815686656.000.. \n",
      "Epoch: 284/1000..  Training Loss: 9883106947.657..  Test Loss: 13266980864.000.. \n",
      "Epoch: 285/1000..  Training Loss: 9861109116.343..  Test Loss: 13194170368.000.. \n",
      "Epoch: 286/1000..  Training Loss: 9866119972.571..  Test Loss: 13485750272.000.. \n",
      "Epoch: 287/1000..  Training Loss: 9820720947.200..  Test Loss: 13022518272.000.. \n",
      "Epoch: 288/1000..  Training Loss: 9812663749.486..  Test Loss: 13640558592.000.. \n",
      "Epoch: 289/1000..  Training Loss: 9787610492.343..  Test Loss: 12861110272.000.. \n",
      "Epoch: 290/1000..  Training Loss: 9789130005.943..  Test Loss: 13424596992.000.. \n",
      "Epoch: 291/1000..  Training Loss: 9770978274.743..  Test Loss: 13173549056.000.. \n",
      "Epoch: 292/1000..  Training Loss: 9730179496.229..  Test Loss: 13263596544.000.. \n",
      "Epoch: 293/1000..  Training Loss: 9749484778.057..  Test Loss: 12993032192.000.. \n",
      "Epoch: 294/1000..  Training Loss: 9725767665.371..  Test Loss: 13511109632.000.. \n",
      "Epoch: 295/1000..  Training Loss: 9723779818.057..  Test Loss: 14200247296.000.. \n",
      "Epoch: 296/1000..  Training Loss: 9699979776.000..  Test Loss: 12899452928.000.. \n",
      "Epoch: 297/1000..  Training Loss: 9696799656.229..  Test Loss: 13411529728.000.. \n",
      "Epoch: 298/1000..  Training Loss: 9688393011.200..  Test Loss: 13134113792.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/1000..  Training Loss: 9649973774.629..  Test Loss: 13495650304.000.. \n",
      "Epoch: 300/1000..  Training Loss: 9649177760.914..  Test Loss: 13049416704.000.. \n",
      "Epoch: 301/1000..  Training Loss: 9602992010.971..  Test Loss: 12918197248.000.. \n",
      "Epoch: 302/1000..  Training Loss: 9575837184.000..  Test Loss: 12480557056.000.. \n",
      "Epoch: 303/1000..  Training Loss: 9584052677.486..  Test Loss: 13128984576.000.. \n",
      "Epoch: 304/1000..  Training Loss: 9557456340.114..  Test Loss: 12562127872.000.. \n",
      "Epoch: 305/1000..  Training Loss: 9574522953.143..  Test Loss: 12955828224.000.. \n",
      "Epoch: 306/1000..  Training Loss: 9525215553.829..  Test Loss: 12946080768.000.. \n",
      "Epoch: 307/1000..  Training Loss: 9554639754.971..  Test Loss: 13467933696.000.. \n",
      "Epoch: 308/1000..  Training Loss: 9543937696.914..  Test Loss: 12390988800.000.. \n",
      "Epoch: 309/1000..  Training Loss: 9477357041.371..  Test Loss: 12352455680.000.. \n",
      "Epoch: 310/1000..  Training Loss: 9509059481.600..  Test Loss: 13052972032.000.. \n",
      "Epoch: 311/1000..  Training Loss: 9448676293.486..  Test Loss: 13691799552.000.. \n",
      "Epoch: 312/1000..  Training Loss: 9437694581.029..  Test Loss: 13005658112.000.. \n",
      "Epoch: 313/1000..  Training Loss: 9421706883.657..  Test Loss: 12961739776.000.. \n",
      "Epoch: 314/1000..  Training Loss: 9421006014.171..  Test Loss: 13130117120.000.. \n",
      "Epoch: 315/1000..  Training Loss: 9406587421.257..  Test Loss: 13382688768.000.. \n",
      "Epoch: 316/1000..  Training Loss: 9390213514.971..  Test Loss: 13309676544.000.. \n",
      "Epoch: 317/1000..  Training Loss: 9403308470.857..  Test Loss: 12472772608.000.. \n",
      "Epoch: 318/1000..  Training Loss: 9342199639.771..  Test Loss: 12652487680.000.. \n",
      "Epoch: 319/1000..  Training Loss: 9287480744.229..  Test Loss: 13209968640.000.. \n",
      "Epoch: 320/1000..  Training Loss: 9370798138.514..  Test Loss: 12802591744.000.. \n",
      "Epoch: 321/1000..  Training Loss: 9298506810.514..  Test Loss: 12739960832.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9260354925.714..  Test Loss: 13770776576.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9315366897.371..  Test Loss: 12103944192.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9266263756.800..  Test Loss: 12206368768.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9245746278.400..  Test Loss: 12518682624.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9201348198.400..  Test Loss: 12595347456.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9217866342.400..  Test Loss: 12220323840.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9187685171.200..  Test Loss: 12444703744.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9168476511.086..  Test Loss: 12741705728.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9186376791.771..  Test Loss: 12853846016.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9186009336.686..  Test Loss: 12497397760.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9150312535.771..  Test Loss: 12942526464.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9160782072.686..  Test Loss: 12649310208.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9063533041.371..  Test Loss: 12200729600.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9083575530.057..  Test Loss: 12424054784.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9045532042.971..  Test Loss: 12501982208.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9049115706.514..  Test Loss: 13246554112.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9021083648.000..  Test Loss: 12472148992.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9053987635.200..  Test Loss: 12860208128.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9020511597.714..  Test Loss: 12450812928.000.. \n",
      "Epoch: 341/1000..  Training Loss: 8990454959.543..  Test Loss: 12294967296.000.. \n",
      "Epoch: 342/1000..  Training Loss: 8968043476.114..  Test Loss: 13196371968.000.. \n",
      "Epoch: 343/1000..  Training Loss: 8989727641.600..  Test Loss: 12932492288.000.. \n",
      "Epoch: 344/1000..  Training Loss: 8925920394.971..  Test Loss: 12081380352.000.. \n",
      "Epoch: 345/1000..  Training Loss: 8940761512.229..  Test Loss: 13072100352.000.. \n",
      "Epoch: 346/1000..  Training Loss: 8927635412.114..  Test Loss: 12300910592.000.. \n",
      "Epoch: 347/1000..  Training Loss: 8941773165.714..  Test Loss: 12236742656.000.. \n",
      "Epoch: 348/1000..  Training Loss: 8873628218.514..  Test Loss: 12164295680.000.. \n",
      "Epoch: 349/1000..  Training Loss: 8875880842.971..  Test Loss: 12401199104.000.. \n",
      "Epoch: 350/1000..  Training Loss: 8855296512.000..  Test Loss: 12002856960.000.. \n",
      "Epoch: 351/1000..  Training Loss: 8844195225.600..  Test Loss: 12901374976.000.. \n",
      "Epoch: 352/1000..  Training Loss: 8856383605.029..  Test Loss: 12143775744.000.. \n",
      "Epoch: 353/1000..  Training Loss: 8809542114.743..  Test Loss: 11876990976.000.. \n",
      "Epoch: 354/1000..  Training Loss: 8779422178.743..  Test Loss: 12504690688.000.. \n",
      "Epoch: 355/1000..  Training Loss: 8794839449.600..  Test Loss: 12445412352.000.. \n",
      "Epoch: 356/1000..  Training Loss: 8748847952.457..  Test Loss: 13308677120.000.. \n",
      "Epoch: 357/1000..  Training Loss: 8772502308.571..  Test Loss: 12570311680.000.. \n",
      "Epoch: 358/1000..  Training Loss: 8730063813.486..  Test Loss: 11687941120.000.. \n",
      "Epoch: 359/1000..  Training Loss: 8724597869.714..  Test Loss: 11989588992.000.. \n",
      "Epoch: 360/1000..  Training Loss: 8663096188.343..  Test Loss: 11848653824.000.. \n",
      "Epoch: 361/1000..  Training Loss: 8700299388.343..  Test Loss: 12730416128.000.. \n",
      "Epoch: 362/1000..  Training Loss: 8644955823.543..  Test Loss: 13067405312.000.. \n",
      "Epoch: 363/1000..  Training Loss: 8697863519.086..  Test Loss: 11899513856.000.. \n",
      "Epoch: 364/1000..  Training Loss: 8633546649.600..  Test Loss: 11952624640.000.. \n",
      "Epoch: 365/1000..  Training Loss: 8585339479.771..  Test Loss: 11843390464.000.. \n",
      "Epoch: 366/1000..  Training Loss: 8576882073.600..  Test Loss: 12282089472.000.. \n",
      "Epoch: 367/1000..  Training Loss: 8597794143.086..  Test Loss: 12014794752.000.. \n",
      "Epoch: 368/1000..  Training Loss: 8607812432.457..  Test Loss: 12716926976.000.. \n",
      "Epoch: 369/1000..  Training Loss: 8581953345.829..  Test Loss: 12026683392.000.. \n",
      "Epoch: 370/1000..  Training Loss: 8555150028.800..  Test Loss: 11481426944.000.. \n",
      "Epoch: 371/1000..  Training Loss: 8548806641.371..  Test Loss: 11363253248.000.. \n",
      "Epoch: 372/1000..  Training Loss: 8534233921.829..  Test Loss: 11625061376.000.. \n",
      "Epoch: 373/1000..  Training Loss: 8504817386.057..  Test Loss: 12301511680.000.. \n",
      "Epoch: 374/1000..  Training Loss: 8506139911.314..  Test Loss: 12030904320.000.. \n",
      "Epoch: 375/1000..  Training Loss: 8479410146.743..  Test Loss: 11482223616.000.. \n",
      "Epoch: 376/1000..  Training Loss: 8493114104.686..  Test Loss: 11567744000.000.. \n",
      "Epoch: 377/1000..  Training Loss: 8439172959.086..  Test Loss: 11837893632.000.. \n",
      "Epoch: 378/1000..  Training Loss: 8382017038.629..  Test Loss: 11897022464.000.. \n",
      "Epoch: 379/1000..  Training Loss: 8389730099.200..  Test Loss: 11679938560.000.. \n",
      "Epoch: 380/1000..  Training Loss: 8411176535.771..  Test Loss: 11095382016.000.. \n",
      "Epoch: 381/1000..  Training Loss: 8378010580.114..  Test Loss: 11580124160.000.. \n",
      "Epoch: 382/1000..  Training Loss: 8308161433.600..  Test Loss: 11774409728.000.. \n",
      "Epoch: 383/1000..  Training Loss: 8339601334.857..  Test Loss: 11277625344.000.. \n",
      "Epoch: 384/1000..  Training Loss: 8308815945.143..  Test Loss: 12113134592.000.. \n",
      "Epoch: 385/1000..  Training Loss: 8303543632.457..  Test Loss: 11531745280.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8311937375.086..  Test Loss: 11966095360.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8246538225.371..  Test Loss: 11288844288.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8263928905.143..  Test Loss: 10991235072.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8202303736.686..  Test Loss: 11127700480.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8255708745.143..  Test Loss: 11307364352.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8182801100.800..  Test Loss: 11284545536.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8204177737.143..  Test Loss: 10727412736.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8192085467.429..  Test Loss: 10863267840.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8176515766.857..  Test Loss: 11022556160.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8078714580.114..  Test Loss: 11100942336.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8137257632.914..  Test Loss: 11896957952.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8118112621.714..  Test Loss: 11530103808.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8071516657.371..  Test Loss: 11550234624.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 399/1000..  Training Loss: 8091584848.457..  Test Loss: 11369995264.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8082742593.829..  Test Loss: 11173090304.000.. \n",
      "Epoch: 401/1000..  Training Loss: 8051199517.257..  Test Loss: 12041559040.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8007215221.029..  Test Loss: 10789919744.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8040846189.714..  Test Loss: 11068902400.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8009944656.457..  Test Loss: 11188584448.000.. \n",
      "Epoch: 405/1000..  Training Loss: 7984464193.829..  Test Loss: 11314574336.000.. \n",
      "Epoch: 406/1000..  Training Loss: 7954978479.543..  Test Loss: 11692235776.000.. \n",
      "Epoch: 407/1000..  Training Loss: 7928406337.829..  Test Loss: 10472365056.000.. \n",
      "Epoch: 408/1000..  Training Loss: 7916512285.257..  Test Loss: 10646784000.000.. \n",
      "Epoch: 409/1000..  Training Loss: 7916201749.943..  Test Loss: 10589010944.000.. \n",
      "Epoch: 410/1000..  Training Loss: 7931783767.771..  Test Loss: 10942643200.000.. \n",
      "Epoch: 411/1000..  Training Loss: 7862080014.629..  Test Loss: 10688667648.000.. \n",
      "Epoch: 412/1000..  Training Loss: 7925525577.143..  Test Loss: 11052843008.000.. \n",
      "Epoch: 413/1000..  Training Loss: 7833990846.171..  Test Loss: 10516269056.000.. \n",
      "Epoch: 414/1000..  Training Loss: 7789162613.029..  Test Loss: 10833698816.000.. \n",
      "Epoch: 415/1000..  Training Loss: 7844607429.486..  Test Loss: 10890804224.000.. \n",
      "Epoch: 416/1000..  Training Loss: 7792132359.314..  Test Loss: 10495962112.000.. \n",
      "Epoch: 417/1000..  Training Loss: 7759283931.429..  Test Loss: 10854427648.000.. \n",
      "Epoch: 418/1000..  Training Loss: 7798855387.429..  Test Loss: 11714245632.000.. \n",
      "Epoch: 419/1000..  Training Loss: 7816807950.629..  Test Loss: 11020663808.000.. \n",
      "Epoch: 420/1000..  Training Loss: 7717382392.686..  Test Loss: 10959263744.000.. \n",
      "Epoch: 421/1000..  Training Loss: 7711006178.743..  Test Loss: 10582203392.000.. \n",
      "Epoch: 422/1000..  Training Loss: 7685692357.486..  Test Loss: 10517847040.000.. \n",
      "Epoch: 423/1000..  Training Loss: 7663546338.743..  Test Loss: 10531394560.000.. \n",
      "Epoch: 424/1000..  Training Loss: 7686603600.457..  Test Loss: 10266016768.000.. \n",
      "Epoch: 425/1000..  Training Loss: 7629705025.829..  Test Loss: 10943997952.000.. \n",
      "Epoch: 426/1000..  Training Loss: 7648906005.943..  Test Loss: 10639446016.000.. \n",
      "Epoch: 427/1000..  Training Loss: 7578360290.743..  Test Loss: 10155227136.000.. \n",
      "Epoch: 428/1000..  Training Loss: 7633905598.171..  Test Loss: 10317072384.000.. \n",
      "Epoch: 429/1000..  Training Loss: 7585849621.943..  Test Loss: 10609118208.000.. \n",
      "Epoch: 430/1000..  Training Loss: 7567402144.914..  Test Loss: 10384833536.000.. \n",
      "Epoch: 431/1000..  Training Loss: 7609928630.857..  Test Loss: 10367790080.000.. \n",
      "Epoch: 432/1000..  Training Loss: 7534000128.000..  Test Loss: 10247384064.000.. \n",
      "Epoch: 433/1000..  Training Loss: 7505836938.971..  Test Loss: 10907250688.000.. \n",
      "Epoch: 434/1000..  Training Loss: 7474782237.257..  Test Loss: 10181057536.000.. \n",
      "Epoch: 435/1000..  Training Loss: 7481137678.629..  Test Loss: 10739479552.000.. \n",
      "Epoch: 436/1000..  Training Loss: 7565587858.286..  Test Loss: 10127834112.000.. \n",
      "Epoch: 437/1000..  Training Loss: 7473835285.943..  Test Loss: 10442771456.000.. \n",
      "Epoch: 438/1000..  Training Loss: 7519270751.086..  Test Loss: 10320995328.000.. \n",
      "Epoch: 439/1000..  Training Loss: 7441276796.343..  Test Loss: 10173933568.000.. \n",
      "Epoch: 440/1000..  Training Loss: 7435274283.886..  Test Loss: 10353648640.000.. \n",
      "Epoch: 441/1000..  Training Loss: 7413127723.886..  Test Loss: 11082181632.000.. \n",
      "Epoch: 442/1000..  Training Loss: 7423195640.686..  Test Loss: 10235486208.000.. \n",
      "Epoch: 443/1000..  Training Loss: 7373174345.143..  Test Loss: 10376514560.000.. \n",
      "Epoch: 444/1000..  Training Loss: 7339661370.514..  Test Loss: 10738187264.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7379886855.314..  Test Loss: 10545980416.000.. \n",
      "Epoch: 446/1000..  Training Loss: 7329018631.314..  Test Loss: 9881070592.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7339133440.000..  Test Loss: 10735205376.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7287553909.029..  Test Loss: 9671463936.000.. \n",
      "Epoch: 449/1000..  Training Loss: 7359372383.086..  Test Loss: 9847726080.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7321368561.371..  Test Loss: 10299857920.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7215699295.086..  Test Loss: 9836862464.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7339590385.371..  Test Loss: 10223708160.000.. \n",
      "Epoch: 453/1000..  Training Loss: 7233893361.371..  Test Loss: 11406171136.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7254452253.257..  Test Loss: 10619400192.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7189542794.971..  Test Loss: 9412859904.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7165406581.029..  Test Loss: 9526508544.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7138723730.286..  Test Loss: 11167834112.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7168018812.343..  Test Loss: 9738935296.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7073781335.771..  Test Loss: 10352319488.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7130225503.086..  Test Loss: 9974715392.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7123507946.057..  Test Loss: 9833136128.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7063146093.714..  Test Loss: 10588755968.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7108386786.743..  Test Loss: 9711603712.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7137466485.029..  Test Loss: 9432400896.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7104932703.086..  Test Loss: 9578956800.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7033936625.371..  Test Loss: 9971914752.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7027379046.400..  Test Loss: 9687612416.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7017606977.829..  Test Loss: 10087942144.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7014428796.343..  Test Loss: 10910274560.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7064893995.886..  Test Loss: 9634181120.000.. \n",
      "Epoch: 471/1000..  Training Loss: 6967110312.229..  Test Loss: 9219767296.000.. \n",
      "Epoch: 472/1000..  Training Loss: 6949940004.571..  Test Loss: 10517623808.000.. \n",
      "Epoch: 473/1000..  Training Loss: 6988288863.086..  Test Loss: 9332507648.000.. \n",
      "Epoch: 474/1000..  Training Loss: 6953459251.200..  Test Loss: 10425563136.000.. \n",
      "Epoch: 475/1000..  Training Loss: 6930930080.914..  Test Loss: 10300165120.000.. \n",
      "Epoch: 476/1000..  Training Loss: 6881087882.971..  Test Loss: 10171055104.000.. \n",
      "Epoch: 477/1000..  Training Loss: 6822462976.000..  Test Loss: 9103596544.000.. \n",
      "Epoch: 478/1000..  Training Loss: 6911514799.543..  Test Loss: 9558611968.000.. \n",
      "Epoch: 479/1000..  Training Loss: 6843043167.086..  Test Loss: 10150323200.000.. \n",
      "Epoch: 480/1000..  Training Loss: 6840474448.457..  Test Loss: 9410365440.000.. \n",
      "Epoch: 481/1000..  Training Loss: 6850221758.171..  Test Loss: 9391284224.000.. \n",
      "Epoch: 482/1000..  Training Loss: 6765021864.229..  Test Loss: 9131289600.000.. \n",
      "Epoch: 483/1000..  Training Loss: 6772757365.029..  Test Loss: 9280134144.000.. \n",
      "Epoch: 484/1000..  Training Loss: 6749978543.543..  Test Loss: 9247148032.000.. \n",
      "Epoch: 485/1000..  Training Loss: 6737609603.657..  Test Loss: 9404345344.000.. \n",
      "Epoch: 486/1000..  Training Loss: 6794430785.829..  Test Loss: 9224325120.000.. \n",
      "Epoch: 487/1000..  Training Loss: 6810615296.000..  Test Loss: 9023271936.000.. \n",
      "Epoch: 488/1000..  Training Loss: 6760422231.771..  Test Loss: 9776179200.000.. \n",
      "Epoch: 489/1000..  Training Loss: 6688804395.886..  Test Loss: 8950696960.000.. \n",
      "Epoch: 490/1000..  Training Loss: 6687570110.171..  Test Loss: 10352062464.000.. \n",
      "Epoch: 491/1000..  Training Loss: 6716344290.743..  Test Loss: 9336192000.000.. \n",
      "Epoch: 492/1000..  Training Loss: 6641554161.371..  Test Loss: 9099343872.000.. \n",
      "Epoch: 493/1000..  Training Loss: 6714857047.771..  Test Loss: 9200974848.000.. \n",
      "Epoch: 494/1000..  Training Loss: 6593690587.429..  Test Loss: 8927994880.000.. \n",
      "Epoch: 495/1000..  Training Loss: 6687289073.371..  Test Loss: 9074551808.000.. \n",
      "Epoch: 496/1000..  Training Loss: 6657262665.143..  Test Loss: 9322217472.000.. \n",
      "Epoch: 497/1000..  Training Loss: 6653992192.000..  Test Loss: 9288080384.000.. \n",
      "Epoch: 498/1000..  Training Loss: 6568767041.829..  Test Loss: 10222213120.000.. \n",
      "Epoch: 499/1000..  Training Loss: 6588590131.200..  Test Loss: 9100459008.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500/1000..  Training Loss: 6552684273.371..  Test Loss: 9628988416.000.. \n",
      "Epoch: 501/1000..  Training Loss: 6545777290.971..  Test Loss: 9063138304.000.. \n",
      "Epoch: 502/1000..  Training Loss: 6492509527.771..  Test Loss: 9363329024.000.. \n",
      "Epoch: 503/1000..  Training Loss: 6498436736.000..  Test Loss: 9961062400.000.. \n",
      "Epoch: 504/1000..  Training Loss: 6509383416.686..  Test Loss: 9632073728.000.. \n",
      "Epoch: 505/1000..  Training Loss: 6522416237.714..  Test Loss: 10022818816.000.. \n",
      "Epoch: 506/1000..  Training Loss: 6487301354.057..  Test Loss: 9515204608.000.. \n",
      "Epoch: 507/1000..  Training Loss: 6439285343.086..  Test Loss: 8884210688.000.. \n",
      "Epoch: 508/1000..  Training Loss: 6549831292.343..  Test Loss: 8770197504.000.. \n",
      "Epoch: 509/1000..  Training Loss: 6467097936.457..  Test Loss: 9163181056.000.. \n",
      "Epoch: 510/1000..  Training Loss: 6397468445.257..  Test Loss: 9038213120.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6380444423.314..  Test Loss: 8659516416.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6393609881.600..  Test Loss: 10125724672.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6388795136.000..  Test Loss: 8734960640.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6391584665.600..  Test Loss: 9163042816.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6419052719.543..  Test Loss: 8574998016.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6369059759.543..  Test Loss: 9497877504.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6297799409.371..  Test Loss: 8515257856.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6301567458.743..  Test Loss: 8469928448.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6279618560.000..  Test Loss: 8941572096.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6305484924.343..  Test Loss: 8557642752.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6236911579.429..  Test Loss: 9393272832.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6212825285.486..  Test Loss: 8920566784.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6246711398.400..  Test Loss: 9493009408.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6251833512.229..  Test Loss: 8898137088.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6230495626.971..  Test Loss: 9006394368.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6214154283.886..  Test Loss: 9476346880.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6226788754.286..  Test Loss: 8375824384.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6186708158.171..  Test Loss: 8995041280.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6138968334.629..  Test Loss: 8774611968.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6191795229.257..  Test Loss: 8562085888.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6196580088.686..  Test Loss: 8429592064.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6071270085.486..  Test Loss: 8872992768.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6066547141.486..  Test Loss: 9702629376.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6093565542.400..  Test Loss: 10066690048.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6190303400.229..  Test Loss: 8694539264.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6137843565.714..  Test Loss: 8599124992.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6079141039.543..  Test Loss: 9027132416.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6039555547.429..  Test Loss: 8106906624.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6093341930.057..  Test Loss: 8883636224.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6032898318.629..  Test Loss: 8329233408.000.. \n",
      "Epoch: 541/1000..  Training Loss: 5947795207.314..  Test Loss: 8495997952.000.. \n",
      "Epoch: 542/1000..  Training Loss: 5962374487.771..  Test Loss: 8112799744.000.. \n",
      "Epoch: 543/1000..  Training Loss: 5962270602.971..  Test Loss: 8311810560.000.. \n",
      "Epoch: 544/1000..  Training Loss: 5969324229.486..  Test Loss: 8229359616.000.. \n",
      "Epoch: 545/1000..  Training Loss: 5977644024.686..  Test Loss: 8871189504.000.. \n",
      "Epoch: 546/1000..  Training Loss: 5894885507.657..  Test Loss: 8767677440.000.. \n",
      "Epoch: 547/1000..  Training Loss: 5970959060.114..  Test Loss: 8199286784.000.. \n",
      "Epoch: 548/1000..  Training Loss: 5955854453.029..  Test Loss: 8398938112.000.. \n",
      "Epoch: 549/1000..  Training Loss: 5949997443.657..  Test Loss: 7900467200.000.. \n",
      "Epoch: 550/1000..  Training Loss: 5950127067.429..  Test Loss: 8026013184.000.. \n",
      "Epoch: 551/1000..  Training Loss: 5863736202.971..  Test Loss: 8334715392.000.. \n",
      "Epoch: 552/1000..  Training Loss: 5816458576.457..  Test Loss: 8336155648.000.. \n",
      "Epoch: 553/1000..  Training Loss: 5818222621.257..  Test Loss: 8141376000.000.. \n",
      "Epoch: 554/1000..  Training Loss: 5833028732.343..  Test Loss: 8112819712.000.. \n",
      "Epoch: 555/1000..  Training Loss: 5808553135.543..  Test Loss: 7753167872.000.. \n",
      "Epoch: 556/1000..  Training Loss: 5883368484.571..  Test Loss: 8033490432.000.. \n",
      "Epoch: 557/1000..  Training Loss: 5824199087.543..  Test Loss: 8425031168.000.. \n",
      "Epoch: 558/1000..  Training Loss: 5809876853.029..  Test Loss: 8587868672.000.. \n",
      "Epoch: 559/1000..  Training Loss: 5856096702.171..  Test Loss: 8331797504.000.. \n",
      "Epoch: 560/1000..  Training Loss: 5698560892.343..  Test Loss: 7842219008.000.. \n",
      "Epoch: 561/1000..  Training Loss: 5768825150.171..  Test Loss: 8181197312.000.. \n",
      "Epoch: 562/1000..  Training Loss: 5727317489.371..  Test Loss: 7937830912.000.. \n",
      "Epoch: 563/1000..  Training Loss: 5770509173.029..  Test Loss: 7750513664.000.. \n",
      "Epoch: 564/1000..  Training Loss: 5744419671.771..  Test Loss: 8417026048.000.. \n",
      "Epoch: 565/1000..  Training Loss: 5690182392.686..  Test Loss: 8143037440.000.. \n",
      "Epoch: 566/1000..  Training Loss: 5710760440.686..  Test Loss: 7946982400.000.. \n",
      "Epoch: 567/1000..  Training Loss: 5649432832.000..  Test Loss: 8404581888.000.. \n",
      "Epoch: 568/1000..  Training Loss: 5654590866.286..  Test Loss: 7883282944.000.. \n",
      "Epoch: 569/1000..  Training Loss: 5657845584.457..  Test Loss: 8540111872.000.. \n",
      "Epoch: 570/1000..  Training Loss: 5675574813.257..  Test Loss: 9341903872.000.. \n",
      "Epoch: 571/1000..  Training Loss: 5607601930.971..  Test Loss: 7984971776.000.. \n",
      "Epoch: 572/1000..  Training Loss: 5608041574.400..  Test Loss: 8368632832.000.. \n",
      "Epoch: 573/1000..  Training Loss: 5546266880.000..  Test Loss: 7826337792.000.. \n",
      "Epoch: 574/1000..  Training Loss: 5597158740.114..  Test Loss: 8052110336.000.. \n",
      "Epoch: 575/1000..  Training Loss: 5609212046.629..  Test Loss: 7738627072.000.. \n",
      "Epoch: 576/1000..  Training Loss: 5516047637.943..  Test Loss: 7811176960.000.. \n",
      "Epoch: 577/1000..  Training Loss: 5569099000.686..  Test Loss: 7795592704.000.. \n",
      "Epoch: 578/1000..  Training Loss: 5534065408.000..  Test Loss: 7790372352.000.. \n",
      "Epoch: 579/1000..  Training Loss: 5536254529.829..  Test Loss: 7467210240.000.. \n",
      "Epoch: 580/1000..  Training Loss: 5528108280.686..  Test Loss: 8020837888.000.. \n",
      "Epoch: 581/1000..  Training Loss: 5503603031.771..  Test Loss: 7939436032.000.. \n",
      "Epoch: 582/1000..  Training Loss: 5424132490.971..  Test Loss: 7927508480.000.. \n",
      "Epoch: 583/1000..  Training Loss: 5463642887.314..  Test Loss: 7875961856.000.. \n",
      "Epoch: 584/1000..  Training Loss: 5474171274.971..  Test Loss: 7454923264.000.. \n",
      "Epoch: 585/1000..  Training Loss: 5500843278.629..  Test Loss: 7960120832.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5440892218.514..  Test Loss: 7673440768.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5470402157.714..  Test Loss: 8013029376.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5411550259.200..  Test Loss: 8201182720.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5386628300.800..  Test Loss: 7468149248.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5429618929.371..  Test Loss: 7606627840.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5405845906.286..  Test Loss: 7615498752.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5438407021.714..  Test Loss: 7517725696.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5340926515.200..  Test Loss: 8401132032.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5351887937.829..  Test Loss: 7329066496.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5369618717.257..  Test Loss: 7621664768.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5376698880.000..  Test Loss: 7375762432.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5275323018.971..  Test Loss: 7440187392.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5332988174.629..  Test Loss: 7138976768.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5263460725.029..  Test Loss: 7408672768.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5302286423.771..  Test Loss: 7570154496.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5255466335.086..  Test Loss: 7516853248.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 602/1000..  Training Loss: 5259655928.686..  Test Loss: 7329656320.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5292507589.486..  Test Loss: 7717046784.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5252775445.943..  Test Loss: 7276354048.000.. \n",
      "Epoch: 605/1000..  Training Loss: 5202118407.314..  Test Loss: 7506763776.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5284808265.143..  Test Loss: 7556924928.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5282138155.886..  Test Loss: 8584564224.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5186424956.343..  Test Loss: 7369271808.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5234209075.200..  Test Loss: 7925458432.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5229295776.914..  Test Loss: 7348483584.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5210457234.286..  Test Loss: 7295421952.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5228183120.457..  Test Loss: 8035743232.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5134767879.314..  Test Loss: 7082644480.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5156709990.400..  Test Loss: 7446623744.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5154695007.086..  Test Loss: 8125218816.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5130880899.657..  Test Loss: 6955869184.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5112073450.057..  Test Loss: 7625756160.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5089775718.400..  Test Loss: 7194641408.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5089925244.343..  Test Loss: 7441091072.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5100888510.171..  Test Loss: 7637517312.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5173067541.943..  Test Loss: 6923509760.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5078468381.257..  Test Loss: 7094157312.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5117681400.686..  Test Loss: 7616857088.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5154088294.400..  Test Loss: 8063033344.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5009131893.029..  Test Loss: 6970859520.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5081329217.829..  Test Loss: 7416759808.000.. \n",
      "Epoch: 627/1000..  Training Loss: 4972771986.286..  Test Loss: 7311814656.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5020307452.343..  Test Loss: 7476747776.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5020150827.886..  Test Loss: 7889739264.000.. \n",
      "Epoch: 630/1000..  Training Loss: 4979821860.571..  Test Loss: 8040214016.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5000918330.514..  Test Loss: 7528677376.000.. \n",
      "Epoch: 632/1000..  Training Loss: 4941198021.486..  Test Loss: 7360864256.000.. \n",
      "Epoch: 633/1000..  Training Loss: 4982119837.257..  Test Loss: 6695198208.000.. \n",
      "Epoch: 634/1000..  Training Loss: 4967240228.571..  Test Loss: 6948269568.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5072659616.914..  Test Loss: 6648750592.000.. \n",
      "Epoch: 636/1000..  Training Loss: 4920282038.857..  Test Loss: 6908909056.000.. \n",
      "Epoch: 637/1000..  Training Loss: 4990731146.971..  Test Loss: 7279794688.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5002422571.886..  Test Loss: 7126032384.000.. \n",
      "Epoch: 639/1000..  Training Loss: 4961039542.857..  Test Loss: 7109328384.000.. \n",
      "Epoch: 640/1000..  Training Loss: 4887786715.429..  Test Loss: 6685611520.000.. \n",
      "Epoch: 641/1000..  Training Loss: 4929167374.629..  Test Loss: 6649793024.000.. \n",
      "Epoch: 642/1000..  Training Loss: 4929368612.571..  Test Loss: 7225671168.000.. \n",
      "Epoch: 643/1000..  Training Loss: 4912049152.000..  Test Loss: 7678891008.000.. \n",
      "Epoch: 644/1000..  Training Loss: 4884737638.400..  Test Loss: 6615125504.000.. \n",
      "Epoch: 645/1000..  Training Loss: 4928444211.200..  Test Loss: 6610893824.000.. \n",
      "Epoch: 646/1000..  Training Loss: 4875260375.771..  Test Loss: 6852161536.000.. \n",
      "Epoch: 647/1000..  Training Loss: 4923984288.914..  Test Loss: 6673506816.000.. \n",
      "Epoch: 648/1000..  Training Loss: 4889964639.086..  Test Loss: 7134257152.000.. \n",
      "Epoch: 649/1000..  Training Loss: 4860743628.800..  Test Loss: 6491021824.000.. \n",
      "Epoch: 650/1000..  Training Loss: 4845287862.857..  Test Loss: 7312224256.000.. \n",
      "Epoch: 651/1000..  Training Loss: 4855091507.200..  Test Loss: 7431544320.000.. \n",
      "Epoch: 652/1000..  Training Loss: 4900921344.000..  Test Loss: 6538756608.000.. \n",
      "Epoch: 653/1000..  Training Loss: 4833624155.429..  Test Loss: 6772244992.000.. \n",
      "Epoch: 654/1000..  Training Loss: 4785676565.943..  Test Loss: 6868070400.000.. \n",
      "Epoch: 655/1000..  Training Loss: 4799169901.714..  Test Loss: 6843940352.000.. \n",
      "Epoch: 656/1000..  Training Loss: 4815268139.886..  Test Loss: 6871431168.000.. \n",
      "Epoch: 657/1000..  Training Loss: 4823608393.143..  Test Loss: 6522825216.000.. \n",
      "Epoch: 658/1000..  Training Loss: 4844692483.657..  Test Loss: 6805650432.000.. \n",
      "Epoch: 659/1000..  Training Loss: 4801062253.714..  Test Loss: 6735413248.000.. \n",
      "Epoch: 660/1000..  Training Loss: 4809585155.657..  Test Loss: 6931682304.000.. \n",
      "Epoch: 661/1000..  Training Loss: 4827037659.429..  Test Loss: 6771093504.000.. \n",
      "Epoch: 662/1000..  Training Loss: 4786389196.800..  Test Loss: 6756813312.000.. \n",
      "Epoch: 663/1000..  Training Loss: 4744743555.657..  Test Loss: 6467170304.000.. \n",
      "Epoch: 664/1000..  Training Loss: 4735158374.400..  Test Loss: 6453005312.000.. \n",
      "Epoch: 665/1000..  Training Loss: 4763587203.657..  Test Loss: 7119006208.000.. \n",
      "Epoch: 666/1000..  Training Loss: 4816416416.914..  Test Loss: 7614852608.000.. \n",
      "Epoch: 667/1000..  Training Loss: 4799574037.943..  Test Loss: 6529997824.000.. \n",
      "Epoch: 668/1000..  Training Loss: 4722394426.514..  Test Loss: 6855635968.000.. \n",
      "Epoch: 669/1000..  Training Loss: 4688264499.200..  Test Loss: 6692124160.000.. \n",
      "Epoch: 670/1000..  Training Loss: 4679179735.771..  Test Loss: 6712792576.000.. \n",
      "Epoch: 671/1000..  Training Loss: 4730991308.800..  Test Loss: 6565490688.000.. \n",
      "Epoch: 672/1000..  Training Loss: 4743092059.429..  Test Loss: 6460302848.000.. \n",
      "Epoch: 673/1000..  Training Loss: 4715657523.200..  Test Loss: 6427975168.000.. \n",
      "Epoch: 674/1000..  Training Loss: 4659724507.429..  Test Loss: 6347023360.000.. \n",
      "Epoch: 675/1000..  Training Loss: 4709071100.343..  Test Loss: 6377409536.000.. \n",
      "Epoch: 676/1000..  Training Loss: 4715557551.543..  Test Loss: 7930150400.000.. \n",
      "Epoch: 677/1000..  Training Loss: 4727106516.114..  Test Loss: 7283196928.000.. \n",
      "Epoch: 678/1000..  Training Loss: 4716220203.886..  Test Loss: 6223711744.000.. \n",
      "Epoch: 679/1000..  Training Loss: 4650494361.600..  Test Loss: 6438675456.000.. \n",
      "Epoch: 680/1000..  Training Loss: 4679051907.657..  Test Loss: 7087192576.000.. \n",
      "Epoch: 681/1000..  Training Loss: 4652936162.743..  Test Loss: 6518711296.000.. \n",
      "Epoch: 682/1000..  Training Loss: 4667510886.400..  Test Loss: 6370770944.000.. \n",
      "Epoch: 683/1000..  Training Loss: 4722189560.686..  Test Loss: 6147992064.000.. \n",
      "Epoch: 684/1000..  Training Loss: 4660842254.629..  Test Loss: 7844142592.000.. \n",
      "Epoch: 685/1000..  Training Loss: 4697762066.286..  Test Loss: 6112338432.000.. \n",
      "Epoch: 686/1000..  Training Loss: 4709108253.257..  Test Loss: 6176290816.000.. \n",
      "Epoch: 687/1000..  Training Loss: 4656933149.257..  Test Loss: 6315473408.000.. \n",
      "Epoch: 688/1000..  Training Loss: 4684681574.400..  Test Loss: 6359680000.000.. \n",
      "Epoch: 689/1000..  Training Loss: 4679444955.429..  Test Loss: 6294564352.000.. \n",
      "Epoch: 690/1000..  Training Loss: 4565907126.857..  Test Loss: 6827565056.000.. \n",
      "Epoch: 691/1000..  Training Loss: 4671188384.914..  Test Loss: 7224416768.000.. \n",
      "Epoch: 692/1000..  Training Loss: 4588101851.429..  Test Loss: 6892907008.000.. \n",
      "Epoch: 693/1000..  Training Loss: 4648810437.486..  Test Loss: 6311895552.000.. \n",
      "Epoch: 694/1000..  Training Loss: 4565000857.600..  Test Loss: 6553929728.000.. \n",
      "Epoch: 695/1000..  Training Loss: 4592384270.629..  Test Loss: 7663331840.000.. \n",
      "Epoch: 696/1000..  Training Loss: 4650373039.543..  Test Loss: 6351614464.000.. \n",
      "Epoch: 697/1000..  Training Loss: 4635944521.143..  Test Loss: 6371542528.000.. \n",
      "Epoch: 698/1000..  Training Loss: 4603055711.086..  Test Loss: 6028974080.000.. \n",
      "Epoch: 699/1000..  Training Loss: 4506447275.886..  Test Loss: 6757737472.000.. \n",
      "Epoch: 700/1000..  Training Loss: 4642068538.514..  Test Loss: 5984153088.000.. \n",
      "Epoch: 701/1000..  Training Loss: 4585359594.057..  Test Loss: 6801701376.000.. \n",
      "Epoch: 702/1000..  Training Loss: 4571684352.000..  Test Loss: 6580097024.000.. \n",
      "Epoch: 703/1000..  Training Loss: 4603397288.229..  Test Loss: 6430068224.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 704/1000..  Training Loss: 4631554940.343..  Test Loss: 6113408512.000.. \n",
      "Epoch: 705/1000..  Training Loss: 4551731368.229..  Test Loss: 6052107776.000.. \n",
      "Epoch: 706/1000..  Training Loss: 4478268701.257..  Test Loss: 7273640960.000.. \n",
      "Epoch: 707/1000..  Training Loss: 4544677090.743..  Test Loss: 6316582912.000.. \n",
      "Epoch: 708/1000..  Training Loss: 4519249408.000..  Test Loss: 6163984384.000.. \n",
      "Epoch: 709/1000..  Training Loss: 4540028386.743..  Test Loss: 6369879040.000.. \n",
      "Epoch: 710/1000..  Training Loss: 4480606153.143..  Test Loss: 6523401728.000.. \n",
      "Epoch: 711/1000..  Training Loss: 4583530327.771..  Test Loss: 7534657536.000.. \n",
      "Epoch: 712/1000..  Training Loss: 4546568155.429..  Test Loss: 6383946240.000.. \n",
      "Epoch: 713/1000..  Training Loss: 4497810278.400..  Test Loss: 6199217152.000.. \n",
      "Epoch: 714/1000..  Training Loss: 4513693820.343..  Test Loss: 6384215040.000.. \n",
      "Epoch: 715/1000..  Training Loss: 4551272067.657..  Test Loss: 6082624000.000.. \n",
      "Epoch: 716/1000..  Training Loss: 4496827103.086..  Test Loss: 6506961408.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4486198762.057..  Test Loss: 6338379264.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4488010174.171..  Test Loss: 6483316224.000.. \n",
      "Epoch: 719/1000..  Training Loss: 4536190602.971..  Test Loss: 6103584256.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4584474375.314..  Test Loss: 7193726464.000.. \n",
      "Epoch: 721/1000..  Training Loss: 4489294793.143..  Test Loss: 5888722432.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4498026276.571..  Test Loss: 6321959936.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4530137131.886..  Test Loss: 6115865088.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4480012865.829..  Test Loss: 5974124032.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4536507435.886..  Test Loss: 6022724096.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4473507401.143..  Test Loss: 6191277056.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4394909184.000..  Test Loss: 6359673856.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4455524125.257..  Test Loss: 6169906688.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4478143480.686..  Test Loss: 5779943936.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4471391663.543..  Test Loss: 6025307648.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4423746216.229..  Test Loss: 5886925312.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4451997235.200..  Test Loss: 6049065472.000.. \n",
      "Epoch: 733/1000..  Training Loss: 4495264570.514..  Test Loss: 6505506304.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4496217179.429..  Test Loss: 5839717376.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4433084189.257..  Test Loss: 6119384064.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4445161537.829..  Test Loss: 6459826688.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4402255637.943..  Test Loss: 6501732352.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4449959248.457..  Test Loss: 6023710720.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4475838485.943..  Test Loss: 5737553920.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4488779882.057..  Test Loss: 6814361600.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4414732331.886..  Test Loss: 5906872320.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4407312274.286..  Test Loss: 5677784064.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4435155642.514..  Test Loss: 6258820096.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4412650294.857..  Test Loss: 5875471872.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4373104585.143..  Test Loss: 6105608192.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4345148993.829..  Test Loss: 5970701312.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4419830389.029..  Test Loss: 6921602048.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4436478705.371..  Test Loss: 5825137152.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4418604763.429..  Test Loss: 6324346880.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4406717827.657..  Test Loss: 5790136832.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4421589781.943..  Test Loss: 5688779264.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4410514823.314..  Test Loss: 6360420352.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4387945610.971..  Test Loss: 6221780480.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4388507011.657..  Test Loss: 5777279488.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4352726597.486..  Test Loss: 6481389056.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4369132781.714..  Test Loss: 5879618048.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4400835145.143..  Test Loss: 6354457600.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4482445399.771..  Test Loss: 5759714816.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4395410044.343..  Test Loss: 5792729088.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4417428538.514..  Test Loss: 6139147264.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4429287544.686..  Test Loss: 6429223424.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4431172410.514..  Test Loss: 6442539520.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4382870279.314..  Test Loss: 6311140864.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4334646414.629..  Test Loss: 5635553280.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4333570976.914..  Test Loss: 5724424192.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4418698978.743..  Test Loss: 5687101440.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4380018636.800..  Test Loss: 5674462720.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4383914064.457..  Test Loss: 5768269312.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4431433439.086..  Test Loss: 5556026880.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4327410121.143..  Test Loss: 5982904320.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4378613844.114..  Test Loss: 5898006528.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4346095893.943..  Test Loss: 5747660800.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4365026486.857..  Test Loss: 5525166592.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4365855283.200..  Test Loss: 5496989184.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4386021412.571..  Test Loss: 6542640640.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4317265247.086..  Test Loss: 6041611776.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4354697881.600..  Test Loss: 5855749120.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4346557696.000..  Test Loss: 5909885440.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4358431495.314..  Test Loss: 5870063104.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4379961373.257..  Test Loss: 5620459008.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4367970311.314..  Test Loss: 6641966592.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4339698812.343..  Test Loss: 5566925312.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4359806182.400..  Test Loss: 5672271872.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4361404123.429..  Test Loss: 5424113152.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4342331765.029..  Test Loss: 5633307136.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4362269198.629..  Test Loss: 6371892736.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4365540469.029..  Test Loss: 5656146432.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4315945691.429..  Test Loss: 5391336960.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4362198257.371..  Test Loss: 5955640832.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4340916589.714..  Test Loss: 5727976960.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4349312855.771..  Test Loss: 5562742272.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4309467867.429..  Test Loss: 5811899392.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4355461500.343..  Test Loss: 5571416064.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4295734674.286..  Test Loss: 5927154688.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4374399985.371..  Test Loss: 6106392576.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4298034132.114..  Test Loss: 5869855744.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4323131914.971..  Test Loss: 6366741504.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4286070813.257..  Test Loss: 5473544192.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4278708487.314..  Test Loss: 5477651968.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4273908165.486..  Test Loss: 5690577920.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4324727672.686..  Test Loss: 6309926400.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4321276661.029..  Test Loss: 6938188288.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4350854242.743..  Test Loss: 5416487936.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4297772002.743..  Test Loss: 5369529856.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4337182325.029..  Test Loss: 5598745600.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 806/1000..  Training Loss: 4318010997.029..  Test Loss: 5739379712.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4327497216.000..  Test Loss: 5446070784.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4295375173.486..  Test Loss: 5334259200.000.. \n",
      "Epoch: 809/1000..  Training Loss: 4404195309.714..  Test Loss: 5684583936.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4355292145.371..  Test Loss: 5357946880.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4295285814.857..  Test Loss: 5496658944.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4310810752.000..  Test Loss: 6195332096.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4294758743.771..  Test Loss: 5979163136.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4311521221.486..  Test Loss: 5687832064.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4304114706.286..  Test Loss: 5524188672.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4333211794.286..  Test Loss: 5382673920.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4402895630.629..  Test Loss: 6558931456.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4290963050.057..  Test Loss: 5455096832.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4300137362.286..  Test Loss: 5604670976.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4380072974.629..  Test Loss: 5308483072.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4339301017.600..  Test Loss: 5383523328.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4325053271.771..  Test Loss: 6317497344.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4344327855.543..  Test Loss: 5362826240.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4317398988.800..  Test Loss: 5657734656.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4356472729.600..  Test Loss: 5707681280.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4330990014.171..  Test Loss: 5626513408.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4312430917.486..  Test Loss: 5269546496.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4350064435.200..  Test Loss: 5301590528.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4297340957.257..  Test Loss: 5332375040.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4295074186.971..  Test Loss: 6220623872.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4360559125.943..  Test Loss: 5279574528.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4335982131.200..  Test Loss: 5920457216.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4290027688.229..  Test Loss: 5779054080.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4311868869.486..  Test Loss: 5401776128.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4329652538.514..  Test Loss: 5342533120.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4327971788.800..  Test Loss: 5861996544.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4339261440.000..  Test Loss: 5258032640.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4310006403.657..  Test Loss: 5575684096.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4250067748.571..  Test Loss: 5468683264.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4300906905.600..  Test Loss: 5657243648.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4347844352.000..  Test Loss: 5873316352.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4323524651.886..  Test Loss: 5468567552.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4293758921.143..  Test Loss: 5314557440.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4362940708.571..  Test Loss: 5712053760.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4251776117.029..  Test Loss: 5666964992.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4283177380.571..  Test Loss: 5418131968.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4225637997.714..  Test Loss: 6250198528.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4277156915.200..  Test Loss: 5550980608.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4233823349.029..  Test Loss: 5562303488.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4308518773.029..  Test Loss: 5575519232.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4269190209.829..  Test Loss: 5282047488.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4276728122.514..  Test Loss: 5431534592.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4334356589.714..  Test Loss: 5844888064.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4304309167.543..  Test Loss: 6185975808.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4285404920.686..  Test Loss: 5302201856.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4294446028.800..  Test Loss: 5580174848.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4309946170.514..  Test Loss: 5507427840.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4347084873.143..  Test Loss: 6360020992.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4399418675.200..  Test Loss: 5660198912.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4301243121.371..  Test Loss: 5405571584.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4303405685.029..  Test Loss: 5341971968.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4273486058.057..  Test Loss: 5201514496.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4268545543.314..  Test Loss: 5472672256.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4278076416.000..  Test Loss: 5464249344.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4274092328.229..  Test Loss: 5613981184.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4310114373.486..  Test Loss: 5261817344.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4311670776.686..  Test Loss: 5784370176.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4320038875.429..  Test Loss: 5295584256.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4257406968.686..  Test Loss: 5550738944.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4260492990.171..  Test Loss: 5861493248.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4277613772.800..  Test Loss: 5189744128.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4289939163.429..  Test Loss: 5201396736.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4291898624.000..  Test Loss: 5318612480.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4304247859.200..  Test Loss: 5899119616.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4241343444.114..  Test Loss: 5474605056.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4302486001.371..  Test Loss: 5569432576.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4302970514.286..  Test Loss: 5701307904.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4222176885.029..  Test Loss: 5393286656.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4288110431.086..  Test Loss: 5899459584.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4287518690.743..  Test Loss: 5670737408.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4313459039.086..  Test Loss: 5366729728.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4218235768.686..  Test Loss: 5511996416.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4237646423.771..  Test Loss: 5449868288.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4271359312.457..  Test Loss: 6082819072.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4226575879.314..  Test Loss: 5198817792.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4310634207.086..  Test Loss: 5604978176.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4258570240.000..  Test Loss: 5292598272.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4264333652.114..  Test Loss: 5808832000.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4289228880.457..  Test Loss: 5414864384.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4260674837.943..  Test Loss: 5291981312.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4263736100.571..  Test Loss: 5166016000.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4283644942.629..  Test Loss: 5198963712.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4284398240.914..  Test Loss: 5658829312.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4277021520.457..  Test Loss: 5731732480.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4252229244.343..  Test Loss: 5630100992.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4292772944.457..  Test Loss: 5362011648.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4217790888.229..  Test Loss: 5440296448.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4222065327.543..  Test Loss: 5336698368.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4274609364.114..  Test Loss: 5237707264.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4255464330.971..  Test Loss: 5246617088.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4274036801.829..  Test Loss: 5222808576.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4335976565.029..  Test Loss: 5256092672.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4317867410.286..  Test Loss: 5423657472.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4261287910.400..  Test Loss: 5620709376.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4325391440.457..  Test Loss: 5203440640.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4284995832.686..  Test Loss: 5334056448.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4247611439.543..  Test Loss: 5672978432.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 908/1000..  Training Loss: 4290550275.657..  Test Loss: 5812303872.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4288680199.314..  Test Loss: 5848798720.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4249927475.200..  Test Loss: 5790326784.000.. \n",
      "Epoch: 911/1000..  Training Loss: 4282135606.857..  Test Loss: 5182215168.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4223788258.743..  Test Loss: 5294424064.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4286930556.343..  Test Loss: 5336260096.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4268160530.286..  Test Loss: 5533853184.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4250349158.400..  Test Loss: 5320288768.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4232843428.571..  Test Loss: 5822277120.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4304830815.086..  Test Loss: 5399414272.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4244091465.143..  Test Loss: 5367036928.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4289254999.771..  Test Loss: 5366156800.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4286665742.629..  Test Loss: 5163875840.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4212132790.857..  Test Loss: 5425141248.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4333227070.171..  Test Loss: 6258727424.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4277284458.057..  Test Loss: 6710175232.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4226854092.800..  Test Loss: 5330933248.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4261873188.571..  Test Loss: 5542368768.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4206325079.771..  Test Loss: 5323619840.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4210749608.229..  Test Loss: 5759586304.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4225964522.057..  Test Loss: 5569462784.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4274758729.143..  Test Loss: 5629363712.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4298429520.457..  Test Loss: 5187817472.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4248302504.229..  Test Loss: 5359093248.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4287657289.143..  Test Loss: 5391144448.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4265982968.686..  Test Loss: 5482861056.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4313194203.429..  Test Loss: 5279188992.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4277393415.314..  Test Loss: 5394288128.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4287707103.086..  Test Loss: 5431497728.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4308719275.886..  Test Loss: 5183114752.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4266329585.371..  Test Loss: 5310094336.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4344691807.086..  Test Loss: 5387730432.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4258717209.600..  Test Loss: 5725532672.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4246103968.914..  Test Loss: 5152314880.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4253368144.457..  Test Loss: 5267547648.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4229192777.143..  Test Loss: 5415426560.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4309782418.286..  Test Loss: 5506388992.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4295447829.943..  Test Loss: 5924843520.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4246153837.714..  Test Loss: 5636310528.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4262675649.829..  Test Loss: 5122078208.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4213016956.343..  Test Loss: 5963259904.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4213340584.229..  Test Loss: 5483942912.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4286645642.971..  Test Loss: 5151213056.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4306384969.143..  Test Loss: 5106436608.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4224883108.571..  Test Loss: 5233211904.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4182478972.343..  Test Loss: 5193881600.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4323268615.314..  Test Loss: 5162616320.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4218925783.771..  Test Loss: 5511113216.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4277504881.371..  Test Loss: 5261699584.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4278042455.771..  Test Loss: 5352029184.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4275621909.943..  Test Loss: 5166329344.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4228327325.257..  Test Loss: 5287926784.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4257237847.771..  Test Loss: 5396877312.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4308685578.971..  Test Loss: 5090516992.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4230863842.743..  Test Loss: 5961819648.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4186757683.200..  Test Loss: 5216090624.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4228275031.771..  Test Loss: 5229987328.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4257974915.657..  Test Loss: 5080370176.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4258463239.314..  Test Loss: 5201777664.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4205341674.057..  Test Loss: 6029855232.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4258059827.200..  Test Loss: 5114172416.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4284138554.514..  Test Loss: 5397552640.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4283995951.543..  Test Loss: 5096643584.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4251636842.057..  Test Loss: 5420861952.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4222775409.371..  Test Loss: 5077308928.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4221236677.486..  Test Loss: 6240171520.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4247067205.486..  Test Loss: 5175399936.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4263844871.314..  Test Loss: 5509586432.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4219308302.629..  Test Loss: 5392961024.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4271174955.886..  Test Loss: 5373543936.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4259952932.571..  Test Loss: 5729151488.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4278351125.943..  Test Loss: 5490423296.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4235681492.114..  Test Loss: 5168118272.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4274299684.571..  Test Loss: 5225502720.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4328410843.429..  Test Loss: 5394351616.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4245582357.943..  Test Loss: 5196001792.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4232380481.829..  Test Loss: 5532764672.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4262704501.029..  Test Loss: 5086420480.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4255066993.371..  Test Loss: 5128504320.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4206912036.571..  Test Loss: 5309802496.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4312651512.686..  Test Loss: 5343860224.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4277154340.571..  Test Loss: 5583740928.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4286571168.914..  Test Loss: 5840465408.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4261564489.143..  Test Loss: 5152647680.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4228586971.429..  Test Loss: 5109679616.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4235299858.286..  Test Loss: 5200729600.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4272421727.086..  Test Loss: 5129826816.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4259620703.086..  Test Loss: 5168346624.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4230437061.486..  Test Loss: 5426155520.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4241752897.829..  Test Loss: 6079492608.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4230398862.629..  Test Loss: 5225916416.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4235084229.486..  Test Loss: 5789160448.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4239486273.829..  Test Loss: 6966005248.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 3\n",
      "Epoch: 1/1000..  Training Loss: 13474236558.222..  Test Loss: 12749443072.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13461758364.444..  Test Loss: 12576148480.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13490737920.000..  Test Loss: 12648037376.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13451205134.222..  Test Loss: 12803761152.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13501619797.333..  Test Loss: 12936232960.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13493046869.333..  Test Loss: 12342072320.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13512708551.111..  Test Loss: 12681464832.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13489480476.444..  Test Loss: 12435846144.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13482106254.222..  Test Loss: 12453724160.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13469316821.333..  Test Loss: 12333373440.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13514596835.556..  Test Loss: 12570022912.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13504959488.000..  Test Loss: 12816616448.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13476425998.222..  Test Loss: 12698101760.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13455711516.444..  Test Loss: 12438387712.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13515088696.889..  Test Loss: 12719416320.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13478570567.111..  Test Loss: 12493804544.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13465326478.222..  Test Loss: 12384636928.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13503332864.000..  Test Loss: 12963162112.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13439626296.889..  Test Loss: 12357439488.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13450924885.333..  Test Loss: 12745296896.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13486581731.556..  Test Loss: 12290410496.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13451268124.444..  Test Loss: 12423596032.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13452456561.778..  Test Loss: 12980230144.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13474427662.222..  Test Loss: 12702680064.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13437093376.000..  Test Loss: 12272571392.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13459372288.000..  Test Loss: 12902097920.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13440266410.667..  Test Loss: 12737462272.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13471218432.000..  Test Loss: 12561422336.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13449148871.111..  Test Loss: 12457067520.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13450387968.000..  Test Loss: 12692882432.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13429097642.667..  Test Loss: 12573824000.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13434644679.111..  Test Loss: 12923855872.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13447688391.111..  Test Loss: 13103567872.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13406992512.000..  Test Loss: 12607488000.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13429037368.889..  Test Loss: 12566228992.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13435688120.889..  Test Loss: 13028247552.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13356229404.444..  Test Loss: 12985172992.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13424583822.222..  Test Loss: 13123817472.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13384785550.222..  Test Loss: 12601799680.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13396338702.222..  Test Loss: 12400116736.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13385311772.444..  Test Loss: 12767989760.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13405018453.333..  Test Loss: 12592368640.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13364268572.444..  Test Loss: 12689773568.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13375191751.111..  Test Loss: 12432569344.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13377696284.444..  Test Loss: 12250415104.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13352028842.667..  Test Loss: 12557427712.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13367061717.333..  Test Loss: 12710671360.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13335501240.889..  Test Loss: 12732753920.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13325663829.333..  Test Loss: 12605174784.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13331031068.444..  Test Loss: 12674256896.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13304727580.444..  Test Loss: 12245406720.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13339916942.222..  Test Loss: 12452635648.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13316870826.667..  Test Loss: 12821478400.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13308746040.889..  Test Loss: 12188875776.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13312610304.000..  Test Loss: 12611310592.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13318052010.667..  Test Loss: 12547070976.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13328716643.556..  Test Loss: 12554764288.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13272028359.111..  Test Loss: 12357536768.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13249790933.333..  Test Loss: 12693962752.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13279815281.778..  Test Loss: 12385650688.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13243136455.111..  Test Loss: 12738869248.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13238838243.556..  Test Loss: 12667548672.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13234616490.667..  Test Loss: 12493507584.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13239765376.000..  Test Loss: 12488991744.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13237038592.000..  Test Loss: 12150840320.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13239728440.889..  Test Loss: 12548252672.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13316017009.778..  Test Loss: 12288562176.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13220984234.667..  Test Loss: 12382189568.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13205806165.333..  Test Loss: 12495964160.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13150844643.556..  Test Loss: 12492409856.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13230175345.778..  Test Loss: 12382757888.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13210966343.111..  Test Loss: 12356260864.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13181909959.111..  Test Loss: 12780069888.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13226700003.556..  Test Loss: 12455982080.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13187539299.556..  Test Loss: 12478857216.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13187612160.000..  Test Loss: 12296844288.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13129701831.111..  Test Loss: 12571334656.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13174702122.667..  Test Loss: 12097452032.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13149916017.778..  Test Loss: 12256968704.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13138599296.000..  Test Loss: 12264739840.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13109065728.000..  Test Loss: 12096290816.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13180936874.667..  Test Loss: 12242673664.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13084327409.778..  Test Loss: 12032566272.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13088752384.000..  Test Loss: 12194193408.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13039657457.778..  Test Loss: 12704716800.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13081736888.889..  Test Loss: 12607254528.000.. \n",
      "Epoch: 87/1000..  Training Loss: 13071541518.222..  Test Loss: 12130079744.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13082903281.778..  Test Loss: 12300433408.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13045858474.667..  Test Loss: 12329689088.000.. \n",
      "Epoch: 90/1000..  Training Loss: 13037038250.667..  Test Loss: 12038894592.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13090107306.667..  Test Loss: 12301396992.000.. \n",
      "Epoch: 92/1000..  Training Loss: 13008476160.000..  Test Loss: 12540180480.000.. \n",
      "Epoch: 93/1000..  Training Loss: 12988311409.778..  Test Loss: 12664003584.000.. \n",
      "Epoch: 94/1000..  Training Loss: 12950860785.778..  Test Loss: 12669508608.000.. \n",
      "Epoch: 95/1000..  Training Loss: 13004997973.333..  Test Loss: 12157920256.000.. \n",
      "Epoch: 96/1000..  Training Loss: 12972551367.111..  Test Loss: 12069999616.000.. \n",
      "Epoch: 97/1000..  Training Loss: 12995911125.333..  Test Loss: 12237432832.000.. \n",
      "Epoch: 98/1000..  Training Loss: 12995633848.889..  Test Loss: 12493589504.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12980123008.000..  Test Loss: 12184289280.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12980449777.778..  Test Loss: 12298457088.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000..  Training Loss: 12958378439.111..  Test Loss: 12540239872.000.. \n",
      "Epoch: 102/1000..  Training Loss: 12959760711.111..  Test Loss: 12385366016.000.. \n",
      "Epoch: 103/1000..  Training Loss: 12934973212.444..  Test Loss: 12154688512.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12966868152.889..  Test Loss: 12297859072.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12924595854.222..  Test Loss: 12581202944.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12925008156.444..  Test Loss: 11948170240.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12913821354.667..  Test Loss: 12082413568.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12911682360.889..  Test Loss: 12273099776.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12847929998.222..  Test Loss: 12262392832.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12890552035.556..  Test Loss: 12164861952.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12846441614.222..  Test Loss: 11958327296.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12819071317.333..  Test Loss: 12159357952.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12827505308.444..  Test Loss: 12187784192.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12810741546.667..  Test Loss: 12203709440.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12818819925.333..  Test Loss: 11836574720.000.. \n",
      "Epoch: 116/1000..  Training Loss: 12778731832.889..  Test Loss: 12144014336.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12804189582.222..  Test Loss: 11955504128.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12799071104.000..  Test Loss: 12372620288.000.. \n",
      "Epoch: 119/1000..  Training Loss: 12742091818.667..  Test Loss: 11942548480.000.. \n",
      "Epoch: 120/1000..  Training Loss: 12750608412.444..  Test Loss: 11837861888.000.. \n",
      "Epoch: 121/1000..  Training Loss: 12712876984.889..  Test Loss: 12209083392.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12774623004.444..  Test Loss: 12523662336.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12712735559.111..  Test Loss: 11963962368.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12688909141.333..  Test Loss: 12026183680.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12718320583.111..  Test Loss: 12153375744.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12689536540.444..  Test Loss: 11785390080.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12683521152.000..  Test Loss: 12406223872.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12675472227.556..  Test Loss: 12230390784.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12650070428.444..  Test Loss: 11915688960.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12635923797.333..  Test Loss: 11780172800.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12612555747.556..  Test Loss: 11855512576.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12592858510.222..  Test Loss: 11921387520.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12608421546.667..  Test Loss: 12367287296.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12639259804.444..  Test Loss: 11987627008.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12582001607.111..  Test Loss: 11885681664.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12569225614.222..  Test Loss: 12175062016.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12593740145.778..  Test Loss: 12156851200.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12535265152.000..  Test Loss: 12614258688.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12494635192.889..  Test Loss: 11888817152.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12544953457.778..  Test Loss: 12306792448.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12552544839.111..  Test Loss: 11940917248.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12501138659.556..  Test Loss: 11775059968.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12483162766.222..  Test Loss: 11721700352.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12503255978.667..  Test Loss: 11814090752.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12483069809.778..  Test Loss: 11742808064.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12462532707.556..  Test Loss: 11859014656.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12446711580.444..  Test Loss: 12377166848.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12434556899.556..  Test Loss: 11946750976.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12395611093.333..  Test Loss: 11608437760.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12486046122.667..  Test Loss: 11626584064.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12407258851.556..  Test Loss: 11893404672.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12379411242.667..  Test Loss: 12071224320.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12324803996.444..  Test Loss: 11543380992.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12347611534.222..  Test Loss: 11733167104.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12324163982.222..  Test Loss: 11846420480.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12343106986.667..  Test Loss: 11703222272.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12286761045.333..  Test Loss: 11547001856.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12351341184.000..  Test Loss: 11549733888.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12335821155.556..  Test Loss: 11661192192.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12278547498.667..  Test Loss: 11472214016.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12399684664.889..  Test Loss: 11859985408.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12272125098.667..  Test Loss: 12157858816.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12222514759.111..  Test Loss: 11728623616.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12277708430.222..  Test Loss: 11746526208.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12223937080.889..  Test Loss: 11463653376.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12185924764.444..  Test Loss: 11841287168.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12199539740.444..  Test Loss: 11645260800.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12223266773.333..  Test Loss: 11406595072.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12163757226.667..  Test Loss: 11592321024.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12190988103.111..  Test Loss: 11397634048.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12186341546.667..  Test Loss: 11475841024.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12126658972.444..  Test Loss: 11366940672.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12121670371.556..  Test Loss: 11429966848.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12090572629.333..  Test Loss: 11505662976.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12089397575.111..  Test Loss: 11531932672.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12122473031.111..  Test Loss: 11419606016.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12129784433.778..  Test Loss: 11495408640.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12098945365.333..  Test Loss: 11944962048.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12093365632.000..  Test Loss: 11868259328.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12029414172.444..  Test Loss: 11582295040.000.. \n",
      "Epoch: 181/1000..  Training Loss: 12051940124.444..  Test Loss: 11528598528.000.. \n",
      "Epoch: 182/1000..  Training Loss: 11981801827.556..  Test Loss: 11374887936.000.. \n",
      "Epoch: 183/1000..  Training Loss: 11999488355.556..  Test Loss: 11762647040.000.. \n",
      "Epoch: 184/1000..  Training Loss: 12009590385.778..  Test Loss: 11510742016.000.. \n",
      "Epoch: 185/1000..  Training Loss: 11992902485.333..  Test Loss: 11551739904.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11924918528.000..  Test Loss: 11562846208.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11956386104.889..  Test Loss: 11368564736.000.. \n",
      "Epoch: 188/1000..  Training Loss: 11962999381.333..  Test Loss: 11089912832.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11878232092.444..  Test Loss: 11383882752.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11888323740.444..  Test Loss: 11677862912.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11897769301.333..  Test Loss: 10999421952.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11861151004.444..  Test Loss: 11250747392.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11826239971.556..  Test Loss: 11067414528.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11835967374.222..  Test Loss: 11248608256.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11836329230.222..  Test Loss: 11279719424.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11815339690.667..  Test Loss: 11039513600.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11783652124.444..  Test Loss: 11379580928.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11796957696.000..  Test Loss: 11107003392.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11796879217.778..  Test Loss: 11135899648.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200/1000..  Training Loss: 11765057706.667..  Test Loss: 11476280320.000.. \n",
      "Epoch: 201/1000..  Training Loss: 11706731861.333..  Test Loss: 10926009344.000.. \n",
      "Epoch: 202/1000..  Training Loss: 11756985528.889..  Test Loss: 11090468864.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11710278186.667..  Test Loss: 11554418688.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11732714581.333..  Test Loss: 11389022208.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11694591573.333..  Test Loss: 10967471104.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11714930503.111..  Test Loss: 10982431744.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11624705237.333..  Test Loss: 11528818688.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11643975466.667..  Test Loss: 11341197312.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11576981361.778..  Test Loss: 11058185216.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11600444615.111..  Test Loss: 10984858624.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11728995228.444..  Test Loss: 11103470592.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11613916828.444..  Test Loss: 10891771904.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11609775402.667..  Test Loss: 11043049472.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11554163029.333..  Test Loss: 10777171968.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11552604103.111..  Test Loss: 10924060672.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11541064291.556..  Test Loss: 11210349568.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11481129614.222..  Test Loss: 11159069696.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11543564757.333..  Test Loss: 10722470912.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11506446919.111..  Test Loss: 10708276224.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11443602304.000..  Test Loss: 10617916416.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11450434560.000..  Test Loss: 10937003008.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11481971086.222..  Test Loss: 11481523200.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11393254542.222..  Test Loss: 10852569088.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11387583004.444..  Test Loss: 10720652288.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11437432661.333..  Test Loss: 10971505664.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11404944056.889..  Test Loss: 11203919872.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11401889080.889..  Test Loss: 11024785408.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11309050453.333..  Test Loss: 10668791808.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11311095466.667..  Test Loss: 10681072640.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11355727857.778..  Test Loss: 10923190272.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11290767872.000..  Test Loss: 11092144128.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11312013781.333..  Test Loss: 10757283840.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11297691861.333..  Test Loss: 10654755840.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11278181418.667..  Test Loss: 10624049152.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11292301909.333..  Test Loss: 10915610624.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11224466560.000..  Test Loss: 10979074048.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11182184618.667..  Test Loss: 10978638848.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11179283726.222..  Test Loss: 10551329792.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11157968199.111..  Test Loss: 10587867136.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11147271879.111..  Test Loss: 10551626752.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11162286791.111..  Test Loss: 10966449152.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11295843299.556..  Test Loss: 10502262784.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11143141888.000..  Test Loss: 10668811264.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11097353287.111..  Test Loss: 10712050688.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11096671687.111..  Test Loss: 10880538624.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11057985038.222..  Test Loss: 11139456000.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11056620472.889..  Test Loss: 10981789696.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11047046058.667..  Test Loss: 10749071360.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11062878748.444..  Test Loss: 10466820096.000.. \n",
      "Epoch: 250/1000..  Training Loss: 10991043754.667..  Test Loss: 10549002240.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11008091320.889..  Test Loss: 10568905728.000.. \n",
      "Epoch: 252/1000..  Training Loss: 11005162865.778..  Test Loss: 10568369152.000.. \n",
      "Epoch: 253/1000..  Training Loss: 10920715107.556..  Test Loss: 10659820544.000.. \n",
      "Epoch: 254/1000..  Training Loss: 10943243050.667..  Test Loss: 10574035968.000.. \n",
      "Epoch: 255/1000..  Training Loss: 10940612750.222..  Test Loss: 10197611520.000.. \n",
      "Epoch: 256/1000..  Training Loss: 10912082460.444..  Test Loss: 10553972736.000.. \n",
      "Epoch: 257/1000..  Training Loss: 10921346929.778..  Test Loss: 10382290944.000.. \n",
      "Epoch: 258/1000..  Training Loss: 10858087267.556..  Test Loss: 10332017664.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10895570218.667..  Test Loss: 10447612928.000.. \n",
      "Epoch: 260/1000..  Training Loss: 10817702528.000..  Test Loss: 10438567936.000.. \n",
      "Epoch: 261/1000..  Training Loss: 10853256064.000..  Test Loss: 10790695936.000.. \n",
      "Epoch: 262/1000..  Training Loss: 10810353237.333..  Test Loss: 10702903296.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10808230570.667..  Test Loss: 10599618560.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10838498488.889..  Test Loss: 10147320832.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10845323434.667..  Test Loss: 10395909120.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10785179505.778..  Test Loss: 10193274880.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10754961976.889..  Test Loss: 10762917888.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10702022186.667..  Test Loss: 10336119808.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10763286129.778..  Test Loss: 10050675712.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10742359409.778..  Test Loss: 10548483072.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10644454428.444..  Test Loss: 10065421312.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10635147904.000..  Test Loss: 10420790272.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10610041429.333..  Test Loss: 10038913024.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10628446264.889..  Test Loss: 10055914496.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10662466560.000..  Test Loss: 10038017024.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10615943708.444..  Test Loss: 10396989440.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10559245511.111..  Test Loss: 10331820032.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10525069269.333..  Test Loss: 10084590592.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10567373952.000..  Test Loss: 10308605952.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10558063644.444..  Test Loss: 10783204352.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10495051648.000..  Test Loss: 10440215552.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10505485681.778..  Test Loss: 10204473344.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10505718144.000..  Test Loss: 10186522624.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10501670798.222..  Test Loss: 9786949632.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10433032177.778..  Test Loss: 10370631680.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10441054222.222..  Test Loss: 10083210240.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10405974613.333..  Test Loss: 9977279488.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10393219342.222..  Test Loss: 9788625920.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10391595576.889..  Test Loss: 9846891520.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10342813496.889..  Test Loss: 10231992320.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10382293845.333..  Test Loss: 10233186304.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10349817528.889..  Test Loss: 9829129216.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10382948252.444..  Test Loss: 9905101824.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10347507214.222..  Test Loss: 9970380800.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10301866666.667..  Test Loss: 9792929792.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10257344099.556..  Test Loss: 9699696640.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10228347121.778..  Test Loss: 10247002112.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10330547356.444..  Test Loss: 10271130624.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299/1000..  Training Loss: 10255199744.000..  Test Loss: 9745847296.000.. \n",
      "Epoch: 300/1000..  Training Loss: 10212353934.222..  Test Loss: 9976702976.000.. \n",
      "Epoch: 301/1000..  Training Loss: 10219104782.222..  Test Loss: 9681209344.000.. \n",
      "Epoch: 302/1000..  Training Loss: 10249066168.889..  Test Loss: 9986415616.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10196209777.778..  Test Loss: 9923682304.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10154553628.444..  Test Loss: 9746173952.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10121774080.000..  Test Loss: 9789445120.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10137733404.444..  Test Loss: 10258053120.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10088968263.111..  Test Loss: 9950899200.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10142641856.000..  Test Loss: 10200817664.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10143140565.333..  Test Loss: 9592348672.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10060768995.556..  Test Loss: 10062648320.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10073173489.778..  Test Loss: 9660199936.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10060998257.778..  Test Loss: 9684445184.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10005343857.778..  Test Loss: 9995701248.000.. \n",
      "Epoch: 314/1000..  Training Loss: 9962211754.667..  Test Loss: 9576268800.000.. \n",
      "Epoch: 315/1000..  Training Loss: 10024729386.667..  Test Loss: 9457721344.000.. \n",
      "Epoch: 316/1000..  Training Loss: 9975276629.333..  Test Loss: 10181224448.000.. \n",
      "Epoch: 317/1000..  Training Loss: 9920510364.444..  Test Loss: 9788755968.000.. \n",
      "Epoch: 318/1000..  Training Loss: 9991142656.000..  Test Loss: 9884550144.000.. \n",
      "Epoch: 319/1000..  Training Loss: 9953448519.111..  Test Loss: 9451125760.000.. \n",
      "Epoch: 320/1000..  Training Loss: 9876631822.222..  Test Loss: 9700111360.000.. \n",
      "Epoch: 321/1000..  Training Loss: 9855378375.111..  Test Loss: 9328842752.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9857102606.222..  Test Loss: 9506564096.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9843818453.333..  Test Loss: 9673137152.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9796459591.111..  Test Loss: 10148168704.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9799439985.778..  Test Loss: 9410927616.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9892687360.000..  Test Loss: 9921229824.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9766851214.222..  Test Loss: 9711514624.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9749683157.333..  Test Loss: 9895196672.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9764950087.111..  Test Loss: 9826979840.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9690540956.444..  Test Loss: 9428962304.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9699764437.333..  Test Loss: 10054079488.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9650320227.556..  Test Loss: 9631793152.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9647813475.556..  Test Loss: 9512457216.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9620632049.778..  Test Loss: 9746989056.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9573955882.667..  Test Loss: 9470067712.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9605874304.000..  Test Loss: 9711929344.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9535516316.444..  Test Loss: 9266234368.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9556503907.556..  Test Loss: 9428000768.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9536452195.556..  Test Loss: 9165912064.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9510485162.667..  Test Loss: 9801975808.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9602589070.222..  Test Loss: 9591436288.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9527327374.222..  Test Loss: 9281540096.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9523074730.667..  Test Loss: 9590436864.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9450779192.889..  Test Loss: 9731202048.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9566747562.667..  Test Loss: 9190519808.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9461873678.222..  Test Loss: 9074418688.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9453199104.000..  Test Loss: 9636203520.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9415497130.667..  Test Loss: 8951110656.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9397620664.889..  Test Loss: 9087291392.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9411214563.556..  Test Loss: 9078322176.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9418962986.667..  Test Loss: 9093268480.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9390472704.000..  Test Loss: 8930631680.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9307633664.000..  Test Loss: 9700455424.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9355031495.111..  Test Loss: 9219080192.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9323944832.000..  Test Loss: 9139664896.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9272498332.444..  Test Loss: 9081523200.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9292377941.333..  Test Loss: 9217790976.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9273466154.667..  Test Loss: 9075445760.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9247327985.778..  Test Loss: 9072964608.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9217894784.000..  Test Loss: 9413790720.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9164545351.111..  Test Loss: 9101032448.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9214597020.444..  Test Loss: 9261155328.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9208004081.778..  Test Loss: 8947560448.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9153300849.778..  Test Loss: 8808197120.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9095657528.889..  Test Loss: 8839226368.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9090608597.333..  Test Loss: 9073037312.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9072284359.111..  Test Loss: 8875251712.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9059848206.222..  Test Loss: 8968455168.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9076162730.667..  Test Loss: 8782005248.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9062659313.778..  Test Loss: 8692574208.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9081842154.667..  Test Loss: 9121009664.000.. \n",
      "Epoch: 372/1000..  Training Loss: 8998507264.000..  Test Loss: 8905127936.000.. \n",
      "Epoch: 373/1000..  Training Loss: 8963008497.778..  Test Loss: 8687238144.000.. \n",
      "Epoch: 374/1000..  Training Loss: 9027532529.778..  Test Loss: 9184911360.000.. \n",
      "Epoch: 375/1000..  Training Loss: 8899050012.444..  Test Loss: 9249453056.000.. \n",
      "Epoch: 376/1000..  Training Loss: 8949710364.444..  Test Loss: 8867728384.000.. \n",
      "Epoch: 377/1000..  Training Loss: 8979079566.222..  Test Loss: 9344106496.000.. \n",
      "Epoch: 378/1000..  Training Loss: 8927240604.444..  Test Loss: 8878602240.000.. \n",
      "Epoch: 379/1000..  Training Loss: 8839339797.333..  Test Loss: 8699850752.000.. \n",
      "Epoch: 380/1000..  Training Loss: 8896999452.444..  Test Loss: 8775607296.000.. \n",
      "Epoch: 381/1000..  Training Loss: 8824023665.778..  Test Loss: 8577086976.000.. \n",
      "Epoch: 382/1000..  Training Loss: 8906200064.000..  Test Loss: 8589530624.000.. \n",
      "Epoch: 383/1000..  Training Loss: 8895201920.000..  Test Loss: 8550084096.000.. \n",
      "Epoch: 384/1000..  Training Loss: 8799043200.000..  Test Loss: 8570460672.000.. \n",
      "Epoch: 385/1000..  Training Loss: 8845952433.778..  Test Loss: 8959996928.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8828558279.111..  Test Loss: 9002021888.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8753330574.222..  Test Loss: 8537169920.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8759922830.222..  Test Loss: 8454503424.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8758973952.000..  Test Loss: 8702024704.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8710588160.000..  Test Loss: 8336076288.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8619559793.778..  Test Loss: 8593724416.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8718799274.667..  Test Loss: 8756150272.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8669495509.333..  Test Loss: 8490614784.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8674040689.778..  Test Loss: 8644185088.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8617453752.889..  Test Loss: 8975976448.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8678605838.222..  Test Loss: 8250951680.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8581822321.778..  Test Loss: 8666774528.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8589918798.222..  Test Loss: 8428923392.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8563619456.000..  Test Loss: 8416454656.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8545320775.111..  Test Loss: 8262321152.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 401/1000..  Training Loss: 8545595548.444..  Test Loss: 8353572864.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8582400312.889..  Test Loss: 8740480000.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8475150378.667..  Test Loss: 8760544256.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8437008014.222..  Test Loss: 8421498880.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8527381162.667..  Test Loss: 8629873664.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8353062428.444..  Test Loss: 8266590208.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8420456448.000..  Test Loss: 8432124928.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8461257443.556..  Test Loss: 8391659008.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8386831957.333..  Test Loss: 8319196160.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8320698965.333..  Test Loss: 8138029568.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8329546638.222..  Test Loss: 8431124480.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8355854968.889..  Test Loss: 8178342912.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8316128668.444..  Test Loss: 7892724224.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8306987235.556..  Test Loss: 8186456576.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8249446343.111..  Test Loss: 8202573312.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8306012245.333..  Test Loss: 7820923392.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8263961400.889..  Test Loss: 8784607232.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8267040455.111..  Test Loss: 7910910464.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8188942762.667..  Test Loss: 8400264192.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8211585180.444..  Test Loss: 8252642816.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8176451072.000..  Test Loss: 7962767872.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8181280867.556..  Test Loss: 8065004032.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8102642958.222..  Test Loss: 7871035904.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8144412878.222..  Test Loss: 8108198400.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8177041976.889..  Test Loss: 7909933056.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8159785479.111..  Test Loss: 7968586752.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8072807559.111..  Test Loss: 8170349568.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8043475840.000..  Test Loss: 7798327808.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8093220807.111..  Test Loss: 7762885632.000.. \n",
      "Epoch: 430/1000..  Training Loss: 7994998698.667..  Test Loss: 7691142144.000.. \n",
      "Epoch: 431/1000..  Training Loss: 7983645056.000..  Test Loss: 7724176896.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8030027918.222..  Test Loss: 8382403072.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8013217991.111..  Test Loss: 8060152320.000.. \n",
      "Epoch: 434/1000..  Training Loss: 7955546951.111..  Test Loss: 7935988224.000.. \n",
      "Epoch: 435/1000..  Training Loss: 8013234019.556..  Test Loss: 7604999680.000.. \n",
      "Epoch: 436/1000..  Training Loss: 7992935978.667..  Test Loss: 7922623488.000.. \n",
      "Epoch: 437/1000..  Training Loss: 7925855374.222..  Test Loss: 7855079424.000.. \n",
      "Epoch: 438/1000..  Training Loss: 7838568433.778..  Test Loss: 7865506304.000.. \n",
      "Epoch: 439/1000..  Training Loss: 7927311281.778..  Test Loss: 7575475200.000.. \n",
      "Epoch: 440/1000..  Training Loss: 7773860551.111..  Test Loss: 7845443072.000.. \n",
      "Epoch: 441/1000..  Training Loss: 7870077624.889..  Test Loss: 7607875072.000.. \n",
      "Epoch: 442/1000..  Training Loss: 7834991985.778..  Test Loss: 8063211008.000.. \n",
      "Epoch: 443/1000..  Training Loss: 7838207360.000..  Test Loss: 7671142912.000.. \n",
      "Epoch: 444/1000..  Training Loss: 7801928291.556..  Test Loss: 7582931456.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7796696796.444..  Test Loss: 7676435456.000.. \n",
      "Epoch: 446/1000..  Training Loss: 7778454428.444..  Test Loss: 7456037376.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7823347683.556..  Test Loss: 7859075584.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7715971520.000..  Test Loss: 7655980032.000.. \n",
      "Epoch: 449/1000..  Training Loss: 7717661020.444..  Test Loss: 7549474816.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7726690389.333..  Test Loss: 8054773248.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7694758784.000..  Test Loss: 7543751680.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7676703921.778..  Test Loss: 7699671040.000.. \n",
      "Epoch: 453/1000..  Training Loss: 7669074759.111..  Test Loss: 7372472832.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7636510592.000..  Test Loss: 7309463552.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7622078037.333..  Test Loss: 7431054336.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7623574840.889..  Test Loss: 7920559104.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7604381134.222..  Test Loss: 7251707904.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7570471872.000..  Test Loss: 7531355136.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7588861767.111..  Test Loss: 7368069632.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7576075093.333..  Test Loss: 7544670720.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7542545848.889..  Test Loss: 7592230912.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7593694072.889..  Test Loss: 7224988672.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7549686862.222..  Test Loss: 7581587968.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7523011925.333..  Test Loss: 7580094464.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7450249386.667..  Test Loss: 7506004992.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7474620124.444..  Test Loss: 7167862784.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7452397020.444..  Test Loss: 7242347008.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7438238833.778..  Test Loss: 7266226176.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7495882417.778..  Test Loss: 7139245056.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7432106346.667..  Test Loss: 7286637056.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7355038869.333..  Test Loss: 7121448960.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7328042652.444..  Test Loss: 7030616576.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7290487537.778..  Test Loss: 6917338112.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7342049265.778..  Test Loss: 7644355584.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7328685361.778..  Test Loss: 7230179328.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7310532024.889..  Test Loss: 7289096704.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7230466481.778..  Test Loss: 7302675456.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7258159950.222..  Test Loss: 7108298752.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7282282261.333..  Test Loss: 6943621120.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7259504981.333..  Test Loss: 7135664128.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7166721187.556..  Test Loss: 7295155712.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7197441962.667..  Test Loss: 6943562240.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7226490289.778..  Test Loss: 7150018048.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7198002325.333..  Test Loss: 6764128768.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7187420394.667..  Test Loss: 7028057600.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7197664320.000..  Test Loss: 6915608576.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7193016362.667..  Test Loss: 7212513792.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7107643335.111..  Test Loss: 7089735680.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7151081884.444..  Test Loss: 7202449408.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7145501333.333..  Test Loss: 6681125888.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7111792512.000..  Test Loss: 6864239616.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7040256455.111..  Test Loss: 7005396992.000.. \n",
      "Epoch: 493/1000..  Training Loss: 7123243015.111..  Test Loss: 6656729600.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7074135566.222..  Test Loss: 6889972736.000.. \n",
      "Epoch: 495/1000..  Training Loss: 6970666424.889..  Test Loss: 6917982208.000.. \n",
      "Epoch: 496/1000..  Training Loss: 7030532394.667..  Test Loss: 6684941824.000.. \n",
      "Epoch: 497/1000..  Training Loss: 6987474346.667..  Test Loss: 7372931072.000.. \n",
      "Epoch: 498/1000..  Training Loss: 7048643569.778..  Test Loss: 6912818176.000.. \n",
      "Epoch: 499/1000..  Training Loss: 6997088177.778..  Test Loss: 6963621888.000.. \n",
      "Epoch: 500/1000..  Training Loss: 7066202979.556..  Test Loss: 6654476800.000.. \n",
      "Epoch: 501/1000..  Training Loss: 7041009251.556..  Test Loss: 6822632960.000.. \n",
      "Epoch: 502/1000..  Training Loss: 6955444010.667..  Test Loss: 6545867264.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 503/1000..  Training Loss: 6952567765.333..  Test Loss: 6695567872.000.. \n",
      "Epoch: 504/1000..  Training Loss: 6876001464.889..  Test Loss: 6733502464.000.. \n",
      "Epoch: 505/1000..  Training Loss: 6950455722.667..  Test Loss: 6718778880.000.. \n",
      "Epoch: 506/1000..  Training Loss: 6896890865.778..  Test Loss: 6366206464.000.. \n",
      "Epoch: 507/1000..  Training Loss: 6844092394.667..  Test Loss: 6444832256.000.. \n",
      "Epoch: 508/1000..  Training Loss: 6868726762.667..  Test Loss: 6797456896.000.. \n",
      "Epoch: 509/1000..  Training Loss: 6854897237.333..  Test Loss: 6336975360.000.. \n",
      "Epoch: 510/1000..  Training Loss: 6837802702.222..  Test Loss: 6894209536.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6814603335.111..  Test Loss: 6674995712.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6773339207.111..  Test Loss: 6355752960.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6789470755.556..  Test Loss: 6712480256.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6797392270.222..  Test Loss: 6556295168.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6696714673.778..  Test Loss: 6592858112.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6685115320.889..  Test Loss: 6521603072.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6682044551.111..  Test Loss: 6244864512.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6709838869.333..  Test Loss: 6384678912.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6714754467.556..  Test Loss: 6321982464.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6755629696.000..  Test Loss: 6416767488.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6679748259.556..  Test Loss: 6490307072.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6688739470.222..  Test Loss: 6287166976.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6636655018.667..  Test Loss: 6512589824.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6665086513.778..  Test Loss: 6395274240.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6550042808.889..  Test Loss: 6123283968.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6575843235.556..  Test Loss: 6409159168.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6584491427.556..  Test Loss: 6363011584.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6585560064.000..  Test Loss: 6172877312.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6605872277.333..  Test Loss: 6129790976.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6491218140.444..  Test Loss: 6241048064.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6541719274.667..  Test Loss: 6174917632.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6504369635.556..  Test Loss: 6519698944.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6546512128.000..  Test Loss: 6306292736.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6445873400.889..  Test Loss: 6487239680.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6500347477.333..  Test Loss: 6195671552.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6528424768.000..  Test Loss: 6727827456.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6440975516.444..  Test Loss: 6114499072.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6523792618.667..  Test Loss: 6138962432.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6445700216.889..  Test Loss: 6121932800.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6395887267.556..  Test Loss: 6077354496.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6388607018.667..  Test Loss: 6185529856.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6457071879.111..  Test Loss: 6029696000.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6398604643.556..  Test Loss: 5863076864.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6386563029.333..  Test Loss: 6136629760.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6383192241.778..  Test Loss: 6289680896.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6347658368.000..  Test Loss: 6272926720.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6453443374.222..  Test Loss: 6399769088.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6353922346.667..  Test Loss: 5974949888.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6278210460.444..  Test Loss: 5918784000.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6360982720.000..  Test Loss: 6345719808.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6245431765.333..  Test Loss: 5772366336.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6285460728.889..  Test Loss: 5704064512.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6198093447.111..  Test Loss: 6049289728.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6191259306.667..  Test Loss: 6148701184.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6315333532.444..  Test Loss: 5868280832.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6152051818.667..  Test Loss: 5936291328.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6248992625.778..  Test Loss: 5901464064.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6201136924.444..  Test Loss: 5924600320.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6139846264.889..  Test Loss: 5695287808.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6134590158.222..  Test Loss: 5902231040.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6204412849.778..  Test Loss: 5987297280.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6100921287.111..  Test Loss: 5882507776.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6110038798.222..  Test Loss: 5539032576.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6051831623.111..  Test Loss: 6058199552.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6030065550.222..  Test Loss: 5818620928.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6024546801.778..  Test Loss: 5660649984.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6092792021.333..  Test Loss: 5812098048.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6103813489.778..  Test Loss: 5803119104.000.. \n",
      "Epoch: 569/1000..  Training Loss: 6025999665.778..  Test Loss: 5483309056.000.. \n",
      "Epoch: 570/1000..  Training Loss: 6046585784.889..  Test Loss: 5575266304.000.. \n",
      "Epoch: 571/1000..  Training Loss: 5974922417.778..  Test Loss: 5952697856.000.. \n",
      "Epoch: 572/1000..  Training Loss: 6003457180.444..  Test Loss: 5881648128.000.. \n",
      "Epoch: 573/1000..  Training Loss: 6029458133.333..  Test Loss: 5694944256.000.. \n",
      "Epoch: 574/1000..  Training Loss: 5987808021.333..  Test Loss: 5601988608.000.. \n",
      "Epoch: 575/1000..  Training Loss: 6031518051.556..  Test Loss: 5548350464.000.. \n",
      "Epoch: 576/1000..  Training Loss: 5961594922.667..  Test Loss: 5580795392.000.. \n",
      "Epoch: 577/1000..  Training Loss: 6000789002.667..  Test Loss: 5776736256.000.. \n",
      "Epoch: 578/1000..  Training Loss: 5957730140.444..  Test Loss: 5423097856.000.. \n",
      "Epoch: 579/1000..  Training Loss: 5910600078.222..  Test Loss: 5686774272.000.. \n",
      "Epoch: 580/1000..  Training Loss: 6015100231.111..  Test Loss: 5803010560.000.. \n",
      "Epoch: 581/1000..  Training Loss: 5937844664.889..  Test Loss: 5584553472.000.. \n",
      "Epoch: 582/1000..  Training Loss: 5952534442.667..  Test Loss: 5538974208.000.. \n",
      "Epoch: 583/1000..  Training Loss: 5954673856.000..  Test Loss: 5553138176.000.. \n",
      "Epoch: 584/1000..  Training Loss: 5848328860.444..  Test Loss: 5559366144.000.. \n",
      "Epoch: 585/1000..  Training Loss: 5912879864.889..  Test Loss: 5637016064.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5797594979.556..  Test Loss: 5568640512.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5835754076.444..  Test Loss: 5369705984.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5810695374.222..  Test Loss: 5359170560.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5841347676.444..  Test Loss: 5517010432.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5808724266.667..  Test Loss: 5499717120.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5847071452.444..  Test Loss: 5571885056.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5782818816.000..  Test Loss: 5290564608.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5857718464.000..  Test Loss: 5557705216.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5760381710.222..  Test Loss: 5379897344.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5765391303.111..  Test Loss: 5821114368.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5754793258.667..  Test Loss: 5405611520.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5745893688.889..  Test Loss: 5289927680.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5739563498.667..  Test Loss: 5182401536.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5739846378.667..  Test Loss: 5114217472.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5711982584.889..  Test Loss: 5693385216.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5779027776.000..  Test Loss: 5372871680.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5745719644.444..  Test Loss: 5358373376.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5697845333.333..  Test Loss: 5335205376.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5806038840.889..  Test Loss: 5139022848.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 605/1000..  Training Loss: 5719470705.778..  Test Loss: 5363268096.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5608994837.333..  Test Loss: 5260093952.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5657354325.333..  Test Loss: 5200385024.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5614946510.222..  Test Loss: 5219707904.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5581970517.333..  Test Loss: 5136419328.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5673568490.667..  Test Loss: 5062410752.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5561777457.778..  Test Loss: 5012302336.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5661793479.111..  Test Loss: 4979162624.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5618434229.333..  Test Loss: 5144832000.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5563588657.778..  Test Loss: 5186964992.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5567139214.222..  Test Loss: 5125020160.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5551895843.556..  Test Loss: 5118169088.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5576688106.667..  Test Loss: 5398803968.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5555002709.333..  Test Loss: 5085597184.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5552436259.556..  Test Loss: 5166758400.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5510644721.778..  Test Loss: 4832277504.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5514942961.778..  Test Loss: 4917873152.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5521149440.000..  Test Loss: 4917221888.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5471093319.111..  Test Loss: 5389884928.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5435623189.333..  Test Loss: 4948816896.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5504462876.444..  Test Loss: 4909782016.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5515750364.444..  Test Loss: 4854005760.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5437929621.333..  Test Loss: 5346568192.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5496242602.667..  Test Loss: 5420728320.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5373824849.778..  Test Loss: 4758217216.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5426500885.333..  Test Loss: 5000931840.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5454944817.778..  Test Loss: 4891311616.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5445430919.111..  Test Loss: 4723350016.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5466180088.889..  Test Loss: 4884039168.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5384454556.444..  Test Loss: 5403931136.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5407701169.778..  Test Loss: 4919880704.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5432400426.667..  Test Loss: 4599481344.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5468302755.556..  Test Loss: 4667600384.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5359136903.111..  Test Loss: 4783599104.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5331252821.333..  Test Loss: 5087290368.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5371665799.111..  Test Loss: 4793729536.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5322891320.889..  Test Loss: 4723063808.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5409893802.667..  Test Loss: 5055134208.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5355358023.111..  Test Loss: 4773507072.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5385739064.889..  Test Loss: 4517681664.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5389430243.556..  Test Loss: 4866955776.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5327458755.556..  Test Loss: 4598569472.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5276323989.333..  Test Loss: 4610241024.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5317245155.556..  Test Loss: 4702982144.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5260274688.000..  Test Loss: 4652664320.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5250778808.889..  Test Loss: 4571773952.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5271317973.333..  Test Loss: 5193203712.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5349970439.111..  Test Loss: 4751132160.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5332438819.556..  Test Loss: 4684786688.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5262479221.333..  Test Loss: 4655264256.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5249975054.222..  Test Loss: 4867910656.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5339324017.778..  Test Loss: 4989196800.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5290443214.222..  Test Loss: 4760959488.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5269135040.000..  Test Loss: 4758497792.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5287870432.000..  Test Loss: 4575451648.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5274598229.333..  Test Loss: 4639472128.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5236257536.000..  Test Loss: 4498123264.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5196160874.667..  Test Loss: 4670461952.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5247792568.889..  Test Loss: 4612039168.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5203565482.667..  Test Loss: 4583234048.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5180244138.667..  Test Loss: 4586530304.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5246891975.111..  Test Loss: 4931743744.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5112429240.889..  Test Loss: 4543624704.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5139622720.000..  Test Loss: 5225445376.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5194910030.222..  Test Loss: 4889297920.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5126430684.444..  Test Loss: 4730998272.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5164099573.333..  Test Loss: 4688411136.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5181462492.444..  Test Loss: 4372142592.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5230009635.556..  Test Loss: 4488483840.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5132371050.667..  Test Loss: 4510318592.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5167225742.222..  Test Loss: 4365024768.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5133891306.667..  Test Loss: 4441449984.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5122522524.444..  Test Loss: 4439577600.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5142012693.333..  Test Loss: 4295620608.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5089548899.556..  Test Loss: 4498996224.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5113213468.444..  Test Loss: 4556469760.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5151504896.000..  Test Loss: 4670259712.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5103021457.778..  Test Loss: 4448637440.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5087501262.222..  Test Loss: 4371268608.000.. \n",
      "Epoch: 684/1000..  Training Loss: 5050737386.667..  Test Loss: 4373231616.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5100297326.222..  Test Loss: 4602359808.000.. \n",
      "Epoch: 686/1000..  Training Loss: 5115390165.333..  Test Loss: 4221179648.000.. \n",
      "Epoch: 687/1000..  Training Loss: 5153494563.556..  Test Loss: 4260116224.000.. \n",
      "Epoch: 688/1000..  Training Loss: 5068735864.889..  Test Loss: 4269232128.000.. \n",
      "Epoch: 689/1000..  Training Loss: 5096898901.333..  Test Loss: 4679568384.000.. \n",
      "Epoch: 690/1000..  Training Loss: 5035326446.222..  Test Loss: 4178073856.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5164258880.000..  Test Loss: 4076055296.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5098028576.000..  Test Loss: 4168720384.000.. \n",
      "Epoch: 693/1000..  Training Loss: 5049243704.889..  Test Loss: 4290081280.000.. \n",
      "Epoch: 694/1000..  Training Loss: 5044200938.667..  Test Loss: 4225491456.000.. \n",
      "Epoch: 695/1000..  Training Loss: 5132701205.333..  Test Loss: 4112102656.000.. \n",
      "Epoch: 696/1000..  Training Loss: 4984301916.444..  Test Loss: 4150277120.000.. \n",
      "Epoch: 697/1000..  Training Loss: 5047272028.444..  Test Loss: 4255008000.000.. \n",
      "Epoch: 698/1000..  Training Loss: 4997739847.111..  Test Loss: 4210224640.000.. \n",
      "Epoch: 699/1000..  Training Loss: 4957450929.778..  Test Loss: 4000718080.000.. \n",
      "Epoch: 700/1000..  Training Loss: 5058221176.889..  Test Loss: 4295741952.000.. \n",
      "Epoch: 701/1000..  Training Loss: 5018835836.444..  Test Loss: 4415533056.000.. \n",
      "Epoch: 702/1000..  Training Loss: 5057124131.556..  Test Loss: 4174534400.000.. \n",
      "Epoch: 703/1000..  Training Loss: 5058324679.111..  Test Loss: 4248883200.000.. \n",
      "Epoch: 704/1000..  Training Loss: 5010626062.222..  Test Loss: 4046256896.000.. \n",
      "Epoch: 705/1000..  Training Loss: 4991712284.444..  Test Loss: 4060316928.000.. \n",
      "Epoch: 706/1000..  Training Loss: 5064524352.000..  Test Loss: 4112637952.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 707/1000..  Training Loss: 5033899456.000..  Test Loss: 4090653952.000.. \n",
      "Epoch: 708/1000..  Training Loss: 4959220942.222..  Test Loss: 4249375232.000.. \n",
      "Epoch: 709/1000..  Training Loss: 4963388295.111..  Test Loss: 4203869184.000.. \n",
      "Epoch: 710/1000..  Training Loss: 5041601386.667..  Test Loss: 4064660736.000.. \n",
      "Epoch: 711/1000..  Training Loss: 4920237219.556..  Test Loss: 4127341824.000.. \n",
      "Epoch: 712/1000..  Training Loss: 4925485137.778..  Test Loss: 4213781760.000.. \n",
      "Epoch: 713/1000..  Training Loss: 4984613845.333..  Test Loss: 3960044800.000.. \n",
      "Epoch: 714/1000..  Training Loss: 5001908039.111..  Test Loss: 3980054016.000.. \n",
      "Epoch: 715/1000..  Training Loss: 4996687139.556..  Test Loss: 4044399616.000.. \n",
      "Epoch: 716/1000..  Training Loss: 4936159424.000..  Test Loss: 4141122560.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4954689457.778..  Test Loss: 4187817216.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4930156280.889..  Test Loss: 4000888576.000.. \n",
      "Epoch: 719/1000..  Training Loss: 4998799900.444..  Test Loss: 4009288192.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4945275441.778..  Test Loss: 3915776000.000.. \n",
      "Epoch: 721/1000..  Training Loss: 4967847889.778..  Test Loss: 4166626048.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4899614890.667..  Test Loss: 4003364864.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4960046705.778..  Test Loss: 4017394176.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4928471992.889..  Test Loss: 3917719296.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4936285006.222..  Test Loss: 4009842432.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4930488899.556..  Test Loss: 4143596544.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4987384490.667..  Test Loss: 3937650432.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4945954428.444..  Test Loss: 4113935104.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4914933646.222..  Test Loss: 3969699840.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4983993863.111..  Test Loss: 3907979520.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4905937208.889..  Test Loss: 3986268160.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4910148657.778..  Test Loss: 4051990272.000.. \n",
      "Epoch: 733/1000..  Training Loss: 4889769080.889..  Test Loss: 4042596864.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4973896284.444..  Test Loss: 4158356736.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4884634069.333..  Test Loss: 4163532544.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4984367363.556..  Test Loss: 3793524224.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4945128583.111..  Test Loss: 3876702976.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4938530481.778..  Test Loss: 3858018816.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4895411896.889..  Test Loss: 3819735296.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4878604590.222..  Test Loss: 3840094208.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4841511310.222..  Test Loss: 3925906432.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4881163491.556..  Test Loss: 3793642496.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4935875317.333..  Test Loss: 3736651008.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4905910200.889..  Test Loss: 4058616320.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4933890382.222..  Test Loss: 3965304320.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4890684963.556..  Test Loss: 4078085888.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4880186048.000..  Test Loss: 3864462336.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4867926520.889..  Test Loss: 3759838720.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4935113212.444..  Test Loss: 3753955584.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4947216746.667..  Test Loss: 3731467520.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4896003680.000..  Test Loss: 3765703936.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4866347328.000..  Test Loss: 3944672768.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4924168405.333..  Test Loss: 3703846912.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4900221617.778..  Test Loss: 3964186112.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4981949504.000..  Test Loss: 3959913984.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4866409095.111..  Test Loss: 3999440384.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4881061859.556..  Test Loss: 3842623232.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4917632014.222..  Test Loss: 3883181056.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4928957475.556..  Test Loss: 3891980032.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4820171847.111..  Test Loss: 3800818176.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4887673301.333..  Test Loss: 4045275648.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4865195939.556..  Test Loss: 3617549056.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4881983950.222..  Test Loss: 3849403648.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4938369066.667..  Test Loss: 3691188224.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4816021589.333..  Test Loss: 3665001728.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4915073297.778..  Test Loss: 3662909184.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4964816263.111..  Test Loss: 3876183552.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4824290659.556..  Test Loss: 3954271488.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4850410609.778..  Test Loss: 3756694272.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4813155463.111..  Test Loss: 3677908224.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4875865827.556..  Test Loss: 3661733120.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4876531427.556..  Test Loss: 3580205056.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4858420764.444..  Test Loss: 3828784384.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4808884224.000..  Test Loss: 3694117632.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4822809344.000..  Test Loss: 3672761344.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4767504725.333..  Test Loss: 3815286784.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4863593422.222..  Test Loss: 3719546112.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4831460259.556..  Test Loss: 3985149952.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4769014158.222..  Test Loss: 3974033920.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4795131392.000..  Test Loss: 3700622848.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4770863758.222..  Test Loss: 3666405376.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4837821902.222..  Test Loss: 3803877376.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4757524401.778..  Test Loss: 3548703744.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4812176199.111..  Test Loss: 3774170624.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4871674730.667..  Test Loss: 3574454784.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4832702560.000..  Test Loss: 3782099200.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4805320501.333..  Test Loss: 3830260736.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4817139683.556..  Test Loss: 3853342464.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4825695822.222..  Test Loss: 3864677888.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4807876206.222..  Test Loss: 3707487744.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4864219093.333..  Test Loss: 3869738752.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4745547562.667..  Test Loss: 3630119936.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4791933795.556..  Test Loss: 3725559552.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4875910677.333..  Test Loss: 3676395264.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4839788252.444..  Test Loss: 3635419904.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4810287196.444..  Test Loss: 3492768256.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4884141411.556..  Test Loss: 3679784704.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4843796003.556..  Test Loss: 3644056576.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4794617984.000..  Test Loss: 3637161216.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4826325845.333..  Test Loss: 3630609408.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4801994140.444..  Test Loss: 3606742784.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4757966346.667..  Test Loss: 3530723840.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4752638592.000..  Test Loss: 3588850688.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4784121472.000..  Test Loss: 3482692864.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4845971612.444..  Test Loss: 3686798592.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4858807054.222..  Test Loss: 3723700992.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4840550442.667..  Test Loss: 3873908480.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4813804536.889..  Test Loss: 3537851648.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 809/1000..  Training Loss: 4862502791.111..  Test Loss: 3661147136.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4796321621.333..  Test Loss: 3501137920.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4740222471.111..  Test Loss: 3491334656.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4808133909.333..  Test Loss: 3628835840.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4758220686.222..  Test Loss: 3587568640.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4746874311.111..  Test Loss: 3742659328.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4883616334.222..  Test Loss: 3657816832.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4805268394.667..  Test Loss: 3488103680.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4806374208.000..  Test Loss: 3740113408.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4860039271.111..  Test Loss: 3479372288.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4831553585.778..  Test Loss: 3652295936.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4818070691.556..  Test Loss: 3941021440.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4833750176.000..  Test Loss: 3797132800.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4884584995.556..  Test Loss: 3865954560.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4829082204.444..  Test Loss: 3692300800.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4753788629.333..  Test Loss: 3785034496.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4841391004.444..  Test Loss: 3635273728.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4823941297.778..  Test Loss: 3611140096.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4818453084.444..  Test Loss: 3577542400.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4727066791.111..  Test Loss: 3563132160.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4824524792.889..  Test Loss: 3565085952.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4783054158.222..  Test Loss: 3614457344.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4794651701.333..  Test Loss: 3596614912.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4853724174.222..  Test Loss: 3956197120.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4795211569.778..  Test Loss: 3425954048.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4758509568.000..  Test Loss: 3508059392.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4740320679.111..  Test Loss: 3396404992.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4785906012.444..  Test Loss: 3545974272.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4826943886.222..  Test Loss: 3647779840.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4770594688.000..  Test Loss: 3652691456.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4737094414.222..  Test Loss: 3453791232.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4811059185.778..  Test Loss: 3486523392.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4843146865.778..  Test Loss: 3520344832.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4782700992.000..  Test Loss: 3577598208.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4820663032.889..  Test Loss: 3535230208.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4769594090.667..  Test Loss: 3403796992.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4792027754.667..  Test Loss: 3552774912.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4838999736.889..  Test Loss: 3734375680.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4762757774.222..  Test Loss: 3828628224.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4774125482.667..  Test Loss: 3670685952.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4801083768.889..  Test Loss: 3597920512.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4861107790.222..  Test Loss: 3362814464.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4739722894.222..  Test Loss: 3392182784.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4765920689.778..  Test Loss: 3417969920.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4772430812.444..  Test Loss: 3412944896.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4765763228.444..  Test Loss: 3866043648.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4756671189.333..  Test Loss: 3420151040.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4801937749.333..  Test Loss: 3378934528.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4881264995.556..  Test Loss: 3635021056.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4753473639.111..  Test Loss: 3580900608.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4752598712.889..  Test Loss: 3410432000.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4770105031.111..  Test Loss: 3351663872.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4766077930.667..  Test Loss: 3619220992.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4770021361.778..  Test Loss: 3600519424.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4776651477.333..  Test Loss: 3387235840.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4808369571.556..  Test Loss: 3615576576.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4827092088.889..  Test Loss: 3424620800.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4810574606.222..  Test Loss: 3705435392.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4759468273.778..  Test Loss: 3519961600.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4808549568.000..  Test Loss: 3466482688.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4782293347.556..  Test Loss: 3768929024.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4783180579.556..  Test Loss: 3489984256.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4841194382.222..  Test Loss: 3421617408.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4805961571.556..  Test Loss: 3714571520.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4788616853.333..  Test Loss: 3600825600.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4793571342.222..  Test Loss: 3505398784.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4847888888.889..  Test Loss: 3404805632.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4784760298.667..  Test Loss: 3501434112.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4792149269.333..  Test Loss: 3407499264.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4692067420.444..  Test Loss: 3414599936.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4830061703.111..  Test Loss: 3466147584.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4789339623.111..  Test Loss: 3491597312.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4815038300.444..  Test Loss: 3522488832.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4779206528.000..  Test Loss: 3637796096.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4720032519.111..  Test Loss: 3569435648.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4755899612.444..  Test Loss: 3442474752.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4753764913.778..  Test Loss: 3378235392.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4780525532.444..  Test Loss: 3463951872.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4790340508.444..  Test Loss: 3605903104.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4767936426.667..  Test Loss: 3391943168.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4744405831.111..  Test Loss: 3379070464.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4814765969.778..  Test Loss: 3469142272.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4724817379.556..  Test Loss: 3692160000.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4766539477.333..  Test Loss: 3656248064.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4725694784.000..  Test Loss: 3551683072.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4734107726.222..  Test Loss: 3407145216.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4758684629.333..  Test Loss: 3453019136.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4676081176.889..  Test Loss: 3441886464.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4655537592.889..  Test Loss: 3464675584.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4796809635.556..  Test Loss: 3388589824.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4753104871.111..  Test Loss: 3378434816.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4734115847.111..  Test Loss: 3533098240.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4774793354.667..  Test Loss: 3567773440.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4685985294.222..  Test Loss: 3580720384.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4797782997.333..  Test Loss: 3482848512.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4736252768.000..  Test Loss: 3655623936.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4793046855.111..  Test Loss: 3510194944.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4800654570.667..  Test Loss: 3541130240.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4740698474.667..  Test Loss: 3409465600.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4758486097.778..  Test Loss: 3455299072.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4764288554.667..  Test Loss: 3562696448.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4697900874.667..  Test Loss: 3377028096.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 911/1000..  Training Loss: 4751213859.556..  Test Loss: 3568628992.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4752958865.778..  Test Loss: 3393270528.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4697505464.889..  Test Loss: 3793647360.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4766334976.000..  Test Loss: 3454821376.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4732752903.111..  Test Loss: 3398587648.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4751252344.889..  Test Loss: 3429752832.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4685026929.778..  Test Loss: 3471502336.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4748772472.889..  Test Loss: 3359593472.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4732879530.667..  Test Loss: 3542369536.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4701858897.778..  Test Loss: 3531248128.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4754005066.667..  Test Loss: 3586058240.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4722793272.889..  Test Loss: 3521437184.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4825634766.222..  Test Loss: 3438499584.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4755496206.222..  Test Loss: 3410758912.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4761147843.556..  Test Loss: 3427771648.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4729388437.333..  Test Loss: 3704921344.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4699161891.556..  Test Loss: 3538478848.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4761520128.000..  Test Loss: 3403085824.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4701064487.111..  Test Loss: 3688156672.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4760920561.778..  Test Loss: 3380216320.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4782464448.000..  Test Loss: 3513967616.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4777610069.333..  Test Loss: 3476968704.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4718043818.667..  Test Loss: 3541492736.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4699653048.889..  Test Loss: 3371869952.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4728730176.000..  Test Loss: 3598499584.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4734459221.333..  Test Loss: 3459265280.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4768549240.889..  Test Loss: 3409859584.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4704867278.222..  Test Loss: 3533419264.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4718841095.111..  Test Loss: 3467758336.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4777393400.889..  Test Loss: 3395454976.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4743127495.111..  Test Loss: 3785521152.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4707273930.667..  Test Loss: 3580192000.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4694410972.444..  Test Loss: 3513576192.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4749691640.889..  Test Loss: 3451522816.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4739195918.222..  Test Loss: 3338733568.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4713575331.556..  Test Loss: 3435950336.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4731752412.444..  Test Loss: 3554565632.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4713822094.222..  Test Loss: 3752172800.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4746218929.778..  Test Loss: 3594055424.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4675246485.333..  Test Loss: 3309975296.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4722254947.556..  Test Loss: 3383598336.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4777657706.667..  Test Loss: 3535093760.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4716835669.333..  Test Loss: 3370035456.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4750483768.889..  Test Loss: 3541906176.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4708575658.667..  Test Loss: 3592389120.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4757112014.222..  Test Loss: 3788800000.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4756624284.444..  Test Loss: 3605856256.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4761137020.444..  Test Loss: 3449148672.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4780160213.333..  Test Loss: 3364266496.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4780071381.333..  Test Loss: 3394237184.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4742996728.889..  Test Loss: 3417797120.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4680869070.222..  Test Loss: 3473021184.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4725529507.556..  Test Loss: 3322671872.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4729267840.000..  Test Loss: 3609832960.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4749280675.556..  Test Loss: 3407043328.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4719466247.111..  Test Loss: 3361888256.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4749065365.333..  Test Loss: 3406966272.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4747675448.889..  Test Loss: 3420862464.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4709076515.556..  Test Loss: 3358752768.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4670508188.444..  Test Loss: 3547080192.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4745963136.000..  Test Loss: 3426041088.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4734760625.778..  Test Loss: 3499911168.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4675648931.556..  Test Loss: 3414705920.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4715196316.444..  Test Loss: 3457251328.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4695502734.222..  Test Loss: 3335877888.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4699773404.444..  Test Loss: 3379549440.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4719216618.667..  Test Loss: 3452008960.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4722696092.444..  Test Loss: 3535231744.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4659098040.889..  Test Loss: 3301942016.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4759203128.889..  Test Loss: 3341548800.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4684927772.444..  Test Loss: 3523112192.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4746662456.889..  Test Loss: 3393247488.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4657365738.667..  Test Loss: 3444349952.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4727337294.222..  Test Loss: 3329459968.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4714061329.778..  Test Loss: 3656655360.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4712352248.889..  Test Loss: 3405978624.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4739352640.000..  Test Loss: 3499215872.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4717265358.222..  Test Loss: 3391661568.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4785628970.667..  Test Loss: 3545728512.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4681599744.000..  Test Loss: 3442831104.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4709449664.000..  Test Loss: 3457561344.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4759122720.000..  Test Loss: 3552484864.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4684374784.000..  Test Loss: 3462266368.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4684875406.222..  Test Loss: 3335503104.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4680545557.333..  Test Loss: 3583011584.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4698212963.556..  Test Loss: 3842429440.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4765098403.556..  Test Loss: 3589618432.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4692514488.889..  Test Loss: 3510356992.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4762358414.222..  Test Loss: 3599661312.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4736190485.333..  Test Loss: 3445216256.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold: 4\n",
      "Epoch: 1/1000..  Training Loss: 13466598257.778..  Test Loss: 12654410752.000.. \n",
      "Epoch: 2/1000..  Training Loss: 13465489351.111..  Test Loss: 12608614400.000.. \n",
      "Epoch: 3/1000..  Training Loss: 13466094819.556..  Test Loss: 12456009728.000.. \n",
      "Epoch: 4/1000..  Training Loss: 13465540465.778..  Test Loss: 13161413632.000.. \n",
      "Epoch: 5/1000..  Training Loss: 13463748807.111..  Test Loss: 12140221440.000.. \n",
      "Epoch: 6/1000..  Training Loss: 13466013383.111..  Test Loss: 12344993792.000.. \n",
      "Epoch: 7/1000..  Training Loss: 13463921351.111..  Test Loss: 12851116032.000.. \n",
      "Epoch: 8/1000..  Training Loss: 13462149831.111..  Test Loss: 12538840064.000.. \n",
      "Epoch: 9/1000..  Training Loss: 13461074716.444..  Test Loss: 13732706304.000.. \n",
      "Epoch: 10/1000..  Training Loss: 13461097941.333..  Test Loss: 13639661568.000.. \n",
      "Epoch: 11/1000..  Training Loss: 13459390321.778..  Test Loss: 12647862272.000.. \n",
      "Epoch: 12/1000..  Training Loss: 13457011228.444..  Test Loss: 12774110208.000.. \n",
      "Epoch: 13/1000..  Training Loss: 13454504732.444..  Test Loss: 12101555200.000.. \n",
      "Epoch: 14/1000..  Training Loss: 13451771989.333..  Test Loss: 12926109696.000.. \n",
      "Epoch: 15/1000..  Training Loss: 13451347242.667..  Test Loss: 12222781440.000.. \n",
      "Epoch: 16/1000..  Training Loss: 13449326165.333..  Test Loss: 12197355520.000.. \n",
      "Epoch: 17/1000..  Training Loss: 13448138666.667..  Test Loss: 13131959296.000.. \n",
      "Epoch: 18/1000..  Training Loss: 13445612828.444..  Test Loss: 13152224256.000.. \n",
      "Epoch: 19/1000..  Training Loss: 13441924892.444..  Test Loss: 12987331584.000.. \n",
      "Epoch: 20/1000..  Training Loss: 13440956529.778..  Test Loss: 12365926400.000.. \n",
      "Epoch: 21/1000..  Training Loss: 13441422136.889..  Test Loss: 12977718272.000.. \n",
      "Epoch: 22/1000..  Training Loss: 13436071509.333..  Test Loss: 13163803648.000.. \n",
      "Epoch: 23/1000..  Training Loss: 13430626602.667..  Test Loss: 12529154048.000.. \n",
      "Epoch: 24/1000..  Training Loss: 13427014144.000..  Test Loss: 12065651712.000.. \n",
      "Epoch: 25/1000..  Training Loss: 13426494549.333..  Test Loss: 12820978688.000.. \n",
      "Epoch: 26/1000..  Training Loss: 13427755292.444..  Test Loss: 13132283904.000.. \n",
      "Epoch: 27/1000..  Training Loss: 13415383751.111..  Test Loss: 12484353024.000.. \n",
      "Epoch: 28/1000..  Training Loss: 13416247168.000..  Test Loss: 12158164992.000.. \n",
      "Epoch: 29/1000..  Training Loss: 13408278983.111..  Test Loss: 13240686592.000.. \n",
      "Epoch: 30/1000..  Training Loss: 13406889272.889..  Test Loss: 12131559424.000.. \n",
      "Epoch: 31/1000..  Training Loss: 13402522595.556..  Test Loss: 12162601984.000.. \n",
      "Epoch: 32/1000..  Training Loss: 13405365532.444..  Test Loss: 12299476992.000.. \n",
      "Epoch: 33/1000..  Training Loss: 13395127352.889..  Test Loss: 12734459904.000.. \n",
      "Epoch: 34/1000..  Training Loss: 13388872035.556..  Test Loss: 12629176320.000.. \n",
      "Epoch: 35/1000..  Training Loss: 13381625386.667..  Test Loss: 12500133888.000.. \n",
      "Epoch: 36/1000..  Training Loss: 13379520227.556..  Test Loss: 13670847488.000.. \n",
      "Epoch: 37/1000..  Training Loss: 13376067100.444..  Test Loss: 12615252992.000.. \n",
      "Epoch: 38/1000..  Training Loss: 13371576661.333..  Test Loss: 12262597632.000.. \n",
      "Epoch: 39/1000..  Training Loss: 13364951552.000..  Test Loss: 12284633088.000.. \n",
      "Epoch: 40/1000..  Training Loss: 13365055800.889..  Test Loss: 12555986944.000.. \n",
      "Epoch: 41/1000..  Training Loss: 13356941980.444..  Test Loss: 12660880384.000.. \n",
      "Epoch: 42/1000..  Training Loss: 13354103779.556..  Test Loss: 12774353920.000.. \n",
      "Epoch: 43/1000..  Training Loss: 13345732608.000..  Test Loss: 12423251968.000.. \n",
      "Epoch: 44/1000..  Training Loss: 13341561386.667..  Test Loss: 12366704640.000.. \n",
      "Epoch: 45/1000..  Training Loss: 13337285546.667..  Test Loss: 12960870400.000.. \n",
      "Epoch: 46/1000..  Training Loss: 13334392661.333..  Test Loss: 12183161856.000.. \n",
      "Epoch: 47/1000..  Training Loss: 13328123050.667..  Test Loss: 13673232384.000.. \n",
      "Epoch: 48/1000..  Training Loss: 13322492700.444..  Test Loss: 12717362176.000.. \n",
      "Epoch: 49/1000..  Training Loss: 13309299484.444..  Test Loss: 12534193152.000.. \n",
      "Epoch: 50/1000..  Training Loss: 13314961408.000..  Test Loss: 12953848832.000.. \n",
      "Epoch: 51/1000..  Training Loss: 13303635911.111..  Test Loss: 11979374592.000.. \n",
      "Epoch: 52/1000..  Training Loss: 13300471537.778..  Test Loss: 12756977664.000.. \n",
      "Epoch: 53/1000..  Training Loss: 13290424092.444..  Test Loss: 12541563904.000.. \n",
      "Epoch: 54/1000..  Training Loss: 13281121280.000..  Test Loss: 12166243328.000.. \n",
      "Epoch: 55/1000..  Training Loss: 13277556366.222..  Test Loss: 14519805952.000.. \n",
      "Epoch: 56/1000..  Training Loss: 13272531256.889..  Test Loss: 12120448000.000.. \n",
      "Epoch: 57/1000..  Training Loss: 13262330410.667..  Test Loss: 13553930240.000.. \n",
      "Epoch: 58/1000..  Training Loss: 13260135196.444..  Test Loss: 13340564480.000.. \n",
      "Epoch: 59/1000..  Training Loss: 13247575864.889..  Test Loss: 12702313472.000.. \n",
      "Epoch: 60/1000..  Training Loss: 13245942243.556..  Test Loss: 12473728000.000.. \n",
      "Epoch: 61/1000..  Training Loss: 13240756565.333..  Test Loss: 12722215936.000.. \n",
      "Epoch: 62/1000..  Training Loss: 13234565148.444..  Test Loss: 12930994176.000.. \n",
      "Epoch: 63/1000..  Training Loss: 13226337009.778..  Test Loss: 13647044608.000.. \n",
      "Epoch: 64/1000..  Training Loss: 13218336341.333..  Test Loss: 12329497600.000.. \n",
      "Epoch: 65/1000..  Training Loss: 13216157496.889..  Test Loss: 13682352128.000.. \n",
      "Epoch: 66/1000..  Training Loss: 13205727829.333..  Test Loss: 13993334784.000.. \n",
      "Epoch: 67/1000..  Training Loss: 13191709283.556..  Test Loss: 12328800256.000.. \n",
      "Epoch: 68/1000..  Training Loss: 13189501809.778..  Test Loss: 14533232640.000.. \n",
      "Epoch: 69/1000..  Training Loss: 13180453731.556..  Test Loss: 12774222848.000.. \n",
      "Epoch: 70/1000..  Training Loss: 13173396181.333..  Test Loss: 12909035520.000.. \n",
      "Epoch: 71/1000..  Training Loss: 13168557411.556..  Test Loss: 12867180544.000.. \n",
      "Epoch: 72/1000..  Training Loss: 13161989632.000..  Test Loss: 13493650432.000.. \n",
      "Epoch: 73/1000..  Training Loss: 13160686008.889..  Test Loss: 15055756288.000.. \n",
      "Epoch: 74/1000..  Training Loss: 13140591331.556..  Test Loss: 12682669056.000.. \n",
      "Epoch: 75/1000..  Training Loss: 13133984540.444..  Test Loss: 13877032960.000.. \n",
      "Epoch: 76/1000..  Training Loss: 13125677368.889..  Test Loss: 12333580288.000.. \n",
      "Epoch: 77/1000..  Training Loss: 13122798990.222..  Test Loss: 12415249408.000.. \n",
      "Epoch: 78/1000..  Training Loss: 13110155292.444..  Test Loss: 12135495680.000.. \n",
      "Epoch: 79/1000..  Training Loss: 13102813383.111..  Test Loss: 12290836480.000.. \n",
      "Epoch: 80/1000..  Training Loss: 13097070080.000..  Test Loss: 14192691200.000.. \n",
      "Epoch: 81/1000..  Training Loss: 13088072888.889..  Test Loss: 12368600064.000.. \n",
      "Epoch: 82/1000..  Training Loss: 13081753656.889..  Test Loss: 13005462528.000.. \n",
      "Epoch: 83/1000..  Training Loss: 13071331498.667..  Test Loss: 14970520576.000.. \n",
      "Epoch: 84/1000..  Training Loss: 13065040753.778..  Test Loss: 15557112832.000.. \n",
      "Epoch: 85/1000..  Training Loss: 13061603669.333..  Test Loss: 13191070720.000.. \n",
      "Epoch: 86/1000..  Training Loss: 13051817415.111..  Test Loss: 12216988672.000.. \n",
      "Epoch: 87/1000..  Training Loss: 13039462300.444..  Test Loss: 13580095488.000.. \n",
      "Epoch: 88/1000..  Training Loss: 13032299008.000..  Test Loss: 12477535232.000.. \n",
      "Epoch: 89/1000..  Training Loss: 13019304561.778..  Test Loss: 12420260864.000.. \n",
      "Epoch: 90/1000..  Training Loss: 13018723370.667..  Test Loss: 12013232128.000.. \n",
      "Epoch: 91/1000..  Training Loss: 13005287040.000..  Test Loss: 12542004224.000.. \n",
      "Epoch: 92/1000..  Training Loss: 12997922588.444..  Test Loss: 13142888448.000.. \n",
      "Epoch: 93/1000..  Training Loss: 12984312661.333..  Test Loss: 13846247424.000.. \n",
      "Epoch: 94/1000..  Training Loss: 12979942314.667..  Test Loss: 12550196224.000.. \n",
      "Epoch: 95/1000..  Training Loss: 12968798478.222..  Test Loss: 11975832576.000.. \n",
      "Epoch: 96/1000..  Training Loss: 12957264540.444..  Test Loss: 11907143680.000.. \n",
      "Epoch: 97/1000..  Training Loss: 12950584817.778..  Test Loss: 13357765632.000.. \n",
      "Epoch: 98/1000..  Training Loss: 12939357155.556..  Test Loss: 12960534528.000.. \n",
      "Epoch: 99/1000..  Training Loss: 12936780686.222..  Test Loss: 12531249152.000.. \n",
      "Epoch: 100/1000..  Training Loss: 12929984213.333..  Test Loss: 12883302400.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000..  Training Loss: 12915008085.333..  Test Loss: 12327785472.000.. \n",
      "Epoch: 102/1000..  Training Loss: 12908759196.444..  Test Loss: 12425503744.000.. \n",
      "Epoch: 103/1000..  Training Loss: 12899142499.556..  Test Loss: 12366643200.000.. \n",
      "Epoch: 104/1000..  Training Loss: 12892143089.778..  Test Loss: 12112603136.000.. \n",
      "Epoch: 105/1000..  Training Loss: 12878554624.000..  Test Loss: 13095288832.000.. \n",
      "Epoch: 106/1000..  Training Loss: 12860235548.444..  Test Loss: 12060720128.000.. \n",
      "Epoch: 107/1000..  Training Loss: 12863554261.333..  Test Loss: 13080422400.000.. \n",
      "Epoch: 108/1000..  Training Loss: 12852834190.222..  Test Loss: 13345855488.000.. \n",
      "Epoch: 109/1000..  Training Loss: 12837655182.222..  Test Loss: 13282183168.000.. \n",
      "Epoch: 110/1000..  Training Loss: 12831744455.111..  Test Loss: 13555233792.000.. \n",
      "Epoch: 111/1000..  Training Loss: 12823160263.111..  Test Loss: 13002630144.000.. \n",
      "Epoch: 112/1000..  Training Loss: 12815326606.222..  Test Loss: 12816420864.000.. \n",
      "Epoch: 113/1000..  Training Loss: 12801210453.333..  Test Loss: 13845045248.000.. \n",
      "Epoch: 114/1000..  Training Loss: 12791102435.556..  Test Loss: 12758311936.000.. \n",
      "Epoch: 115/1000..  Training Loss: 12781162325.333..  Test Loss: 13692099584.000.. \n",
      "Epoch: 116/1000..  Training Loss: 12768231964.444..  Test Loss: 12395600896.000.. \n",
      "Epoch: 117/1000..  Training Loss: 12761652053.333..  Test Loss: 12652589056.000.. \n",
      "Epoch: 118/1000..  Training Loss: 12751018453.333..  Test Loss: 13080986624.000.. \n",
      "Epoch: 119/1000..  Training Loss: 12744600832.000..  Test Loss: 12049196032.000.. \n",
      "Epoch: 120/1000..  Training Loss: 12735243690.667..  Test Loss: 12427546624.000.. \n",
      "Epoch: 121/1000..  Training Loss: 12716871281.778..  Test Loss: 12866341888.000.. \n",
      "Epoch: 122/1000..  Training Loss: 12707314944.000..  Test Loss: 13777687552.000.. \n",
      "Epoch: 123/1000..  Training Loss: 12703155811.556..  Test Loss: 12741471232.000.. \n",
      "Epoch: 124/1000..  Training Loss: 12681936526.222..  Test Loss: 12397165568.000.. \n",
      "Epoch: 125/1000..  Training Loss: 12676366193.778..  Test Loss: 12293111808.000.. \n",
      "Epoch: 126/1000..  Training Loss: 12670323370.667..  Test Loss: 12658766848.000.. \n",
      "Epoch: 127/1000..  Training Loss: 12659088440.889..  Test Loss: 13177972736.000.. \n",
      "Epoch: 128/1000..  Training Loss: 12646169415.111..  Test Loss: 12149645312.000.. \n",
      "Epoch: 129/1000..  Training Loss: 12635617123.556..  Test Loss: 12627336192.000.. \n",
      "Epoch: 130/1000..  Training Loss: 12619529827.556..  Test Loss: 13129345024.000.. \n",
      "Epoch: 131/1000..  Training Loss: 12606904334.222..  Test Loss: 15902944256.000.. \n",
      "Epoch: 132/1000..  Training Loss: 12606793102.222..  Test Loss: 12426856448.000.. \n",
      "Epoch: 133/1000..  Training Loss: 12591777080.889..  Test Loss: 12118897664.000.. \n",
      "Epoch: 134/1000..  Training Loss: 12582206264.889..  Test Loss: 12515103744.000.. \n",
      "Epoch: 135/1000..  Training Loss: 12584231253.333..  Test Loss: 12993800192.000.. \n",
      "Epoch: 136/1000..  Training Loss: 12555673344.000..  Test Loss: 12318222336.000.. \n",
      "Epoch: 137/1000..  Training Loss: 12552448469.333..  Test Loss: 12407633920.000.. \n",
      "Epoch: 138/1000..  Training Loss: 12539107783.111..  Test Loss: 12609595392.000.. \n",
      "Epoch: 139/1000..  Training Loss: 12527985294.222..  Test Loss: 12699486208.000.. \n",
      "Epoch: 140/1000..  Training Loss: 12530234851.556..  Test Loss: 12567292928.000.. \n",
      "Epoch: 141/1000..  Training Loss: 12501179363.556..  Test Loss: 13419419648.000.. \n",
      "Epoch: 142/1000..  Training Loss: 12503235953.778..  Test Loss: 12380771328.000.. \n",
      "Epoch: 143/1000..  Training Loss: 12485510115.556..  Test Loss: 12273008640.000.. \n",
      "Epoch: 144/1000..  Training Loss: 12471609386.667..  Test Loss: 14242918400.000.. \n",
      "Epoch: 145/1000..  Training Loss: 12454117404.444..  Test Loss: 12129545216.000.. \n",
      "Epoch: 146/1000..  Training Loss: 12438865208.889..  Test Loss: 12710820864.000.. \n",
      "Epoch: 147/1000..  Training Loss: 12427860778.667..  Test Loss: 12759051264.000.. \n",
      "Epoch: 148/1000..  Training Loss: 12430792007.111..  Test Loss: 12965570560.000.. \n",
      "Epoch: 149/1000..  Training Loss: 12406951096.889..  Test Loss: 12223148032.000.. \n",
      "Epoch: 150/1000..  Training Loss: 12403299541.333..  Test Loss: 12583737344.000.. \n",
      "Epoch: 151/1000..  Training Loss: 12375603114.667..  Test Loss: 12351843328.000.. \n",
      "Epoch: 152/1000..  Training Loss: 12373068430.222..  Test Loss: 12790617088.000.. \n",
      "Epoch: 153/1000..  Training Loss: 12369183445.333..  Test Loss: 13044642816.000.. \n",
      "Epoch: 154/1000..  Training Loss: 12353457720.889..  Test Loss: 13260683264.000.. \n",
      "Epoch: 155/1000..  Training Loss: 12347562012.444..  Test Loss: 12609424384.000.. \n",
      "Epoch: 156/1000..  Training Loss: 12333581738.667..  Test Loss: 12471257088.000.. \n",
      "Epoch: 157/1000..  Training Loss: 12324270791.111..  Test Loss: 12145912832.000.. \n",
      "Epoch: 158/1000..  Training Loss: 12301132942.222..  Test Loss: 12019354624.000.. \n",
      "Epoch: 159/1000..  Training Loss: 12273607523.556..  Test Loss: 11778621440.000.. \n",
      "Epoch: 160/1000..  Training Loss: 12271944960.000..  Test Loss: 12087041024.000.. \n",
      "Epoch: 161/1000..  Training Loss: 12269479424.000..  Test Loss: 11549032448.000.. \n",
      "Epoch: 162/1000..  Training Loss: 12248218851.556..  Test Loss: 11796695040.000.. \n",
      "Epoch: 163/1000..  Training Loss: 12246450830.222..  Test Loss: 12243042304.000.. \n",
      "Epoch: 164/1000..  Training Loss: 12226691015.111..  Test Loss: 11643486208.000.. \n",
      "Epoch: 165/1000..  Training Loss: 12223935559.111..  Test Loss: 11403383808.000.. \n",
      "Epoch: 166/1000..  Training Loss: 12193954759.111..  Test Loss: 11324512256.000.. \n",
      "Epoch: 167/1000..  Training Loss: 12195897059.556..  Test Loss: 12700827648.000.. \n",
      "Epoch: 168/1000..  Training Loss: 12162470869.333..  Test Loss: 13673725952.000.. \n",
      "Epoch: 169/1000..  Training Loss: 12161842816.000..  Test Loss: 11546257408.000.. \n",
      "Epoch: 170/1000..  Training Loss: 12149350684.444..  Test Loss: 11775791104.000.. \n",
      "Epoch: 171/1000..  Training Loss: 12134825315.556..  Test Loss: 11873340416.000.. \n",
      "Epoch: 172/1000..  Training Loss: 12117967118.222..  Test Loss: 11598151680.000.. \n",
      "Epoch: 173/1000..  Training Loss: 12114959701.333..  Test Loss: 11858801664.000.. \n",
      "Epoch: 174/1000..  Training Loss: 12097425991.111..  Test Loss: 11431517184.000.. \n",
      "Epoch: 175/1000..  Training Loss: 12060926279.111..  Test Loss: 11553826816.000.. \n",
      "Epoch: 176/1000..  Training Loss: 12084069873.778..  Test Loss: 12574116864.000.. \n",
      "Epoch: 177/1000..  Training Loss: 12066182883.556..  Test Loss: 12643784704.000.. \n",
      "Epoch: 178/1000..  Training Loss: 12062208995.556..  Test Loss: 12051059712.000.. \n",
      "Epoch: 179/1000..  Training Loss: 12032749184.000..  Test Loss: 11859494912.000.. \n",
      "Epoch: 180/1000..  Training Loss: 12004973496.889..  Test Loss: 11810095104.000.. \n",
      "Epoch: 181/1000..  Training Loss: 12009504483.556..  Test Loss: 12133316608.000.. \n",
      "Epoch: 182/1000..  Training Loss: 11977911708.444..  Test Loss: 11518117888.000.. \n",
      "Epoch: 183/1000..  Training Loss: 11973853283.556..  Test Loss: 11873812480.000.. \n",
      "Epoch: 184/1000..  Training Loss: 11969017159.111..  Test Loss: 14185163776.000.. \n",
      "Epoch: 185/1000..  Training Loss: 11946336384.000..  Test Loss: 12821010432.000.. \n",
      "Epoch: 186/1000..  Training Loss: 11926508515.556..  Test Loss: 12068891648.000.. \n",
      "Epoch: 187/1000..  Training Loss: 11933031111.111..  Test Loss: 11402502144.000.. \n",
      "Epoch: 188/1000..  Training Loss: 11922430108.444..  Test Loss: 11467270144.000.. \n",
      "Epoch: 189/1000..  Training Loss: 11903673528.889..  Test Loss: 11427042304.000.. \n",
      "Epoch: 190/1000..  Training Loss: 11869681038.222..  Test Loss: 12915442688.000.. \n",
      "Epoch: 191/1000..  Training Loss: 11869813191.111..  Test Loss: 11559095296.000.. \n",
      "Epoch: 192/1000..  Training Loss: 11867275178.667..  Test Loss: 12261673984.000.. \n",
      "Epoch: 193/1000..  Training Loss: 11846689152.000..  Test Loss: 11499406336.000.. \n",
      "Epoch: 194/1000..  Training Loss: 11833171228.444..  Test Loss: 11733169152.000.. \n",
      "Epoch: 195/1000..  Training Loss: 11817974200.889..  Test Loss: 11773848576.000.. \n",
      "Epoch: 196/1000..  Training Loss: 11804039907.556..  Test Loss: 12879790080.000.. \n",
      "Epoch: 197/1000..  Training Loss: 11792300928.000..  Test Loss: 13126416384.000.. \n",
      "Epoch: 198/1000..  Training Loss: 11779509660.444..  Test Loss: 11533401088.000.. \n",
      "Epoch: 199/1000..  Training Loss: 11758466403.556..  Test Loss: 11296268288.000.. \n",
      "Epoch: 200/1000..  Training Loss: 11771098112.000..  Test Loss: 11379667968.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/1000..  Training Loss: 11744106211.556..  Test Loss: 11964561408.000.. \n",
      "Epoch: 202/1000..  Training Loss: 11716587548.444..  Test Loss: 11200514048.000.. \n",
      "Epoch: 203/1000..  Training Loss: 11720963896.889..  Test Loss: 11064403968.000.. \n",
      "Epoch: 204/1000..  Training Loss: 11714589084.444..  Test Loss: 11606843392.000.. \n",
      "Epoch: 205/1000..  Training Loss: 11667735125.333..  Test Loss: 12397178880.000.. \n",
      "Epoch: 206/1000..  Training Loss: 11667754837.333..  Test Loss: 11600717824.000.. \n",
      "Epoch: 207/1000..  Training Loss: 11648730282.667..  Test Loss: 11660984320.000.. \n",
      "Epoch: 208/1000..  Training Loss: 11645757226.667..  Test Loss: 11539346432.000.. \n",
      "Epoch: 209/1000..  Training Loss: 11608616263.111..  Test Loss: 11814170624.000.. \n",
      "Epoch: 210/1000..  Training Loss: 11607227662.222..  Test Loss: 11662025728.000.. \n",
      "Epoch: 211/1000..  Training Loss: 11574521272.889..  Test Loss: 14035519488.000.. \n",
      "Epoch: 212/1000..  Training Loss: 11595553863.111..  Test Loss: 11152956416.000.. \n",
      "Epoch: 213/1000..  Training Loss: 11579297920.000..  Test Loss: 11549409280.000.. \n",
      "Epoch: 214/1000..  Training Loss: 11552200405.333..  Test Loss: 11705546752.000.. \n",
      "Epoch: 215/1000..  Training Loss: 11527955569.778..  Test Loss: 12170089472.000.. \n",
      "Epoch: 216/1000..  Training Loss: 11522879445.333..  Test Loss: 11163543552.000.. \n",
      "Epoch: 217/1000..  Training Loss: 11524046364.444..  Test Loss: 12064376832.000.. \n",
      "Epoch: 218/1000..  Training Loss: 11507795484.444..  Test Loss: 11814142976.000.. \n",
      "Epoch: 219/1000..  Training Loss: 11496299320.889..  Test Loss: 11606495232.000.. \n",
      "Epoch: 220/1000..  Training Loss: 11489736234.667..  Test Loss: 11682018304.000.. \n",
      "Epoch: 221/1000..  Training Loss: 11457115036.444..  Test Loss: 12034937856.000.. \n",
      "Epoch: 222/1000..  Training Loss: 11452459235.556..  Test Loss: 11160351744.000.. \n",
      "Epoch: 223/1000..  Training Loss: 11447915605.333..  Test Loss: 11453895680.000.. \n",
      "Epoch: 224/1000..  Training Loss: 11450366492.444..  Test Loss: 11178662912.000.. \n",
      "Epoch: 225/1000..  Training Loss: 11380799246.222..  Test Loss: 11558669312.000.. \n",
      "Epoch: 226/1000..  Training Loss: 11393575950.222..  Test Loss: 12193717248.000.. \n",
      "Epoch: 227/1000..  Training Loss: 11354159943.111..  Test Loss: 11168092160.000.. \n",
      "Epoch: 228/1000..  Training Loss: 11367164643.556..  Test Loss: 11479370752.000.. \n",
      "Epoch: 229/1000..  Training Loss: 11332238748.444..  Test Loss: 11234419712.000.. \n",
      "Epoch: 230/1000..  Training Loss: 11325762147.556..  Test Loss: 11281051648.000.. \n",
      "Epoch: 231/1000..  Training Loss: 11313010588.444..  Test Loss: 11111086080.000.. \n",
      "Epoch: 232/1000..  Training Loss: 11303813816.889..  Test Loss: 11537072128.000.. \n",
      "Epoch: 233/1000..  Training Loss: 11291660316.444..  Test Loss: 12013351936.000.. \n",
      "Epoch: 234/1000..  Training Loss: 11259610467.556..  Test Loss: 11583051776.000.. \n",
      "Epoch: 235/1000..  Training Loss: 11245000718.222..  Test Loss: 11290147840.000.. \n",
      "Epoch: 236/1000..  Training Loss: 11245970232.889..  Test Loss: 11058488320.000.. \n",
      "Epoch: 237/1000..  Training Loss: 11217326634.667..  Test Loss: 11156446208.000.. \n",
      "Epoch: 238/1000..  Training Loss: 11205095338.667..  Test Loss: 11022301184.000.. \n",
      "Epoch: 239/1000..  Training Loss: 11183260629.333..  Test Loss: 11009530880.000.. \n",
      "Epoch: 240/1000..  Training Loss: 11202079288.889..  Test Loss: 12501050368.000.. \n",
      "Epoch: 241/1000..  Training Loss: 11190297912.889..  Test Loss: 11527279616.000.. \n",
      "Epoch: 242/1000..  Training Loss: 11109048007.111..  Test Loss: 13387543552.000.. \n",
      "Epoch: 243/1000..  Training Loss: 11122102456.889..  Test Loss: 13390483456.000.. \n",
      "Epoch: 244/1000..  Training Loss: 11127427712.000..  Test Loss: 13998584832.000.. \n",
      "Epoch: 245/1000..  Training Loss: 11094530801.778..  Test Loss: 11520095232.000.. \n",
      "Epoch: 246/1000..  Training Loss: 11097309980.444..  Test Loss: 11072463872.000.. \n",
      "Epoch: 247/1000..  Training Loss: 11052511900.444..  Test Loss: 11022414848.000.. \n",
      "Epoch: 248/1000..  Training Loss: 11073721841.778..  Test Loss: 11699641344.000.. \n",
      "Epoch: 249/1000..  Training Loss: 11017069710.222..  Test Loss: 11628803072.000.. \n",
      "Epoch: 250/1000..  Training Loss: 11054084608.000..  Test Loss: 11069940736.000.. \n",
      "Epoch: 251/1000..  Training Loss: 11022174037.333..  Test Loss: 12544101376.000.. \n",
      "Epoch: 252/1000..  Training Loss: 10985781191.111..  Test Loss: 11062337536.000.. \n",
      "Epoch: 253/1000..  Training Loss: 10948303729.778..  Test Loss: 12095674368.000.. \n",
      "Epoch: 254/1000..  Training Loss: 10933372160.000..  Test Loss: 10858686464.000.. \n",
      "Epoch: 255/1000..  Training Loss: 10951126912.000..  Test Loss: 11082285056.000.. \n",
      "Epoch: 256/1000..  Training Loss: 10939558058.667..  Test Loss: 11784361984.000.. \n",
      "Epoch: 257/1000..  Training Loss: 10938225009.778..  Test Loss: 12443494400.000.. \n",
      "Epoch: 258/1000..  Training Loss: 10915896220.444..  Test Loss: 11663841280.000.. \n",
      "Epoch: 259/1000..  Training Loss: 10915077006.222..  Test Loss: 11037665280.000.. \n",
      "Epoch: 260/1000..  Training Loss: 10849798784.000..  Test Loss: 11250071552.000.. \n",
      "Epoch: 261/1000..  Training Loss: 10862362311.111..  Test Loss: 11277166592.000.. \n",
      "Epoch: 262/1000..  Training Loss: 10834403740.444..  Test Loss: 11035810816.000.. \n",
      "Epoch: 263/1000..  Training Loss: 10833186403.556..  Test Loss: 10955492352.000.. \n",
      "Epoch: 264/1000..  Training Loss: 10814877696.000..  Test Loss: 11132806144.000.. \n",
      "Epoch: 265/1000..  Training Loss: 10796409969.778..  Test Loss: 11217785856.000.. \n",
      "Epoch: 266/1000..  Training Loss: 10796275057.778..  Test Loss: 10659068928.000.. \n",
      "Epoch: 267/1000..  Training Loss: 10742582115.556..  Test Loss: 11225094144.000.. \n",
      "Epoch: 268/1000..  Training Loss: 10786202069.333..  Test Loss: 11489270784.000.. \n",
      "Epoch: 269/1000..  Training Loss: 10753502776.889..  Test Loss: 12249495552.000.. \n",
      "Epoch: 270/1000..  Training Loss: 10730638151.111..  Test Loss: 11224391680.000.. \n",
      "Epoch: 271/1000..  Training Loss: 10707298005.333..  Test Loss: 10910705664.000.. \n",
      "Epoch: 272/1000..  Training Loss: 10661704419.556..  Test Loss: 11812235264.000.. \n",
      "Epoch: 273/1000..  Training Loss: 10658503210.667..  Test Loss: 11125085184.000.. \n",
      "Epoch: 274/1000..  Training Loss: 10671267072.000..  Test Loss: 10957784064.000.. \n",
      "Epoch: 275/1000..  Training Loss: 10632959232.000..  Test Loss: 11102868480.000.. \n",
      "Epoch: 276/1000..  Training Loss: 10654377642.667..  Test Loss: 10800972800.000.. \n",
      "Epoch: 277/1000..  Training Loss: 10576661859.556..  Test Loss: 11278832640.000.. \n",
      "Epoch: 278/1000..  Training Loss: 10584991587.556..  Test Loss: 10654486528.000.. \n",
      "Epoch: 279/1000..  Training Loss: 10573445063.111..  Test Loss: 10863956992.000.. \n",
      "Epoch: 280/1000..  Training Loss: 10556617984.000..  Test Loss: 10731133952.000.. \n",
      "Epoch: 281/1000..  Training Loss: 10529163022.222..  Test Loss: 10528103424.000.. \n",
      "Epoch: 282/1000..  Training Loss: 10503445191.111..  Test Loss: 10538041344.000.. \n",
      "Epoch: 283/1000..  Training Loss: 10529632668.444..  Test Loss: 10612037632.000.. \n",
      "Epoch: 284/1000..  Training Loss: 10506607516.444..  Test Loss: 10921407488.000.. \n",
      "Epoch: 285/1000..  Training Loss: 10466780131.556..  Test Loss: 10539593728.000.. \n",
      "Epoch: 286/1000..  Training Loss: 10461612060.444..  Test Loss: 10659085312.000.. \n",
      "Epoch: 287/1000..  Training Loss: 10414380145.778..  Test Loss: 10836965376.000.. \n",
      "Epoch: 288/1000..  Training Loss: 10445314033.778..  Test Loss: 10949263360.000.. \n",
      "Epoch: 289/1000..  Training Loss: 10404281429.333..  Test Loss: 11038016512.000.. \n",
      "Epoch: 290/1000..  Training Loss: 10403090289.778..  Test Loss: 11467035648.000.. \n",
      "Epoch: 291/1000..  Training Loss: 10386190293.333..  Test Loss: 11181714432.000.. \n",
      "Epoch: 292/1000..  Training Loss: 10386713528.889..  Test Loss: 10807714816.000.. \n",
      "Epoch: 293/1000..  Training Loss: 10401469952.000..  Test Loss: 10727402496.000.. \n",
      "Epoch: 294/1000..  Training Loss: 10327524295.111..  Test Loss: 11330222080.000.. \n",
      "Epoch: 295/1000..  Training Loss: 10351068728.889..  Test Loss: 10796968960.000.. \n",
      "Epoch: 296/1000..  Training Loss: 10302391196.444..  Test Loss: 11500600320.000.. \n",
      "Epoch: 297/1000..  Training Loss: 10311647175.111..  Test Loss: 10748141568.000.. \n",
      "Epoch: 298/1000..  Training Loss: 10280568632.889..  Test Loss: 10556729344.000.. \n",
      "Epoch: 299/1000..  Training Loss: 10256722944.000..  Test Loss: 11295527936.000.. \n",
      "Epoch: 300/1000..  Training Loss: 10220211200.000..  Test Loss: 10790180864.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 301/1000..  Training Loss: 10239797276.444..  Test Loss: 10837628928.000.. \n",
      "Epoch: 302/1000..  Training Loss: 10213041891.556..  Test Loss: 10454379520.000.. \n",
      "Epoch: 303/1000..  Training Loss: 10163535118.222..  Test Loss: 13433111552.000.. \n",
      "Epoch: 304/1000..  Training Loss: 10173612657.778..  Test Loss: 11451128832.000.. \n",
      "Epoch: 305/1000..  Training Loss: 10175194240.000..  Test Loss: 10279050240.000.. \n",
      "Epoch: 306/1000..  Training Loss: 10150249144.889..  Test Loss: 10686338048.000.. \n",
      "Epoch: 307/1000..  Training Loss: 10094286919.111..  Test Loss: 11118907392.000.. \n",
      "Epoch: 308/1000..  Training Loss: 10132879061.333..  Test Loss: 11065910272.000.. \n",
      "Epoch: 309/1000..  Training Loss: 10094099626.667..  Test Loss: 10651927552.000.. \n",
      "Epoch: 310/1000..  Training Loss: 10102183324.444..  Test Loss: 11208642560.000.. \n",
      "Epoch: 311/1000..  Training Loss: 10052980423.111..  Test Loss: 10298621952.000.. \n",
      "Epoch: 312/1000..  Training Loss: 10056874453.333..  Test Loss: 10386762752.000.. \n",
      "Epoch: 313/1000..  Training Loss: 10033040512.000..  Test Loss: 10902836224.000.. \n",
      "Epoch: 314/1000..  Training Loss: 10027148458.667..  Test Loss: 10828180480.000.. \n",
      "Epoch: 315/1000..  Training Loss: 9992986126.222..  Test Loss: 11261965312.000.. \n",
      "Epoch: 316/1000..  Training Loss: 9968236487.111..  Test Loss: 10870371328.000.. \n",
      "Epoch: 317/1000..  Training Loss: 9955070890.667..  Test Loss: 10287100928.000.. \n",
      "Epoch: 318/1000..  Training Loss: 9933358008.889..  Test Loss: 11315303424.000.. \n",
      "Epoch: 319/1000..  Training Loss: 9918396842.667..  Test Loss: 10775864320.000.. \n",
      "Epoch: 320/1000..  Training Loss: 9942252216.889..  Test Loss: 11191646208.000.. \n",
      "Epoch: 321/1000..  Training Loss: 9932971761.778..  Test Loss: 11154832384.000.. \n",
      "Epoch: 322/1000..  Training Loss: 9905510641.778..  Test Loss: 10793480192.000.. \n",
      "Epoch: 323/1000..  Training Loss: 9870082659.556..  Test Loss: 11342750720.000.. \n",
      "Epoch: 324/1000..  Training Loss: 9833600327.111..  Test Loss: 10892399616.000.. \n",
      "Epoch: 325/1000..  Training Loss: 9824866147.556..  Test Loss: 10117541888.000.. \n",
      "Epoch: 326/1000..  Training Loss: 9823615729.778..  Test Loss: 10250905600.000.. \n",
      "Epoch: 327/1000..  Training Loss: 9816064426.667..  Test Loss: 10475660288.000.. \n",
      "Epoch: 328/1000..  Training Loss: 9765846656.000..  Test Loss: 10138970112.000.. \n",
      "Epoch: 329/1000..  Training Loss: 9740079431.111..  Test Loss: 10522018816.000.. \n",
      "Epoch: 330/1000..  Training Loss: 9737758520.889..  Test Loss: 10479991808.000.. \n",
      "Epoch: 331/1000..  Training Loss: 9715403064.889..  Test Loss: 10164341760.000.. \n",
      "Epoch: 332/1000..  Training Loss: 9770765468.444..  Test Loss: 10521100288.000.. \n",
      "Epoch: 333/1000..  Training Loss: 9762263196.444..  Test Loss: 11290733568.000.. \n",
      "Epoch: 334/1000..  Training Loss: 9692958705.778..  Test Loss: 11001946112.000.. \n",
      "Epoch: 335/1000..  Training Loss: 9646644707.556..  Test Loss: 10926202880.000.. \n",
      "Epoch: 336/1000..  Training Loss: 9641494983.111..  Test Loss: 10322185216.000.. \n",
      "Epoch: 337/1000..  Training Loss: 9654565532.444..  Test Loss: 10547929088.000.. \n",
      "Epoch: 338/1000..  Training Loss: 9609630179.556..  Test Loss: 11257182208.000.. \n",
      "Epoch: 339/1000..  Training Loss: 9587620394.667..  Test Loss: 11109373952.000.. \n",
      "Epoch: 340/1000..  Training Loss: 9597876053.333..  Test Loss: 10804297728.000.. \n",
      "Epoch: 341/1000..  Training Loss: 9599713450.667..  Test Loss: 10906104832.000.. \n",
      "Epoch: 342/1000..  Training Loss: 9585289571.556..  Test Loss: 10290703360.000.. \n",
      "Epoch: 343/1000..  Training Loss: 9549801728.000..  Test Loss: 11283730432.000.. \n",
      "Epoch: 344/1000..  Training Loss: 9473184853.333..  Test Loss: 10409317376.000.. \n",
      "Epoch: 345/1000..  Training Loss: 9518008248.889..  Test Loss: 10684826624.000.. \n",
      "Epoch: 346/1000..  Training Loss: 9499161344.000..  Test Loss: 10624608256.000.. \n",
      "Epoch: 347/1000..  Training Loss: 9478010140.444..  Test Loss: 10565824512.000.. \n",
      "Epoch: 348/1000..  Training Loss: 9472170353.778..  Test Loss: 10282004480.000.. \n",
      "Epoch: 349/1000..  Training Loss: 9486839224.889..  Test Loss: 10070899712.000.. \n",
      "Epoch: 350/1000..  Training Loss: 9462983224.889..  Test Loss: 10475405312.000.. \n",
      "Epoch: 351/1000..  Training Loss: 9415198350.222..  Test Loss: 12657967104.000.. \n",
      "Epoch: 352/1000..  Training Loss: 9422806599.111..  Test Loss: 9925029888.000.. \n",
      "Epoch: 353/1000..  Training Loss: 9381751139.556..  Test Loss: 10461290496.000.. \n",
      "Epoch: 354/1000..  Training Loss: 9372709262.222..  Test Loss: 10047071232.000.. \n",
      "Epoch: 355/1000..  Training Loss: 9361583473.778..  Test Loss: 9968008192.000.. \n",
      "Epoch: 356/1000..  Training Loss: 9319981681.778..  Test Loss: 10084838400.000.. \n",
      "Epoch: 357/1000..  Training Loss: 9334027079.111..  Test Loss: 10129536000.000.. \n",
      "Epoch: 358/1000..  Training Loss: 9317776504.889..  Test Loss: 10189755392.000.. \n",
      "Epoch: 359/1000..  Training Loss: 9306254080.000..  Test Loss: 12745791488.000.. \n",
      "Epoch: 360/1000..  Training Loss: 9303598755.556..  Test Loss: 10426340352.000.. \n",
      "Epoch: 361/1000..  Training Loss: 9283913358.222..  Test Loss: 10294983680.000.. \n",
      "Epoch: 362/1000..  Training Loss: 9235541091.556..  Test Loss: 9854894080.000.. \n",
      "Epoch: 363/1000..  Training Loss: 9198544597.333..  Test Loss: 10567981056.000.. \n",
      "Epoch: 364/1000..  Training Loss: 9237936682.667..  Test Loss: 10538606592.000.. \n",
      "Epoch: 365/1000..  Training Loss: 9196003640.889..  Test Loss: 9889736704.000.. \n",
      "Epoch: 366/1000..  Training Loss: 9181702656.000..  Test Loss: 10666182656.000.. \n",
      "Epoch: 367/1000..  Training Loss: 9133925504.000..  Test Loss: 9683118080.000.. \n",
      "Epoch: 368/1000..  Training Loss: 9141811015.111..  Test Loss: 9971782656.000.. \n",
      "Epoch: 369/1000..  Training Loss: 9099199075.556..  Test Loss: 9961982976.000.. \n",
      "Epoch: 370/1000..  Training Loss: 9147163790.222..  Test Loss: 10663757824.000.. \n",
      "Epoch: 371/1000..  Training Loss: 9139304064.000..  Test Loss: 10489074688.000.. \n",
      "Epoch: 372/1000..  Training Loss: 9081356359.111..  Test Loss: 10639315968.000.. \n",
      "Epoch: 373/1000..  Training Loss: 9089870833.778..  Test Loss: 10325604352.000.. \n",
      "Epoch: 374/1000..  Training Loss: 8996385521.778..  Test Loss: 10333044736.000.. \n",
      "Epoch: 375/1000..  Training Loss: 9017849927.111..  Test Loss: 10880644096.000.. \n",
      "Epoch: 376/1000..  Training Loss: 8954844245.333..  Test Loss: 9977558016.000.. \n",
      "Epoch: 377/1000..  Training Loss: 8965105920.000..  Test Loss: 9745128448.000.. \n",
      "Epoch: 378/1000..  Training Loss: 8974121998.222..  Test Loss: 9597483008.000.. \n",
      "Epoch: 379/1000..  Training Loss: 8959975950.222..  Test Loss: 9942338560.000.. \n",
      "Epoch: 380/1000..  Training Loss: 8974743623.111..  Test Loss: 9669626880.000.. \n",
      "Epoch: 381/1000..  Training Loss: 8914184632.889..  Test Loss: 10056735744.000.. \n",
      "Epoch: 382/1000..  Training Loss: 8907413034.667..  Test Loss: 10118714368.000.. \n",
      "Epoch: 383/1000..  Training Loss: 8843570289.778..  Test Loss: 12358061056.000.. \n",
      "Epoch: 384/1000..  Training Loss: 8870843121.778..  Test Loss: 10474757120.000.. \n",
      "Epoch: 385/1000..  Training Loss: 8814335800.889..  Test Loss: 9855279104.000.. \n",
      "Epoch: 386/1000..  Training Loss: 8849169664.000..  Test Loss: 10537374720.000.. \n",
      "Epoch: 387/1000..  Training Loss: 8897971214.222..  Test Loss: 9831613440.000.. \n",
      "Epoch: 388/1000..  Training Loss: 8787135744.000..  Test Loss: 10262014976.000.. \n",
      "Epoch: 389/1000..  Training Loss: 8788697386.667..  Test Loss: 9540606976.000.. \n",
      "Epoch: 390/1000..  Training Loss: 8789966336.000..  Test Loss: 10903598080.000.. \n",
      "Epoch: 391/1000..  Training Loss: 8770509767.111..  Test Loss: 9952293888.000.. \n",
      "Epoch: 392/1000..  Training Loss: 8752109226.667..  Test Loss: 10491225088.000.. \n",
      "Epoch: 393/1000..  Training Loss: 8762188103.111..  Test Loss: 9817425920.000.. \n",
      "Epoch: 394/1000..  Training Loss: 8734373034.667..  Test Loss: 9258208256.000.. \n",
      "Epoch: 395/1000..  Training Loss: 8717779768.889..  Test Loss: 9504795648.000.. \n",
      "Epoch: 396/1000..  Training Loss: 8674804800.000..  Test Loss: 9503834112.000.. \n",
      "Epoch: 397/1000..  Training Loss: 8617226311.111..  Test Loss: 9348174848.000.. \n",
      "Epoch: 398/1000..  Training Loss: 8666885987.556..  Test Loss: 11151676416.000.. \n",
      "Epoch: 399/1000..  Training Loss: 8642889450.667..  Test Loss: 10000648192.000.. \n",
      "Epoch: 400/1000..  Training Loss: 8555558997.333..  Test Loss: 10066392064.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 401/1000..  Training Loss: 8602632533.333..  Test Loss: 10381854720.000.. \n",
      "Epoch: 402/1000..  Training Loss: 8538287004.444..  Test Loss: 8930579456.000.. \n",
      "Epoch: 403/1000..  Training Loss: 8499745450.667..  Test Loss: 8998200320.000.. \n",
      "Epoch: 404/1000..  Training Loss: 8520320824.889..  Test Loss: 8773865472.000.. \n",
      "Epoch: 405/1000..  Training Loss: 8541368135.111..  Test Loss: 8540137472.000.. \n",
      "Epoch: 406/1000..  Training Loss: 8477653617.778..  Test Loss: 8301683712.000.. \n",
      "Epoch: 407/1000..  Training Loss: 8416057927.111..  Test Loss: 8248131584.000.. \n",
      "Epoch: 408/1000..  Training Loss: 8425933724.444..  Test Loss: 8278899712.000.. \n",
      "Epoch: 409/1000..  Training Loss: 8456316572.444..  Test Loss: 7837558784.000.. \n",
      "Epoch: 410/1000..  Training Loss: 8394845297.778..  Test Loss: 8656449536.000.. \n",
      "Epoch: 411/1000..  Training Loss: 8366771200.000..  Test Loss: 7808913920.000.. \n",
      "Epoch: 412/1000..  Training Loss: 8364743096.889..  Test Loss: 8063042560.000.. \n",
      "Epoch: 413/1000..  Training Loss: 8337948295.111..  Test Loss: 7998789120.000.. \n",
      "Epoch: 414/1000..  Training Loss: 8324162979.556..  Test Loss: 9194777600.000.. \n",
      "Epoch: 415/1000..  Training Loss: 8314246705.778..  Test Loss: 8158045184.000.. \n",
      "Epoch: 416/1000..  Training Loss: 8304053802.667..  Test Loss: 7702563328.000.. \n",
      "Epoch: 417/1000..  Training Loss: 8289565440.000..  Test Loss: 8340150784.000.. \n",
      "Epoch: 418/1000..  Training Loss: 8266118691.556..  Test Loss: 9187118080.000.. \n",
      "Epoch: 419/1000..  Training Loss: 8244813838.222..  Test Loss: 8153393664.000.. \n",
      "Epoch: 420/1000..  Training Loss: 8205280753.778..  Test Loss: 8075512320.000.. \n",
      "Epoch: 421/1000..  Training Loss: 8163449272.889..  Test Loss: 8050087424.000.. \n",
      "Epoch: 422/1000..  Training Loss: 8197687324.444..  Test Loss: 7699048448.000.. \n",
      "Epoch: 423/1000..  Training Loss: 8168034631.111..  Test Loss: 8557332992.000.. \n",
      "Epoch: 424/1000..  Training Loss: 8200396302.222..  Test Loss: 7787337216.000.. \n",
      "Epoch: 425/1000..  Training Loss: 8120300266.667..  Test Loss: 8132493312.000.. \n",
      "Epoch: 426/1000..  Training Loss: 8169195520.000..  Test Loss: 7587888640.000.. \n",
      "Epoch: 427/1000..  Training Loss: 8108255168.000..  Test Loss: 7849566208.000.. \n",
      "Epoch: 428/1000..  Training Loss: 8075229226.667..  Test Loss: 10604945408.000.. \n",
      "Epoch: 429/1000..  Training Loss: 8019330552.889..  Test Loss: 7494893568.000.. \n",
      "Epoch: 430/1000..  Training Loss: 8025640732.444..  Test Loss: 7523526144.000.. \n",
      "Epoch: 431/1000..  Training Loss: 8073380536.889..  Test Loss: 8301820928.000.. \n",
      "Epoch: 432/1000..  Training Loss: 8079254044.444..  Test Loss: 9365273600.000.. \n",
      "Epoch: 433/1000..  Training Loss: 8007792910.222..  Test Loss: 8064043008.000.. \n",
      "Epoch: 434/1000..  Training Loss: 7959328682.667..  Test Loss: 8032284160.000.. \n",
      "Epoch: 435/1000..  Training Loss: 7933986780.444..  Test Loss: 7272155136.000.. \n",
      "Epoch: 436/1000..  Training Loss: 7932466645.333..  Test Loss: 8181283840.000.. \n",
      "Epoch: 437/1000..  Training Loss: 7998772928.000..  Test Loss: 7691560960.000.. \n",
      "Epoch: 438/1000..  Training Loss: 7930412138.667..  Test Loss: 7849982976.000.. \n",
      "Epoch: 439/1000..  Training Loss: 7923233294.222..  Test Loss: 7449954816.000.. \n",
      "Epoch: 440/1000..  Training Loss: 7911960320.000..  Test Loss: 7729463296.000.. \n",
      "Epoch: 441/1000..  Training Loss: 7873985322.667..  Test Loss: 8677016576.000.. \n",
      "Epoch: 442/1000..  Training Loss: 7850057450.667..  Test Loss: 7506783744.000.. \n",
      "Epoch: 443/1000..  Training Loss: 7886921585.778..  Test Loss: 8185774080.000.. \n",
      "Epoch: 444/1000..  Training Loss: 7830922261.333..  Test Loss: 7500605952.000.. \n",
      "Epoch: 445/1000..  Training Loss: 7814366051.556..  Test Loss: 7382194688.000.. \n",
      "Epoch: 446/1000..  Training Loss: 7787780451.556..  Test Loss: 7101126656.000.. \n",
      "Epoch: 447/1000..  Training Loss: 7797913457.778..  Test Loss: 7829950976.000.. \n",
      "Epoch: 448/1000..  Training Loss: 7723462784.000..  Test Loss: 7736865280.000.. \n",
      "Epoch: 449/1000..  Training Loss: 7764917120.000..  Test Loss: 7663925760.000.. \n",
      "Epoch: 450/1000..  Training Loss: 7755344042.667..  Test Loss: 7269844992.000.. \n",
      "Epoch: 451/1000..  Training Loss: 7708035285.333..  Test Loss: 7312923648.000.. \n",
      "Epoch: 452/1000..  Training Loss: 7671507584.000..  Test Loss: 8063240704.000.. \n",
      "Epoch: 453/1000..  Training Loss: 7662131911.111..  Test Loss: 7060360704.000.. \n",
      "Epoch: 454/1000..  Training Loss: 7629687552.000..  Test Loss: 7165154304.000.. \n",
      "Epoch: 455/1000..  Training Loss: 7707206200.889..  Test Loss: 7657491968.000.. \n",
      "Epoch: 456/1000..  Training Loss: 7615653162.667..  Test Loss: 7611779584.000.. \n",
      "Epoch: 457/1000..  Training Loss: 7640464768.000..  Test Loss: 7215963136.000.. \n",
      "Epoch: 458/1000..  Training Loss: 7600395996.444..  Test Loss: 8372487168.000.. \n",
      "Epoch: 459/1000..  Training Loss: 7528906851.556..  Test Loss: 7066499584.000.. \n",
      "Epoch: 460/1000..  Training Loss: 7530028600.889..  Test Loss: 7133287424.000.. \n",
      "Epoch: 461/1000..  Training Loss: 7527605127.111..  Test Loss: 6672749568.000.. \n",
      "Epoch: 462/1000..  Training Loss: 7522084736.000..  Test Loss: 6935930880.000.. \n",
      "Epoch: 463/1000..  Training Loss: 7502324103.111..  Test Loss: 6944956928.000.. \n",
      "Epoch: 464/1000..  Training Loss: 7500257479.111..  Test Loss: 7272115712.000.. \n",
      "Epoch: 465/1000..  Training Loss: 7503160476.444..  Test Loss: 7698242560.000.. \n",
      "Epoch: 466/1000..  Training Loss: 7397291633.778..  Test Loss: 6824023040.000.. \n",
      "Epoch: 467/1000..  Training Loss: 7404582506.667..  Test Loss: 6935147008.000.. \n",
      "Epoch: 468/1000..  Training Loss: 7441300728.889..  Test Loss: 6780633088.000.. \n",
      "Epoch: 469/1000..  Training Loss: 7409385799.111..  Test Loss: 7200324608.000.. \n",
      "Epoch: 470/1000..  Training Loss: 7389297009.778..  Test Loss: 6723081728.000.. \n",
      "Epoch: 471/1000..  Training Loss: 7403468942.222..  Test Loss: 7295162368.000.. \n",
      "Epoch: 472/1000..  Training Loss: 7376869909.333..  Test Loss: 8284709888.000.. \n",
      "Epoch: 473/1000..  Training Loss: 7339039317.333..  Test Loss: 6772552704.000.. \n",
      "Epoch: 474/1000..  Training Loss: 7346013340.444..  Test Loss: 6967494144.000.. \n",
      "Epoch: 475/1000..  Training Loss: 7326051555.556..  Test Loss: 6853306368.000.. \n",
      "Epoch: 476/1000..  Training Loss: 7254774165.333..  Test Loss: 6679728128.000.. \n",
      "Epoch: 477/1000..  Training Loss: 7235523463.111..  Test Loss: 6488901632.000.. \n",
      "Epoch: 478/1000..  Training Loss: 7222529713.778..  Test Loss: 8194503168.000.. \n",
      "Epoch: 479/1000..  Training Loss: 7184784362.667..  Test Loss: 6589477376.000.. \n",
      "Epoch: 480/1000..  Training Loss: 7243197020.444..  Test Loss: 7020835328.000.. \n",
      "Epoch: 481/1000..  Training Loss: 7177827640.889..  Test Loss: 6821417984.000.. \n",
      "Epoch: 482/1000..  Training Loss: 7160675520.000..  Test Loss: 6478285824.000.. \n",
      "Epoch: 483/1000..  Training Loss: 7148428942.222..  Test Loss: 8233554432.000.. \n",
      "Epoch: 484/1000..  Training Loss: 7131789162.667..  Test Loss: 6572086272.000.. \n",
      "Epoch: 485/1000..  Training Loss: 7092487594.667..  Test Loss: 8194189312.000.. \n",
      "Epoch: 486/1000..  Training Loss: 7095064156.444..  Test Loss: 7777954304.000.. \n",
      "Epoch: 487/1000..  Training Loss: 7097879544.889..  Test Loss: 6816532480.000.. \n",
      "Epoch: 488/1000..  Training Loss: 7074911402.667..  Test Loss: 7148130816.000.. \n",
      "Epoch: 489/1000..  Training Loss: 7083499313.778..  Test Loss: 8241154048.000.. \n",
      "Epoch: 490/1000..  Training Loss: 7095378040.889..  Test Loss: 7948680192.000.. \n",
      "Epoch: 491/1000..  Training Loss: 7007924565.333..  Test Loss: 6777036800.000.. \n",
      "Epoch: 492/1000..  Training Loss: 7037932224.000..  Test Loss: 7496972800.000.. \n",
      "Epoch: 493/1000..  Training Loss: 6993627164.444..  Test Loss: 7719580160.000.. \n",
      "Epoch: 494/1000..  Training Loss: 7049335296.000..  Test Loss: 6941481472.000.. \n",
      "Epoch: 495/1000..  Training Loss: 7032387256.889..  Test Loss: 6364012032.000.. \n",
      "Epoch: 496/1000..  Training Loss: 6945705521.778..  Test Loss: 6723832320.000.. \n",
      "Epoch: 497/1000..  Training Loss: 6893985827.556..  Test Loss: 6483578880.000.. \n",
      "Epoch: 498/1000..  Training Loss: 6934075605.333..  Test Loss: 6339722240.000.. \n",
      "Epoch: 499/1000..  Training Loss: 6933291662.222..  Test Loss: 8380973056.000.. \n",
      "Epoch: 500/1000..  Training Loss: 6881841852.444..  Test Loss: 6914451456.000.. \n",
      "Epoch: 501/1000..  Training Loss: 6886463032.889..  Test Loss: 6513068544.000.. \n",
      "Epoch: 502/1000..  Training Loss: 6836878179.556..  Test Loss: 6845128704.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 503/1000..  Training Loss: 6894603811.556..  Test Loss: 6256835072.000.. \n",
      "Epoch: 504/1000..  Training Loss: 6815743992.889..  Test Loss: 6263619584.000.. \n",
      "Epoch: 505/1000..  Training Loss: 6835480568.889..  Test Loss: 6992764928.000.. \n",
      "Epoch: 506/1000..  Training Loss: 6800456504.889..  Test Loss: 6808314880.000.. \n",
      "Epoch: 507/1000..  Training Loss: 6755225564.444..  Test Loss: 7072586240.000.. \n",
      "Epoch: 508/1000..  Training Loss: 6735828821.333..  Test Loss: 7481572864.000.. \n",
      "Epoch: 509/1000..  Training Loss: 6837954481.778..  Test Loss: 7383402496.000.. \n",
      "Epoch: 510/1000..  Training Loss: 6743518798.222..  Test Loss: 7489899008.000.. \n",
      "Epoch: 511/1000..  Training Loss: 6711986001.778..  Test Loss: 6457362944.000.. \n",
      "Epoch: 512/1000..  Training Loss: 6718705194.667..  Test Loss: 6292445696.000.. \n",
      "Epoch: 513/1000..  Training Loss: 6718558115.556..  Test Loss: 7519855616.000.. \n",
      "Epoch: 514/1000..  Training Loss: 6721566805.333..  Test Loss: 6918879744.000.. \n",
      "Epoch: 515/1000..  Training Loss: 6672217329.778..  Test Loss: 5941336576.000.. \n",
      "Epoch: 516/1000..  Training Loss: 6769859185.778..  Test Loss: 6280180224.000.. \n",
      "Epoch: 517/1000..  Training Loss: 6627283946.667..  Test Loss: 6998842880.000.. \n",
      "Epoch: 518/1000..  Training Loss: 6621111324.444..  Test Loss: 6481439232.000.. \n",
      "Epoch: 519/1000..  Training Loss: 6597340864.000..  Test Loss: 6072446464.000.. \n",
      "Epoch: 520/1000..  Training Loss: 6620099399.111..  Test Loss: 6544198144.000.. \n",
      "Epoch: 521/1000..  Training Loss: 6659871523.556..  Test Loss: 6179679744.000.. \n",
      "Epoch: 522/1000..  Training Loss: 6558778247.111..  Test Loss: 6444629504.000.. \n",
      "Epoch: 523/1000..  Training Loss: 6596595114.667..  Test Loss: 6184826368.000.. \n",
      "Epoch: 524/1000..  Training Loss: 6563673827.556..  Test Loss: 6927292416.000.. \n",
      "Epoch: 525/1000..  Training Loss: 6528089208.889..  Test Loss: 6317492736.000.. \n",
      "Epoch: 526/1000..  Training Loss: 6449200376.889..  Test Loss: 7700119552.000.. \n",
      "Epoch: 527/1000..  Training Loss: 6539214869.333..  Test Loss: 6733470720.000.. \n",
      "Epoch: 528/1000..  Training Loss: 6487246001.778..  Test Loss: 7121695232.000.. \n",
      "Epoch: 529/1000..  Training Loss: 6522095239.111..  Test Loss: 5906782720.000.. \n",
      "Epoch: 530/1000..  Training Loss: 6502544490.667..  Test Loss: 5903329280.000.. \n",
      "Epoch: 531/1000..  Training Loss: 6539699107.556..  Test Loss: 7032395264.000.. \n",
      "Epoch: 532/1000..  Training Loss: 6461191310.222..  Test Loss: 5918479360.000.. \n",
      "Epoch: 533/1000..  Training Loss: 6458385351.111..  Test Loss: 6302816768.000.. \n",
      "Epoch: 534/1000..  Training Loss: 6366736014.222..  Test Loss: 5912058368.000.. \n",
      "Epoch: 535/1000..  Training Loss: 6402561159.111..  Test Loss: 6097917440.000.. \n",
      "Epoch: 536/1000..  Training Loss: 6377958542.222..  Test Loss: 5860105216.000.. \n",
      "Epoch: 537/1000..  Training Loss: 6428292586.667..  Test Loss: 6595514368.000.. \n",
      "Epoch: 538/1000..  Training Loss: 6398289934.222..  Test Loss: 5845232128.000.. \n",
      "Epoch: 539/1000..  Training Loss: 6343371441.778..  Test Loss: 5802968576.000.. \n",
      "Epoch: 540/1000..  Training Loss: 6351076992.000..  Test Loss: 5893247488.000.. \n",
      "Epoch: 541/1000..  Training Loss: 6323027704.889..  Test Loss: 5801472000.000.. \n",
      "Epoch: 542/1000..  Training Loss: 6269729706.667..  Test Loss: 6266664448.000.. \n",
      "Epoch: 543/1000..  Training Loss: 6346619818.667..  Test Loss: 6152098816.000.. \n",
      "Epoch: 544/1000..  Training Loss: 6298087914.667..  Test Loss: 6357690368.000.. \n",
      "Epoch: 545/1000..  Training Loss: 6316783928.889..  Test Loss: 6089964032.000.. \n",
      "Epoch: 546/1000..  Training Loss: 6239261632.000..  Test Loss: 6686844928.000.. \n",
      "Epoch: 547/1000..  Training Loss: 6257744312.889..  Test Loss: 5946279936.000.. \n",
      "Epoch: 548/1000..  Training Loss: 6221153742.222..  Test Loss: 5639206400.000.. \n",
      "Epoch: 549/1000..  Training Loss: 6279649927.111..  Test Loss: 5614744064.000.. \n",
      "Epoch: 550/1000..  Training Loss: 6225507861.333..  Test Loss: 6554515968.000.. \n",
      "Epoch: 551/1000..  Training Loss: 6144149667.556..  Test Loss: 5678036992.000.. \n",
      "Epoch: 552/1000..  Training Loss: 6144031303.111..  Test Loss: 5672729600.000.. \n",
      "Epoch: 553/1000..  Training Loss: 6116275249.778..  Test Loss: 5533511680.000.. \n",
      "Epoch: 554/1000..  Training Loss: 6136170581.333..  Test Loss: 5722140672.000.. \n",
      "Epoch: 555/1000..  Training Loss: 6144155747.556..  Test Loss: 5454354944.000.. \n",
      "Epoch: 556/1000..  Training Loss: 6120219854.222..  Test Loss: 5842459648.000.. \n",
      "Epoch: 557/1000..  Training Loss: 6137272512.000..  Test Loss: 5551014912.000.. \n",
      "Epoch: 558/1000..  Training Loss: 6105991125.333..  Test Loss: 5658431488.000.. \n",
      "Epoch: 559/1000..  Training Loss: 6115933176.889..  Test Loss: 6078618624.000.. \n",
      "Epoch: 560/1000..  Training Loss: 6120474737.778..  Test Loss: 6055012352.000.. \n",
      "Epoch: 561/1000..  Training Loss: 6044722449.778..  Test Loss: 5418825216.000.. \n",
      "Epoch: 562/1000..  Training Loss: 6090399495.111..  Test Loss: 6043871232.000.. \n",
      "Epoch: 563/1000..  Training Loss: 6021341013.333..  Test Loss: 5615213056.000.. \n",
      "Epoch: 564/1000..  Training Loss: 6024288426.667..  Test Loss: 5625653760.000.. \n",
      "Epoch: 565/1000..  Training Loss: 6056984625.778..  Test Loss: 5671899648.000.. \n",
      "Epoch: 566/1000..  Training Loss: 6021853944.889..  Test Loss: 5791450112.000.. \n",
      "Epoch: 567/1000..  Training Loss: 6017126016.000..  Test Loss: 6436137984.000.. \n",
      "Epoch: 568/1000..  Training Loss: 6045912128.000..  Test Loss: 5453639168.000.. \n",
      "Epoch: 569/1000..  Training Loss: 6001077297.778..  Test Loss: 6332923904.000.. \n",
      "Epoch: 570/1000..  Training Loss: 5967612956.444..  Test Loss: 5288067584.000.. \n",
      "Epoch: 571/1000..  Training Loss: 5948193692.444..  Test Loss: 5464220160.000.. \n",
      "Epoch: 572/1000..  Training Loss: 5985659726.222..  Test Loss: 5862167552.000.. \n",
      "Epoch: 573/1000..  Training Loss: 5910430396.444..  Test Loss: 5425717248.000.. \n",
      "Epoch: 574/1000..  Training Loss: 5899634048.000..  Test Loss: 5983631872.000.. \n",
      "Epoch: 575/1000..  Training Loss: 5853868615.111..  Test Loss: 5691874816.000.. \n",
      "Epoch: 576/1000..  Training Loss: 5909335736.889..  Test Loss: 6106478080.000.. \n",
      "Epoch: 577/1000..  Training Loss: 5864206684.444..  Test Loss: 5367602688.000.. \n",
      "Epoch: 578/1000..  Training Loss: 5887045425.778..  Test Loss: 5654946816.000.. \n",
      "Epoch: 579/1000..  Training Loss: 5896432768.000..  Test Loss: 6938927616.000.. \n",
      "Epoch: 580/1000..  Training Loss: 5819996273.778..  Test Loss: 5241144832.000.. \n",
      "Epoch: 581/1000..  Training Loss: 5772849201.778..  Test Loss: 5358307328.000.. \n",
      "Epoch: 582/1000..  Training Loss: 5798995875.556..  Test Loss: 6166452736.000.. \n",
      "Epoch: 583/1000..  Training Loss: 5811367082.667..  Test Loss: 5411682816.000.. \n",
      "Epoch: 584/1000..  Training Loss: 5711864647.111..  Test Loss: 5359403008.000.. \n",
      "Epoch: 585/1000..  Training Loss: 5781203089.778..  Test Loss: 5204380160.000.. \n",
      "Epoch: 586/1000..  Training Loss: 5855485575.111..  Test Loss: 5219803136.000.. \n",
      "Epoch: 587/1000..  Training Loss: 5807098119.111..  Test Loss: 5151347712.000.. \n",
      "Epoch: 588/1000..  Training Loss: 5791965649.778..  Test Loss: 7760111616.000.. \n",
      "Epoch: 589/1000..  Training Loss: 5773919928.889..  Test Loss: 5014743040.000.. \n",
      "Epoch: 590/1000..  Training Loss: 5699855360.000..  Test Loss: 5506878976.000.. \n",
      "Epoch: 591/1000..  Training Loss: 5734237639.111..  Test Loss: 5168513536.000.. \n",
      "Epoch: 592/1000..  Training Loss: 5694655424.000..  Test Loss: 5007473152.000.. \n",
      "Epoch: 593/1000..  Training Loss: 5736445048.889..  Test Loss: 5043874304.000.. \n",
      "Epoch: 594/1000..  Training Loss: 5728589233.778..  Test Loss: 5157954560.000.. \n",
      "Epoch: 595/1000..  Training Loss: 5760249230.222..  Test Loss: 5225616384.000.. \n",
      "Epoch: 596/1000..  Training Loss: 5698100316.444..  Test Loss: 5135712256.000.. \n",
      "Epoch: 597/1000..  Training Loss: 5727728348.444..  Test Loss: 5520223744.000.. \n",
      "Epoch: 598/1000..  Training Loss: 5633906951.111..  Test Loss: 5177272832.000.. \n",
      "Epoch: 599/1000..  Training Loss: 5645356963.556..  Test Loss: 4995881472.000.. \n",
      "Epoch: 600/1000..  Training Loss: 5662631736.889..  Test Loss: 5599968256.000.. \n",
      "Epoch: 601/1000..  Training Loss: 5695648213.333..  Test Loss: 5132800000.000.. \n",
      "Epoch: 602/1000..  Training Loss: 5587460849.778..  Test Loss: 5946373632.000.. \n",
      "Epoch: 603/1000..  Training Loss: 5639409344.000..  Test Loss: 5289574400.000.. \n",
      "Epoch: 604/1000..  Training Loss: 5661077315.556..  Test Loss: 4863992832.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 605/1000..  Training Loss: 5571366983.111..  Test Loss: 5233273856.000.. \n",
      "Epoch: 606/1000..  Training Loss: 5694629212.444..  Test Loss: 4972545536.000.. \n",
      "Epoch: 607/1000..  Training Loss: 5631820103.111..  Test Loss: 4846395904.000.. \n",
      "Epoch: 608/1000..  Training Loss: 5514444846.222..  Test Loss: 4929400320.000.. \n",
      "Epoch: 609/1000..  Training Loss: 5520405002.667..  Test Loss: 5135711744.000.. \n",
      "Epoch: 610/1000..  Training Loss: 5629641905.778..  Test Loss: 4880004608.000.. \n",
      "Epoch: 611/1000..  Training Loss: 5550041308.444..  Test Loss: 4732630016.000.. \n",
      "Epoch: 612/1000..  Training Loss: 5564513976.889..  Test Loss: 4738108928.000.. \n",
      "Epoch: 613/1000..  Training Loss: 5478688974.222..  Test Loss: 5225014272.000.. \n",
      "Epoch: 614/1000..  Training Loss: 5549998286.222..  Test Loss: 5001382400.000.. \n",
      "Epoch: 615/1000..  Training Loss: 5410617777.778..  Test Loss: 4964465664.000.. \n",
      "Epoch: 616/1000..  Training Loss: 5521875832.889..  Test Loss: 5063435264.000.. \n",
      "Epoch: 617/1000..  Training Loss: 5535831061.333..  Test Loss: 4862772736.000.. \n",
      "Epoch: 618/1000..  Training Loss: 5508842794.667..  Test Loss: 5367083008.000.. \n",
      "Epoch: 619/1000..  Training Loss: 5490765646.222..  Test Loss: 4716527104.000.. \n",
      "Epoch: 620/1000..  Training Loss: 5484669902.222..  Test Loss: 4900940288.000.. \n",
      "Epoch: 621/1000..  Training Loss: 5478045674.667..  Test Loss: 5503428608.000.. \n",
      "Epoch: 622/1000..  Training Loss: 5461003825.778..  Test Loss: 6080856064.000.. \n",
      "Epoch: 623/1000..  Training Loss: 5367860256.000..  Test Loss: 4665224192.000.. \n",
      "Epoch: 624/1000..  Training Loss: 5394948519.111..  Test Loss: 5489456640.000.. \n",
      "Epoch: 625/1000..  Training Loss: 5417210090.667..  Test Loss: 5049166336.000.. \n",
      "Epoch: 626/1000..  Training Loss: 5354226695.111..  Test Loss: 4704049664.000.. \n",
      "Epoch: 627/1000..  Training Loss: 5451866204.444..  Test Loss: 4593420800.000.. \n",
      "Epoch: 628/1000..  Training Loss: 5361699029.333..  Test Loss: 4825713664.000.. \n",
      "Epoch: 629/1000..  Training Loss: 5353138432.000..  Test Loss: 5567080960.000.. \n",
      "Epoch: 630/1000..  Training Loss: 5464362816.000..  Test Loss: 5116459008.000.. \n",
      "Epoch: 631/1000..  Training Loss: 5306128590.222..  Test Loss: 6648650240.000.. \n",
      "Epoch: 632/1000..  Training Loss: 5317012316.444..  Test Loss: 4809265152.000.. \n",
      "Epoch: 633/1000..  Training Loss: 5391465009.778..  Test Loss: 4798311936.000.. \n",
      "Epoch: 634/1000..  Training Loss: 5267235328.000..  Test Loss: 4925577216.000.. \n",
      "Epoch: 635/1000..  Training Loss: 5380781560.889..  Test Loss: 4508678656.000.. \n",
      "Epoch: 636/1000..  Training Loss: 5346010033.778..  Test Loss: 4664384512.000.. \n",
      "Epoch: 637/1000..  Training Loss: 5318916167.111..  Test Loss: 4886743040.000.. \n",
      "Epoch: 638/1000..  Training Loss: 5310657468.444..  Test Loss: 4692563456.000.. \n",
      "Epoch: 639/1000..  Training Loss: 5298229347.556..  Test Loss: 4775257088.000.. \n",
      "Epoch: 640/1000..  Training Loss: 5368785976.889..  Test Loss: 4476063232.000.. \n",
      "Epoch: 641/1000..  Training Loss: 5237708885.333..  Test Loss: 4524503040.000.. \n",
      "Epoch: 642/1000..  Training Loss: 5344605354.667..  Test Loss: 5456432640.000.. \n",
      "Epoch: 643/1000..  Training Loss: 5269926336.000..  Test Loss: 4474820096.000.. \n",
      "Epoch: 644/1000..  Training Loss: 5313729400.889..  Test Loss: 4563339264.000.. \n",
      "Epoch: 645/1000..  Training Loss: 5261054933.333..  Test Loss: 5738273280.000.. \n",
      "Epoch: 646/1000..  Training Loss: 5246795303.111..  Test Loss: 4539830272.000.. \n",
      "Epoch: 647/1000..  Training Loss: 5283287836.444..  Test Loss: 4764643328.000.. \n",
      "Epoch: 648/1000..  Training Loss: 5284420544.000..  Test Loss: 5058977280.000.. \n",
      "Epoch: 649/1000..  Training Loss: 5245296551.111..  Test Loss: 4961547264.000.. \n",
      "Epoch: 650/1000..  Training Loss: 5273222983.111..  Test Loss: 5024216576.000.. \n",
      "Epoch: 651/1000..  Training Loss: 5191106062.222..  Test Loss: 4564181504.000.. \n",
      "Epoch: 652/1000..  Training Loss: 5261631715.556..  Test Loss: 5871519232.000.. \n",
      "Epoch: 653/1000..  Training Loss: 5152806229.333..  Test Loss: 4459435520.000.. \n",
      "Epoch: 654/1000..  Training Loss: 5209594830.222..  Test Loss: 4381591552.000.. \n",
      "Epoch: 655/1000..  Training Loss: 5186507704.889..  Test Loss: 4352457216.000.. \n",
      "Epoch: 656/1000..  Training Loss: 5258709383.111..  Test Loss: 4513332224.000.. \n",
      "Epoch: 657/1000..  Training Loss: 5168039712.000..  Test Loss: 4701623296.000.. \n",
      "Epoch: 658/1000..  Training Loss: 5175172320.000..  Test Loss: 4401010176.000.. \n",
      "Epoch: 659/1000..  Training Loss: 5167514232.889..  Test Loss: 4868498432.000.. \n",
      "Epoch: 660/1000..  Training Loss: 5200155384.889..  Test Loss: 4419907072.000.. \n",
      "Epoch: 661/1000..  Training Loss: 5156804700.444..  Test Loss: 4565454336.000.. \n",
      "Epoch: 662/1000..  Training Loss: 5145214008.889..  Test Loss: 5198504960.000.. \n",
      "Epoch: 663/1000..  Training Loss: 5178126812.444..  Test Loss: 4442630144.000.. \n",
      "Epoch: 664/1000..  Training Loss: 5190230051.556..  Test Loss: 4522789888.000.. \n",
      "Epoch: 665/1000..  Training Loss: 5115478343.111..  Test Loss: 4398645248.000.. \n",
      "Epoch: 666/1000..  Training Loss: 5199340629.333..  Test Loss: 4560531968.000.. \n",
      "Epoch: 667/1000..  Training Loss: 5145192938.667..  Test Loss: 4787224576.000.. \n",
      "Epoch: 668/1000..  Training Loss: 5098091214.222..  Test Loss: 4216376064.000.. \n",
      "Epoch: 669/1000..  Training Loss: 5117178545.778..  Test Loss: 4452658176.000.. \n",
      "Epoch: 670/1000..  Training Loss: 5096252928.000..  Test Loss: 4413530112.000.. \n",
      "Epoch: 671/1000..  Training Loss: 5109760746.667..  Test Loss: 4355036672.000.. \n",
      "Epoch: 672/1000..  Training Loss: 5014060309.333..  Test Loss: 4705320960.000.. \n",
      "Epoch: 673/1000..  Training Loss: 5074337891.556..  Test Loss: 4303123456.000.. \n",
      "Epoch: 674/1000..  Training Loss: 5075127936.000..  Test Loss: 5391427584.000.. \n",
      "Epoch: 675/1000..  Training Loss: 5075695004.444..  Test Loss: 4343612416.000.. \n",
      "Epoch: 676/1000..  Training Loss: 5046010389.333..  Test Loss: 4784215552.000.. \n",
      "Epoch: 677/1000..  Training Loss: 5098763484.444..  Test Loss: 4950063616.000.. \n",
      "Epoch: 678/1000..  Training Loss: 5049687573.333..  Test Loss: 4408163840.000.. \n",
      "Epoch: 679/1000..  Training Loss: 5084478300.444..  Test Loss: 4194661632.000.. \n",
      "Epoch: 680/1000..  Training Loss: 5071032661.333..  Test Loss: 4273151488.000.. \n",
      "Epoch: 681/1000..  Training Loss: 5067716693.333..  Test Loss: 4984499712.000.. \n",
      "Epoch: 682/1000..  Training Loss: 5012836906.667..  Test Loss: 5449001472.000.. \n",
      "Epoch: 683/1000..  Training Loss: 5063721795.556..  Test Loss: 4270058240.000.. \n",
      "Epoch: 684/1000..  Training Loss: 4993323847.111..  Test Loss: 4164700928.000.. \n",
      "Epoch: 685/1000..  Training Loss: 5016414890.667..  Test Loss: 4098077184.000.. \n",
      "Epoch: 686/1000..  Training Loss: 4961358510.222..  Test Loss: 4072889600.000.. \n",
      "Epoch: 687/1000..  Training Loss: 4994782144.000..  Test Loss: 4295239680.000.. \n",
      "Epoch: 688/1000..  Training Loss: 5040883896.889..  Test Loss: 4133338368.000.. \n",
      "Epoch: 689/1000..  Training Loss: 4986835384.889..  Test Loss: 4123621632.000.. \n",
      "Epoch: 690/1000..  Training Loss: 5006540977.778..  Test Loss: 4092284160.000.. \n",
      "Epoch: 691/1000..  Training Loss: 5010729934.222..  Test Loss: 4112189696.000.. \n",
      "Epoch: 692/1000..  Training Loss: 5027389866.667..  Test Loss: 4513589760.000.. \n",
      "Epoch: 693/1000..  Training Loss: 4975233351.111..  Test Loss: 4154191872.000.. \n",
      "Epoch: 694/1000..  Training Loss: 4990200974.222..  Test Loss: 4019201024.000.. \n",
      "Epoch: 695/1000..  Training Loss: 5028964263.111..  Test Loss: 6427767296.000.. \n",
      "Epoch: 696/1000..  Training Loss: 4965437674.667..  Test Loss: 4455258112.000.. \n",
      "Epoch: 697/1000..  Training Loss: 4945467157.333..  Test Loss: 4033632000.000.. \n",
      "Epoch: 698/1000..  Training Loss: 4971512981.333..  Test Loss: 4043970816.000.. \n",
      "Epoch: 699/1000..  Training Loss: 4910916096.000..  Test Loss: 4377033216.000.. \n",
      "Epoch: 700/1000..  Training Loss: 4956418766.222..  Test Loss: 4722561536.000.. \n",
      "Epoch: 701/1000..  Training Loss: 4974286464.000..  Test Loss: 4346700288.000.. \n",
      "Epoch: 702/1000..  Training Loss: 4927718588.444..  Test Loss: 4012909568.000.. \n",
      "Epoch: 703/1000..  Training Loss: 4858594496.000..  Test Loss: 4795885568.000.. \n",
      "Epoch: 704/1000..  Training Loss: 4917123420.444..  Test Loss: 4134681856.000.. \n",
      "Epoch: 705/1000..  Training Loss: 4944465735.111..  Test Loss: 3933299968.000.. \n",
      "Epoch: 706/1000..  Training Loss: 4917327192.889..  Test Loss: 4056177920.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 707/1000..  Training Loss: 4893955143.111..  Test Loss: 4613108224.000.. \n",
      "Epoch: 708/1000..  Training Loss: 4864035214.222..  Test Loss: 4005488896.000.. \n",
      "Epoch: 709/1000..  Training Loss: 4845178442.667..  Test Loss: 5176556544.000.. \n",
      "Epoch: 710/1000..  Training Loss: 4907919587.556..  Test Loss: 4162784512.000.. \n",
      "Epoch: 711/1000..  Training Loss: 4911491832.889..  Test Loss: 4305142784.000.. \n",
      "Epoch: 712/1000..  Training Loss: 4897846375.111..  Test Loss: 4620808704.000.. \n",
      "Epoch: 713/1000..  Training Loss: 4845369038.222..  Test Loss: 4116489984.000.. \n",
      "Epoch: 714/1000..  Training Loss: 4829443690.667..  Test Loss: 4012472064.000.. \n",
      "Epoch: 715/1000..  Training Loss: 4869288888.889..  Test Loss: 4546700288.000.. \n",
      "Epoch: 716/1000..  Training Loss: 4868882119.111..  Test Loss: 5774785024.000.. \n",
      "Epoch: 717/1000..  Training Loss: 4882541767.111..  Test Loss: 3890718976.000.. \n",
      "Epoch: 718/1000..  Training Loss: 4848467712.000..  Test Loss: 4008094976.000.. \n",
      "Epoch: 719/1000..  Training Loss: 4797677223.111..  Test Loss: 4350712320.000.. \n",
      "Epoch: 720/1000..  Training Loss: 4895968775.111..  Test Loss: 4257756160.000.. \n",
      "Epoch: 721/1000..  Training Loss: 4860923740.444..  Test Loss: 4077827840.000.. \n",
      "Epoch: 722/1000..  Training Loss: 4870891178.667..  Test Loss: 4375442432.000.. \n",
      "Epoch: 723/1000..  Training Loss: 4811845432.889..  Test Loss: 4048528640.000.. \n",
      "Epoch: 724/1000..  Training Loss: 4838039950.222..  Test Loss: 4169017088.000.. \n",
      "Epoch: 725/1000..  Training Loss: 4911819441.778..  Test Loss: 3819188736.000.. \n",
      "Epoch: 726/1000..  Training Loss: 4895737656.889..  Test Loss: 3807068672.000.. \n",
      "Epoch: 727/1000..  Training Loss: 4849123107.556..  Test Loss: 4181347840.000.. \n",
      "Epoch: 728/1000..  Training Loss: 4858416949.333..  Test Loss: 3906823424.000.. \n",
      "Epoch: 729/1000..  Training Loss: 4853131121.778..  Test Loss: 4305526784.000.. \n",
      "Epoch: 730/1000..  Training Loss: 4833262464.000..  Test Loss: 3930802432.000.. \n",
      "Epoch: 731/1000..  Training Loss: 4808056832.000..  Test Loss: 4090908160.000.. \n",
      "Epoch: 732/1000..  Training Loss: 4808659790.222..  Test Loss: 4088721920.000.. \n",
      "Epoch: 733/1000..  Training Loss: 4802648910.222..  Test Loss: 3841677568.000.. \n",
      "Epoch: 734/1000..  Training Loss: 4880668195.556..  Test Loss: 3761798400.000.. \n",
      "Epoch: 735/1000..  Training Loss: 4823253646.222..  Test Loss: 4168784128.000.. \n",
      "Epoch: 736/1000..  Training Loss: 4749260216.889..  Test Loss: 4249801216.000.. \n",
      "Epoch: 737/1000..  Training Loss: 4827738033.778..  Test Loss: 4199686656.000.. \n",
      "Epoch: 738/1000..  Training Loss: 4781206378.667..  Test Loss: 3829568768.000.. \n",
      "Epoch: 739/1000..  Training Loss: 4861617251.556..  Test Loss: 6391924736.000.. \n",
      "Epoch: 740/1000..  Training Loss: 4783832526.222..  Test Loss: 4465449472.000.. \n",
      "Epoch: 741/1000..  Training Loss: 4800409539.556..  Test Loss: 3974852608.000.. \n",
      "Epoch: 742/1000..  Training Loss: 4871070819.556..  Test Loss: 6731295232.000.. \n",
      "Epoch: 743/1000..  Training Loss: 4769190769.778..  Test Loss: 3783656960.000.. \n",
      "Epoch: 744/1000..  Training Loss: 4813377194.667..  Test Loss: 5346769920.000.. \n",
      "Epoch: 745/1000..  Training Loss: 4776993461.333..  Test Loss: 3851239424.000.. \n",
      "Epoch: 746/1000..  Training Loss: 4792234300.444..  Test Loss: 3890935552.000.. \n",
      "Epoch: 747/1000..  Training Loss: 4852846716.444..  Test Loss: 5676664832.000.. \n",
      "Epoch: 748/1000..  Training Loss: 4822846947.556..  Test Loss: 4005831680.000.. \n",
      "Epoch: 749/1000..  Training Loss: 4790612060.444..  Test Loss: 5754935808.000.. \n",
      "Epoch: 750/1000..  Training Loss: 4735119182.222..  Test Loss: 5132971008.000.. \n",
      "Epoch: 751/1000..  Training Loss: 4813922901.333..  Test Loss: 4247289856.000.. \n",
      "Epoch: 752/1000..  Training Loss: 4817008903.111..  Test Loss: 3673165824.000.. \n",
      "Epoch: 753/1000..  Training Loss: 4820653127.111..  Test Loss: 3783515648.000.. \n",
      "Epoch: 754/1000..  Training Loss: 4824222215.111..  Test Loss: 3853794816.000.. \n",
      "Epoch: 755/1000..  Training Loss: 4758996017.778..  Test Loss: 3903339264.000.. \n",
      "Epoch: 756/1000..  Training Loss: 4806897184.000..  Test Loss: 4119956736.000.. \n",
      "Epoch: 757/1000..  Training Loss: 4789700295.111..  Test Loss: 3970775808.000.. \n",
      "Epoch: 758/1000..  Training Loss: 4796371456.000..  Test Loss: 3800349952.000.. \n",
      "Epoch: 759/1000..  Training Loss: 4741200263.111..  Test Loss: 3720682752.000.. \n",
      "Epoch: 760/1000..  Training Loss: 4832823196.444..  Test Loss: 3855838720.000.. \n",
      "Epoch: 761/1000..  Training Loss: 4787616021.333..  Test Loss: 3698932480.000.. \n",
      "Epoch: 762/1000..  Training Loss: 4767690688.000..  Test Loss: 3997007360.000.. \n",
      "Epoch: 763/1000..  Training Loss: 4768754901.333..  Test Loss: 3921584128.000.. \n",
      "Epoch: 764/1000..  Training Loss: 4806930816.000..  Test Loss: 3752319488.000.. \n",
      "Epoch: 765/1000..  Training Loss: 4766636586.667..  Test Loss: 3742091264.000.. \n",
      "Epoch: 766/1000..  Training Loss: 4751421667.556..  Test Loss: 4213433600.000.. \n",
      "Epoch: 767/1000..  Training Loss: 4734801265.778..  Test Loss: 3702996736.000.. \n",
      "Epoch: 768/1000..  Training Loss: 4796732728.889..  Test Loss: 3776397568.000.. \n",
      "Epoch: 769/1000..  Training Loss: 4788143957.333..  Test Loss: 3732381440.000.. \n",
      "Epoch: 770/1000..  Training Loss: 4756397376.000..  Test Loss: 4185241856.000.. \n",
      "Epoch: 771/1000..  Training Loss: 4763631146.667..  Test Loss: 3664503552.000.. \n",
      "Epoch: 772/1000..  Training Loss: 4751836899.556..  Test Loss: 3710041856.000.. \n",
      "Epoch: 773/1000..  Training Loss: 4743649863.111..  Test Loss: 3660278016.000.. \n",
      "Epoch: 774/1000..  Training Loss: 4723920995.556..  Test Loss: 3761403392.000.. \n",
      "Epoch: 775/1000..  Training Loss: 4781763804.444..  Test Loss: 3694399744.000.. \n",
      "Epoch: 776/1000..  Training Loss: 4707932828.444..  Test Loss: 4026363136.000.. \n",
      "Epoch: 777/1000..  Training Loss: 4778917415.111..  Test Loss: 3734772224.000.. \n",
      "Epoch: 778/1000..  Training Loss: 4743012821.333..  Test Loss: 5022246912.000.. \n",
      "Epoch: 779/1000..  Training Loss: 4694083100.444..  Test Loss: 3859153408.000.. \n",
      "Epoch: 780/1000..  Training Loss: 4731429795.556..  Test Loss: 3830702080.000.. \n",
      "Epoch: 781/1000..  Training Loss: 4788201230.222..  Test Loss: 4153004544.000.. \n",
      "Epoch: 782/1000..  Training Loss: 4731070471.111..  Test Loss: 3616754944.000.. \n",
      "Epoch: 783/1000..  Training Loss: 4791585194.667..  Test Loss: 3760032256.000.. \n",
      "Epoch: 784/1000..  Training Loss: 4723561130.667..  Test Loss: 3713649920.000.. \n",
      "Epoch: 785/1000..  Training Loss: 4778815523.556..  Test Loss: 4959961088.000.. \n",
      "Epoch: 786/1000..  Training Loss: 4761957980.444..  Test Loss: 4625746432.000.. \n",
      "Epoch: 787/1000..  Training Loss: 4735102798.222..  Test Loss: 3887525376.000.. \n",
      "Epoch: 788/1000..  Training Loss: 4781572448.000..  Test Loss: 3699361024.000.. \n",
      "Epoch: 789/1000..  Training Loss: 4773925923.556..  Test Loss: 3726445824.000.. \n",
      "Epoch: 790/1000..  Training Loss: 4756784277.333..  Test Loss: 4263048192.000.. \n",
      "Epoch: 791/1000..  Training Loss: 4783944814.222..  Test Loss: 3975627776.000.. \n",
      "Epoch: 792/1000..  Training Loss: 4730481386.667..  Test Loss: 3589903104.000.. \n",
      "Epoch: 793/1000..  Training Loss: 4720903864.889..  Test Loss: 3742868736.000.. \n",
      "Epoch: 794/1000..  Training Loss: 4712108117.333..  Test Loss: 3806783488.000.. \n",
      "Epoch: 795/1000..  Training Loss: 4756684465.778..  Test Loss: 3629228288.000.. \n",
      "Epoch: 796/1000..  Training Loss: 4764336419.556..  Test Loss: 4706633728.000.. \n",
      "Epoch: 797/1000..  Training Loss: 4753676487.111..  Test Loss: 3686321920.000.. \n",
      "Epoch: 798/1000..  Training Loss: 4718233735.111..  Test Loss: 4552803328.000.. \n",
      "Epoch: 799/1000..  Training Loss: 4760786019.556..  Test Loss: 4075578624.000.. \n",
      "Epoch: 800/1000..  Training Loss: 4748664704.000..  Test Loss: 3579839232.000.. \n",
      "Epoch: 801/1000..  Training Loss: 4754479736.889..  Test Loss: 3588169984.000.. \n",
      "Epoch: 802/1000..  Training Loss: 4727786631.111..  Test Loss: 3648716032.000.. \n",
      "Epoch: 803/1000..  Training Loss: 4725463758.222..  Test Loss: 5843987456.000.. \n",
      "Epoch: 804/1000..  Training Loss: 4732168376.889..  Test Loss: 3543880960.000.. \n",
      "Epoch: 805/1000..  Training Loss: 4728064056.889..  Test Loss: 4043460096.000.. \n",
      "Epoch: 806/1000..  Training Loss: 4749074944.000..  Test Loss: 3763872256.000.. \n",
      "Epoch: 807/1000..  Training Loss: 4720518051.556..  Test Loss: 3617540096.000.. \n",
      "Epoch: 808/1000..  Training Loss: 4676976568.889..  Test Loss: 3780563712.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 809/1000..  Training Loss: 4731605582.222..  Test Loss: 4274844928.000.. \n",
      "Epoch: 810/1000..  Training Loss: 4773420017.778..  Test Loss: 3747869440.000.. \n",
      "Epoch: 811/1000..  Training Loss: 4693325418.667..  Test Loss: 3781842176.000.. \n",
      "Epoch: 812/1000..  Training Loss: 4754666218.667..  Test Loss: 3628795648.000.. \n",
      "Epoch: 813/1000..  Training Loss: 4749825809.778..  Test Loss: 4053834496.000.. \n",
      "Epoch: 814/1000..  Training Loss: 4732404224.000..  Test Loss: 3684433152.000.. \n",
      "Epoch: 815/1000..  Training Loss: 4746497795.556..  Test Loss: 3751494656.000.. \n",
      "Epoch: 816/1000..  Training Loss: 4714827239.111..  Test Loss: 3693342464.000.. \n",
      "Epoch: 817/1000..  Training Loss: 4680688494.222..  Test Loss: 3538624512.000.. \n",
      "Epoch: 818/1000..  Training Loss: 4726017464.889..  Test Loss: 3614222080.000.. \n",
      "Epoch: 819/1000..  Training Loss: 4729412387.556..  Test Loss: 4855488000.000.. \n",
      "Epoch: 820/1000..  Training Loss: 4748950062.222..  Test Loss: 3938666240.000.. \n",
      "Epoch: 821/1000..  Training Loss: 4740665934.222..  Test Loss: 4156879360.000.. \n",
      "Epoch: 822/1000..  Training Loss: 4710673095.111..  Test Loss: 3813726976.000.. \n",
      "Epoch: 823/1000..  Training Loss: 4708835569.778..  Test Loss: 3708690688.000.. \n",
      "Epoch: 824/1000..  Training Loss: 4708400967.111..  Test Loss: 3721012480.000.. \n",
      "Epoch: 825/1000..  Training Loss: 4706685660.444..  Test Loss: 3579777536.000.. \n",
      "Epoch: 826/1000..  Training Loss: 4722636842.667..  Test Loss: 3629354496.000.. \n",
      "Epoch: 827/1000..  Training Loss: 4795970382.222..  Test Loss: 3584044544.000.. \n",
      "Epoch: 828/1000..  Training Loss: 4750956273.778..  Test Loss: 4165223424.000.. \n",
      "Epoch: 829/1000..  Training Loss: 4732611662.222..  Test Loss: 4245161728.000.. \n",
      "Epoch: 830/1000..  Training Loss: 4755085525.333..  Test Loss: 3618363648.000.. \n",
      "Epoch: 831/1000..  Training Loss: 4732830421.333..  Test Loss: 3557297920.000.. \n",
      "Epoch: 832/1000..  Training Loss: 4677199182.222..  Test Loss: 3521264640.000.. \n",
      "Epoch: 833/1000..  Training Loss: 4707689272.889..  Test Loss: 3584624384.000.. \n",
      "Epoch: 834/1000..  Training Loss: 4752144750.222..  Test Loss: 3609042176.000.. \n",
      "Epoch: 835/1000..  Training Loss: 4724377621.333..  Test Loss: 3793790976.000.. \n",
      "Epoch: 836/1000..  Training Loss: 4696001863.111..  Test Loss: 3573777664.000.. \n",
      "Epoch: 837/1000..  Training Loss: 4696607936.000..  Test Loss: 3694970112.000.. \n",
      "Epoch: 838/1000..  Training Loss: 4688696682.667..  Test Loss: 5548575232.000.. \n",
      "Epoch: 839/1000..  Training Loss: 4707977216.000..  Test Loss: 5294593536.000.. \n",
      "Epoch: 840/1000..  Training Loss: 4760681333.333..  Test Loss: 3591445504.000.. \n",
      "Epoch: 841/1000..  Training Loss: 4721995669.333..  Test Loss: 3651428352.000.. \n",
      "Epoch: 842/1000..  Training Loss: 4689899534.222..  Test Loss: 3667597568.000.. \n",
      "Epoch: 843/1000..  Training Loss: 4739453767.111..  Test Loss: 4017612544.000.. \n",
      "Epoch: 844/1000..  Training Loss: 4743698325.333..  Test Loss: 3574330368.000.. \n",
      "Epoch: 845/1000..  Training Loss: 4694096615.111..  Test Loss: 4144264192.000.. \n",
      "Epoch: 846/1000..  Training Loss: 4759382904.889..  Test Loss: 4679780352.000.. \n",
      "Epoch: 847/1000..  Training Loss: 4729895651.556..  Test Loss: 3537182464.000.. \n",
      "Epoch: 848/1000..  Training Loss: 4716158353.778..  Test Loss: 3514708992.000.. \n",
      "Epoch: 849/1000..  Training Loss: 4735277397.333..  Test Loss: 3533929728.000.. \n",
      "Epoch: 850/1000..  Training Loss: 4685194816.000..  Test Loss: 3617785856.000.. \n",
      "Epoch: 851/1000..  Training Loss: 4694972977.778..  Test Loss: 4912503296.000.. \n",
      "Epoch: 852/1000..  Training Loss: 4702660636.444..  Test Loss: 3553820416.000.. \n",
      "Epoch: 853/1000..  Training Loss: 4726457464.889..  Test Loss: 3572320000.000.. \n",
      "Epoch: 854/1000..  Training Loss: 4781497984.000..  Test Loss: 3543722240.000.. \n",
      "Epoch: 855/1000..  Training Loss: 4661289351.111..  Test Loss: 3602096384.000.. \n",
      "Epoch: 856/1000..  Training Loss: 4685869248.000..  Test Loss: 3640784896.000.. \n",
      "Epoch: 857/1000..  Training Loss: 4715820920.889..  Test Loss: 3636244480.000.. \n",
      "Epoch: 858/1000..  Training Loss: 4701340288.000..  Test Loss: 3502040064.000.. \n",
      "Epoch: 859/1000..  Training Loss: 4616876736.000..  Test Loss: 3975300352.000.. \n",
      "Epoch: 860/1000..  Training Loss: 4711243395.556..  Test Loss: 3520261632.000.. \n",
      "Epoch: 861/1000..  Training Loss: 4720813880.889..  Test Loss: 4880993280.000.. \n",
      "Epoch: 862/1000..  Training Loss: 4694529109.333..  Test Loss: 3912859136.000.. \n",
      "Epoch: 863/1000..  Training Loss: 4724372480.000..  Test Loss: 3593447424.000.. \n",
      "Epoch: 864/1000..  Training Loss: 4747744071.111..  Test Loss: 4367419904.000.. \n",
      "Epoch: 865/1000..  Training Loss: 4734534158.222..  Test Loss: 3643707392.000.. \n",
      "Epoch: 866/1000..  Training Loss: 4726201770.667..  Test Loss: 4162979584.000.. \n",
      "Epoch: 867/1000..  Training Loss: 4650022382.222..  Test Loss: 3701181952.000.. \n",
      "Epoch: 868/1000..  Training Loss: 4692081969.778..  Test Loss: 4506582016.000.. \n",
      "Epoch: 869/1000..  Training Loss: 4710160931.556..  Test Loss: 4005481728.000.. \n",
      "Epoch: 870/1000..  Training Loss: 4762405937.778..  Test Loss: 4100326400.000.. \n",
      "Epoch: 871/1000..  Training Loss: 4737632682.667..  Test Loss: 3548928512.000.. \n",
      "Epoch: 872/1000..  Training Loss: 4744586240.000..  Test Loss: 3822580992.000.. \n",
      "Epoch: 873/1000..  Training Loss: 4681213390.222..  Test Loss: 3841305344.000.. \n",
      "Epoch: 874/1000..  Training Loss: 4680284046.222..  Test Loss: 3953559296.000.. \n",
      "Epoch: 875/1000..  Training Loss: 4694201486.222..  Test Loss: 3494178048.000.. \n",
      "Epoch: 876/1000..  Training Loss: 4676130126.222..  Test Loss: 4133776640.000.. \n",
      "Epoch: 877/1000..  Training Loss: 4683355598.222..  Test Loss: 3863638016.000.. \n",
      "Epoch: 878/1000..  Training Loss: 4732153066.667..  Test Loss: 3623404800.000.. \n",
      "Epoch: 879/1000..  Training Loss: 4682945073.778..  Test Loss: 3796586496.000.. \n",
      "Epoch: 880/1000..  Training Loss: 4703708547.556..  Test Loss: 3536613376.000.. \n",
      "Epoch: 881/1000..  Training Loss: 4719242730.667..  Test Loss: 3539375360.000.. \n",
      "Epoch: 882/1000..  Training Loss: 4673828544.000..  Test Loss: 3555400192.000.. \n",
      "Epoch: 883/1000..  Training Loss: 4664634364.444..  Test Loss: 3500475392.000.. \n",
      "Epoch: 884/1000..  Training Loss: 4715119331.556..  Test Loss: 4619245056.000.. \n",
      "Epoch: 885/1000..  Training Loss: 4701991680.000..  Test Loss: 3754263296.000.. \n",
      "Epoch: 886/1000..  Training Loss: 4732928547.556..  Test Loss: 4205366528.000.. \n",
      "Epoch: 887/1000..  Training Loss: 4674644177.778..  Test Loss: 4542113792.000.. \n",
      "Epoch: 888/1000..  Training Loss: 4726512583.111..  Test Loss: 3659235840.000.. \n",
      "Epoch: 889/1000..  Training Loss: 4697099562.667..  Test Loss: 3549635584.000.. \n",
      "Epoch: 890/1000..  Training Loss: 4684975431.111..  Test Loss: 3477742848.000.. \n",
      "Epoch: 891/1000..  Training Loss: 4718025095.111..  Test Loss: 3483819264.000.. \n",
      "Epoch: 892/1000..  Training Loss: 4677882133.333..  Test Loss: 3492076288.000.. \n",
      "Epoch: 893/1000..  Training Loss: 4703652248.889..  Test Loss: 3730592768.000.. \n",
      "Epoch: 894/1000..  Training Loss: 4732441251.556..  Test Loss: 4431098368.000.. \n",
      "Epoch: 895/1000..  Training Loss: 4686179072.000..  Test Loss: 3535207680.000.. \n",
      "Epoch: 896/1000..  Training Loss: 4643216014.222..  Test Loss: 3579846656.000.. \n",
      "Epoch: 897/1000..  Training Loss: 4686608896.000..  Test Loss: 3675330816.000.. \n",
      "Epoch: 898/1000..  Training Loss: 4673543168.000..  Test Loss: 3657352960.000.. \n",
      "Epoch: 899/1000..  Training Loss: 4698684487.111..  Test Loss: 3592818176.000.. \n",
      "Epoch: 900/1000..  Training Loss: 4676276167.111..  Test Loss: 3564197376.000.. \n",
      "Epoch: 901/1000..  Training Loss: 4659843747.556..  Test Loss: 3582095360.000.. \n",
      "Epoch: 902/1000..  Training Loss: 4731009632.000..  Test Loss: 4534149120.000.. \n",
      "Epoch: 903/1000..  Training Loss: 4696377820.444..  Test Loss: 3774162176.000.. \n",
      "Epoch: 904/1000..  Training Loss: 4671043470.222..  Test Loss: 3824415744.000.. \n",
      "Epoch: 905/1000..  Training Loss: 4699840881.778..  Test Loss: 3607858432.000.. \n",
      "Epoch: 906/1000..  Training Loss: 4698142321.778..  Test Loss: 3460622080.000.. \n",
      "Epoch: 907/1000..  Training Loss: 4661270378.667..  Test Loss: 3673619456.000.. \n",
      "Epoch: 908/1000..  Training Loss: 4722943779.556..  Test Loss: 3532212480.000.. \n",
      "Epoch: 909/1000..  Training Loss: 4708541752.889..  Test Loss: 3957761280.000.. \n",
      "Epoch: 910/1000..  Training Loss: 4641163626.667..  Test Loss: 3655185152.000.. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 911/1000..  Training Loss: 4647741973.333..  Test Loss: 3529084160.000.. \n",
      "Epoch: 912/1000..  Training Loss: 4616042808.889..  Test Loss: 5461155328.000.. \n",
      "Epoch: 913/1000..  Training Loss: 4739043740.444..  Test Loss: 3699263744.000.. \n",
      "Epoch: 914/1000..  Training Loss: 4680753543.111..  Test Loss: 3537040128.000.. \n",
      "Epoch: 915/1000..  Training Loss: 4656114979.556..  Test Loss: 3460975616.000.. \n",
      "Epoch: 916/1000..  Training Loss: 4707471729.778..  Test Loss: 4561554432.000.. \n",
      "Epoch: 917/1000..  Training Loss: 4702110819.556..  Test Loss: 3497109248.000.. \n",
      "Epoch: 918/1000..  Training Loss: 4683558883.556..  Test Loss: 3606550016.000.. \n",
      "Epoch: 919/1000..  Training Loss: 4693631800.889..  Test Loss: 3770564352.000.. \n",
      "Epoch: 920/1000..  Training Loss: 4701313848.889..  Test Loss: 3860905216.000.. \n",
      "Epoch: 921/1000..  Training Loss: 4671454243.556..  Test Loss: 3837485568.000.. \n",
      "Epoch: 922/1000..  Training Loss: 4691143971.556..  Test Loss: 3520384000.000.. \n",
      "Epoch: 923/1000..  Training Loss: 4683700693.333..  Test Loss: 3431356928.000.. \n",
      "Epoch: 924/1000..  Training Loss: 4728146080.000..  Test Loss: 4743523328.000.. \n",
      "Epoch: 925/1000..  Training Loss: 4721536298.667..  Test Loss: 4027101696.000.. \n",
      "Epoch: 926/1000..  Training Loss: 4695966215.111..  Test Loss: 3865094400.000.. \n",
      "Epoch: 927/1000..  Training Loss: 4698980053.333..  Test Loss: 3470904576.000.. \n",
      "Epoch: 928/1000..  Training Loss: 4638848270.222..  Test Loss: 3541177088.000.. \n",
      "Epoch: 929/1000..  Training Loss: 4684357063.111..  Test Loss: 3688153088.000.. \n",
      "Epoch: 930/1000..  Training Loss: 4696883072.000..  Test Loss: 3446352896.000.. \n",
      "Epoch: 931/1000..  Training Loss: 4732952042.667..  Test Loss: 3569166336.000.. \n",
      "Epoch: 932/1000..  Training Loss: 4679966065.778..  Test Loss: 3497418752.000.. \n",
      "Epoch: 933/1000..  Training Loss: 4735829504.000..  Test Loss: 3454460416.000.. \n",
      "Epoch: 934/1000..  Training Loss: 4687202190.222..  Test Loss: 3425237504.000.. \n",
      "Epoch: 935/1000..  Training Loss: 4637452856.889..  Test Loss: 3653099008.000.. \n",
      "Epoch: 936/1000..  Training Loss: 4689374449.778..  Test Loss: 3650282752.000.. \n",
      "Epoch: 937/1000..  Training Loss: 4658401998.222..  Test Loss: 3479024128.000.. \n",
      "Epoch: 938/1000..  Training Loss: 4666521742.222..  Test Loss: 3550547968.000.. \n",
      "Epoch: 939/1000..  Training Loss: 4647010417.778..  Test Loss: 3521819392.000.. \n",
      "Epoch: 940/1000..  Training Loss: 4708803804.444..  Test Loss: 3647295232.000.. \n",
      "Epoch: 941/1000..  Training Loss: 4662621866.667..  Test Loss: 3809349120.000.. \n",
      "Epoch: 942/1000..  Training Loss: 4677675591.111..  Test Loss: 3599542016.000.. \n",
      "Epoch: 943/1000..  Training Loss: 4645508472.889..  Test Loss: 3469450496.000.. \n",
      "Epoch: 944/1000..  Training Loss: 4677527879.111..  Test Loss: 4266724096.000.. \n",
      "Epoch: 945/1000..  Training Loss: 4664366627.556..  Test Loss: 3457913600.000.. \n",
      "Epoch: 946/1000..  Training Loss: 4634887338.667..  Test Loss: 4170021632.000.. \n",
      "Epoch: 947/1000..  Training Loss: 4657603335.111..  Test Loss: 3631535616.000.. \n",
      "Epoch: 948/1000..  Training Loss: 4711869738.667..  Test Loss: 3552853760.000.. \n",
      "Epoch: 949/1000..  Training Loss: 4650103367.111..  Test Loss: 3473559808.000.. \n",
      "Epoch: 950/1000..  Training Loss: 4684635712.000..  Test Loss: 3834084608.000.. \n",
      "Epoch: 951/1000..  Training Loss: 4694584273.778..  Test Loss: 4333836800.000.. \n",
      "Epoch: 952/1000..  Training Loss: 4715226851.556..  Test Loss: 4098494976.000.. \n",
      "Epoch: 953/1000..  Training Loss: 4680305166.222..  Test Loss: 3525598720.000.. \n",
      "Epoch: 954/1000..  Training Loss: 4707167516.444..  Test Loss: 3621259520.000.. \n",
      "Epoch: 955/1000..  Training Loss: 4676441799.111..  Test Loss: 3477655040.000.. \n",
      "Epoch: 956/1000..  Training Loss: 4718077063.111..  Test Loss: 3495405824.000.. \n",
      "Epoch: 957/1000..  Training Loss: 4723825102.222..  Test Loss: 3552769280.000.. \n",
      "Epoch: 958/1000..  Training Loss: 4686898147.556..  Test Loss: 3604537088.000.. \n",
      "Epoch: 959/1000..  Training Loss: 4711913429.333..  Test Loss: 4455606784.000.. \n",
      "Epoch: 960/1000..  Training Loss: 4674091740.444..  Test Loss: 3493231360.000.. \n",
      "Epoch: 961/1000..  Training Loss: 4693755985.778..  Test Loss: 3633958656.000.. \n",
      "Epoch: 962/1000..  Training Loss: 4661097315.556..  Test Loss: 3797840896.000.. \n",
      "Epoch: 963/1000..  Training Loss: 4685028320.000..  Test Loss: 3555722496.000.. \n",
      "Epoch: 964/1000..  Training Loss: 4668475818.667..  Test Loss: 3484656896.000.. \n",
      "Epoch: 965/1000..  Training Loss: 4628530225.778..  Test Loss: 3436581376.000.. \n",
      "Epoch: 966/1000..  Training Loss: 4655909184.000..  Test Loss: 3443317504.000.. \n",
      "Epoch: 967/1000..  Training Loss: 4740456298.667..  Test Loss: 4797011968.000.. \n",
      "Epoch: 968/1000..  Training Loss: 4719240220.444..  Test Loss: 3560761600.000.. \n",
      "Epoch: 969/1000..  Training Loss: 4650299015.111..  Test Loss: 5397273088.000.. \n",
      "Epoch: 970/1000..  Training Loss: 4639423367.111..  Test Loss: 3439922432.000.. \n",
      "Epoch: 971/1000..  Training Loss: 4716783900.444..  Test Loss: 3532265984.000.. \n",
      "Epoch: 972/1000..  Training Loss: 4697207861.333..  Test Loss: 3663920896.000.. \n",
      "Epoch: 973/1000..  Training Loss: 4675427264.000..  Test Loss: 3467691264.000.. \n",
      "Epoch: 974/1000..  Training Loss: 4654686378.667..  Test Loss: 4733223936.000.. \n",
      "Epoch: 975/1000..  Training Loss: 4614684181.333..  Test Loss: 3989781248.000.. \n",
      "Epoch: 976/1000..  Training Loss: 4644143047.111..  Test Loss: 3613089792.000.. \n",
      "Epoch: 977/1000..  Training Loss: 4698008270.222..  Test Loss: 5238868480.000.. \n",
      "Epoch: 978/1000..  Training Loss: 4682059505.778..  Test Loss: 3725815296.000.. \n",
      "Epoch: 979/1000..  Training Loss: 4684604736.000..  Test Loss: 3691612160.000.. \n",
      "Epoch: 980/1000..  Training Loss: 4698205418.667..  Test Loss: 3854109440.000.. \n",
      "Epoch: 981/1000..  Training Loss: 4682938033.778..  Test Loss: 3637858048.000.. \n",
      "Epoch: 982/1000..  Training Loss: 4648039658.667..  Test Loss: 3698566400.000.. \n",
      "Epoch: 983/1000..  Training Loss: 4653229944.889..  Test Loss: 3550140160.000.. \n",
      "Epoch: 984/1000..  Training Loss: 4701087395.556..  Test Loss: 3689539072.000.. \n",
      "Epoch: 985/1000..  Training Loss: 4658737301.333..  Test Loss: 3535818752.000.. \n",
      "Epoch: 986/1000..  Training Loss: 4679826958.222..  Test Loss: 3672508928.000.. \n",
      "Epoch: 987/1000..  Training Loss: 4681051377.778..  Test Loss: 3433782528.000.. \n",
      "Epoch: 988/1000..  Training Loss: 4682865628.444..  Test Loss: 3781508096.000.. \n",
      "Epoch: 989/1000..  Training Loss: 4660023360.000..  Test Loss: 3581556224.000.. \n",
      "Epoch: 990/1000..  Training Loss: 4652501816.889..  Test Loss: 3444662016.000.. \n",
      "Epoch: 991/1000..  Training Loss: 4646920732.444..  Test Loss: 3480407040.000.. \n",
      "Epoch: 992/1000..  Training Loss: 4607398151.111..  Test Loss: 3460787456.000.. \n",
      "Epoch: 993/1000..  Training Loss: 4653307953.778..  Test Loss: 3439825664.000.. \n",
      "Epoch: 994/1000..  Training Loss: 4642555541.333..  Test Loss: 3469868544.000.. \n",
      "Epoch: 995/1000..  Training Loss: 4728887310.222..  Test Loss: 3624896256.000.. \n",
      "Epoch: 996/1000..  Training Loss: 4652276401.778..  Test Loss: 3479852288.000.. \n",
      "Epoch: 997/1000..  Training Loss: 4687285674.667..  Test Loss: 3920099584.000.. \n",
      "Epoch: 998/1000..  Training Loss: 4647130033.778..  Test Loss: 3506518016.000.. \n",
      "Epoch: 999/1000..  Training Loss: 4628467456.000..  Test Loss: 3482338304.000.. \n",
      "Epoch: 1000/1000..  Training Loss: 4659953095.111..  Test Loss: 3445777152.000.. \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv = cv.split(X_train_scaled, y_train)\n",
    "\n",
    "m_hidden_layers = 10\n",
    "\n",
    "n_input = 6\n",
    "n_hidden = 4\n",
    "n_output = 1\n",
    "\n",
    "bs = 64\n",
    "device = \"cuda:0\"\n",
    "epochs = 1000\n",
    "\n",
    "network_type = \"regression\"\n",
    "\n",
    "regressors = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "    print(\"Model for Fold: \" + str(fold))\n",
    "\n",
    "    train_set, train_labels = X_train_scaled[train_idx], y_train[train_idx]\n",
    "    valid_set, valid_labels = X_train_scaled[val_idx], y_train[val_idx]\n",
    "    \n",
    "    trainset = HousePriceDataset(train_set, train_labels)\n",
    "    trainloader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    validset = HousePriceDataset(valid_set, valid_labels)\n",
    "    validloader = DataLoader(validset, batch_size = bs, shuffle = True)\n",
    "\n",
    "    regressor = NeuralNetwork(m_hidden_layers, n_input, n_hidden, n_output, network_type).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    criterion_2 = RMSLELoss\n",
    "    optimizer = optim.Adam(regressor.parameters(), lr = 0.005)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        for features, labels in trainloader:\n",
    "\n",
    "            regressor.train()\n",
    "\n",
    "            features = features.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = regressor(features.float())\n",
    "\n",
    "            loss = criterion(output, labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            test_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for features, labels in validloader:\n",
    "                    regressor.eval()\n",
    "\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    output = regressor(features.float())\n",
    "\n",
    "                    test_loss += criterion(output, labels)\n",
    "\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(validloader)))\n",
    "            \n",
    "        \n",
    "        \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations with other metrics\n",
    "- RMSLE Loss and R2 Score\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on Testing Data: 4448829952.0\n",
      "Lets see predictions\n",
      "[88288.77  88289.96  88289.24  88288.305 88288.164 88288.18  88288.62\n",
      " 88289.27  88288.516 88289.414 88289.14  88288.64  88288.734 88288.89\n",
      " 88288.64  88289.76  88288.03  88287.945 88287.9   88287.84  88289.266\n",
      " 88289.54  88288.586 88288.93  88289.5   88287.766 88288.27  88289.516\n",
      " 88289.34  88289.43  88288.7   88287.56  88289.81  88289.4   88289.33\n",
      " 88288.46  88289.09  88288.555 88288.95  88289.51  88288.73  88289.625\n",
      " 88288.695 88288.08  88289.36  88290.12  88290.    88289.75  88288.21\n",
      " 88288.95  88288.69  88289.945 88288.73  88288.086 88289.836 88288.36\n",
      " 88287.96  88289.68  88287.586 88288.17  88289.87  88288.78  88289.03\n",
      " 88288.68  88287.99  88289.27  88289.055 88288.9   88288.87  88289.13\n",
      " 88289.664 88289.305 88287.8   88289.21  88288.76  88289.81  88289.31\n",
      " 88287.516 88288.62  88289.54  88289.32  88288.555 88288.52  88288.93\n",
      " 88289.11  88288.664 88289.56  88289.8   88287.85  88289.29  88288.8\n",
      " 88288.625 88289.77  88289.58  88288.35  88288.86  88289.61  88288.43\n",
      " 88289.26  88290.086 88289.2   88288.43  88288.28  88289.99  88287.13\n",
      " 88288.96  88288.52  88287.836 88289.96  88289.6   88288.516 88288.63\n",
      " 88288.945 88288.016 88289.08  88288.76  88287.89  88288.305 88289.77\n",
      " 88289.18  88289.336 88289.43  88288.11  88289.6   88289.18  88288.43\n",
      " 88288.35  88289.61  88289.54  88287.75  88288.42  88289.42  88288.01\n",
      " 88289.96  88289.914 88288.68  88289.836 88290.055 88289.66  88288.87\n",
      " 88288.93  88287.52  88289.32  88288.36  88288.4   88288.65  88287.25\n",
      " 88289.82  88290.02  88288.484 88288.63  88289.19  88290.1   88287.84\n",
      " 88290.055 88288.85  88287.72  88288.76  88288.3   88289.805 88289.53\n",
      " 88286.92  88287.93  88289.41  88288.74  88287.25  88288.25  88288.98\n",
      " 88287.87  88288.414 88287.62  88288.4   88289.15  88289.6   88290.04\n",
      " 88288.93  88289.43  88288.99  88290.03  88289.21  88289.4   88288.914\n",
      " 88289.266 88289.    88289.84  88289.14  88287.92  88288.72  88289.89\n",
      " 88289.57  88286.85  88289.79  88289.11  88288.72  88288.06  88287.46\n",
      " 88289.24  88288.625 88288.336 88288.73  88289.305 88287.445 88288.62\n",
      " 88289.516 88287.19  88288.375 88287.875 88289.71  88289.445 88288.35\n",
      " 88287.93  88289.71  88288.39  88289.28  88289.06  88288.68  88288.72\n",
      " 88288.92  88289.08  88289.586 88289.695 88289.07  88287.92  88289.336\n",
      " 88288.71  88288.76  88289.11  88287.54  88288.32  88288.18  88287.836\n",
      " 88288.18  88287.96  88288.63  88288.7   88289.836 88290.125 88288.39\n",
      " 88289.21  88290.195 88288.15  88289.516 88287.89  88288.24  88290.01\n",
      " 88288.89  88290.02  88289.14  88288.89  88288.58  88288.52  88289.49\n",
      " 88288.375 88287.984 88289.11  88288.336 88287.73  88288.76  88289.88\n",
      " 88288.02  88289.336 88288.99  88289.195 88289.66  88289.19  88287.914\n",
      " 88289.24  88288.37  88288.79  88288.13  88288.5   88288.02  88289.64\n",
      " 88288.95  88289.86  88288.625 88287.84  88289.305 88290.12  88289.46\n",
      " 88289.75  88289.36  88288.15  88289.62  88289.38  88289.14  88288.805\n",
      " 88287.75  88288.9   88288.53  88288.22  88287.21  88287.99  88288.96\n",
      " 88289.04  88288.46  88289.82  88288.87  88289.445 88288.125 88288.73\n",
      " 88288.51  88290.02  88289.46  88289.19  88289.06  88289.875 88287.95\n",
      " 88287.45  88290.    88289.06  88288.83  88289.84  88288.27  88288.28\n",
      " 88288.35  88290.04  88289.54  88288.14  88289.87  88289.63  88289.32\n",
      " 88289.71  88288.98  88288.445 88289.33  88288.46  88289.31  88287.7\n",
      " 88289.27  88289.29  88288.83  88289.85  88288.24  88288.71  88289.81\n",
      " 88288.336 88287.62  88289.21  88288.13  88288.555 88288.85  88288.78\n",
      " 88288.65  88289.97  88289.1   88289.33  88288.836 88289.14  88287.84\n",
      " 88287.99  88286.25  88289.96  88288.12  88287.83  88288.65  88288.69\n",
      " 88288.766 88290.03  88288.15  88289.305 88287.79  88288.73  88288.94\n",
      " 88289.49  88289.04  88289.375 88289.23  88288.79  88289.96  88288.64\n",
      " 88288.79  88288.96  88289.74  88287.945 88288.64  88289.75  88290.125\n",
      " 88289.54  88289.38  88289.95  88288.76  88289.38  88289.9   88289.9\n",
      " 88289.18  88288.72  88289.55  88288.95  88288.76  88287.26  88288.266\n",
      " 88289.17  88290.    88289.23  88289.29  88289.87  88289.18  88290.086\n",
      " 88287.8   88288.65  88288.37  88287.805 88287.84  88288.98  88288.09\n",
      " 88287.664 88288.625 88289.875 88288.58  88288.875 88289.43  88288.68\n",
      " 88287.74  88289.664 88288.95  88288.914 88288.586 88288.836 88288.234\n",
      " 88287.99  88288.4   88289.75  88288.    88289.06  88288.51  88289.195\n",
      " 88289.62  88288.2   88287.96  88289.336 88289.15  88289.08  88290.\n",
      " 88288.27  88287.266 88289.15  88288.375 88289.62  88288.93  88289.25\n",
      " 88287.5   88288.55  88288.5   88289.75  88288.18  88289.13  88290.02\n",
      " 88288.73  88288.06  88288.16  88289.43  88290.02  88287.24  88289.73\n",
      " 88288.62  88289.625 88288.305 88288.664 88289.22  88288.484 88289.92\n",
      " 88287.64  88287.914 88287.87  88288.5   88289.2   88288.52  88289.34\n",
      " 88288.37  88288.7   88287.89  88288.664 88288.64  88290.086 88289.14\n",
      " 88289.03  88289.51  88290.04  88289.055 88289.305 88288.74  88288.31\n",
      " 88289.52  88288.5   88289.87  88287.77  88287.82  88289.39  88289.06\n",
      " 88288.76  88289.43  88288.44  88288.71  88290.11  88288.586 88288.516\n",
      " 88287.516 88289.875 88288.71  88288.23  88289.81  88289.79  88288.35\n",
      " 88289.24  88288.95  88288.086 88288.76  88289.02  88289.805 88289.54\n",
      " 88288.516 88290.01  88289.34  88288.58  88288.57  88288.8   88288.92\n",
      " 88289.17  88288.96  88288.38  88289.375 88288.27  88289.08  88289.484\n",
      " 88287.89  88288.65  88289.49  88289.055 88288.15  88288.56  88287.93\n",
      " 88288.96  88288.77  88288.63  88289.086 88289.79  88288.87  88289.9\n",
      " 88288.875 88288.68  88288.24  88288.15  88289.61  88288.93  88290.12\n",
      " 88289.04  88288.87  88288.875 88289.23  88288.4   88287.13  88287.68\n",
      " 88288.945 88290.17  88288.95  88289.97  88289.51  88288.555 88288.43\n",
      " 88289.92  88287.29  88287.19  88290.055 88288.125 88289.8   88289.4\n",
      " 88289.31  88288.59  88289.61  88288.79  88288.24  88287.93  88288.9\n",
      " 88288.52  88289.58  88289.83  88288.086 88289.086 88289.74  88289.55\n",
      " 88289.27  88289.15  88287.836 88289.87  88289.914 88288.5   88289.74\n",
      " 88287.95  88289.31  88288.6   88287.6   88289.84  88289.18  88288.09\n",
      " 88289.64  88288.02  88289.4   88289.63  88289.9   88289.555 88289.836\n",
      " 88288.42  88288.37  88289.79  88288.57  88288.945 88288.82  88289.74\n",
      " 88289.09  88289.96  88288.37  88288.96  88289.84  88288.836 88288.91\n",
      " 88288.79  88289.45  88289.24  88288.9   88289.54  88288.625 88289.59\n",
      " 88286.984 88288.52  88288.72  88289.95  88290.12  88287.58  88288.445\n",
      " 88288.03  88289.21  88287.95  88289.6   88288.84  88288.625 88288.6\n",
      " 88288.71  88288.016 88288.19  88288.805 88289.22  88287.875 88288.6\n",
      " 88287.375 88289.24  88289.08  88287.836 88289.9   88287.44  88289.266\n",
      " 88289.34  88288.41  88289.8   88289.19  88289.79  88289.68  88289.33\n",
      " 88287.41  88288.66  88289.2   88289.74  88288.625 88288.664 88288.055\n",
      " 88288.97  88287.62  88288.14  88289.99  88288.52  88288.38  88288.96\n",
      " 88289.02  88288.805 88289.71  88289.555 88288.16  88288.87  88288.54\n",
      " 88288.99  88289.02  88289.51  88289.43  88289.414 88288.37  88285.23\n",
      " 88289.16  88288.52  88290.18  88288.32  88287.99  88288.31  88288.24\n",
      " 88288.9   88288.64  88288.74  88290.01  88289.4   88288.45  88289.08\n",
      " 88289.586 88289.85  88288.93  88289.48  88288.945 88288.93 ]\n",
      "[ 50500  94666 103500  34500  45505  74000  43650 185000  35500 113900\n",
      "  75500 445000  65000  90000  55000 145000 325000 305000 144000  57500\n",
      " 105574 127500  33860 124000  47000  45000  52000  85483  79500  53610\n",
      "  60500  40000 160000  64457  80000  82900 105000  72000  80000  73000\n",
      "  73500 160000  54000  40000  79000  80950  69850  69000  76934 289000\n",
      "  76500  85000 149000  46650 170000  74000  57500  62000  37764  84990\n",
      "  56300 120086  46750  74000  55800 126000  83000  85619  57700 280000\n",
      " 119000  94000  49000 179000 125000  79000 147000  32850  66300 124000\n",
      "  52900  34900  95000  55075  65700  56900 255000 150000  35000  89000\n",
      "  50500  54000 125000  55000  55000 139900 180000  83500 110000  75000\n",
      "  78600 300000 329000 118000 299000 180000  61500  64300  66999  54900\n",
      "  63000  54900  82000  60999  78599  50500  94500 240000  56953  49900\n",
      "  68240  81383  62900 218000  46500  53010  75000  95000  73715  80688\n",
      " 125000 145000  40272 130000 112000 130252 142000 100700 119000  71850\n",
      "  93000  32000 138000  91900  29900 123043  44000  73715 120000  65500\n",
      " 181500 209000  82375  49400  53900 113000  75900 270000  66414  68500\n",
      " 114750 275000  38500 139000  48999  39600  73000  59500  48900  77900\n",
      "  86000  52500 105000  75000  82000 135000 115000  89953 119000  45400\n",
      "  78500  53500  61020  76100  85000  83000  59950  45700  69000 100000\n",
      " 375000 152285 199000  83000  38000  45000 120000 390000  76000 435000\n",
      " 109440  33700  63900 169000  41000  57900  58000 152976 129508  53010\n",
      "  63000 123500 190000  56000 133820  64600 149000  51040  48500 157510\n",
      "  56953  81257  46900  61000 250000  48000 101500  34900  59800 229900\n",
      "  58999  82000  36190  86227 117000 110000 103000  78900  70500  78900\n",
      " 125000 101000 149000  45000 112000 128000  95000  61000 125500 179000\n",
      "  68500 136000  73000  79500 199000  74000  59900  49600  79900  55100\n",
      "  67500 125000  76500  90600  61000  44010 169000 196970  57000  59800\n",
      "  83800 125000  74500  69900  89000  48100  59000  59500  65000 219000\n",
      " 144000  73900  65000 189000 123219  73715 129000  42500  54900  50990\n",
      "  52600  23500  39000 101900 230000 132000  72760  77500 205000  75000\n",
      "  64000  63900  95000  56000  56953  57500  92200  52000  72000  79080\n",
      "  69900  87000  80000  90000 113900 174839  61500 126000  56500  68500\n",
      "  59000 108000  94000  51133  43000 143000  50400  97000 385000  60900\n",
      " 195000  77000  88000  58700  99000  74998  79900  86500 106257  47000\n",
      "  76930 127000 145000  89900  80687  91800  78500  62600  89953  44000\n",
      "  47500 320000 104500  78900  54900  59900  62500  35000  73000  74500\n",
      "  83500  52000  71000  80000  59900 330000 167000 245000  83000  92400\n",
      "  82500  57000  39500 100000  38300  53010 153500  89000  47000 178000\n",
      "  78300  68000 110188  60900  99800 185000 173000  87000 100000  54896\n",
      "  68000  51500  78100  78000  99900 199000  88000  66000  59500  19900\n",
      " 149000  56000  36500  62000 175759  55000 112900  64000 110000  36500\n",
      "  48500 116900  63500  58900 146000 125000  79900  87000 290000  58000\n",
      "  54900  35500 189000  49500  58900  71000  60000 135000  65000  59993\n",
      "  81900  83500  84630  68000  97000  25500  81000  57000 102300  97000\n",
      "  80130 400000 123500  71500 147300  41500 160000 100000  61500  75900\n",
      "  54000 125539  92000  52440  99726  75000  86900 239000 133820  75000\n",
      "  73000  65000  52000  97000  41500  83800  66957  96000  84900 400000\n",
      "  43000  53000  67000 225000 142000 142000 139000 137500 165000  64300\n",
      " 130000 280000  57900 125000  95000 115000  68000  39000  73715  78000\n",
      "  58000 125539  89953  78900  79500  79650 122900  30000 173000  65000\n",
      "  59000  60000  71000  57000 218000  62000  46500  63000 156000 139000\n",
      " 170000  71000  65000  93840 117500 115000  47900 100269 173500  53500\n",
      "  83000 138999 289000 160000  75672 329000  80000 125000  66800 125000\n",
      " 109000  45000  77900 110250  67500  79500 144500  63000  60000 130000\n",
      "  40999  57000 125000  57000  85000  59999  91500 255000  89000 128000\n",
      " 195000  47000  79900  67150 100000  73000 137000 102000 120089 165000\n",
      " 109000 115000  63900  68499 380000 124000 118500 197635  37000  67100\n",
      "  53000  64900  41900  74000 249000  67733 170000  49100  49500  42000\n",
      " 199000  65700  57000  52400 130000  67000 120089  64900  60000  85000\n",
      "  44900 367000  55000  79000  80824 162300  42000  67000  86900  99800\n",
      " 230000  60000  56000  70952 119000 175000  59500 174999 120000 171500\n",
      " 114500  44000  86100  92000 108131  63000  73000  62000 115000  48000\n",
      "  73715  50500 135000  75000 116500  59000 103000 105000  38900  88500\n",
      "  64160 139000  58900 148000 112455  84900  65760 139000 360000  32000\n",
      "  94300  76900  44500 116700  42800  60000  79000  55500  58500  84000\n",
      "  94000 199000  72900  95000 170400 167000 103000  64400  66500  55900\n",
      "  53500  51600  89000  83000  74500 112455 380000  68800 111466  71590\n",
      "  68100  65200 104500  65000 144500 134505  67143 119000  58000  96000\n",
      "  92900  59900  86000 115000  34500 450000  73000  30000  71700 137498\n",
      "  47000  69048  19905 110000  62000  45900  82000  96500  33400 125500\n",
      " 157510 130000 149500  89110  56000  69500]\n",
      "R2 Score: -0.028839128099620304\n",
      "Root Mean Squared Log Error: 0.5264135003089905\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATZElEQVR4nO3df7DddX3n8edLQKjFlYQEjCF60aY7xmmLbEpRu11aXVG0xc6oC20lY9lJtwuzOutuJ+hupZ3SoZ2tdRlba7pSEX9Biy4ZwLoUbam7KxgQEQws0UaJSckFK9BqqcT3/nE+iYebc38k997cm899Pma+c77n8/18z/d9PpPzOt987veck6pCktSXpy10AZKkuWe4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHDXopTkL5P828O9b9v/7Un+x6HuLy0GhrvmVZIdSV6x0HXsk+TSJB8a0V5Jfgigqn67qqZ9c5jtm4g0nwx3aRFKcvRC16Ajm+GuBZFkWZIbkown+bu2fsqEbi9IcnuSR5Ncn2T50P5nJvk/Sb6V5ItJzprD2vaf3Sc5LsmHkjzSjvX5JCcnuQz4l8B7kvx9kve0/i9tfR5tty8detxTk9ya5PEkf5HkD4aOM9b+93Bhkq8Dn27tf5rkb9vj3ZrkRUOP94Ekf5jkk62G/53k2Une3cb0viQvnqtx0ZHFcNdCeRrwJ8DzgOcC3wHeM6HPBcAvA88BngSuAEiyGrgR+C1gOfCfgOuSrJyHOjcAzwLWACcC/w74TlW9A/hr4OKqOr6qLm5vPje2Ok8E3gXcmOTE9lgfAW5v2y4F3jTieP8KeCFwdrv/SWAtcBJwJ/DhCf3fCPwXYAXwBPB/W78VwJ+1GrQEGe5aEFX1SFVdV1XfrqrHgcsYBNuwq6vqnqr6B+C/Am9MchTwS8BNVXVTVX2vqm4GtgLnzPDwb2xn4fuXKfp+l0EY/1BV7a2qO6rqsUn6vgZ4oKqurqonq+qjwH3AzyZ5LvDjwK9X1T9V1WeBLSMe49Kq+oeq+g5AVV1ZVY9X1RMM3hB+LMmzhvp/otX0j8AngH+sqg9W1V7gGsAz9yXKcNeCSPKMJO9L8rUkjwG3Aie08N7nwaH1rwHHMDgjfR7whgnh/JPAqhke/tqqOmF4maLv1cCngI8l2ZXkd5McM0nf57Q6h30NWN22fbOqvj3J8zugLclRSS5P8pU2RjvaphVD/R8aWv/OiPvHT1KrOme4a6G8DfjnwE9U1T8Dfqq1Z6jPmqH15zI4i36YQQBePSGgf7CqLp/rIqvqu1X1G1W1Dngp8FoG00UAE79SdReDN55hzwW+AewGlid5xtC2NRxo+DF/ATgXeAWDqaGx1h6kaRjuOhyOaX+Y3LccDTyTwZnlt9pc9TtH7PdLSda1QPxN4M/adMOHGEx1nN3Obo9LctaIP8jOWpKfTvIj7X8UjzF4g9nbNj8EPH+o+03ADyf5hSRHJ/k3wDrghqr6GoOpo0uTPD3JS4Cfnebwz2Qwj/4I8Azgt+fsial7hrsOh5sYBPm+5VLg3cAPMDgT/xzw5yP2uxr4APC3wHHAfwCoqgcZnNG+HRhncCb/n5mff8/PZvCHyceAbcBfMXhzAfjvwOvblSlXVNUjDM7s38YgkH8NeG1VPdz6/yLwkrbttxjMiT8xxbE/yGBa5xvAlxmMkzQj8cc6pIWR5Brgvqoa9b8WaVY8c5cOkyQ/nuQFSZ6W5FUM/vfxPxe6LvXJT8FJh8+zgY8zuLRyJ/CrVfWFhS1JvXJaRpI65LSMJHVoUUzLrFixosbGxha6DEk6otxxxx0PV9XIr91YFOE+NjbG1q1bF7oMSTqiJJn4iej9nJaRpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOLYpPqB6pxjbduCDH3XH5axbkuJKOHJ65S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6NG24J1mT5DNJtiW5N8lbWvulSb6R5K62nDO0zyVJtie5P8nZ8/kEJEkHmskvMT0JvK2q7kzyTOCOJDe3bb9fVf9tuHOSdcB5wIuA5wB/keSHq2rvXBYuSZrctGfuVbW7qu5s648D24DVU+xyLvCxqnqiqv4G2A6cMRfFSpJm5qDm3JOMAS8GbmtNFye5O8mVSZa1ttXAg0O77WTEm0GSjUm2Jtk6Pj5+0IVLkiY343BPcjxwHfDWqnoMeC/wAuA0YDfwe/u6jti9Dmio2lxV66tq/cqVKw+6cEnS5GYU7kmOYRDsH66qjwNU1UNVtbeqvgf8Md+fetkJrBna/RRg19yVLEmazkyulgnwfmBbVb1rqH3VULefB+5p61uA85Icm+RUYC1w+9yVLEmazkyulnkZ8CbgS0nuam1vB85PchqDKZcdwK8AVNW9Sa4FvszgSpuLvFJGkg6vacO9qj7L6Hn0m6bY5zLgslnUJUmaBT+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOnT0QhcwW2ObblzoEiRp0fHMXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ9OGe5I1ST6TZFuSe5O8pbUvT3Jzkgfa7bLWniRXJNme5O4kp8/3k5AkPdVMztyfBN5WVS8EzgQuSrIO2ATcUlVrgVvafYBXA2vbshF475xXLUma0rThXlW7q+rOtv44sA1YDZwLXNW6XQW8rq2fC3ywBj4HnJBk1ZxXLkma1EHNuScZA14M3AacXFW7YfAGAJzUuq0GHhzabWdrm/hYG5NsTbJ1fHz84CuXJE1qxuGe5HjgOuCtVfXYVF1HtNUBDVWbq2p9Va1fuXLlTMuQJM3AjMI9yTEMgv3DVfXx1vzQvumWdrunte8E1gztfgqwa27KlSTNxEyulgnwfmBbVb1raNMWYENb3wBcP9R+Qbtq5kzg0X3TN5Kkw2MmXxz2MuBNwJeS3NXa3g5cDlyb5ELg68Ab2rabgHOA7cC3gTfPacWSpGlNG+5V9VlGz6MDvHxE/wIummVdkqRZ8BOqktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tC04Z7kyiR7ktwz1HZpkm8kuast5wxtuyTJ9iT3Jzl7vgqXJE1uJmfuHwBeNaL996vqtLbcBJBkHXAe8KK2zx8mOWquipUkzcy04V5VtwLfnOHjnQt8rKqeqKq/AbYDZ8yiPknSIZjNnPvFSe5u0zbLWttq4MGhPjtbmyTpMDrUcH8v8ALgNGA38HutPSP61qgHSLIxydYkW8fHxw+xDEnSKIcU7lX1UFXtrarvAX/M96dedgJrhrqeAuya5DE2V9X6qlq/cuXKQylDkjSJQwr3JKuG7v48sO9Kmi3AeUmOTXIqsBa4fXYlSpIO1tHTdUjyUeAsYEWSncA7gbOSnMZgymUH8CsAVXVvkmuBLwNPAhdV1d75KV2SNJlpw72qzh/R/P4p+l8GXDaboiRJs+MnVCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOTfsbqlp8xjbduGDH3nH5axbs2JJmzjN3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0LThnuTKJHuS3DPUtjzJzUkeaLfLWnuSXJFke5K7k5w+n8VLkkabyZn7B4BXTWjbBNxSVWuBW9p9gFcDa9uyEXjv3JQpSToY04Z7Vd0KfHNC87nAVW39KuB1Q+0frIHPASckWTVXxUqSZuZQ59xPrqrdAO32pNa+GnhwqN/O1naAJBuTbE2ydXx8/BDLkCSNMtd/UM2IthrVsao2V9X6qlq/cuXKOS5Dkpa2Qw33h/ZNt7TbPa19J7BmqN8pwK5DL0+SdCgONdy3ABva+gbg+qH2C9pVM2cCj+6bvpEkHT7T/lhHko8CZwErkuwE3glcDlyb5ELg68AbWvebgHOA7cC3gTfPQ82SpGlMG+5Vdf4km14+om8BF822KEnS7PgJVUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXo6NnsnGQH8DiwF3iyqtYnWQ5cA4wBO4A3VtXfza5MSdLBmIsz95+uqtOqan27vwm4parWAre0+5Kkw2g+pmXOBa5q61cBr5uHY0iSpjDbcC/gfyW5I8nG1nZyVe0GaLcnjdoxycYkW5NsHR8fn2UZkqRhs5pzB15WVbuSnATcnOS+me5YVZuBzQDr16+vWdYhSRoyqzP3qtrVbvcAnwDOAB5Ksgqg3e6ZbZGSpINzyGfuSX4QeFpVPd7WXwn8JrAF2ABc3m6vn4tCtTiMbbpxQY674/LXLMhxpSPVbKZlTgY+kWTf43ykqv48yeeBa5NcCHwdeMPsy5QkHYxDDveq+irwYyPaHwFePpuiJEmz4ydUJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1aDa/oSodNgv1w9zgj3PryOSZuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQl0JK01jIyzAXgpd+9sFwl7RoLNQbaY9vaE7LSFKHPHOX9BRLbRqqV/N25p7kVUnuT7I9yab5Oo4k6UDzcuae5CjgD4B/DewEPp9kS1V9eT6OJ0mz0eN3F83XmfsZwPaq+mpV/RPwMeDceTqWJGmC+ZpzXw08OHR/J/ATwx2SbAQ2trt/n+QR4OF5qudItwLHZjKOzeQcm9EW1bjkd2a1+/Mm2zBf4Z4RbfWUO1Wbgc37d0i2VtX6earniObYTM6xmZxjM9pSGZf5mpbZCawZun8KsGuejiVJmmC+wv3zwNokpyZ5OnAesGWejiVJmmBepmWq6skkFwOfAo4Crqyqe6fZbfM025cyx2Zyjs3kHJvRlsS4pKqm7yVJOqL49QOS1CHDXZI6tCjCvdevKkhyZZI9Se4Zalue5OYkD7TbZa09Sa5oY3B3ktOH9tnQ+j+QZMNQ+79I8qW2zxVJMtUxFpMka5J8Jsm2JPcmeUtrX/Ljk+S4JLcn+WIbm99o7acmua3VfU27WIEkx7b729v2saHHuqS135/k7KH2ka+5yY6xmCQ5KskXktzQ7jsuo1TVgi4M/uD6FeD5wNOBLwLrFrquOXpuPwWcDtwz1Pa7wKa2vgn4nbZ+DvBJBp8ROBO4rbUvB77abpe19WVt2+3AS9o+nwRePdUxFtMCrAJOb+vPBP4fsM7xKVq9x7f1Y4Db2nO+Fjivtf8R8Ktt/d8Df9TWzwOuaevr2uvpWODU9jo7aqrX3GTHWEwL8B+BjwA3TFXzUhuXA8ZpwQsYvPg+NXT/EuCSha5rDp/fGE8N9/uBVW19FXB/W38fcP7EfsD5wPuG2t/X2lYB9w217+832TEW8wJcz+C7iByfp47LM4A7GXzC+2Hg6Na+/3XD4Kq0l7T1o1u/THwt7es32Wuu7TPyGItlYfCZmVuAnwFumKrmpTQuo5bFMC0z6qsKVi9QLYfDyVW1G6DdntTaJxuHqdp3jmif6hiLUvvv8osZnKE6PuyfergL2APczOCM8ltV9WTrMvx89o9B2/4ocCIHP2YnTnGMxeLdwK8B32v3p6p5KY3LARZDuE/7VQVLxGTjcLDtR5QkxwPXAW+tqsem6jqirdvxqaq9VXUagzPVM4AXjurWbudqbBb1mCV5LbCnqu4Ybh7RdUmNy2QWQ7gvta8qeCjJKoB2u6e1TzYOU7WfMqJ9qmMsKkmOYRDsH66qj7dmx2dIVX0L+EsGc+4nJNn3wcPh57N/DNr2ZwHf5ODH7OEpjrEYvAz4uSQ7GHzT7M8wOJNf6uMy0mII96X2VQVbgH1XdGxgMNe8r/2CdlXImcCjbcrgU8ArkyxrV3W8ksF8327g8SRntqtALpjwWKOOsWi0mt8PbKuqdw1tWvLjk2RlkhPa+g8ArwC2AZ8BXt+6TRybfc/n9cCnazA5vAU4r101ciqwlsEfmUe+5to+kx1jwVXVJVV1SlWNMaj501X1iyzxcZnUQk/6tz9QnMPgaomvAO9Y6Hrm8Hl9FNgNfJfBWcGFDObvbgEeaLfLW98w+IGTrwBfAtYPPc4vA9vb8uah9vXAPW2f9/D9TxyPPMZiWoCfZPBf27uBu9pyjuNTAD8KfKGNzT3Ar7f25zMIoe3AnwLHtvbj2v3tbfvzhx7rHe3530+7Wqi1j3zNTXaMxbYAZ/H9q2UclxGLXz8gSR1aDNMykqQ5ZrhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDv1/W/khD3zS7NIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evalset = HousePriceDataset(X_test_scaled, y_test)\n",
    "loader  = DataLoader(evalset, batch_size=len(X_test_scaled))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in loader: \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        \n",
    "        outputs = 0\n",
    "        for regressor in regressors:\n",
    "            regressor.eval()\n",
    "            output = regressor(features.float())\n",
    "            outputs += output\n",
    "        \n",
    "        outputs = outputs / len(models)\n",
    "        \n",
    "Ypred = outputs.cpu().numpy().squeeze()\n",
    "Yreal = labels.cpu().numpy()\n",
    "\n",
    "print(\"Loss on Testing Data:\", criterion(output, labels).item())\n",
    "\n",
    "print(\"Lets see predictions\")\n",
    "print(Ypred)\n",
    "print(Yreal)\n",
    "\n",
    "rmsle = RMSLELoss(output, labels)\n",
    "r2 = r2_score(Yreal, Ypred)\n",
    "\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Root Mean Squared Log Error:\", rmsle.item())\n",
    "\n",
    "plt.hist(Ypred)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(Yreal)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And Sklearn Baseline\n",
    "# It seems that the problem is still here \n",
    "- Even in sklearn if you run multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error Neural Network Sklearn:  0.5421149256846797\n",
      "R2 Score: -0.0008876584575641111\n",
      "[97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301 97494.1115301 97494.1115301 97494.1115301 97494.1115301\n",
      " 97494.1115301]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes = (4, 4, 4, 4, 4, 4, 4, 4, 4), max_iter = 1000)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Root Mean Squared Log Error Neural Network Sklearn: \", RMSLELoss_for_numpy(y_predict, y_test))\n",
    "\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "\n",
    "print(y_predict)\n",
    "\n",
    "plt.hist(y_predict)\n",
    "plt.title(\"Predictions Histogram\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_test)\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for improvements\n",
    "- Bayesion Optimization for neural network parameters (num_layers, num_neurons, etc.)\n",
    "- Meta-Models for the regresion part, with stacking or blending methodology\n",
    "- Other type of date preprocessing and feature extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
